# Report {#ch-report}

```{r, echo=FALSE}
source("_common.R")
source("_stan_options.R")
library("broom.mixed")
```

Viene qui presentato un esempio di report nel quale, usando i dati di @mehr20165, vengono replicate alcune analisi statistiche riportate dagli autori. Gli autori usano un approccio frequentista. Le stesse analisi verranno svolte anche mediante l'approccio bayesiano.

## Motivazione

Iniziamo con una breve descrizione dello studio.

Nel loro studio, @mehr20165 discutono i significati sociali della musica in età evolutiva. @mehr20165 avanzano l'ipotesi che la musica sia capace di trasmettere significati sociali anche nel caso di bambini molto piccoli. Per valutare questa ipotesi, @mehr20165 esaminano un campione di 32 bambini di età media pari a 5.6 mesi (SD = 0.31, gamma di variazione: 5.1--6.1). Nel primo esperimento, @mehr20165 si chiedono se la familiarità con una melodia possa modulare una preferenza sociale, ovvero possa influenzare i tempi di fissazione dello sguardo (*looking-time*) che i bambini dirigono verso un adulto estraeneo il quale, cantando, produce o una melodia conosciuta (prodotta in precedenza dai genitori) o una melodia sconosciuta.

Nella prima fase dell'esperimento, ai genitori dei bambini veniva chiesto di imparare una nuova ninna-nanna e di ripeterla spesso al figlio/a. Nella seconda fase dell'esperimento (test), ai bambini venivano presentati due video, uno di fianco all'altro.  Uno dei due video faceva vedere un adulto sconosciuto al bambino che cantava la melodia che, in precedenza, i genitori avevano presentato ai bambini; l'altro video faceva vedere uno sconosciuto che cantava una ninna-nanna non precedentemente presentata ai bambini.

@mehr20165 hanno ipotizzato che i bambini avrebbero preferito l'adulto sconosciuto che cantava la melodia familiare allo sconosciuto che cantava una melodia non familiare.

Per operazionalizzare la preferenza, nello studio quale variabile dipendente veniva considerato il tempo di fissazione dello sguardo del bambino.

Nelle prove baseline (16 s ciascuna), ai bambini sono stati presentati due video che facevano vedere gli stessi due adulti che, nella fase test, cantavano le due melodie; in questo caso, però gli attori non cantavano ma si limitavano a sorridere.

Mediante una prima analisi statistica gli autori hanno verificato che i bambini non dimostravano una specifica preferenza per uno dei due sconosciuti, quando questi non cantavano.

In una seconda analisi statistica, gli autori si sono chiesti se i tempi di fissazione dello sguardo fossero maggiori quando lo sconosciuto cantava la ninna-nanna familiare piuttosto che quella non familiare. L'analisi statistica eseguita dagli autori a questo proposito è un test $t$ di Student. Gli autori riportano un valore della statistica test $t_{31} = 2.96$, un $p$-valore di 0.06 e un intervallo di confidenza al 95% pari a [0.529, 0.658]. La dimensione dell'effetto, misurata con un $d$ di Cohen, è pari a 0.52.

Lo scopo del presente esercizio è quello di replicare questi risultati utilizzando i dati resi disponibili dagli autori. L'analisi statistica riportata sopra verrà qui eseguita usando due diversi metodi statistici: l'approccio frequentista e l'approccio bayesiano.

## Analisi dei dati

Per replicare i risultati riportati da @mehr20165, iniziamo a leggere in $\mathsf{R}$ i dati contenuti nel file ```MehrSongSpelke_exp_1.csv```. Questo risultato si ottiene utilizzando la funzione ```import()``` contenuta nel pacchetto ```rio```. 

```{r}
mehr <- rio::import(here::here("data", "MehrSongSpelke_exp_1.csv"))
```

I nomi delle colonne di ```mehr``` vengono restituiti usando la funzione ```names()``` che prende come argomento il nome del data.frame:

```{r eval=FALSE}
names(mehr)
```

Possiamo selezionare i dati del primo esperimento nel modo seguente.

```{r}
df_exp1 <- mehr %>% 
  dplyr::filter(exp1 == 1)
```

L'istruzione precedente dice che l'oggetto ```mehr``` (che è un data.frame) viene passato alla funzione ```filter()``` contenuta nel pacchetto ```dplyr```. L'argomento passato a ```filter()``` istruisce $\mathsf{R}$ a selezionare unicamente le righe di ```mehr``` nelle quali la colonna ```exp``` assume il valore 1.  Il sottoinsieme delle righe selezionate corrisponde alle osservazioni che fanno parte del primo esperimento. L'operatore di attribuzione ```<-``` assegna al risultato che abbiamo ottenuto (ovvero, ai dati del primo esperimento) il nome ```df_exp1```.

La variabile ```Test_Proportion_Gaze_to_Singer``` è la variabile dipendente del primo esperimento. Esaminiamola mediante un istogramma.

```{r}
tibble(y = df_exp1$Test_Proportion_Gaze_to_Singer) %>% 
ggplot(aes(y)) +
  geom_histogram()
```

Più utile risulta usare una stima della densità della frequenza dei dati.

```{r}
tibble(y = df_exp1$Test_Proportion_Gaze_to_Singer) %>% 
ggplot(aes(y)) +
  geom_density()
```

Media e deviazione standard delle proporzioni del tempo passato dai bambini a fissare la faccia della persona target, rispetto al tempo di fissazione complessivo, si ottengono nel modo seguente:

```{r}
df_exp1 %>% 
  summarise(
    p = mean(Test_Proportion_Gaze_to_Singer),
    std = sd(Test_Proportion_Gaze_to_Singer)
  )
```

Il valore di 0.59 indica che i bambini preferiscono fissare l'adulto sconosciuto che canta la melodia familiare, piuttosto che l'adulto sconosciuto che canta una melodia non familiare, come ipotizzato dagli autori. Lo scopo dell'analisi statistica è quello di stabilire se tale discrepanza dal 50% (assenza di preferenza) può essere considerata come un risultato "robusto", oppure se debba essere attribuita alla variabilità campionaria.

## Approccio frequentista

Replichiamo qui sotto l'analisi statistica svolta dagli autori.

### Test $t$ di Student per un solo campione

Gli autori usano l'approccio frequentista per fare inferenza su $\mu$, ovvero sulla proporzione media del tempo complessivo di fissazione dello sguardo verso lo sconosciuto che cantava la melodia familiare, rispetto al tempo di fissazione complessivo (che include le fissazioni verso lo sconosciuto che cantava la ninna-nanna ignota). 

Nel caso presente, l'ipotesi nulla è 

$$
H_0: \mu = 0.5.
$$

L'ipotesi nulla ci dice che, se i bambini non dimostrano alcuna preferenza allora, *nella popolazione*, la variabile ```Test_Proportion_Gaze_to_Singer``` dovrebbe assumere il valore 0.5. 

Contrapposta all'ipotesi nulla è l'ipotesi alternativa, ovvero l'ipotesi che i bambini dimostrino un qualche tipo di preferenza. Ci sono due possibilità. Se i bambini preferiscono la melodia familiare, *nella popolazione* il valore medio di ```Test_Proportion_Gaze_to_Singer``` dovrebbe essere maggiore di 0.5; se i bambini preferiscono la melodia sconosciuta, *nella popolazione* il valore medio di ```Test_Proportion_Gaze_to_Singer``` dovrebbe essere minore di 0.5. 

Iniziamo ad esaminare la distribuzione dei dati. Il test statistico utilizzato dagli autori è il test $t$ di Student. Questo test può essere usato *solo se* i dati del campione provengono da una distribuzione normale. Per stabilire se sia sensato assumere che i dati seguono la distribuzione gaussiana, esaminiamo il diagramma quantile-quantile.

```{r}
tibble(y = df_exp1$Test_Proportion_Gaze_to_Singer) %>% 
  ggplot(aes(sample = y)) +
  stat_qq() + 
  stat_qq_line()
```

Il diagramma quantile-quantile indica che è ragionevole assumere che, nella popolazione, i dati seguano la legge Normale.

Dato che l'assunzione di gaussianità è ragionevole, procediamo con il $t$ test.
La proporzione del looking-time diretta allo sconosciuto che canta la melodia familiare è

```{r}
m <- mean(df_exp1$Test_Proportion_Gaze_to_Singer)
m
```

pari a `r round(m, 2)`. 

Questo valore è stato trovato usando la funzione ```mean()```. L'argomento passato a ```mean()``` è il vettore dei valori numerici che descrivono, per ciascun bambino, la proporzione del looking-time diretta verso lo sconosciuto che canta la melodia familiare. La sintassi ```$``` viene utilizzata per estrarre dal DataFrame ```df_exp1``` la colonna  ```Test_Proportion_Gaze_to_Singer```. 

L'errore standard della media è 

$$
\sigma_{\bar{y}} = \frac{\sigma}{\sqrt{n}}.
$$

Una stima dell'errore standard si ottiene utilizzando la deviazione standard del campione al posto di $\sigma$.

```{r}
se <- sd(df_exp1$Test_Proportion_Gaze_to_Singer) / sqrt(length(df_exp1$Test_Proportion_Gaze_to_Singer))
se
```

Nell'istruzione precedente, la funzione ```length()``` ritorna il numero di elementi di un vettore ovvero, nel nostro caso, l'ampiezza del campione.

### Test di ipotesi

La statistica test $T$ non è altro che il valore standardizzato della media campionaria all'interno della distribuzione campionaria delle medie dei campioni di ampiezza $n$. Standardizzare significa sottrarre la media della distribuzione e dividere per la deviazione standard della distribuzione. Nel caso presente, la distribuzione è la distribuzione di tutte le possibili medie di campioni di ampiezza $n$ che possono essere estratti dalla popolazione. In precedenza abbiamo visto che la distribuzione campionaria delle medie dei campioni ha una media, $\mu_{\bar{Y}}$,uguale alla media della popolazione, $\mu$. La deviazione standard delle medie dei campioni di ampiezza $n$, $\sigma_{\bar{Y}}$, è uguale alla deviazione standard della popolazione divisa per la radice quadrata di $n$, $\frac{\sigma}{\sqrt{n}}$.

Per standardizzare la media campionaria 0.59 è dunque necessario conoscere 

- la media della popolazione delle medie (proporzioni) del looking-time di tutti i possibili bambini di 5.6 anni che potrebbero partecipare all'esperimento di @mehr20165;
- la deviazione standard della popolazione delle medie (proporzioni) del looking-time di tutti i possibili bambini di 5.6 anni che potrebbero partecipare all'esperimento di @mehr20165.

Si noti che @mehr20165 trattano la proporzione del looking-time come se fosse una media. 

Ovviamente questi due parametri sono sconosciuti. L'approccio frequentista risolve questo problema nel modo seguente. 

- Anziché usare $\sigma$, che è ignoto, viene usata una stima di $\sigma$ che viene fornita dalla deviazione standard del campione.
- Anziché usare $\mu$, che è ignoto, viene usato il valore che l'ipotesi nulla assegna a questo parametro.

Si utilizza per $\mu$ il valore ipotizzato dall'ipotesi nulla perché l'approccio frequentista svolge un ragionamento contro-fattuale, ovvero si chiede quale sia la probabilità di osservare il risultato osservato (o uno ancora più estremo), *se l'ipotesi nulla fosse vera*. Se tale probabilità è piccola, ovvero se l'ipotesi nulla produce delle previsioni molto diverse dal risultato effettivamente osservato, allora il ricercatore rifiuta l'ipotesi nulla.

Standardizziamo dunque la media del campione *assumendo vera* $H_0$, ovvero ipotizzando che $\mu = 0.5$.

$$
T = \frac{\bar{Y} - \mu_0}{\hat{\sigma}_{\bar{Y}}} = \frac{0.59 - 0.50}{0.032} = 2.96
$$

Ovvero

```{r}
T <- (m - 0.5) / se
T
```

Dato che $\sigma$ viene stimato da $s$, i valori standardizzati della media del campione non si distribuiscono secondo la legge Normale, ma seguono la distribuzione $t$ di Student con $n-1$ gradi di libertà. Questa affermazione viene dimostrata dall'approccio frequentista utilizzando alcuni teoremi -- è facile trovare questa dimostrazione nei testi introduttivi di statistica.

Dobbiamo dunque valutare la statistica $T = 2.96$ in riferimento alla distribuzione $t$ di Student con 31 gradi di libertà.

```{r}
dof <- length(df_exp1$Test_Proportion_Gaze_to_Singer) - 1
dof
```

Per chiarire, la figura qui sotto riporta la distribuzione $t$ di Student con 31 gradi di libertà.

```{r}
ggplot(
  data.frame(x = c(-4, 4)), 
  aes(x)
  ) +
  stat_function(fun = dt, args = list(df = 31), geom = "line") +
  labs(
    x = "x",
    y = "Densità"
  )
```

La densità $t_{31}$ descrive la distribuzione campionaria *standardizzata* delle medie di campioni di ampiezza $n=31$. La standardizzazione è stata ottenuta 

- usando $s$ al posto di $\sigma$,
- assumendo $\mu = 0.5$, così come ipotizzato da $H_0$.

In base a questa ipotetica distribuzione campionaria standardizzata delle medie di campioni di ampiezza 31, il valore atteso della media standardizzata, chiamata *statistica T*, è uguale a 0. Tanto più lontani da 0, in valore assoluto, sono i valori della statistica $T$ osservata nel campione esaminato, tanto più discrepanti sono i valori osservati rispetto a ciò che predice l'ipotesi nulla.

Il test di ipotesi frequentista si chiede: se costruiamo la distribuzione campionaria standardizzata delle medie di campioni di ampiezza $n=31$ come indicato sopra, ovvero assumendo vera $H_0$, qual è la *probabilità* di ottenere un risultato come quello ottenuto nel campione, o più estremo?

La probabilità cercata, che si chiama valore-$p$, è indicata dalle due aree evidenziate della figura seguente.

```{r}
critical_t <- 2.96
ggplot(data.frame(x = c(-4, 4)), aes(x)) +
  stat_function(fun = dt,
                geom = "line",
                args = list(df = 31)
                ) +
  stat_function(fun = dt,
                geom = "area",
                fill = "steelblue",
                xlim = c(critical_t, 4),
                args = list(df = 31)
                ) +
  stat_function(fun = dt,
                geom = "area",
                fill = "steelblue",
                xlim = c(-4, -critical_t),
                args = list(df = 31)
                )
```

Il valore-$p$ si trova dunque nel modo seguente.

```{r}
round(2 * (1 - pt(T, dof)), 3)
```

Nell'istruzione precedente abbiamo calcolato l'area sottesa alla distribuzione $t_{31}$ nell'intervallo $[-\infty, -2.960]$ e nell'intervallo $[2.960, \infty]$.

Dato che il valore-$p$ è *minore* del valore $\alpha = 0.05$ convenzionalmente usato quale soglia di riferimento, gli autori concludono *rigettando* l'ipotesi nulla e concludendo che il risultato ottenuto è *statisticamente significativo*. In altre parole, il valore di 0.59 è sufficientemente lontano da 0.50 da potere concludere che i bambini mostrano effettivamente una preferenza verso l'adulto che canta una ninna-nanna familiare piuttosto che verso un adulto che canta una ninna-nanna non familiare. In altre parole ancora, non crediamo che la differenza tra 0.59 e 0.50 possa essere spiegata come una semplice fluttuazione dei dati attribuibile alla variabilità campionaria.

È facile trovare il risultato precedente usando la funzione ```t.test()```:

```{r}
t.test(df_exp1$Test_Proportion_Gaze_to_Singer, mu = 0.5)
```

### Intervallo di fiducia

L'intervallo di fiducia si calcola come

$$
\text{stima del parametro} \pm t \times \text{errore standard}.
$$

Nel caso presente, l'intervallo di fiducia al livello di confidenza del 95% è dato da

```{r}
round(m + c(-1, 1) * qt(0.975, dof) * se, 3)
```

Tale risultato riproduce quello di `t.test()` e quello riportato da @mehr20165.

### La dimensione dell'effetto

Una stima della dimensione dell'effetto si ottiene dal rapporto tra la differenza tra le medie e la deviazione standard. Nel caso presente, ci interessa la differenza tra la media (che è una proporzione) osservata nel campione (0.59) e la media ipotizzata da $H_0$ (0.5). L'unità di misura di tale differenza tra medie viene fornita dall'errore standard.

```{r}
round(
  (m - 0.5) / sd(df_exp1$Test_Proportion_Gaze_to_Singer),
  3
)
```

Anche il $d$ di Cohen così calcolato coincide con il valore riportato dagli autori. Essendo il valore trovato maggiore di 0.5, possiamo dire che la dimensione dell'effetto è "media". 


## Analisi Bayesiana

Facciamo ora inferenza su $\mu$ usando l'approccio bayesiano. 

Considereremo $y$, ovvero `df_exp1$Test_Proportion_Gaze_to_Singer`, come una variabile continua per la quale è sensato assumere un meccanismo generatore dei dati gaussiano di media e deviazione standard ignote (così come hanno fatto gli autori). L'inferenza riguarda il parametro $\mu$, ovvero la media della popolazione da cui sono stati estratti i dati.

### Modello in linguaggio Stan

Scriviamo il modello Stan seguendo le indicazioni fornite nella dispensa. Il modello verrà salvato nella cartella `code` con il nome `normalmodel.stan`:

```{r}
modelString = "
data {
  int<lower=0> N;
  vector[N] y;
}
parameters {
  real mu;
  real<lower=0> sigma;
}
model {
  mu ~ normal(0.0, 2.0);
  sigma ~ cauchy(0, 5.0);
  y ~ normal(mu, sigma);
}
"
writeLines(modelString, con = "code/normalmodel.stan")
```

Sistemiamo i dati nel formato appropriato per Stan:

```{r}
data_list <- list(
  N = length(df_exp1$Test_Proportion_Gaze_to_Singer),
  y = df_exp1$Test_Proportion_Gaze_to_Singer
)
data_list
```

Leggiamo il file in cui abbiamo salvato il codice Stan

```{r}
file <- file.path("code", "normalmodel.stan")
```

compiliamo il modello

```{r}
mod <- cmdstan_model(file)
```

Eseguiamo il campionamento MCMC.

```{r, results='hide'}
fit <- mod$sample(
  data = data_list,
  iter_sampling = 10000L,
  iter_warmup = 5000L,
  seed = 123,
  chains = 4L,
  refresh = 0
)
```

La convergenza e il "mixing" del campionamanto MCMC possono essere controllate mediante il _trace plot_ che mostra l'andamento delle simulazioni e ci dice se stiamo effettivamente utilizzando una distribuzione limite:

```{r}
stanfit <- rstan::read_stan_csv(fit$output_files())
stanfit %>% 
  mcmc_trace(pars = c("mu", "sigma"), size = 0.1)
```

La stima della distribuzione a posteriori per $\mu$ per ciascuna delle quattro catene usate può essere rappresentata graficamente nel modo seguente:

```{r}
mcmc_dens_overlay(stanfit, pars = "mu") + 
  ylab("density")
```

Stampiamo la statistica $\hat{R}$:

```{r}
bayesplot::rhat(stanfit, pars = c("mu", "sigma"))
```

Utilizzando l'oggetto `stanfit`, possiamo recuperare la statistica di Geweke nel modo seguente:

```{r}
fit_mcmc <- As.mcmc.list(
  stanfit,
  pars = c("mu", "sigma")
)
coda::geweke.diag(fit_mcmc, frac1 = .1, frac2 = .5) 
```

La statistica di Geweke è uguale a zero quando le medie delle due porzioni della  catena di Markov sono uguali. Valori maggiori di $\mid 2 \mid$ suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria.

Dopo avere trasformato l'oggetto `fit` nel formato `stanfit`, le stime a posteriori dei parametri si ottengono con

```{r}
s <- summary(
  stanfit, 
  c("mu", "sigma"), 
  probs = c(0.025, 0.50, 0.975)
  )
s$summary  
```

I risultati replicano quelli precedenti.

Modifichiamo ora il modello in due modi: ipotizziamo un meccanismo generativo $t$ di Student e inseriamo una distribuzione a priori più sensata per il parametro $\mu$. Essendo $\mu$ una proporzione, può solo assumere valori compresi tra 0 e 1. Pertanto, quale distribuzione a priori, userò qui una distribuzione Beta. Nel codice seguente ho anche aggiunto il blocco `generated quantities` per potere poi esaminare i *posterior predictive checks*.

```{r}
modelString = "
data {
  int<lower=0> N;
  vector[N] y;
}
parameters {
  real mu;
  real<lower=0> sigma;
  real<lower=0> nu;
}
model {
  mu ~ beta(2, 2);
  sigma ~ cauchy(0.0, 5.0);
  nu ~ gamma(2, 0.1);
  y ~ student_t(nu, mu, sigma);
}
generated quantities {
  vector[N] y_rep;
  for (i in 1 : N) {
    y_rep[i] = student_t_rng(nu, mu, sigma);
  }
}

"
writeLines(modelString, con = "code/modelt.stan")
```

Leggo il file in cui ho salvato il codice Stan.

```{r}
file2 <- file.path("code", "modelt.stan")
```

Compilo il modello.

```{r}
mod2 <- cmdstan_model(file2)
```

Eseguo il campionamento MCMC.

```{r, results='hide'}
fit2 <- mod2$sample(
  data = data_list,
  iter_sampling = 10000L,
  iter_warmup = 5000L,
  seed = 123,
  chains = 4L,
  refresh = 0
)
```

Trasformo `fit2` in formato `stanfit`.

```{r}
stanfit2 <- rstan::read_stan_csv(fit2$output_files())
```

Le stime a posteriori dei parametri si ottengono nel modo seguente.

```{r}
s <- summary(
  stanfit2, 
  c("mu", "sigma"), 
  probs = c(0.025, 0.50, 0.975),
  use_cache = TRUE
  )
s$summary  
```

I risultati sono molto simili a quelli trovati in precedenza. 

Genero il PPC. Inizio a estrarre i dati previsti futuri.

```{r}
y_rep <- as.matrix(stanfit2, pars = "y_rep")
dim(y_rep)
```

Creo un diagramma il quale presente insieme la distribuzione dei dati osservati e la distribuzione di 200 campioni casuali di dati previsti futuri che sono stati generati in base al modello utilizzato.

```{r}
ppc_dens_overlay(data_list$y, y_rep[1:200, ])
```

C'è una buona corrispondenza tra i dati osservati e i dati generati dal modello. Pertanto concludiamo che il modello è adeguato per i dati in esame.

Possiamo dunque concludere, con un grado di certezza soggettiva del 95%, che la proporzione del tempo complessivo di fissazione dello sguardo verso lo sconosciuto che cantava la ninnna-nanna familiare, piuttosto che verso lo sconosciuto che cantava una canzone ignota, è compresa nell'intervallo [`r round(s$summary[1, 4], 3)`, `r round(s$summary[1, 6], 3)`].

## Confronto tra due gruppi

### Approccio frequentista 

In un'altra delle analisi statistiche svolte da @mehr20165, i ricercatori hanno confrontato il tempo di fissazione dello sguardo verso lo sconosciuto che sorride soltanto e lo sconosciuto che canta la ninna-nanna familiare.  Questo è un esempio di misure ripetute, ovvero di dati appaiati.  Lo stesso bambino viene esaminato in due condizioni diverse. Nella prima condizione deve scegliere tra un adulto sconosciuto che mantiene un'espressione neutra e un adulto sconosciuto che sorride. Nella seconda condizione deve scegliere tra un adulto sconosciuto che canta una ninna-nanna familiare e un adulto sconosciuto che canta una ninna-nanna non familiare. 

Questo confronto lo scopo seguente.  Se non c'è differenza tra le due condizioni, si può concludere che il comportamento dei bambini si può attribuire ad una generica preferenza per ciò che è piacevole (il sorriso o una melodia familiare), ma non ha nulla a che fare con uno specifico significato sociale delle melodie conosciute per i bambini di questa fascia d'età.  Se invece si trova differenza tra le due condizioni, nel senso che la preferenza per la ninna-nanna conosciuta è maggiore della preferenza per il sorriso, allora ci sono evidenze più forti che le melodie conosciute sono particolarmente importanti, e hanno un significato sociale, per i bambini di questa fascia d'età.

La distribuzione delle proporzioni dei tempi di fissazione dello sguardo nelle due condizioni è presentata nel pannello nella Figura 2a dell'articolo di @mehr20165. Riproduciamo questa figura. 

I tempi di fissazione dello sguardo nelle condizioni baseline e test corrispondono, rispettivamente, alle variabili ```Baseline_Proportion_Gaze_to_Singer``` e ```Test_Proportion_Gaze_to_Singer```. 

Per replicare la Figura 2a dobbiamo sistemare i dati nel formato ``long'', ovvero nel formato in cui a ciascuna colonna del DataFrame corrisponde una variabile. Nel caso presente, una variabile verrà chiamata *condizione*, con modalità *baseline* e *test*, mentre una seconda variabile, *y*, riporta i tempi di fissazione dello sguardo. Per creare un DataFrame che contiene queste due variabili, procediamo come segue.

```{r}
condizione <- factor(
  rep(
    c("baseline", "test"), 
    each = length(df_exp1$Baseline_Proportion_Gaze_to_Singer)
    )
  )
y <- c(df_exp1$Baseline_Proportion_Gaze_to_Singer, df_exp1$Test_Proportion_Gaze_to_Singer)
df2 <- data.frame(condizione, y)
head(df2)
dim(df2)
```

Il boxplotot si crea con le seguenti istruzioni:

```{r}
p <- df2 %>%
  ggplot(aes(x = condizione, y = y, fill = condizione)) +
  geom_boxplot(alpha = 0.7) +
  scale_y_continuous(
    name = "Proporzione di fissazioni verso il \ncantante di canzone familiare"
  ) +
  scale_x_discrete(name = "Condizione") +
  theme(legend.position = "none") +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  stat_summary(
    fun.y = mean, colour = "darkred", geom = "point",
    shape = 18, size = 6
  )
p
```

Un confronto tra le due condizioni viene effettuato dagli autori con un test $t$ di Student per campioni appaiati. Ciò che è di interesse nei dati è la *differenza* nella proporzione di looking-time nelle due condizioni.  Calcoliamo dunque questa differenza.

```{r}
diff <- df_exp1$Test_Proportion_Gaze_to_Singer - df_exp1$Baseline_Proportion_Gaze_to_Singer
diff
```

Iniziamo con il verificare la gaussianità dei dati.

```{r}
tibble(y = diff) %>% 
  ggplot(aes(sample = y)) +
  stat_qq() + 
  stat_qq_line()
```

Il diagramma quantile-quantile suggerisce che l'ipotesi di Normalità è sensata.

Calcolo la media delle differenze delle proporzioni looking-time nelle due condizioni.

```{r}
m <- mean(diff)
m
```

L'errore standard delle differenze è il seguente.

```{r}
se <- sd(diff) / sqrt(length(diff))
se
```

La statistica $T$ si calcola nel modo seguente.

```{r}
T <- (m - 0) / se
T
```

I gradi di libertà sono sempre uguali a 31.

```{r}
nu <- length(diff) - 1
nu
```

Calcolo il valore-$p$.

```{r}
2 * (1 - pt(T, nu))
```

Usando `t.test()` otteniamo lo stesso risulato.

```{r}
t.test(diff, mu = 0)
```

Questi risultati replicano ciò che è riportato dagli autori: $t_{31}$ = 2.42, $p$ = 0.022.

L'intervallo di confidenza si trova nel modo seguente.

```{r}
mean(diff) + c(-1, 1) * qt(.975, nu) * se
```

Si noti che tali valori riproducono quelli trovati dalla funzione `t.test()`.

La dimensione dell'effetto è pari a $d$ = 0.43.

```{r}
d <- mean(diff) / sd(diff)
d
```

Le stime dell'intervallo di confidenza e la dimensione dell'effetto coincidono con i valori riportati da @mehr20165.

### Analisi bayesiana

Anche in questo caso possiamo ripetere l'analisi usando un approccio bayesiano. L'analisi statistica è sostanzialmente identica a quella già descritta sopra. In questo caso, però, la variabile dipendente è `diff`. Sistemiamo dunque i dati nel formato appropriato per Stan.

```{r}
data2_list <- list(
  N = length(diff),
  y = diff
)
data2_list
```

Usiamo nuovamente il modello `modelt.stan` che abbiamo già compilato in precedenza ed eseguiamo il campionamento MCMC.

```{r, results='hide'}
fit3 <- mod2$sample(
  data = data2_list,
  iter_sampling = 10000L,
  iter_warmup = 5000L,
  seed = 123,
  chains = 4L,
  refresh = 0
)
```

Trasformiamo `fit3` in formato `stanfit`.

```{r}
stanfit3 <- rstan::read_stan_csv(fit3$output_files())
```

Esaminiamo le stime a posteriori dei parametri.

```{r}
s <- summary(
  stanfit3, 
  c("mu", "sigma"), 
  probs = c(0.025, 0.50, 0.975)
  )
s$summary  
```

I risultati sono molto simili ai precedenti. L'intervallo di credibilità al 95% non include lo 0. Possiamo dunque concludere che c'è una "credibile" differenza nel looking-time misurato nelle due condizioni.

Dall'output precedente possiamo ottenere una stima della dimensione dell'effetto:

```{r}
s$summary[1, 1]	/	s$summary[2, 1]
```

Anche in questo caso, il risultato è simile a quello ottenuto con l'approccio frequentista, anche se non identico.

## Conclusioni

@mehr20165 riportano che i bambini di cinque mesi dirigono in modo preferenziale la propria attenzione verso un adulto sconosciuto che canta una ninna-nanna familiare piuttosto che verso un adulto sconosciuto che canta una ninna-nanna non familiare. Questi risultati sono stati trovati quando la familiarizzazione con la ninna-nanna veniva creata mediante l'interazione tra il bambino e un adulto che faceva parte del suo ambiente domestico. L'attenzione dei bambini, invece, non veniva modulata dalla familiarità della ninna-nanna se familiarità sorgeva come esposizione precedente con un adulto che non faceva parte dell'ambiente domestico del bambino. In base a tali risultati, @mehr20165 concludono che le melodie prodotte nell'ambiente domestico, attraverso l'interazione tra il bambino e un adulto conosciuto, sono dotate di un particolare significato sociale per i bambini.



