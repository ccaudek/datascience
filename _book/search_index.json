[["index.html", "Data Science per psicologi Prefazione La psicologia e la Data science Come studiare Sviluppare un metodo di studio efficace", " Data Science per psicologi Corrado Caudek 2022-04-22 Prefazione Data Science per psicologi contiene il materiale delle lezioni dell’insegnamento di Psicometria B000286 (A.A. 2021/2022) rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze. Psicometria si propone di fornire agli studenti un’introduzione all’analisi dei dati in psicologia. Le conoscenze/competenze che verranno sviluppate in questo insegnamento sono quelle della Data science, ovvero un insieme di conoscenze/competenze che si pongono all’intersezione tra statistica (ovvero, richiedono la capacità di comprendere teoremi statistici) e informatica (ovvero, richiedono la capacità di sapere utilizzare un software). La psicologia e la Data science Sembra sensato spendere due parole su un tema che è importante per gli studenti: quello indicato dal titolo di questo Capitolo. È ovvio che agli studenti di psicologia la statistica non piace. Se piacesse, forse studierebbero Data science e non psicologia; ma non lo fanno. Di conseguenza, gli studenti di psicologia si chiedono: “perché dobbiamo perdere tanto tempo a studiare queste cose quando in realtà quello che ci interessa è tutt’altro?” Questa è una bella domanda. C’è una ragione molto semplice che dovrebbe farci capire perché la Data science è così importante per la psicologia. Infatti, a ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia gli individui ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, in certi casi, predire. In questo senso, la psicologia è molto diversa dall’ingegneria, per esempio. Le proprietà di un determinato ponte sotto certe condizioni, ad esempio, sono molto simili a quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non può dirsi degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l’oggetto di studio proprio della psicologia: è dunque chiaro che i problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri. Questa è la ragione per cui abbiamo tanto bisogno della Data science in psicologia: perché la Data science ci consente di descrivere la variazione e il cambiamento. E queste sono appunto le caratteristiche di base dei fenomeni psicologici. Sono sicuro che, leggendo queste righe, a molti studenti sarà venuta in mente la seguente domanda: perché non chiediamo a qualche esperto di fare il “lavoro sporco” (ovvero le analisi statistiche) per noi, mentre noi (gli psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli “tecnici” della Data science? La risposta a questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della Data science. Le tematiche della Data science non possono essere ignorate né dai ricercatori in psicologia né da coloro che svolgono la professione di psicologo al di fuori dell’Università. Infatti, anche i professionisti al di fuori dall’università non possono fare a meno di leggere la letteratura psicologica più recente: il continuo aggiornamento delle conoscenze è infatti richiesto dalla deontologia della professione. Ma per potere fare questo è necessario conoscere un bel po’ di Data science! Basta aprire a caso una rivista specialistica di psicologia per rendersi conto di quanto ciò sia vero: gli articoli che riportano i risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. E la comprensione della letteratura psicologica rappresenta un requisito minimo nel bagaglio professionale dello psicologo. Le considerazioni precedenti cercano di chiarire il seguente punto: la Data science non è qualcosa da studiare a malincuore, in un singolo insegnamento universitario, per poi poterla tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano gli strumenti della Data science in tantissimi ambiti della loro attività professionale: in particolare quando costruiscono, somministrano e interpretano i test psicometrici. È dunque chiaro che possedere delle solide basi di Data science è un tassello imprescindibile del bagaglio professionale dello psicologo. In questo insegnamento verrano trattati i temi base della Data science e verrà adottato un punto di vista bayesiano, che corrisponde all’approccio più recente e sempre più diffuso in psicologia. Come studiare Il giusto metodo di studio per prepararsi all’esame di Psicometria è quello di seguire attivamente le lezioni, assimilare i concetti via via che essi vengono presentati e verificare in autonomia le procedure presentate a lezione. Incoraggio gli studenti a farmi domande per chiarire ciò che non è stato capito appieno. Incoraggio gli studenti a utilizzare i forum attivi su Moodle e, soprattutto, a svolgere gli esercizi proposti su Moodle. I problemi forniti su Moodle rappresentano il livello di difficoltà richiesto per superare l’esame e consentono allo studente di comprendere se le competenze sviluppate fino a quel punto sono sufficienti rispetto alle richieste dell’esame. La prima fase dello studio, che è sicuramente individuale, è quella in cui è necessario acquisire le conoscenze teoriche relative ai problemi che saranno presentati all’esame. La seconda fase di studio, che può essere facilitata da scambi con altri e da incontri di gruppo, porta ad acquisire la capacità di applicare le conoscenze: è necessario capire come usare un software (\\(\\textsf{R}\\)) per applicare i concetti statistici alla specifica situazione del problema che si vuole risolvere. Le due fasi non sono però separate: il saper fare molto spesso ci aiuta a capire meglio. Sviluppare un metodo di studio efficace Avendo insegnato molte volte in passato un corso introduttivo di analisi dei dati ho notato nel corso degli anni che gli studenti con l’atteggiamento mentale che descriverò qui sotto generalmente ottengono ottimi risultati. Alcuni studenti sviluppano naturalmente questo approccio allo studio, ma altri hanno bisogno di fare uno sforzo per maturarlo. Fornisco qui sotto una breve descrizione del “metodo di studio” che, nella mia esperienza, è il più efficace per affrontare le richieste di questo insegnamento. Dedicate un tempo sufficiente al materiale di base, apparentemente facile; assicuratevi di averlo capito bene. Cercate le lacune nella vostra comprensione. Leggere presentazioni diverse dello stesso materiale (in libri o articoli diversi) può fornire nuove intuizioni. Gli errori che facciamo sono i nostri migliori maestri. Istintivamente cerchiamo di dimenticare subito i nostri errori. Ma il miglior modo di imparare è apprendere dagli errori che commettiamo. In questo senso, una soluzione corretta è meno utile di una soluzione sbagliata. Quando commettiamo un errore questo ci fornisce un’informazione importante: ci fa capire qual è il materiale di studio sul quale dobbiamo ritornare e che dobbiamo capire meglio. C’è ovviamente un aspetto “psicologico” nello studio. Quando un esercizio o problema ci sembra incomprensibile, la cosa migliore da fare è dire: “mi arrendo”, “non ho idea di cosa fare!”. Questo ci rilassa: ci siamo già arresi, quindi non abbiamo niente da perdere, non dobbiamo più preoccuparci. Ma non dobbiamo fermarci qui. Le cose “migliori” che faccio (se ci sono) le faccio quando non ho voglia di lavorare. Alle volte, quando c’è qualcosa che non so fare e non ho idea di come affontare, mi dico: “oggi non ho proprio voglia di fare fatica”, non ho voglia di mettermi nello stato mentale per cui “in 10 minuti devo risolvere il problema perché dopo devo fare altre cose”. Però ho voglia di divertirmi con quel problema e allora mi dedico a qualche aspetto “marginale” del problema, che so come affrontare, oppure considero l’aspetto più difficile del problema, quello che non so come risolvere, ma invece di cercare di risolverlo, guardo come altre persone hanno affrontato problemi simili, opppure lo stesso problema in un altro contesto. Non mi pongo l’obiettivo “risolvi il problema in 10 minuti”, ma invece quello di farmi un’idea “generale” del problema, o quello di capire un caso più specifico e più semplice del problema. Senza nessuna pressione. Infatti, in quel momento ho deciso di non lavorare (ovvero, di non fare fatica). Va benissimo se “parto per la tangente”, ovvero se mi metto a leggere del materiale che sembra avere poco a che fare con il problema centrale (le nostre intuizioni e la nostra curiosità solitamente ci indirizzano sulla strada giusta). Quando faccio così, molto spesso trovo la soluzione del problema che mi ero posto e, paradossalmente, la trovo in un tempo minore di quello che, in precedenza, avevo dedicato a “lavorare” al problema. Allora perché non faccio sempre così? C’è ovviamente l’aspetto dei “10 minuti” che non è sempre facile da dimenticare. Sotto pressione, possiamo solo agire in maniera automatica, ovvero possiamo solo applicare qualcosa che già sappiamo fare. Ma se dobbiamo imparare qualcosa di nuovo, la pressione è un impedimento. È utile farsi da soli delle domande sugli argomenti trattati, senza limitarsi a cercare di risolvere gli esercizi che vengono assegnati. Quando studio qualcosa mi viene in mente: “se questo è vero, allora deve succedere quest’altra cosa”. Allora verifico se questo è vero, di solito con una simulazione. Se i risultati della simulazione sono quelli che mi aspetto, allora vuol dire che ho capito. Se i risultati sono diversi da quelli che mi aspettavo, allora mi rendo conto di non avere capito e ritorno indietro a studiare con più attenzione la teoria che pensavo di avere capito – e ovviamente mi rendo conto che c’era un aspetto che avevo frainteso. Questo tipo di verifica è qualcosa che dobbiamo fare da soli, in prima persona: nessun altro può fare questo al posto nostro. Non aspettatevi di capire tutto la prima volta che incontrate un argomento nuovo.1 È utile farsi una nota mentalmente delle lacune nella vostra comprensione e tornare su di esse in seguito per carcare di colmarle. L’atteggiamento naturale, quando non capiamo i dettagli di qualcosa, è quello di pensare: “non importa, ho capito in maniera approssimativa questo punto, non devo preoccuparmi del resto”. Ma in realtà non è vero: se la nostra comprensione è superficiale, quando il problema verrà presentato in una nuova forma, non riusciremo a risolverlo. Per cui i dubbi che ci vengono quando studiamo qualcosa sono il nostro alleato più prezioso: ci dicono esattamente quali sono gli aspetti che dobbiamo approfondire per potere migliorare la nostra preparazione. È utile sviluppare una visione d’insieme degli argomenti trattati, capire l’obiettivo generale che si vuole raggiungere e avere chiaro il contributo che i vari pezzi di informazione forniscono al raggiungimento di tale obiettivo. Questa organizzazione mentale del materiale di studio facilita la comprensione. È estremamente utile creare degli schemi di ciò che si sta studiando. Non aspettate che sia io a fornirvi un riepilogo di ciò che dovete imparare: sviluppate da soli tali schemi e tali riassunti. Tutti noi dobbiamo imparare l’arte di trovare le informazioni, non solo nel caso di questo insegnamento. Quando vi trovate di fronte a qualcosa che non capite, o ottenete un oscuro messaggio di errore da un software, ricordatevi: “Google is your friend”! Corrado Caudek Marzo 2022 References "],["regr-models-intro.html", "Capitolo 1 Introduzione 1.1 La funzione lineare 1.2 Una media per ciascuna osservazione Commenti e considerazioni finali", " Capitolo 1 Introduzione Lo scopo della ricerca è trovare le associazioni tra le variabili e fare confronti fra le condizioni sperimentali. Nel caso della psicologia, il ricercatore vuole scoprire le leggi generali che descrivono le relazioni tra i costrutti psicologici e le relazioni che intercorrono tra i fenomeni psicologici e quelli non psicologici (sociali, economici, storici, …). Abbiamo già visto come la correlazione di Pearson sia uno strumento adatto a questo scopo. Infatti, essa ci informa sulla direzione e sull’intensità della relazione lineare tra due variabili. Tuttavia, la correlazione non è sufficiente, in quanto il ricercatore ha a disposizione solo i dati di un campione, mentre vorrebbe descrivere la relazione tra le variabili nella popolazione. A causa della variabilità campionaria, le proprietà dei campioni sono necessariamente diverse da quelle della popolazione: ciò che si può osservare nella popolazione potrebbe non emergere nel campione e, al contrario, il campione manifesta caratteristiche che non sono necessariamente presenti nella popolazione. È dunque necessario chiarire, dal punto di vista statistico, il legame che intercorre tra le proprietà del campione e le proprietà della popolazione da cui esso è stato estratto. Il modello lineare utilizza la funzione matematica più semplice per descrivere la relazione fra due variabili, ovvero la funzione lineare. In questo Capitolo vedremo come si possa fare inferenza sulla relazione tra due variabili mediante il modello lineare bayesiano. Inizieremo a descrivere le proprietà geometriche della funzione lineare per poi utilizzare questa semplice funzione per costruire un modello statistico secondo un approccio bayesiano. 1.1 La funzione lineare Iniziamo con un ripasso sulla funzione di lineare. Si chiama funzione lineare una funzione del tipo \\[\\begin{equation} f(x) = a + b x, \\end{equation}\\] dove \\(a\\) e \\(b\\) sono delle costanti. Il grafico di tale funzione è una retta di cui il parametro \\(b\\) è detto coefficiente angolare e il parametro \\(a\\) è detto intercetta con l’asse delle \\(y\\) [infatti, la retta interseca l’asse \\(y\\) nel punto \\((0,a)\\), se \\(b \\neq 0\\)]. Per assegnare un’interpretazione geometrica alle costanti \\(a\\) e \\(b\\) si consideri la funzione \\[\\begin{equation} y = b x. \\end{equation}\\] Tale funzione rappresenta un caso particolare, ovvero quello della proporzionalità diretta tra \\(x\\) e \\(y\\). Il caso generale della linearità \\[\\begin{equation} y = a + b x \\end{equation}\\] non fa altro che sommare una costante \\(a\\) a ciascuno dei valori \\(y = b x\\). Nella funzione lineare \\(y = a + b x\\), se \\(b\\) è positivo allora \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) è negativo allora \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\) la retta è orizzontale, ovvero \\(y\\) non muta al variare di \\(x\\). Consideriamo ora il coefficiente \\(b\\). Si consideri un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\) come indicato nella figura 1.1. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono detti incrementi di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) è uguale al rapporto \\[\\begin{equation} b = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}, \\end{equation}\\] indipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Il modo più semplice per assegnare un’interpretazione geometrica al coefficiente angolare (o pendenza) della retta è dunque quello di porre \\(\\Delta x = 1\\). In tali circostanze infatti \\(b = \\Delta y\\). FIGURA 1.1: La funzione lineare \\(y = a + bx\\). 1.2 Una media per ciascuna osservazione In precedenza abbiamo visto come sia possibile stimare i parametri di un modello bayesiano nel quale le osservazioni sono indipendenti e identicamente distribuite secondo una densità gaussiana, \\[\\begin{equation} Y_i \\stackrel{i.i.d.}{\\sim} \\mathcal{N}(\\mu, \\sigma), \\quad i = 1, \\dots, n. \\tag{1.1} \\end{equation}\\] Il modello (1.1) assume che ogni \\(Y_i\\) sia la realizzazione di una v.c. descritta da una \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Da un punto di vista bayesiano,questo modello può essere implementato assegnando le distribuzioni a priori ai parametri \\(\\mu\\) e \\(\\sigma\\) e generando la verosimiglianza in base ai dati osservati. Con queste informazioni, possono poi essere definite le distribuzioni a posteriori dei parametri (Gelman, Hill, and Vehtari 2020): \\[\\begin{align} Y_i \\mid \\mu, \\sigma &amp; \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\notag\\\\ \\mu &amp; \\sim \\mathcal{N}(\\mu_0, \\tau^2) \\notag\\\\ \\sigma &amp; \\sim \\Cauchy(x_0, \\gamma) \\notag \\end{align}\\] È però comune che vengano registrate altre variabili che possono essere associate alla risposta di interesse \\(y_i\\). Chiamiamo \\(x\\) una di tali variabili. La variabile \\(x\\) viene chiamata predittore (o variabile indipendente) in quanto il ricercatore è tipicamente interessato a predire \\(y_i\\) a partire dal valore assunto da \\(x_i\\). Come si può estende il modello (1.1) descritto in precedenza per lo studio della relazione tra \\(y_i\\) e \\(x_i\\)? Il modello (1.1) assume una media \\(\\mu\\) comune per ciascuna osservazione \\(Y_i\\). Dal momento che desideriamo introdurre una nuova variabile \\(x_i\\) che assume un diverso valore per ciascuna osservazione \\(y_i\\), il modello (1.1) può essere modificato in modo che la media comune \\(\\mu\\) venga sostituita da una media \\(\\mu_i\\) specifica a ciascuna osservazione \\(i\\)-esima: \\[\\begin{equation} Y_i \\mid \\mu_i, \\sigma \\stackrel{ind}{\\sim} \\mathcal{N}(\\mu_i, \\sigma), \\quad i = 1, \\dots, n. \\tag{1.2} \\end{equation}\\] Si noti che le osservazioni \\(Y_1, \\dots, Y_n\\) non sono più identicamente distribuite poiché hanno medie diverse, ma sono ancora indipendenti come indicato dalla notazione ind posta sopra il simbolo \\(\\sim\\) nella (1.2). 1.2.1 Relazione lineare tra la media \\(y \\mid x\\) e il predittore L’approccio che consente di mettere in relazione un predittore \\(x_i\\) con la risposta \\(Y_i\\) è quello di assumere che la media di ciascuna \\(Y_i\\), ovvero \\(\\mu_i\\), sia una funzione lineare del predittore \\(x_i\\). Una tale relazione lineare è scritta come \\[\\begin{equation} \\mu_i = \\beta_0 + \\beta_ 1 x_i, \\quad i = 1, \\dots, n. \\tag{1.3} \\end{equation}\\] Nella (1.3), ciascuna \\(x_i\\) è una costante nota (ecco perché viene usata una lettera minuscola per la \\(x\\)) e \\(\\beta_0\\) e \\(\\beta_ 1\\) sono parametri incogniti. Questi parametri rappresentano l’intercetta e la pendenza della retta di regressione e sono delle variabili casuali.2 L’inferenza bayesiana procede assegnando una distribuzione a priori a \\(\\beta_0\\) e a \\(\\beta_ 1\\) e si esegue l’inferenza riassumendo la distribuzione a posteriori di questi parametri. Nel modello (1.3), la funzione lineare \\(\\beta_0 + \\beta_ 1 x_i\\) è interpretata come il valore atteso della \\(Y_i\\) per ciascun valore \\(x_i\\), mentre l’intercetta \\(\\beta_0\\) rappresenta il valore atteso della \\(Y_i\\) quando \\(x_i = 0\\). Il parametro \\(\\beta_ 1\\) (pendenza) rappresenta invece l’aumento medio della \\(Y_i\\) quando \\(x_i\\) aumenta di un’unità. È importante notare che la relazione lineare (1.2) di parametri \\(\\beta_0\\) e \\(\\beta_ 1\\) descrive l’associazione tra la media \\(\\mu_i\\) e il predittore \\(x_i\\). In altri termini, tale relazione lineare ci fornisce una predizione sul valore medio \\(\\mu_i\\), non sul valore effettivo \\(Y_i\\). 1.2.2 Il modello lineare Sostituendo la (1.3) nella (1.2) otteniamo il modello lineare: \\[\\begin{equation} Y_i \\mid \\beta_0, \\beta_ 1, \\sigma \\stackrel{ind}{\\sim} \\mathcal{N}(\\beta_0 + \\beta_ 1 x_i, \\sigma), \\quad i = 1, \\dots, n. \\tag{1.4} \\end{equation}\\] Questo è un caso speciale del modello di campionamento Normale, dove le \\(Y_i\\) seguono indipendentemente una densità Normale con una media (\\(\\beta_0 + \\beta_ 1 x_i\\)) specifica per ciascuna osservazione e con una deviazione standard (\\(\\sigma\\)) comune a tutte le osservazioni. Poiché include un solo predittore (\\(x\\)), questo modello è comunemente chiamato modello di regressione lineare semplice. Commenti e considerazioni finali Il modello lineare semplice viene usato per descrivere la relazione tra due variabili e per determinare il segno e l’intensità di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base al valore assunto dalla variabile indipendente. References "],["regr-model-lm.html", "Capitolo 2 Il modello lineare visto da vicino 2.1 Stima dei coefficienti di regressione 2.2 Indice di determinazione Commenti e considerazioni finali", " Capitolo 2 Il modello lineare visto da vicino In questo capitolo mi pongo il problema di applicare il modello di regressione bivariata ad un campione di dati. Userò i dati kidiq. Riporto qui di seguito la descrizione di questo set di dati. Data from a survey of adult American women and their children (a subsample from the National Longitudinal Survey of Youth). Source: Gelman and Hill (2007) 434 obs. of 4 variables kid_score Child’s IQ score mom_hs Indicator for whether the mother has a high school degree mom_iq Mother’s IQ score mom_age Mother’s age Leggo i dati in \\(\\mathsf{R}\\). kidiq &lt;- rio::import(here::here( &quot;data&quot;, &quot;kidiq.dta&quot; )) glimpse(kidiq) #&gt; Rows: 434 #&gt; Columns: 5 #&gt; $ kid_score &lt;dbl&gt; 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78, 1… #&gt; $ mom_hs &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, … #&gt; $ mom_iq &lt;dbl&gt; 121.11753, 89.36188, 115.44316, 99.44964, 92.74571, 107.9018… #&gt; $ mom_work &lt;dbl&gt; 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, 3, … #&gt; $ mom_age &lt;dbl&gt; 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 24, … In questo esercizio considererò la relazione tra kid_score e mom_iq. kidiq %&gt;% ggplot(aes(x = mom_iq, y = kid_score)) + geom_point() I dati rappresentati nel diagramma a dispersione suggeriscono che, in questo campione, sembra esserci un’associazione positiva tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq). Mi pongo il problema di descrivere questa associazione mediante una relazione lineare. kidiq %&gt;% ggplot(aes(x = mom_iq, y = kid_score)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) Ci sono infinite rette che, in linea di principio, possono essere usate per “approssimare” la nube di punti nel diagramma a dispersione. È dunque necessario introdurre dei vincoli per selezionare una di queste rette. Un vincolo che viene spesso usato è quello di costringere la retta a passare per il punto \\((\\bar{x}, \\bar{y})\\). kidiq %&gt;% ggplot(aes(x = mom_iq, y = kid_score)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + geom_point( aes(x=mean(mom_iq), y=mean(kid_score)), colour=&quot;red&quot;, size = 4 ) Una retta che passa per il punto \\((\\bar{x}, \\bar{y})\\) ha la proprietà descritta di seguito. Iniziamo a descrivere ciascuna osservazione inserita nel diagramma a dispersione con un’equazione: \\[ y_i = a + b x_i + e_i \\] Le osservazioni \\(y\\) sono kid_score. I primi 10 valori sono i seguenti: kidiq$kid_score[1:10] #&gt; [1] 65 98 85 83 115 98 69 106 102 95 Per fare riferimento a ciascun valore usiamo l’indice \\(i\\). Quindi, ad esempio, \\(y_3\\) è uguale a kidiq$kid_score[3] #&gt; [1] 85 La variabile \\(x\\), nel caso presente, è mom_iq. I primi 10 valori di \\(x\\) sono kidiq$mom_iq[1:10] #&gt; [1] 121.11753 89.36188 115.44316 99.44964 92.74571 107.90184 138.89311 #&gt; [8] 125.14512 81.61953 95.07307 In maniera corrispondente alla \\(y\\), uso un indice per fare riferimento ai singoli valori della variabile. Ad esempio, \\(x_3\\) è kidiq$mom_iq[3] #&gt; [1] 115.4432 L’equazione precedente ci dice che ciascun valore \\(y\\) è dato dalla somma di due componenti: una componente deterministica e una componente aleatoria. Consideriamo il primo valore \\(y\\). Per esso diciamo che \\[ y_1 = a + b x_1 + e_1, \\] laddove \\(a + b x_1\\) è la componente deterministica, detta \\(\\hat{y}\\), e \\(e_1\\) è la componente aleatoria. La componente deterministica è, appunto, la componente di ciascun valore \\(y\\) che possiamo prevedere conoscendo \\(x\\). Non possiamo prevedere perfettamente i valori \\(y\\) – ciò si verificherebbe soltanto se tutti punti del diagramma a dispersione fossero disposti su una retta. Ma non lo sono: la retta è solo un’approssimazione della relazione (lineare) tra \\(x\\) e \\(y\\). Pertanto, conoscendo \\(x\\) possiamo solo prevedere una “componente” di ciascun valore \\(y\\). Cosa significa che possiamo prevedere una componente di ciascuna osservazione \\(y\\)? Significa che il valore \\(y\\) osservato sarà dato dalla somma di due componenti: \\(y_i = \\hat{y}_i + e_i\\). L’affermazione precedente solleva due domande: come possiamo trovare la quota della \\(y\\) che può essere predetta conoscendo \\(x\\)? quant’è grande la porzione della \\(y\\) che può essere predetta conoscendo \\(x\\)? In altre parole, conoscendo la \\(x\\) è possibile predire \\(y\\) con accuratezza oppure no? Rispondere a tali due domanda definisce i primi due obiettivi del modello statistico della regressione lineare. Il terzo obiettivo è quello dell’inferenza, ovvero di capire che relazioni ci sono tra la relazione tra \\(x\\) e \\(y\\) osservata nel campione e la la relazione tra \\(x\\) e \\(y\\) nella popolazione. 2.1 Stima dei coefficienti di regressione Iniziamo con il primo obiettivo, ovvero quello di predire una frazione di ciascuna osservazione \\(y\\) conoscendo \\(x\\). Quindi, nel caso presente, ci chiediamo quanto segue. Il primo bambino del campione ha un QI uguale a 65. Sua madre ha un QI di 121.12. Quanto bene riesco a predire il punteggio QI del bambino conoscendo quello di sua madre? È chiaro, guardando i numeri, che non c’è una corrispondenza perfetta, tutt’altro! Infatti, se guardiamo il diagramma di dispersione ci rendiamo conto che i punti sono piuttosto lontani dalla retta che abbiamo usato per descrivere la relazione tra \\(x\\) e \\(y\\). Tuttavia, il diagramma di dispersione suggerisce che una qualche relazione c’è, seppur debole. Il nostro obiettivo è di descrivere una tale relazione. Una tale relazione è descritta dalla componente deterministica che costituisce una frazione di ciascuna osservazione \\(y\\). Abbiamo deciso di definire una tale componente “deterministica” \\(\\hat{y}_i\\) nei termini della seguente equazione: \\(\\hat{y}_i = a_i + bx_i\\). L’equazione precedente è detta equazione lineare e, dal punto di vista geometrico, corrisponde ad una retta. Ci sono infinite equazioni che potremmo usare per mettere in relazione \\(x\\) e \\(y\\). Abbiamo scelto questa perché è la più semplice. Se guardiamo il diagramma di dispersione, infatti, non ci sono ragioni per descrivere la relazione tra \\(x\\) e \\(y\\) con qualche curva, anziché con una retta. In altri campioni, una curva può essere più sensata di una retta, quale descrizione della relazione media tra \\(x\\) e \\(y\\), ma non nel caso presente. Ricordiamo il principio del rasoio di Occam (ovvero, il principio che sta alla base del pensiero scientifico moderno): se un modello semplice funziona, non c’è ragione di usare un modello più complesso. Dunque, abbiamo capito che vogliamo descrivere la relazione media* tra \\(x\\) e \\(y\\) con una retta, ovvero, con l’equazione lineare \\[ \\hat{y}_i = a + b x_i. \\] L’equazione precedente indica che il modello lineare \\(a + b x_i\\) non è in grado di prevedere il valore di ciascuna osservazione \\(y_i\\). Questo, in generale, non è mai possibile (ovvero, è possibile solo in un caso specifico che, nella realtà empirica, non si verifica mai). L’equazione precedente ci dice che possiamo prevedere solo una frazione di ciascuna osservazione \\(y_i\\), ovvero quella frazione che abbiamo denotato con \\(\\hat{y}_i\\). La componente che non possiamo prevedere con l’equazione \\(a + b x_i\\) si denota con \\(e_i\\). In questo senso diciamo che scomponiamo il valore di ciascuna osservazione \\(y_i\\) in due componenti: la componente deterministica (prevedibile conoscendo \\(x\\)) e la componente aleatoria (non prevedibile conoscendo \\(x\\)): \\[ y_i = \\hat{y}_i + e_i. \\] Il primo obiettivo del modello di regressione è quello di trovare i coefficienti dell’equazione \\[ a + b x_i \\] che consente di predire \\(\\hat{y}_i\\). Questi due coefficienti sono detti coefficienti di regressione. Per trovare i coefficienti di regressione dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo vincolo lo abbiamo espresso prima: vogliamo che la retta \\(\\hat{y}_i = a + b x_i\\) passi per il punto \\((\\bar{x}, \\bar{y})\\). Il punto \\((\\bar{x}, \\bar{y})\\) corrisponde al baricentro del diagramma a dispersione. Ci sono infinite rette che passano per i punto \\((\\bar{x}, \\bar{y})\\). Tutte queste rette soddisfano la seguente proprietà. Nel caso di qualsiasi retta passante per il punto \\((\\bar{x}, \\bar{y})\\) è vero che \\[ \\sum_{i=1}^n e_i = 0. \\] Dal punto di vista geometrico, la componente erratica del modello, \\(e_i\\), corrisponde alla distanza verticale tra ciascun punto e la retta di regressione \\(a + bx\\). Tale componente va sotto il nome di residuo: \\[ e_i = y_i - \\hat{y}_i = y_i - (a + bx_i). \\] L’affermazione precedente dice che la somma di tutte le distanze verticali (che hanno un segno positivo quando il punto è sopra la retta, e un segno negativo quando il punto è sotto la retta) tra le osservazioni e la retta di regressione (passante per il punto \\((\\bar{x}, \\bar{y})\\)) è uguale a zero. Questo significa che non possiamo selezionare una tra le infinite rette che passano per il punto \\((\\bar{x}, \\bar{y})\\) usando il criterio che ci porta a scegliere la retta che rende la più piccola possibile (ovvero, minimizza) la somma dei residui. Infatti, tutte le rette passanti per il punto \\((\\bar{x}, \\bar{y})\\) rendono uguale a zero la somma dei residui. Dunque, dobbiamo trovare qualche altri criterio per scegliere tra le infinite rette che passano per il punto \\((\\bar{x}, \\bar{y})\\). Il criterio che viene normalmente scelto è quello di minimizzare la somma dei quadrati dei residui \\((y_i - \\hat{y}_i)^2\\). In altri termini, vogliamo trovare i coefficienti \\(a\\) e \\(b\\) tali per cui la quantità \\[ \\sum_{i=1}^{n}{(y_i - (a + b x_i))^2} \\] assume il suo valore minimo. I coefficienti che hanno questa proprietà si chiamano coefficienti dei minimi quadrati. Questo problema ha una soluzione analitica. La soluzione analitica si trova riconoscendo il fatto che l’equazione precedente definisce una superficie e il problema diventa quello di trovare il punto minore di questa superficie. Per trovare la soluzione ci si deve rendere conto che il punto di minimo è il punto della superficie nel quale la tangente alla superficie è piatta (ovvero uguale a zero). Rendere uguale a zero la tangente ad una superficie significa porre le derivate parziali rispetto alla direzione \\(x\\) e alla direzione \\(y\\) uguali a zero. Ponendo tali derivate parziali uguali a zero si definisce un sistema di equazioni lineari con due incognite, \\(a\\) e \\(b\\). La soluzione di tali equazioni, che si chiamano equazioni normali, è la seguente: \\[ a = \\bar{y} - b \\bar{x} \\] \\[ b = \\frac{\\mbox{Cov}(x, y)}{\\mbox{Var}(x)} \\] Le due precedenti equazioni corrispondono alla stima dei minimi quadrati dei coefficienti di regressione della retta che minimizza la somma dei quadrati dei residui. Nel caso presente, tali coefficienti sono uguali a: b &lt;- cov(kidiq$kid_score, kidiq$mom_iq) / var(kidiq$mom_iq) b #&gt; [1] 0.6099746 a &lt;- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq) a #&gt; [1] 25.79978 In R li possiamo trovare con la seguente funzione: fm &lt;- lm(kid_score ~ mom_iq, data = kidiq) coef(fm) #&gt; (Intercept) mom_iq #&gt; 25.7997778 0.6099746 In precedenza abbiamo soltanto accennato al problema di come si possono trovano i coefficienti dei minimi quadrati; ritorneremo su questo punto in seguito. Per ora, chiediamoci cosa significano i due coefficienti che abbiamo calcolato. Il coefficiente \\(a\\) si chiama intercetta. L’intercetta, all’interno del diagramma a dispersione, specifica il punto in cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani. Nel caso presente questo valore non è di alcun interesse, perché corrisponde al valore della retta di regressione quando \\(x = 0\\), ovvero quando l’intelligenza della madre è uguale a 0. Vedremo in seguito come, trasformando i dati, è possibile assegnare al coefficiente \\(a\\) un’interpretazione più utile. Per ora mi limito a fornire l’interpretazione del coefficiente. Passando a \\(b\\), possiamo dire che questo secondo coefficiente va sotto il nome di pendenza della retta di regressione. Ovvero ci dice di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso presente, il coefficiente \\(b\\) ci dice che, se il QI delle madri aumenta di 1 punto, il QI dei bambini aumenta in media di 0.61 punti. È importante capire cosa significa che, in base ai risultati della regressione, \\(y\\) aumenta in media di \\(b\\) punti per ciascun aumento unitario di \\(x\\). Il modello statistico di regressione ipotizza che, per ciascun valore osservato \\(x\\) (per esempio, il valore del QI della prima madre del campione, ovvero \\(x = 121.11753\\)) ci sia una distribuzione di valori \\(y\\) nella popolazione, di cui solo uno è stato osservato nel campione. Possiamo facilmente capire che, se consideriamo tutte le madri con QI di 121.12, il punteggio del QI dei loro figli non sia costante, ma assuma tanti valori possibili. Questa distribuzione di valori possibili si chiama distribuzione \\(y\\) condizionata a \\(x\\), ovvero \\(p(y \\mid x_i)\\). Il modello statistico della regressione lineare non può in alcun modo prevedere il valore assunto da ciascuna delle possibili osservazioni che fanno parte della distribuzione \\(p(y \\mid x_i)\\). Il modello della regressione lineare ha un obiettivo più limitato, ovvero si propone di prevedere le medie delle distribuzioni \\(p(y \\mid x_i)\\) conoscendo i valori \\(x\\). Dunque, quando il coefficiente \\(b\\) è uguale a 0.61, questo significa che il modello di regressione predice che la medie della distribuzione condizionata \\(p(y \\mid x_i)\\) aumenta di 0.61 punti se la variabile \\(x\\) (QI delle madri) aumenta di un punto. Questo significa che il modello di regressione non fa una predizione sul punteggio di ciascun valore \\(y_i\\) (in funzione di \\(x\\)), ma solo della media delle distribuzioni condizionate \\(p(y \\mid x_i)\\) di cui il valore osservato \\(y_i\\) è una realizzazione casuale. Possiamo dire la stessa cosa con parole diverse dicendo che il modello di regressione fa delle predizioni sulla componente deterministica di ciascuna osservazione. È più semplice capire questo aspetto se rappresentiamo in maniera grafica la componente “deterministica” \\(\\hat{y}_i = a + b x_i\\) predetta dal modello di regressione. kidiq$yhat &lt;- fm$fitted.values kidiq %&gt;% ggplot(aes(x = mom_iq, y = yhat)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + geom_point( aes(x=mean(mom_iq), y=mean(kid_score)), colour=&quot;red&quot;, size = 4 ) Il diagramma precedente presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). Si vede che i valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione. Dunque, il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione corrisponde alla distanza verticale tra i punti del diagramma a dispersione e la retta di regressione \\[ e_i = y_i - (a + b x_i). \\] Nel caso nella prima osservazione, ad esempio abbiamo: \\[ y_1 = (a + b x_1) + e_1 \\] Abbiamo kidiq$kid_score[1] #&gt; [1] 65 Dunque \\[ e_1 = (a + b x_1) - y_1 \\] e_1 &lt;- kidiq$kid_score[1] - (a + b * kidiq$mom_iq[1]) e_1 #&gt; [1] -34.67839 Ciò significa che il valore osservato \\(y_1 = 65\\) viene scomposto dal modello di regressione in due componenti. La componente deterministica \\(\\hat{y}_1\\), predicibile da \\(x_1\\), è yhat_1 &lt;- a + b * kidiq$mom_iq[1] yhat_1 #&gt; [1] 99.67839 La somma della componente deterministica e della componente erratica, ovviamente, riproduce il valore osservato. yhat_1 + e_1 #&gt; [1] 65 2.1.1 Trasformazione dei dati Consideriamo ora i dati \\(y\\) espressi come differenze dalla media: kidiq$xd &lt;- kidiq$mom_iq - mean(kidiq$mom_iq) Il diagramma a dispersione diventa il seguente. kidiq %&gt;% ggplot(aes(x = xd, y = kid_score)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + geom_point( aes(x=mean(xd), y=mean(kid_score)), colour=&quot;red&quot;, size = 4 ) Nel diagramma precedente, la pendenza della retta di regressione è uguale alla precedente, ma in questo grafico all’intercetta può essere assegnata un’interpretazione dotata di senso. fm1 &lt;- lm(kid_score ~ xd, data = kidiq) coef(fm1) #&gt; (Intercept) xd #&gt; 86.7972350 0.6099746 Nel caso di dati così trasformati, l’intercetta è sempre il punto sull’asse \\(y\\) dove la retta di regressione interseca l’ordinata. Ma, in questo caso, dato che abbiamo traslato i dati di una quantità pari a \\(x - \\bar{x}\\), il valore \\(x = 0\\) corrisponde al valore \\(\\bar{x}\\) nel caso dei dati grezzi. Dunque, l’intercetta avrà la seguente interpretazione: nel caso di dati nei quali \\(x\\) è espresso come differenze dalla media, l’intercetta corrisponde al valore atteso della \\(y\\) in corrispondenza di \\(\\bar{x}\\). In altre parole, per i dati così trasformati, l’intercetta corrisponde al QI atteso (ovvero, medio) dei bambini in corrispondenza del QI medio delle madri. 2.1.2 Il metodo dei minimi quadrati Ora che abbiamo visto come interpretare il coefficienti di regressione, chiediamoci come vengono calcolati. La procedura generale è stata brevemente descritta in precedenza. Vediamo ora come si giunge alla stessa conclusione usando una simulazione. Il problema è di trovare i valori \\(a\\) e \\(b\\) tali per cui la quantità \\(\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\\) assume il valore minore possibile. Questo è un problema di minimizzazione rispetto a due parametri. Per dare un’idea di come si fa, semplifichiamo il problema e supponiamo che uno dei due parametri sia noto, ad esempio \\(a\\), così ci resta una sola incognita. Credo una griglia di valori b_grid possibili, ad esempio: nrep &lt;- 1e5 b_grid &lt;- seq(0, 1, length.out = nrep) Definisco una funzione che calcola la quantità \\(\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\\): sse &lt;- function(a, b, x, y) { sum((y - (a + b * x))^2) } Calcolo la somma degli errori quadratici per ciascun possibile valore b_grid, fissando \\(a = 25.79978\\). sse_res &lt;- rep(NA, nrep) for (i in 1:nrep) { sse_res[i] &lt;- sse(a = 25.79978, b = b_grid[i], x = kidiq$mom_iq, y = kidiq$kid_score) } Esaminiamo il risultato ottenuto. plot( b_grid, sse_res, type = &#39;l&#39; ) Il risultato ottenuto con la simulazione b_grid[which.min(sse_res)] #&gt; [1] 0.6099761 riproduce quello ottenuto per via analitica: b #&gt; [1] 0.6099746 Una simulazione simile, ma computazionalmente più complessa, può essere usata per stimare simultaneamente entrambi i parametri. Ci siamo limitati qui ad una proof of concept del caso più semplice. 2.1.3 Il coefficiente di determinazione Il secondo obiettivo del modello statistico di regressione lineare è quello di stabilire quanto sia grande, in termini proporzionali, la componente \\(y\\) predicibile da \\(x\\), per ciascuna osservazione. Un indice assoluto della bontà di adattamento è fornito dalla deviazione standard dei residui, \\(s_e\\), chiamata anche errore standard della stima. Uno stimatore non distorto della varianza dei residui nella popolazione è dato da \\[ s^2_e = \\frac{\\sum e_i^2}{n-2} \\] e quindi l’errore standard della stima sarà \\[\\begin{equation} s_e = \\sqrt{\\frac{\\sum e_i^2}{n-2}}. \\end{equation}\\] Si noti che questa è la stessa formula della varianza (dato che la media dei residui è zero), tranne per il fatto che al denominatore abbiamo \\(n-2\\). Dato che, per calcolare \\(\\hat{y}\\) abbiamo usato due coefficienti (\\(a\\) e \\(b\\)), si dice che “abbiamo perso due gradi di libertà”. Dato che \\(s_e\\) possiede la stessa unità di misura della variabile \\(y\\), l’errore standard della stima può essere considerato come una sorta di “residuo medio.” – usando la stessa interpretazione che diamo alla deviazione standard in generale. Si noti che la formula precedente non fornisce la “deviazione standard dei residui nel campione” (quella formula avrebbe \\(n\\) al denominatore). Invece, fornisce una stima della deviazione standard dei residui nella popolazione da cui il campione è stato estratto. Verifichiamo quanto detto con i dati a disposizione. I residui possono essere trovati nel modo seguente. e &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq) e[1:10] #&gt; [1] -34.678390 17.691747 -11.217173 -3.461529 32.627697 6.382845 #&gt; [7] -41.521041 3.864881 26.414387 11.208068 Oppure nel modo seguente. fm$residuals[1:10] #&gt; 1 2 3 4 5 6 7 #&gt; -34.678390 17.691747 -11.217173 -3.461529 32.627697 6.382845 -41.521041 #&gt; 8 9 10 #&gt; 3.864881 26.414387 11.208068 Calcolo il residuo medio, prendendo il valore assoluto. mean(abs(e)) #&gt; [1] 14.4686 L’errore standard della regressione è sqrt(sum(e^2) / (length(e) - 2)) #&gt; [1] 18.26612 I due numeri non sono uguali, ma possiamo dire che hanno lo stesso ordine di grandezza. Se usiamo la funzione lm() otteniamo lo stesso valore, chiamato Residual standard error. summary(fm) #&gt; #&gt; Call: #&gt; lm(formula = kid_score ~ mom_iq, data = kidiq) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -56.753 -12.074 2.217 11.710 47.691 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 25.79978 5.91741 4.36 1.63e-05 *** #&gt; mom_iq 0.60997 0.05852 10.42 &lt; 2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 18.27 on 432 degrees of freedom #&gt; Multiple R-squared: 0.201, Adjusted R-squared: 0.1991 #&gt; F-statistic: 108.6 on 1 and 432 DF, p-value: &lt; 2.2e-16 2.2 Indice di determinazione Un importante risultato dei minimi quadrati riguarda la cosiddetta scomposizione della devianza mediante la quale si definisce l’indice di determinazione, il quale fornisce una misura relativa della bontà di adattamento del modello di regressione ai dati del campione. Per una generica osservazione \\(x_i, y_i\\), la variazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere descritta come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\): \\[ y_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}). \\] Se consideriamo tutte le osservazioni, la devianza delle \\(y\\) può essere scomposta nel seguente modo: \\[\\begin{align} \\sum (y_i - \\bar{y})^2 &amp;= \\sum \\left[ e_i + (\\hat{y}_i - \\bar{y}) \\right]^2 = \\sum e_i^2 + \\sum (\\hat{y}_i - \\bar{y})^2 + 2 \\sum e_i (\\hat{y}_i - \\bar{y}) \\notag \\end{align}\\] Per i vincoli imposti sul modello statistico di regressione, il doppio prodotto si annulla, infatti \\[\\begin{align} \\sum e_i (\\hat{y}_i - \\bar{y}) &amp;= \\sum e_i \\hat{y}_i - \\bar{y}\\sum e_i = \\sum e_i (a + b x_i) \\notag \\\\ &amp;= a \\sum e_i + b \\sum e_i x_i = 0 \\notag \\end{align}\\] Il termine \\(b \\sum e_i x_i\\) è uguale a zero perché, come vedremo in seguito, i coefficienti di regressione vengono calcolati in modo tale da rendere nulla \\(\\mbox{Cov}(e, x)\\). Di conseguenza, il termine precedente deve essere nullo. Possiamo dunque concludere che la devianza totale (\\(\\mbox{dev}_T\\)) si scompone nella somma di devianza d’errore (o devianza non spiegata) (\\(\\mbox{dev}_E\\)) e devianza di regressione (o devianza spiegata) (\\(\\mbox{dev}_T\\)): \\[\\begin{align} \\underbrace{\\sum_{i=1}^n (y_i - \\bar{y})^2}_{\\tiny{\\text{Devianza totale}}} &amp;= \\underbrace{\\sum_{i=1}^n e_i^2}_{\\tiny{\\text{Devianza di dispersione}}} + \\underbrace{\\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2}_{\\tiny{\\text{Devianza di regressione}}} \\notag \\end{align}\\] La devianza di regressione, \\(\\mbox{dev_R} \\triangleq \\mbox{dev_T} - \\mbox{dev_E}\\), indica dunque la riduzione degli errori al quadrato che è imputabile alla regressione lineare. Il rapporto \\(\\mbox{dev_R}/\\mbox{dev_T}\\), detto , esprime tale riduzione degli errori in termini proporzionali e definisce il coefficiente di correlazione al quadrato: \\[\\begin{equation} R^2 \\triangleq \\frac{\\mbox{dev_R}}{\\mbox{dev_T}} = 1 - \\frac{\\mbox{dev_E}}{\\mbox{dev_T}}. \\end{equation}\\] Quando l’insieme di tutte le deviazioni della \\(y\\) dalla media è spiegato dall’insieme di tutte le deviazioni della variabile teorica \\(\\hat{y}\\) dalla media, si ha che l’adattamento (o accostamento) del modello al campione di dati è perfetto, la devianza residua è nulla ed \\(r^2 = 1\\); nel caso opposto, la variabilità totale coincide con quella residua, per cui \\(r^2 = 0\\). Tra questi due estremi, \\(r\\) indica l’intensità della relazione lineare tra le due variabili e \\(r^2\\), con \\(0 \\leq r^2 \\leq 1\\), esprime la porzione della devianza totale della \\(y\\) che è spiegata dalla regressione lineare sulla \\(x\\). Per l’esempio in discussione abbiamo quanto segue. La devianza totale è dev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2) dev_t #&gt; [1] 180386.2 La devianza spiegata è dev_r &lt;- sum((fm$fitted.values - mean(kidiq$kid_score))^2) dev_r #&gt; [1] 36248.82 L’indice di determinazione è R2 &lt;- dev_r / dev_t R2 #&gt; [1] 0.2009512 Nell’output di lm() un tale valore è chiamato Multiple R-squared. summary(fm) #&gt; #&gt; Call: #&gt; lm(formula = kid_score ~ mom_iq, data = kidiq) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -56.753 -12.074 2.217 11.710 47.691 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 25.79978 5.91741 4.36 1.63e-05 *** #&gt; mom_iq 0.60997 0.05852 10.42 &lt; 2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 18.27 on 432 degrees of freedom #&gt; Multiple R-squared: 0.201, Adjusted R-squared: 0.1991 #&gt; F-statistic: 108.6 on 1 and 432 DF, p-value: &lt; 2.2e-16 Il risultato ottenuto si può interpretare dicendo che circa il 20% della variabilità dei punteggi del QI dei bambini può essere predetto conoscendo il QI delle madri. 2.2.1 Inferenza sul modello di regressione La discussione precedente era tutta basata sulla trattazione “classica” del modello lineare, ovvero una trattazione basata sulle stime di massima verosimiglianza (se \\(y \\sim \\mathcal{N}(\\alpha + \\beta x, \\sigma)\\), allora le stime dei minimi quadrati coincidono con le stime di massima verosimiglianza). In altre parole, nella discussione precedente non abbiamo considerato in alcun modo le distribuzioni a priori dei parametri \\(\\alpha\\) e \\(\\beta\\). In altre parole, i risultati precedenti si confermano, in un contesto bayesiano, se e solo se imponiamo sui parametri delle distribuzioni a priori non informative (cioè, uniformi). In tali circostanze, le stime di massima verosimiglianza sono identiche al massimo a posteriori bayesiano. Detto questo, il tema dell’inferenza viene trattato dall’approccio frequentista costruendo la “distribuzione campionaria” dei parametri (ovvero la distribuzione dei valori che i parametri otterrebbero in infiniti campioni casuali (\\(x, y\\)) di ampiezza \\(n\\) estratti dalla medesima popolazione) e poi calcolando gli errori standard dei parametri e gli intervalli di fiducia dei parametri. Una domanda frequente è, per esempio, se la pendenza della retta di regressione sia maggiore di zero. Per rispondere a tale domanda l’approccio frequentista calcola l’intervallo di fiducia al 95% per il parametro \\(\\beta\\). Se tale intervallo non include lo zero, e se il limite inferiore di tale intervallo è maggiore di zero, allora si conclude, con un grado di confidenza del 95%, che il vero parametro \\(\\beta\\) nella popolazione è maggiore di zero. Ovvero, si conclude che vi sono evidenze di un’associazione lineare positiva tra \\(x\\) e \\(y\\). Alla stessa conclusione si può arrivare calcolando, in un ottica bayesiana, l’intervallo di credibilità al 95% per il parametro \\(\\beta\\). I due intervalli sono identici se usiamo una distribuzione a priori piatta. Sono invece diversi se usiamo una distribuzione a priori debolmente informativa, oppure informativa. Solitamente si usa una distribuzione a priori debolmente informativa centrata sullo zero. In tali circostanze, l’uso della distribuzione a priori ha solo un effetto di regolarizzazione, ovvero di riduzione del peso delle osservazioni estreme – un tale risultato statistico è molto desiderabile, ma è difficile da ottenere in un contesto frequentista. Vedremo nel prossimo capitolo come può essere svolta l’inferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano. Commenti e considerazioni finali Il modello lineare semplice viene usato per descrivere la relazione tra due variabili e per determinare il segno e l’intensità di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base al valore assunto dalla variabile indipendente. "],["reg-lin-stan.html", "Capitolo 3 Modello lineare in Stan 3.1 Una distribuzione a priori debolmente informativa 3.2 Linguaggio Stan 3.3 Interpretazione dei parametri Commenti e considerazioni finali", " Capitolo 3 Modello lineare in Stan Mostreremo qui come sia possibile usare il linguaggio probabilistico Stan per la stima dei parametri del modello di regressione e per l’inferenza. 3.1 Una distribuzione a priori debolmente informativa Per implementare l’approccio bayesiano è necessario assegnare una distribuzione a priori ai parametri. Nel contesto del modello di regressione è desiderabile scegliere distribuzioni a priori che abbiano uno scarso impatto sulla distribuzione a posteriori. Supponiamo che le nostre credenza a priori sui parametri del modello, \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma\\) siano tra loro indipendenti. Allora possiamo scrivere la distribuzione congiunta dei parametri nel modo seguente: \\[ p(\\beta_0, \\beta_1, \\sigma) = p(\\beta_0)p(\\beta_1)p(\\sigma). \\] Per i coefficienti di regressione possiamo assumere \\(\\beta_0 \\sim \\mathcal{N}(\\mu_0, s_0)\\) e \\(\\beta_1 \\sim \\mathcal{N}(\\mu_1, s_1)\\). Per \\(\\sigma\\) possiamo assumere, ad esempio, \\(\\sigma \\sim \\mbox{Cauchy}(a, b)\\). Moltiplicando la verosimiglianza \\[ \\prod_{i=1}^n p(y_i \\mid x_i; \\beta_0, \\beta_1, \\sigma^2) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{-\\frac{(y_i-(\\beta_0+\\beta_1 x_i))^2}{2\\sigma^2}} \\] per le distribuzioni a priori dei parametri, si ottiene la distribuzione a posteriori. Tuttavia, tale distribuzione non è risolvibile per via analitica. Come in precedenza, usiamo invece un algoritmo MCMC per ottenere una sequenza di campioni casuali dalla distribuzione a posteriori. 3.2 Linguaggio Stan È conveniente usare il linguaggio Stan per ottenere una sequenza MCMC dalla distribuzione a posteriori di un modello di regressione. È semplice formulare la descrizione di un modello bayesiano (verosimiglianza e distribuzione a priori) in uno script scritto in linguaggio Stan. Continuiamo qui l’esempio precedente in cui ci si poneva il problema di descrivere l’associazione tra il QI dei figli e il QI delle madri mediante un modello lineare. I dati sono quelli del dataset kidiq: library(&quot;rio&quot;) df &lt;- rio::import(here::here(&quot;data&quot;, &quot;kidiq.dta&quot;)) head(df) #&gt; kid_score mom_hs mom_iq mom_work mom_age #&gt; 1 65 1 121.11753 4 27 #&gt; 2 98 1 89.36188 4 25 #&gt; 3 85 1 115.44316 4 27 #&gt; 4 83 1 99.44964 3 25 #&gt; 5 115 1 92.74571 4 27 #&gt; 6 98 0 107.90184 1 18 Per farci un’idea del valore dei parametri, adattiamo il modello lineare ai dati mediante la procedura di massima verosimiglianza (come abbiamo fatto nel capitolo precedente): fm &lt;- lm(kid_score ~ mom_iq, data = df) summary(fm) #&gt; #&gt; Call: #&gt; lm(formula = kid_score ~ mom_iq, data = df) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -56.753 -12.074 2.217 11.710 47.691 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 25.79978 5.91741 4.36 1.63e-05 *** #&gt; mom_iq 0.60997 0.05852 10.42 &lt; 2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 18.27 on 432 degrees of freedom #&gt; Multiple R-squared: 0.201, Adjusted R-squared: 0.1991 #&gt; F-statistic: 108.6 on 1 and 432 DF, p-value: &lt; 2.2e-16 Sulla base delle informazioni precedenti, giungiamo alla seguente formulazione bayesiana del modello lineare: \\[ \\begin{aligned} y_i &amp;\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_i \\\\ \\beta_0 &amp;\\sim \\mathcal{N}(25, 10) \\\\ \\beta_1 &amp;\\sim \\mathcal{N}(0, 1) \\\\ \\sigma &amp;\\sim \\text{Cauchy}(18, 5) \\end{aligned} \\] La prima riga definisce la funzione di verosimiglianza e le righe successive definiscono le distribuzioni a priori dei parametri. Il segno \\(\\sim\\) (tilde) si può leggere “si distribuisce come”. La prima riga ci dice che ciascuna osservazione \\(y_i\\) è una variabile casuale che segue la distribuzione gaussiana di parametri \\(\\mu_i\\) e \\(\\sigma\\). La seconda riga specifica, in maniera deterministica, che ciascun \\(\\mu_i\\) è una funzione lineare di \\(x_i\\), con parametri \\(\\beta_0\\) e \\(\\beta_1\\). Le due righe successive specificano le distribuzioni a priori per \\(\\beta_0\\) e \\(\\beta_1\\). La distribuzione a priori di \\(\\beta_0\\) è una distribuzione gaussiana di parametri \\(\\mu_{\\alpha} = 25\\) e deviazione standard \\(\\sigma_{\\alpha} = 10\\); la distribuzione a priori di \\(\\beta_1\\) è una distribuzione gaussiana standardizzata. L’ultima riga definisce la distribuzione a priori di \\(\\sigma\\), ovvero una Cauchy di parametri 18 e 5. Dobbiamo ora specificare il modello bayesiano descritto sopra in linguaggio Stan3. Consideriamo il seguente modello in linguaggio Stan: model_string_1 = &quot; data { int&lt;lower=0&gt; N; vector[N] y; vector[N] x; } parameters { real alpha; real beta; real&lt;lower=0&gt; sigma; } model { // priors alpha ~ normal(25, 10); beta ~ normal(0, 1); sigma ~ cauchy(18, 5); // likelihood for (n in 1:N) y[n] ~ normal(alpha + beta * x[n], sigma); } &quot; writeLines(model_string_1, con = &quot;code/simpleregkidiq.stan&quot;) La funzione modelString() registra una stringa di testo mentre writeLines() crea un file nell’indirizzo specificato. Tale file deve avere l’estensione .stan. Per svolgere l’analisi bayesiana sistemiamo i dati nel formato appropriato per Stan: data_list &lt;- list( N = length(df$kid_score), y = df$kid_score, x = df$mom_iq ) La funzione file.path() ritorna l’indirizzo del file con il codice Stan: file_simple_reg &lt;- file.path(&quot;code&quot;, &quot;simpleregstd.stan&quot;) Prendendo come input un file contenente un programma Stan, la funzione cmdstan_model() ritorna un oggetto di classe CmdStanModel. In pratica, CmdStan traduce un programma Stan in C++ e crea un eseguibile compilato. mod1 &lt;- cmdstan_model(file_simple_reg) Il codice Stan può essere stampato usando il metodo $print(): mod1$print() L’indirizzo dell’eseguibile compilato viene ritornato da $exe_file(): mod1$exe_file() Applicando il metodo $sample() ad un oggetto CmdStanModel eseguiamo il campionamento MCMC: fit_1 &lt;- mod1$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) Al metodo $sample() possono essere passati molti argomenti. La pagina di documentazione è disponibile al seguente link. Un sommario della distribuzione a posteriori per i parametri stimati si ottiene con il metodo $summary(), il quale chiama la funzione summarise_draws() del pacchetto posterior: fit_1$summary(c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 3 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha 25.9 25.9 5.98 6.03 16.1 35.7 1.00 15872. 10568. #&gt; 2 beta 0.609 0.609 0.0591 0.0593 0.512 0.706 1.00 15511. 10930. #&gt; 3 sigma 18.3 18.3 0.631 0.629 17.3 19.4 1.00 16089. 12115. Da questo output possiamo valutare rapidamente la convergenza del modello osservando i valori di Rhat per ciascun parametro. Quando questi sono pari o vicini a 1, le catene hanno realizzato la convergenza. Ci sono molti altri test diagnostici, ma questo test è importante per Stan. Oppure è possibile usare: fit_1$cmdstan_summary() Le statistiche diagnostiche sono fornite dal metodo $cmdstan_diagnose(): fit_1$cmdstan_diagnose() È possibile creare un oggetto di classe stanfit stanfit_1 &lt;- rstan::read_stan_csv(fit_1$output_files()) per poi utilizzare le funzioni del pacchetto bayesplot. Ad esempio: stanfit_1 %&gt;% mcmc_trace(pars = c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;)) Infine, eseguendo la funzione launch_shinystan(fit), è possibile analizzare oggetti di classe stanfit mediante le funzionalità del pacchetto ShinyStan. 3.2.1 Standardizzare i dati Il codice Stan viene eseguito più velocemente se l’input è standardizzato così da avere una media pari a zero e una varianza unitaria.4 Ponendo \\(y = (y_1, \\dots, y_n)\\) e \\(x = (x_1, \\dots, x_n)\\), il modello lineare può essere scritto come \\[ y_i = \\alpha + \\beta x_i + \\varepsilon_i, \\] dove \\[ \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma). \\] Seguendo la notazione del manuale Stan, i parametri del modello lineare sono qui denotati da \\(\\alpha\\) e \\(\\beta\\). Per eseguire la standardizzazione dei dati, è necessario centrare i dati, sottraendo da essi la media campionaria, per poi scalarli dividendo per la deviazione standard campionaria. Una singola osservazione \\(u\\) viene standardizzata dalla funzione \\(z\\) definita da \\[ z_y(u) = \\frac{u - \\bar{y}}{\\texttt{sd}(y)} \\] dove la media \\(\\bar{y}\\) è \\[ \\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i, \\] e la deviazione standard è \\[ \\texttt{sd} = \\left(\\frac{1}{n}\\sum_{i=1}^n(y_i - \\bar{y})^2\\right)^{-\\frac{1}{2}}. \\] La trasformata inversa è definita invertendo i due passaggi precedenti: la deviazione standard è usata per scalare i valori \\(u\\) e la media campionaria è usata per traslare la distribuzione dei valori \\(u\\) scalati: \\[ z_y^{-1}(u) = \\texttt{sd}(y)u + \\bar{y}. \\] Modificando il codice del modello precedente otteniamo il modello Stan per dati standardizzati. Il blocco data è identico a quello del caso precedente. I predittori e la risposta standardizzati sono definiti nel blocco transformed data. Per semplificare la notazione (e velocizzare l’esecuzione), nel blocco model l’istruzione di campionamento è espressa in forma vettorializzata: y_std ~ normal(alpha_std + beta_std * x_std, sigma_std);. model_string_2 = &quot; data { int&lt;lower=0&gt; N; vector[N] y; vector[N] x; } transformed data { vector[N] x_std; vector[N] y_std; x_std = (x - mean(x)) / sd(x); y_std = (y - mean(y)) / sd(y); } parameters { real alpha_std; real beta_std; real&lt;lower=0&gt; sigma_std; } transformed parameters { vector[N] mu_std = alpha_std + beta_std * x_std; } model { alpha_std ~ normal(0, 1); beta_std ~ normal(0, 1); sigma_std ~ normal(0, 1); y_std ~ normal(mu_std, sigma_std); } generated quantities { // transform to the original data scale real alpha; real beta; real&lt;lower=0&gt; sigma; alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y); beta = beta_std * sd(y) / sd(x); sigma = sd(y) * sigma_std; } &quot; writeLines(model_string_2, con = &quot;code/simpleregstd.stan&quot;) Si noti che i parametri vengono rinominati per indicare che non sono i parametri “naturali”, ma per il resto il modello è identico. Sono qui utilizzate distribuzioni a priori debolmente informative per i parametri alpha e beta. I valori dei parametri sulla scala originale dei dati vengono calcolati nel blocco generated quantities e possono essere recuperati con un po’ di algebra. \\[\\begin{align} y_n &amp;= \\textrm{z}_y^{-1}(\\textrm{z}_y(y_n)) \\notag\\\\ &amp;= \\textrm{z}_y^{-1} \\left( \\alpha&#39; + \\beta&#39; \\textrm{z}_x(x_n) + \\epsilon_n&#39; \\right) \\notag\\\\ &amp;= \\textrm{z}_y^{-1} \\left( \\alpha&#39; + \\beta&#39; \\left( \\frac{x_n - \\bar{x}}{\\texttt{sd}(x)} \\right) + \\epsilon_n&#39; \\right) \\notag\\\\ &amp;= \\texttt{sd}(y) \\left( \\alpha&#39; + \\beta&#39; \\left( \\frac{x_n - \\bar{x}}{\\texttt{sd}(x)} \\right) + \\epsilon_n&#39; \\right) + \\bar{y} \\notag\\\\ &amp;= \\left( \\texttt{sd}(y) \\left( \\alpha&#39; - \\beta&#39; \\frac{\\bar{x}}{\\texttt{sd}(x)} \\right) + \\bar{y} \\right) + \\left( \\beta&#39; \\frac{\\texttt{sd}(y)}{\\texttt{sd}(x)} \\right) x_n + \\texttt{sd}(y) \\epsilon&#39;_n, \\end{align}\\] da cui \\[ \\alpha = \\texttt{sd}(y) \\left( \\alpha&#39; - \\beta&#39; \\frac{\\bar{x}}{\\texttt{sd}(x)} \\right) + \\bar{y}; \\qquad \\beta = \\beta&#39; \\frac{\\texttt{sd}(y)}{\\texttt{sd}(x)}; \\qquad \\sigma = \\texttt{sd}(y) \\sigma&#39;. \\] La funzione file.path() ritorna l’indirizzo del file con il codice Stan: file_simple_reg_std &lt;- file.path(&quot;code&quot;, &quot;simpleregstd.stan&quot;) Compiliamo. mod2 &lt;- cmdstan_model(file_simple_reg_std) Eseguo il campionamento MCMC. fit_2 &lt;- mod2$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) Esamino i risultati fit_2$summary(c(&quot;alpha_std&quot;, &quot;beta_std&quot;, &quot;sigma_std&quot;, &quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 6 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha_std 0.000107 -0.000149 0.0432 0.0423 -0.0703 0.0715 1.00 18705. #&gt; 2 beta_std 0.448 0.448 0.0438 0.0443 0.375 0.520 1.00 20084. #&gt; 3 sigma_std 0.897 0.896 0.0311 0.0316 0.848 0.950 1.00 18813. #&gt; 4 alpha 25.9 25.8 6.02 6.02 16.0 35.8 1.00 20176. #&gt; 5 beta 0.609 0.609 0.0596 0.0603 0.511 0.707 1.00 20084. #&gt; 6 sigma 18.3 18.3 0.634 0.644 17.3 19.4 1.00 18813. #&gt; # … with 1 more variable: ess_tail &lt;dbl&gt; Si noti che, avendo usato delle distribuzioni a priori debolmente informative, le stime dei parametri sono molto simili a quelle ottenute mediante la procedura di massima verosimiglianza. coef(fm) #&gt; (Intercept) mom_iq #&gt; 25.7997778 0.6099746 Anziché standardizzare i dati all’interno del programma Stan è anche possibile procedere in un modo diverso, ovvero standardizzare i dati forniti in input. Questa, in realtà, è la procedura usuale. Ciò consente di specificare, per ciascun parametro, una distribuzione a priori su una scala “naturale” per Stan, ovvero quella di una variabile Normale standardizzata. Se non ci sono ragioni particolari per mantenere l’unità di misura dei dati grezzi, standardizzare i dati in input è la strategia migliore. 3.3 Interpretazione dei parametri Ripeto qui la discussione del capitolo precedente. Assegnamo ai parametri la seguente interpretazione. L’intercetta pari a 25.9 indica il QI medio dei bamini la cui madre ha un QI = 0. Ovviamente questo non ha alcun significato. Vedremo nel modello successivo come trasformare il modello in modo da potere assegnare all’intercetta un’interpretazione sensata. La pendenza di 0.61 indica che, all’aumentare di un punto del QI delle madri, il QI medio dei loro bambini aumenta di 0.61 unità. Se consideriamo la gamma di variazione del QI delle madri nel campione, il QI medio dei bambini cambia di 41 punti. Questo indica un sostanziale effetto del QI delle madri sul QI dei loro bambini: \\((138.89 - 71.04) * 0.61 = 41.39\\). Il parametro \\(\\sigma\\) = 18.3 fornisce una stima della dispersione delle osservazioni attorno al valore predetto dal modello lineare, ovvero fornisce una stima della deviazione standard dei residui attorno al valore atteso del modello lineare. 3.3.1 Centrare i predittori Come abbiamo detto in precedenza, per migliorare l’interpretazione dell’intercetta possiamo “centrare” la \\(x\\), ovvero esprimere la \\(x\\) nei termini degli scarti dalla media: \\(x - \\bar{x}\\). In tali circostanze, la pendenza della retta specificata dal modello lineare resta immutata, ma l’intercetta corrisponde a \\(\\E(y \\mid x = \\bar{x})\\). Per ottenere questo risultato, modifichiamo i dati da passare a Stan: data2_list &lt;- list( N = length(df$kid_score), y = df$kid_score, x = df$mom_iq - mean(df$mom_iq) ) Adattiamo il modello: fit_3 &lt;- mod2$sample( data = data2_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) Trasformiamo l’oggetto fit in un oggetto di classe stanfit: stanfit_3 &lt;- rstan::read_stan_csv(fit_3$output_files()) Le stime a posteriori dei parametri si ottengono con fit_3$summary(c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 3 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha 86.8 86.8 0.876 0.871 85.4 88.2 1.00 16318. 11494. #&gt; 2 beta 0.609 0.609 0.0591 0.0589 0.513 0.707 1.00 16206. 11236. #&gt; 3 sigma 18.3 18.3 0.630 0.624 17.3 19.4 1.00 15617. 11986. Si noti la nuova intercetta, ovvero 86.8. Questo valore indica il QI medio dei bambini le cui madri hanno un QI pari alla media del campione. Centrare i dati consente dunque di assegnare all’intercetta un’interpretazione utile. Commenti e considerazioni finali La presente discussione suggerisce che è conveniente standardizzare i dati prima di procedere con l’analisi. Ciò può essere fatto all’interno del codice Stan (come negli esempi di questo Capitolo), oppure prima di passare i dati a Stan. Se vengono usati dati standardizzati diventa poi facile utilizzare distribuzioni a priori debolmente informative per i parametri. Tali distribuzioni a priori hanno, come unico scopo, quello di regolarizzare i dati e di facilitare la stima dei parametri mediante MCMC. Nella discussione che segue ripeto pari pari ciò che è riportato nel manuale del linguaggio Stan.↩︎ Si noti un punto importante. Il fatto di standardizzare i dati fa in modo che le distribuzioni a priori sui parametri vadano espresse sulla scala delle v.c. normali standardizzate. Se centriamo sullo 0 tali distribuzioni a priori, con una deviazione standard dell’ordine di grandezza dell’unità, i discorsi sull’arbitrarietà delle distribuzioni a priori perdono di significato: nel caso di dati standardizzati le distribuzioni a priori formulate come indicato sopra sono distribuzioni debolmente informative il cui unico scopo è la regolarizzazione dei dati, ovvero di mantenere le inferenze in una gamma ragionevole di valori. L’uso di distribuzioni a priori debolmente informative contribuisce nel contempo a limitare l’influenza eccessiva delle osservazioni estreme (valori anomali). Il punto importante qui è che tali distribuzioni a priori non introducono alcuna distorsione sistematica nella stima a posteriori.↩︎ "],["inference-reg-lin-stan.html", "Capitolo 4 Inferenza sul modello lineare 4.1 Rappresentazione grafica dell’incertezza della stima 4.2 Intervalli di credibilità 4.3 Test di ipotesi 4.4 Modello lineare robusto Commenti e considerazioni finali", " Capitolo 4 Inferenza sul modello lineare 4.1 Rappresentazione grafica dell’incertezza della stima Un primo modo per rappresentare l’incertezza dell’inferenza in un ottica bayesiana è quella di rappresentare graficamente la retta specificata dal modello lineare. Continuando con l’esempio descritto nel Capitolo precedente (ovvero, i dati kid_score e i valori mom_iq centrati), usando la funzione rstan::read_stan_csv leggiamo i file CSV generati da cmdstan e trasformiamo le stime a posteriori dei parametri in formato stanfit: stanfit &lt;- rstan::read_stan_csv(fit2$output_files()) posterior &lt;- extract(stanfit) Creiamo ora un diagramma a dispersione dei dati con sovrapposto il valore atteso della \\(y\\): tibble( kid_score = df$kid_score, mom_iq = df$mom_iq - mean(df$mom_iq) ) %&gt;% ggplot(aes(mom_iq, kid_score)) + geom_point() + geom_abline( intercept = mean(posterior$alpha), slope = mean(posterior$beta) ) L’incertezza della stima della retta specifiata dal modello lineare può essere visualizzata tracciando molteplici rette, ciascuna delle quali definita da un diverso valore estratto a caso dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\). Per ottenere questo risultato dobbiamo estrarre le informazioni richieste dall’oggetto stanfit che abbiamo creato; usiamo, per esempio, le funzionalità di tidybayes: tidybayes::get_variables(stanfit) #&gt; [1] &quot;alpha_std&quot; &quot;beta_std&quot; &quot;sigma_std&quot; &quot;alpha&quot; #&gt; [5] &quot;beta&quot; &quot;sigma&quot; &quot;lp__&quot; &quot;accept_stat__&quot; #&gt; [9] &quot;treedepth__&quot; &quot;stepsize__&quot; &quot;divergent__&quot; &quot;n_leapfrog__&quot; #&gt; [13] &quot;energy__&quot; Creiamo un Dataframe in formato tidy (cioè, tale per cui le osservazioni stanno sulle righe e le variabili stanno sulle colonne) che contiene le stime a posteriori di \\(\\alpha\\) e \\(\\beta\\): draws &lt;- stanfit %&gt;% spread_draws(beta, alpha) draws %&gt;% head(10) #&gt; # A tibble: 10 × 5 #&gt; .chain .iteration .draw beta alpha #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 1 0.632 88.4 #&gt; 2 1 2 2 0.491 87.5 #&gt; 3 1 3 3 0.717 85.9 #&gt; 4 1 4 4 0.478 87.5 #&gt; 5 1 5 5 0.610 86.4 #&gt; 6 1 6 6 0.570 86.7 #&gt; 7 1 7 7 0.623 87.0 #&gt; 8 1 8 8 0.616 87.2 #&gt; # … with 2 more rows Possiamo ora generare un diagramma a dispersione con ggplot(): tibble( kid_score = df$kid_score, mom_iq = df$mom_iq - mean(df$mom_iq) ) %&gt;% ggplot(aes(mom_iq, kid_score)) + geom_point() + geom_abline( data = draws, aes(intercept = alpha, slope = beta), size = 0.2, alpha = 0.01, color = &quot;darkgray&quot; ) + geom_abline( intercept = mean(posterior$alpha), slope = mean(posterior$beta) ) + labs( x = &quot;Quoziente di intelligenza della madre&quot;, y = &quot;Quoziente di intelligenza del bambino&quot; ) Il grafico indica che le rette di regressione costruite estraendo a caso valori dalla distribuzione a posteriori dei parametri \\(\\beta_0\\) e \\(\\beta_1\\) tendono ad essere molto simili tra loro. Ciò significa che, relativamente alla dipendenza (lineare) del quoziente di intelligenza del bambino da quello della madra, la nostra incertezza è molto piccola. 4.2 Intervalli di credibilità L’incertezza inferenziale sui parametri può anche essere descritta mediante gli intervalli di credibilità, ovvero gli intervalli che contengono la quota desiderata (es., il 95%) della distribuzione a posteriori. Per l’esempio che stiamo discutendo, gli intervalli di credibilità al 95% si ottengono nel modo seguente: rstantools::posterior_interval( as.matrix(stanfit), prob = 0.95 ) #&gt; 2.5% 97.5% #&gt; alpha_std -0.08427372 0.08441589 #&gt; beta_std 0.36136782 0.53165187 #&gt; sigma_std 0.83902970 0.96033440 #&gt; alpha 85.07713000 88.52020750 #&gt; beta 0.49171840 0.72342520 #&gt; sigma 17.12519250 19.60110750 #&gt; lp__ -173.15907500 -168.54400000 Un grafico che, nel caso dei dati standardizzati, riporta l’intervallo di credibilità ai livelli di probabilità desiderati per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) si ottiene con l’istruzione mcmc_areas( fit2$draws(c(&quot;alpha_std&quot;, &quot;beta_std&quot;, &quot;sigma_std&quot;)), prob = 0.8, prob_outer = 0.95 ) oppure nel modo nel modo seguente stanfit %&gt;% mcmc_intervals( pars = c(&quot;alpha_std&quot;, &quot;beta_std&quot;, &quot;sigma_std&quot;), prob = 0.8, prob_outer = 0.95 ) 4.2.1 Quale soglia usare? Non c’è niente di “magico” o necessario relativamente al livello di 0.95: il valore 0.95 è arbitrario. Sono possibili tantissime altre soglie per quantificare la nostra incertezza: alcuni ricercatori usano il livello di 0.89, altri quello di 0.5. Se l’obiettivo è quello di descrivere il livello della nostra incertezza relativamente alla stima del parametro, allora dobbiamo riconoscere che la nostra incertezza è descritta dall’intera distribuzione a posteriori. Per cui il metodo più semplice, più diretto e più completo per descrivere la nostra incertezza rispetto alla stima dei parametri è semplicemente quello di riportare graficamente tutta la distribuzione a posteriori. Una rappresentazione della distribuzione a posteriori dei parametri del modello dell’esempio si ottiene nel modo seguente: rstan::stan_dens( stanfit, pars = c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;), fill = &quot;lightgray&quot; ) 4.3 Test di ipotesi È facile valutare ipotesi direzionali usando Stan. Per esempio, la probabilità \\(Pr(\\hat{\\beta}_1 &gt; 0)\\) è sum(posterior$beta &gt; 0) / length(posterior$beta) #&gt; [1] 1 ovvero, la probabilità \\(Pr(\\hat{\\beta}_1 &lt; 0)\\) è sum(posterior$beta &lt; 0) / length(posterior$beta) #&gt; [1] 0 4.4 Modello lineare robusto Spesso i ricercatori devono affrontare il problema degli outlier: in presenza di outlier, un modello statistico basato sulla distribuzione gaussiana produrrà delle stime distorte dei parametri, ovvero stime che non si generalizzano ad altri campioni di dati. Il metodo tradizionale per affrontare questo problema è quello di eliminare gli outlier prima di eseguire l’analisi statistica. Il problema di questo approccio, però, è che il criterio utilizzato per eliminare gli outlier, quale esso sia, è arbitrario; dunque, usando criteri diversi per la rimozione di outlier, i ricercatori finiscono per trovare risultati diversi. Questo problema trova una semplice soluzione nell’approccio bayesiano. Il modello lineare che abbiamo dicusso finora ipotizza una specifica distribuzione degli errori, ovvero \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\). In un modello formulato in questi termini, la presenza di solo un valore anomalo e influente ha un effetto drammatico sulle stime dei parametri. Per fare un esempio, introduciamo un singlo valore anomalo e influente nel set dei dati dell’esempio che stiamo discutendo: df2 &lt;- df df2$kid_score[434] &lt;- -500 df2$mom_iq[434] &lt;- 140 Per comodità, calcoliamo le stime di \\(\\alpha\\) e \\(\\beta\\) con il metodo dei minimi quadrati (tali stime sono simili a quelle che si otterrebbero con un modello bayesiano gaussiano che impiega distribuzioni a priori debolmente informative). Sappiamo che, nel campione originale di dati, \\(\\hat{\\beta} \\approx 0.6\\). In presenza di un solo outlier troviamo la stima di \\(\\beta\\) viene drammaticamente ridotta: lm(kid_score ~ mom_iq, data = df2) %&gt;% coef() #&gt; (Intercept) mom_iq #&gt; 49.187954 0.362552 In generale, però, non è necessario assumere \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\). È altrettanto valido un modello che ipotizza una diversa distribuzione di densità per gli errori come, ad esempio, la distribuzione \\(t\\) di Student con un piccolo numero di gradi di libertà. Una caratteristica della \\(t\\) di Student è che le code della distribuzione contengono una massa di probabilità maggiore della distribuzione gaussiana. Ciò fornisce alla \\(t\\) di Student la possibilità di “rendere conto” della presenza di osservazioni lontane dalla media della distribuzione. In altri termini, se in modello lineare usiamo la \\(t\\) di Student quale distribuzione degli errori, la presenza di outlier avrà una minore influenza sulle stime dei parametri di quanto avvenga nel tradizionale modello lineare gaussiano. Per verificare questa affermazione, modifichiamo il codice Stan usato in precedenza in modo tale da ipotizzare che \\(y\\) segua una distribuzione \\(t\\) di Student con un numero \\(\\nu\\) gradi di libertà stimato dal modello: student_t(nu, mu, sigma).5 modelString &lt;- &quot; data { int&lt;lower=0&gt; N; vector[N] y; vector[N] x; } transformed data { vector[N] x_std; vector[N] y_std; x_std = (x - mean(x)) / sd(x); y_std = (y - mean(y)) / sd(y); } parameters { real alpha_std; real beta_std; real&lt;lower=0&gt; sigma_std; real&lt;lower=1&gt; nu; // degrees of freedom is constrained &gt;1 } model { alpha_std ~ normal(0, 1); beta_std ~ normal(0, 1); sigma_std ~ normal(0, 1); nu ~ gamma(2, 0.1); // Juárez and Steel(2010) y_std ~ student_t(nu, alpha_std + beta_std * x_std, sigma_std); } generated quantities { real alpha; real beta; real&lt;lower=0&gt; sigma; alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y); beta = beta_std * sd(y) / sd(x); sigma = sd(y) * sigma_std; } &quot; writeLines(modelString, con = &quot;code/simpleregstdrobust.stan&quot;) Costruiamo la lista dei dati usando il data.frame df2 che include l’outlier: data3_list &lt;- list( N = length(df2$kid_score), y = df2$kid_score, x = df2$mom_iq - mean(df2$mom_iq) ) Adattiamo il modello lineare robusto ai dati: file &lt;- file.path(&quot;code&quot;, &quot;simpleregstdrobust.stan&quot;) mod &lt;- cmdstan_model(file) fit4 &lt;- mod$sample( data = data3_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) Se esaminiamo le stime dei parametri notiamo che la stima di \\(\\beta\\) non è stata influenzata dalla presenza di un’osservazione anomala e influente: fit4$summary(c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;, &quot;nu&quot;)) #&gt; # A tibble: 4 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha 87.8 87.8 0.901 0.898 86.3 89.3 1.00 14740. 12422. #&gt; 2 beta 0.602 0.602 0.0589 0.0587 0.505 0.699 1.00 14903. 11582. #&gt; 3 sigma 15.9 15.9 0.800 0.803 14.6 17.2 1.00 12993. 11619. #&gt; 4 nu 5.58 5.46 1.15 1.09 3.93 7.64 1.00 12998. 11288. Il modello lineare robusto non risente dunque della presenza di outlier. Commenti e considerazioni finali Nell’approccio bayesiano possiamo rappresentare l’incertezza delle nostre credenze a posteriori in due modi: mediante la rappresentazione grafica dell’intera distribuzione a posteriori dei parametri o mediante l’uso degli intervalli di credibilità. Un bonus della discussione del presente Capitolo è quello di mostrare come il modello lineare tradizionale (che assume \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\)) possa essere facilmente esteso nei termini di un modello robusto che offre una semplice soluzione al problema di ridurre l’effetto della presenza di osservazioni outlier. È equivalente scrivere \\(y_i = \\mu_i + \\varepsilon_i\\), dove \\(\\mu_i = \\alpha + \\beta x_i, \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_\\varepsilon),\\) oppure \\(y_i \\sim \\mathcal{N}(\\mu_i, \\sigma_\\varepsilon).\\)↩︎ "],["comp-two-means-stan.html", "Capitolo 5 Confronto tra due gruppi indipendenti 5.1 Modello lineare con una variabile dicotomica 5.2 La dimensione dell’effetto Commenti e considerazioni finali", " Capitolo 5 Confronto tra due gruppi indipendenti Il problema del confronto tra due gruppi indipendenti può essere formulato nei termini di un modello lineare nel quale la variabile \\(X\\) è dicotomica, ovvero assume solo due valori. 5.1 Modello lineare con una variabile dicotomica Se \\(X\\) è una variabile dicotomica con valori 0 e 1, allora per il modello lineare \\(\\mu_i = \\alpha + \\beta x_i\\) abbiamo quanto segue. Quando \\(x=0\\), il modello diventa \\[ \\mu_i = \\alpha \\] mentre, quando \\(x=1\\), il modello diventa \\[ \\mu_i = \\alpha + \\beta. \\] Ciò significa che il parametro \\(\\alpha\\) è uguale al valore atteso del gruppo codificato con \\(X=0\\) e il parametro \\(\\beta\\) è uguale alla differenza tra le medie dei due gruppi (essendo la media del secondo gruppo uguale a \\(\\alpha + \\beta\\)). Il parametro \\(\\beta\\), dunque, codifica l’effetto di una manipolazione sperimentale o di un trattamento, e l’inferenza su \\(\\beta\\) corrisponde direttamente all’inferenza sull’efficacia di un trattamento o di un effetto sperimentale. L’inferenza su \\(\\beta\\), dunque, viene utilizzata per capire quanto “credibile” può essere considerato l’effetto di un trattamento o di una manipolazione sperimentale. 5.1.1 Confronti, non effetti Per “effetto di un trattamento” si intende la differenza tra le medie di due gruppi (per esempio, il gruppo “sperimentale” e il gruppo “di controllo”). Gelman, Hill, and Vehtari (2020) fanno notare come l’uso della terminologia “effetto” implica un modello causale: una variazione di \\(X\\) produce una variazione di \\(Y\\). In generale, il modello lineare descrive una regolarità osservabile nel campione di dati. Ma questa regolarità (ovvero, la presenza di una relazione approssimativamente lineare tra \\(X\\) e \\(Y\\)) non ci dice nulla della presenza (o dell’assenza) di una relazione di causa/effetto tra queste variabili. L’associazione osservata tra le variabili \\(X\\) e \\(Y\\) potrebbe dipendere dall’effetto di una o più altre variabili non misurate, senza che tra \\(X\\) e \\(Y\\) ci sia alcuna relazione causale. In tali circostanze, l’interpretazione più appropriata dei coefficienti del modello lineare è quella che ci porta a pensare ai coefficienti del modello come ai risultati di un confronto. Nel caso presente, il confronto è quello tra il valore atteso del quoziente di intelligenza dei bambini, quando la madre ha oppure non ha completato il ciclo di istruzione secondaria superiore. Dato che l’affermazione precedente è formulata nei termini del valore atteso, questo significa che facciamo riferimento ad un campione di osservazioni. Niente viene detto della relazione causale tra il quoziente di intelligenza del bambino e l’ottenimento del diploma di scuola superiore da parte della madre all’interno del singolo soggetto. Quindi, quando usiamo il termine “effetto” dobbiamo sempre pensare a tale termine come come se fosse contenuto tra virgolette. 5.1.2 Un esempio concreto Esaminiamo nuovamente i dati kid_score discussi da Gelman, Hill, and Vehtari (2020). La domanda della ricerca è se il QI del figlio (misurato sulla scala PIAT) è associato al livello di istruzione della madre. Codifichiamo il livello di istruzione della madre (\\(x\\)) con una variabile indicatrice (ovvero, una variabile che assume solo i valori 0 e 1) tale per cui: \\(x=0\\): la madre non ha completato la scuola secondaria di secondo grado (scuola media superiore); \\(x=1\\): la madre ha completato la scuola media superiore. Supponiamo che i dati siano contenuti nel data.frame df. library(&quot;rio&quot;) df &lt;- rio::import(here(&quot;data&quot;, &quot;kidiq.dta&quot;)) Calcoliamo le statistiche descrittive per i due gruppi: df %&gt;% group_by(mom_hs) %&gt;% summarise( mean_kid_score = mean(kid_score), std = sqrt(var(kid_score)) ) #&gt; # A tibble: 2 × 3 #&gt; mom_hs mean_kid_score std #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 77.5 22.6 #&gt; 2 1 89.3 19.0 Il punteggio medio PIAT è pari a 77.5 per i bambini la cui madre non ha il diploma di scuola media superiore e pari a 89.3 per i bambini la cui madre ha completato la scuola media superiore. Questa differenza suggerisce un’associazione tra le variabili, ma tale differenza potrebbe essere soltanto la conseguenza della variabilità campionaria, senza riflettere una caratteristica generale della popolazione. Come possiamo usare il modello statistico lineare per fare inferenza sulla differenza osservata tra i due gruppi? Non dobbiamo fare nient’altro che usare il modello lineare che abbiamo definito in precedenza. modelString = &quot; data { int&lt;lower=0&gt; N; vector[N] y; vector[N] x; } transformed data { vector[N] x_std; vector[N] y_std; x_std = (x - mean(x)) / sd(x); y_std = (y - mean(y)) / sd(y); } parameters { real alpha_std; real beta_std; real&lt;lower=0&gt; sigma_std; } model { alpha_std ~ normal(0, 2); beta_std ~ normal(0, 2); sigma_std ~ cauchy(0, 2); y_std ~ normal(alpha_std + beta_std * x_std, sigma_std); } generated quantities { real alpha; real beta; real&lt;lower=0&gt; sigma; real cohen_d; alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y); beta = beta_std * sd(y) / sd(x); sigma = sd(y) * sigma_std; cohen_d = beta / sigma; } &quot; writeLines(modelString, con = &quot;code/simpleregstd.stan&quot;) Come in precedenza, salviamo i dati in un oggetto di classe list: data_list &lt;- list( N = length(df$kid_score), y = df$kid_score, x = df$mom_hs ) Compiliamo il modello: file &lt;- file.path(&quot;code&quot;, &quot;simpleregstd.stan&quot;) mod &lt;- cmdstan_model(file) Adattiamo il modello ai dati: fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) Creiamo un grafico con i valori predetti dal modello lineare: stanfit &lt;- rstan::read_stan_csv(fit$output_files()) posterior &lt;- extract(stanfit) tibble( kid_score = df$kid_score, mom_hs = df$mom_hs ) %&gt;% ggplot(aes(mom_hs, kid_score)) + geom_point() + geom_abline(intercept = mean(posterior$alpha), slope = mean(posterior$beta)) + labs( y = &quot;Quoziente di intelligenza del bambino&quot;, x = &quot;Diploma di istruzione secondaria di secondo grado della madre\\n(0 = no; 1 = sì)&quot; ) + scale_x_continuous(breaks=c(0, 1)) Le stime a posteriori dei parametri si ottengono con: fit$summary(c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;, &quot;cohen_d&quot;)) #&gt; # A tibble: 4 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha 77.6 77.5 2.08 2.06 74.1 81.0 1.00 16538. 12192. #&gt; 2 beta 11.8 11.7 2.35 2.34 7.88 15.6 1.00 16718. 12319. #&gt; 3 sigma 19.9 19.9 0.676 0.671 18.8 21.0 1.00 15949. 10908. #&gt; 4 cohen_d 0.592 0.591 0.120 0.119 0.393 0.788 1.00 16771. 12647. I risultati confermano ciò che ci aspettavamo: il coefficiente \\(\\texttt{alpha} = 77.56\\) corrisponde alla media del gruppo codificato con \\(x = 0\\), ovvero la media dei punteggi PIAT per i bambini la cui madre non ha completato la scuola media superiore; il coefficiente \\(\\texttt{beta} = 11.76\\) corrisponde alla differenza tra le medie dei due gruppi, ovvero 89.32 - 77.55 = 11.77 (con piccoli errori di approssimazione). La seguente chiamata ritorna l’intervallo di credibilità al 95% per tutti i parametri del modello: rstantools::posterior_interval( as.matrix(stanfit), prob = 0.95 ) #&gt; 2.5% 97.5% #&gt; alpha_std -0.09401587 0.09248375 #&gt; beta_std 0.14360650 0.32886135 #&gt; sigma_std 0.91337438 1.04372000 #&gt; alpha 73.43237000 81.62094500 #&gt; beta 7.13510525 16.33961500 #&gt; sigma 18.64258750 21.30290500 #&gt; cohen_d 0.35667085 0.82770125 #&gt; lp__ -208.90605000 -204.32400000 Possiamo dunque concludere che i bambini la cui madre ha completato la scuola superiore ottengono in media circa 12 punti in più rispetto ai bambini la cui madre non ha completato la scuola superiore. L’intervallo di credibilità al 95% ci dice che possiamo essere sicuri al 95% che tale differenza sia di almeno 7 punti e possa arrivare fino a ben 16 punti. Per riassumere, possiamo concludere, con un grado di certezza soggettiva del 95%, che c’è un’associazione positiva tra il livello di scolarità della madre e l’intelligenza del bambino: le madri che hanno livello di istruzione più alto della media tendo ad avere bambini il cui QI è anch’esso più alto della media. 5.2 La dimensione dell’effetto Nel caso di due gruppi indipendenti, la dimensione dell’effetto si può stimare con la statistica \\(d\\) di Cohen: \\[ d={\\frac {{\\bar {y}}_{1}-{\\bar {y}}_{2}}{s}}. \\] Nel caso presente, la differenza \\({\\bar {y}}_{1}-{\\bar {y}}_{2}\\) corrisponde a al parametro \\(\\beta\\) del modello lineare. Inoltre, una stima della deviazione starndard comune dei due gruppi è fornita dalla deviazione standard della regressione, ovvero dal parametro \\(\\sigma\\). Nel blocco generated quantities del modello Stan ho calcolato cohen_d = beta / sigma. Ciò significa che Stan calcolerà la distribuzione a posteriori del parametro cohen_d. Possiamo dunque riassumere la distribuzione a posteriori di cohen_d con un qualche indice di tendenza centrale (che sarà la nostra stima della dimensione dell’effetto) e calcolare l’intervallo di credibilità, per esempio al 95%. Questi risultati si ottengono con l’istruzione riportata di seguito: posterior::summarise_draws( stanfit, ~ quantile(.x, probs = c(0.025, 0.5, 0.975)) ) #&gt; # A tibble: 8 × 4 #&gt; variable `2.5%` `50%` `97.5%` #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha_std -0.0940 -0.000366 0.0925 #&gt; 2 beta_std 0.144 0.236 0.329 #&gt; 3 sigma_std 0.913 0.974 1.04 #&gt; 4 alpha 73.4 77.5 81.6 #&gt; 5 beta 7.14 11.7 16.3 #&gt; 6 sigma 18.6 19.9 21.3 #&gt; 7 cohen_d 0.357 0.591 0.828 #&gt; 8 lp__ -209. -205. -204. I risultati dell’analisi bayesiana coincidono con quelli che si ottengono utilizzando la formula del \\(d\\) di Cohen con le medie dei due gruppi e una stima della varianza pooled. Il calcolo della statistica \\(d\\) di Cohen è fornita, ad esempio, dal pacchetto effectsize: library(&quot;effectsize&quot;) (d &lt;- cohens_d(kid_score ~ mom_hs, data = df)) #&gt; Cohen&#39;s d | 95% CI #&gt; -------------------------- #&gt; -0.59 | [-0.83, -0.36] #&gt; #&gt; - Estimated using pooled SD. Il fatto che l’output abbia un segno negativo dipende dal fatto che è stata sottratta la media maggiore dalla media minore (in altri termini, dobbiamo guardare il risultato in valore assoluto). In conclusione, il valore \\(d\\) di Cohen di entità “media” [\\(d\\) &gt; 0.5; Sawilowsky (2009)] può essere interpretato dicendo che la scolarità delle madri ha un’influenza non trascurabile sul QI dei bambini. Commenti e considerazioni finali La dimensione dell’effetto formulata nei termini dell’indice \\(d\\) di Cohen fornisce un indice che non dipende dall’unità di misura delle variabili, ovvero è una differenza media standardizzata. L’intrepretazione di \\(d\\) è semplice: la scala di \\(d\\) è la deviazione standard. Se, per esempio, \\(d = 0.5\\), allora la media di un primo gruppo è mezza deviazione standard più grande della media del secondo gruppo. In questo Capitolo abbiamo visto come \\(d\\) possa essere calcolato mediante un modello lineare bayesiano implementato in linguaggio Stan. References "],["ch-pred-checks.html", "Capitolo 6 Predictive checks 6.1 Campionamento dalla distribuzione predittiva a posteriori 6.2 Campionamento dalla distribuzione predittiva a priori Commenti e considerazioni finali", " Capitolo 6 Predictive checks Nel Capitolo ?? abbiamo visto come si genera la distribuzione predittiva a posteriori nel caso del modello più semplice: quello di un’unica variabile con una data distribuzione di probabilità. In questo capitolo estenderemo questa discussione al modello lineare. Esamineremo un esempio di posterior predictive check in cui simuleremo da \\(p(y^{rep} \\mid \\theta, y)\\), usando le stime a posteriori dei parametri \\(\\theta\\) del modello, e un esempio di prior predictive check in cui simuleremo da \\(p(y^{rep} \\mid \\mathcal{M})\\), ovvero usando il meccanismo generatore dei dati del modello \\(\\mathcal{M}\\) in esame, senza però includere i dati. 6.1 Campionamento dalla distribuzione predittiva a posteriori La distribuzione predittiva a priori equivale alla distribuzione predittiva a posteriori, senza però i dati osservati. Quindi la distribuzione predittiva a priori non è altro che il caso limite della distribuzione predittiva a posteriori, calcolata però senza utilizzare i dati del campione. Il manuale Stan afferma che, se il codice per il il controllo predittivo a posteriori è già stato scritto, ed è possibile impostare il codice in modo che non sia necessario specificare i dati, allora non è necessario fare nient’altro. Consideriamo qui un esempio nel quale vengono usati i dati kidiq (Gelman, Hill, and Vehtari 2020). library(&quot;rio&quot;) df &lt;- rio::import(here(&quot;data&quot;, &quot;kidiq.dta&quot;)) Iniziamo a generare un istogramma dei valori \\(y\\) stanardizzati: df %&gt;% ggplot(aes(scale(kid_score)[, 1])) + geom_histogram() Per svolgere l’analisi bayesiana sistemiamo i dati (standardizzati) nel formato appropriato per Stan: data_list &lt;- list( N = length(df$kid_score), x = scale(df$mom_iq)[, 1], y = scale(df$kid_score)[, 1] ) Il seguente listato specifica il codice Stan necessario per simulare dati dalla distribuzione predittiva a posteriori. stancode &lt;- &#39; data { int&lt;lower=0&gt; N; vector[N] x; vector[N] y; } parameters { real alpha; real beta; real&lt;lower=0&gt; sigma; } model { alpha ~ normal(0, 1); beta ~ normal(0, 1); sigma ~ normal(0, 1); y ~ normal(alpha + beta * x, sigma); } generated quantities { vector[N] y_rep; for(i in 1:N){ y_rep[i] = normal_rng(alpha + beta * x[i], sigma); } } &#39; writeLines(stancode, con = &quot;code/post_pred_check_1.stan&quot;) file &lt;- file.path(&quot;code&quot;, &quot;post_pred_check_1.stan&quot;) mod &lt;- cmdstan_model(file) fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) stanfit1 &lt;- rstan::read_stan_csv(fit$output_files()) Un istogramme dei valori \\(y^{rep}\\) può essere generato nel modo seguente: hist(as.matrix(stanfit1, pars = &quot;y_rep&quot;), breaks = 100) 6.2 Campionamento dalla distribuzione predittiva a priori Per comprendere le assunzioni che abbiamo introdotto nel modello, possiamo generare dati mediante il modello; tali dati, che sono generati interamente dalle distribuzioni a priori, sono chiamati distribuzione predittiva a priori. La generazione della distribuzione predittiva a priori ci aiuta a verificare se le distribuzioni a priori per i parametri del modello hanno senso. Quello che vogliamo sapere qui è: le distribuzioni a priori che abbiamo scelto generano dati che hanno caratteristiche realistiche? Dal punto di vista della programmazione, l’unico cambiamento necessario rispetto al codice utilizzato per la distribuzione predittiva a posteriori è quello di eliminare la porzione di codice che fa riferimento ai dati \\(y\\) – nel caso di un modello lineare, i valori \\(x\\) devono invece essere mantenuti per potere generare \\(y^{sim}\\) (nel codice questa variabile è ancora chiamata y_rep). data_list &lt;- list( N = length(df$kid_score), x = scale(df$mom_iq)[, 1] ) stancode &lt;- &#39; data { int&lt;lower=0&gt; N; vector[N] x; } parameters { real alpha; real beta; real&lt;lower=0&gt; sigma; } model { alpha ~ normal(0, 1); beta ~ normal(0, 1); sigma ~ normal(0, 1); } generated quantities { vector[N] y_rep; for(i in 1:N){ y_rep[i] = normal_rng(alpha + beta * x[i], sigma); } } &#39; writeLines(stancode, con = &quot;code/prior_pred_check_1.stan&quot;) file &lt;- file.path(&quot;code&quot;, &quot;prior_pred_check_1.stan&quot;) mod &lt;- cmdstan_model(file) fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) stanfit2 &lt;- rstan::read_stan_csv(fit$output_files()) Questo è un istogramma della distribuzione preditiva a priori. Tale distribuzione viene usata per valutare se le distribuzioni a priori dei parametri sono sensate. Concludiamo che sono sensate se la distribuzione preditiva a priori include tutti i valori possibili della distribuzione della \\(y\\), senza scostarsti troppo da essa. hist(as.matrix(stanfit2, pars = &quot;y_rep&quot;), breaks = 100) Commenti e considerazioni finali I due predictive checks che abbiamo esaminato in questo capitolo servono due scopi diversi. La distribuzione predittiva a priori viene utilizzata per comprendere le assunzioni introdotte nel modello. Per fare questo possiamo generare dei dati dal modello. Tali dati, che vengono prodotti interamente dalle distribuzioni a priori, sono chiamati distribuzione predittiva a priori. La distribuzione predittiva a priori ci aiuta a capire se le distribuzioni a priori per i parametri del modello hanno un senso. Quello che ci chiedimo è: le distribuzioni a priori generano dei dati che hanno caratteristiche realistiche? Una risposta affermativa a tale domanda corrisponde ad una distribuzione predittiva a priori che è più ampia della distribuzione dei dati osservati, in linea con il principio dei prior debolmente informativi. Tale distribuzione dovrebbe avere almeno una qualche massa nell’intorno ai valori estremi, ma plausibili dei dati; non dovrebbe, invece, esserci massa in corrispondenza di valori di dati completamente implausibili. La distribuzione predittiva a posteriori viene invece utilizzata per esplorare le caratteristiche che potrebbero avere i possibili dati futuri. L’idea alla base del controllo predittivo a posteriori è semplice: se un modello è appropriato, dovremmo essere in grado di usarlo per generare dati che assomigliano ai dati che abbiamo osservato nel campione. La motivazione è simile a quella che ci ha condotto alla distribuzione predittiva a priori, tranne per il fatto che ora abbiamo un modello generativo dei dati basato sui dati osservati. References "],["ch-anova.html", "Capitolo 7 Confronto di \\(k\\) gruppi 7.1 Le abilità sociali di un robot 7.2 I test statistici dell’Analisi della Varianza 7.3 Codice Stan (versione 2)", " Capitolo 7 Confronto di \\(k\\) gruppi L’Analisi della Varianza (ANOVA) consente ai ricercatori di valutare gli effetti di predittori categoriali su una variabile di esito continua. L’ANOVA è un’analisi di regressione nella quale tutte le variabili indipendenti sono qualitative. 7.1 Le abilità sociali di un robot Per illustrare i concetti chiave dell’ANOVA bayesiana considereremo qui una ricerca di Horstmann et al. (2018). I ricercatori si sono chiesti se le persone impiegano più tempo a spegnere un robot quando questo mostra abilità sociali. Nell’esperimento di Horstmann et al. (2018), 85 partecipanti hanno interagito con un robot per un certo tempo. Ai partecipanti è stato detto che lo scopo della loro interazione con il robot era quella di testare un nuovo algoritmo. Dopo il completamento di due compiti fittizi, ai partecipanti veniva detto che, se volevano, potevano spegnere il robot. La variabile di interesse dell’esperimento era il tempo impiegato dai partecipanti per spegnere il robot. Seguendo Bergh et al. (2020), analizzeremo i tempi di spegnimento trasformati su scala logaritmica perché tale variabile mostra una chiara asimmetria positiva. Horstmann et al. (2018) hanno manipolato due variabili in un disegno tra i soggetti. Interaction type. Le risposte verbali dei robot potevano essere o sociali (ad esempio, “Oh sì, la pizza è ottima. Una volta ho mangiato una pizza grande come me.”) o funzionali (ad esempio, “Preferisci la pizza. Ha funzionato bene. Continuiamo.”). Robot’s objection. Il robot poteva protestare quando stava per essere spento (ad esempio, “No! Per favore, non spegnermi! Ho paura di non riuscire ad accendermi di nuovo!”) oppure no. Pertanto, il disegno di questo studio è un’ANOVA tra i soggetti 2 (Interaction type) \\(\\times\\) 2 (Robot’s objection). Iniziamo a leggere i dati d &lt;- rio::import( here(&quot;data&quot;, &quot;pone.0201581.s001.sav&quot;) ) Per comodità creiamo la variabile cond con quattro modalità (SO, FO, SN, FN), dove S significa social interaction, F sta per funcitonal interaction, O sta per objection e N sta per no objection. d$cond &lt;- factor(d$Condition) d$cond &lt;- factor( d$cond, labels = c(&quot;SO&quot;, &quot;FO&quot;, &quot;SN&quot;, &quot;FN&quot;) ) Ci sono alcuni dati mancanti, quindi verranno omesse le righe con NA. Selezionando le colonne di interesse dal data.frame originario otteniamo: dd &lt;- d %&gt;% dplyr::select(cond, SwitchOff_Time) %&gt;% na.omit() Nelle quattro condizioni si osservano le seguenti medie (si veda la Tabella 3 di Horstmann et al. 2018): dd %&gt;% group_by(cond) %&gt;% summarise( avg_sot = mean(SwitchOff_Time, na.rm = TRUE), sd_sot = sd(SwitchOff_Time, na.rm = TRUE) ) #&gt; # A tibble: 4 × 3 #&gt; cond avg_sot sd_sot #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 SO 6.19 4.61 #&gt; 2 FO 14.4 15.4 #&gt; 3 SN 5.05 2.18 #&gt; 4 FN 4.28 2.49 Visualizziamo i dati: dd_summary &lt;- dd %&gt;% group_by(cond) %&gt;% summarize( sot_mean = mean(SwitchOff_Time), sot_sd = sd(SwitchOff_Time), sot_median = median(SwitchOff_Time) ) %&gt;% ungroup() dd %&gt;% ggplot( aes(x = cond, y = SwitchOff_Time, color = cond) ) + ggforce::geom_sina( aes(color = cond, size = 3, alpha = .5) ) + geom_errorbar( aes( y = sot_median, ymin = sot_median, ymax = sot_median ), data = dd_summary, width = 0.5, size = 3 ) + scale_colour_grey(name = &quot;cond&quot;) + labs( x = &quot;&quot;, y = &quot;SwitchOff Time&quot;, color = &quot;Condizione&quot; ) + theme(legend.position = &quot;none&quot;) Su scala logaritmica, l’asimmetria positiva della variabile dd$SwitchOff_Time viene ridotta. Per i dati trasformati, la mediana in ciascuna condizione è: dd$y &lt;- log(dd$SwitchOff_Time + 0.01) dd %&gt;% group_by(cond) %&gt;% summarise( avg_y = median(y) ) #&gt; # A tibble: 4 × 2 #&gt; cond avg_y #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 SO 1.61 #&gt; 2 FO 2.01 #&gt; 3 SN 1.39 #&gt; 4 FN 1.39 Creiamo ora la variabile x che indicizza le quattro condizioni (la variabile x verrà usata nel modello Stan): dd$x &lt;- as.numeric(dd$cond) head(dd) #&gt; cond SwitchOff_Time y x #&gt; 3 SN 6 1.793425 3 #&gt; 4 FO 7 1.947338 2 #&gt; 5 FO 3 1.101940 2 #&gt; 6 FN 4 1.388791 4 #&gt; 7 FN 4 1.388791 4 #&gt; 8 FO 12 2.485740 2 Il modello bayesiano che usiamo qui per il confronto tra le medie dei quattro gruppi è una semplice estensione del modello per la media di un solo gruppo. Il codice usato è ispirato da quello fornito nella seguente pagina web. Per adattare un modello “robusto”, ipotizzeremo che la y segua una distribuzione \\(t\\) di Student con un numero di gradi di libertà stimato dal modello. Il modello classico dell’ANOVA è basato sulle seguenti assunzioni: i residui (cioè la differenza tra il valore dell’\\(i\\)-esima osservazione e la media di tutte le osservazioni nella \\(k\\)-esima condizione) devono seguire la distribuzione normale (normalità); i residui devono avere la stessa deviazione standard nelle \\(k\\) popolazioni da cui abbiamo estratto i dati (omoschedasticità); il disegno sperimentale utilizzato per raccogliere i dati deve garantire l’indipendenza dei residui. Nella presenta formulazione dell’ANOVA bayesiana, l’assunto di normalità non è richiesto, mentre devono essere soddisfatte le condizioni di omoschedasticità e indipendenza. L’ANOVA bayesiana può comunque essere estesa a condizioni che violano sia l’assunto di omoschedasticità sia quello di indipendenza. Ma qui ci limitiamo a discutere il caso più semplice. modelString = &quot; // Comparison of k groups with common variance (ANOVA) data { int&lt;lower=0&gt; N; // number of observations int&lt;lower=0&gt; K; // number of groups int&lt;lower=1,upper=K&gt; x[N]; // discrete group indicators vector[N] y; // real valued observations } parameters { vector[K] mu; // group means real&lt;lower=0&gt; sigma; // common standard deviation real&lt;lower=1&gt; nu; } model { mu ~ normal(0, 2); // weakly informative prior sigma ~ normal(0, 1); // weakly informative prior nu ~ gamma(2, 0.1); // Juárez and Steel(2010) y ~ student_t(nu, mu[x], sigma); // observation model / likelihood } &quot; writeLines(modelString, con = &quot;code/grp_aov.stan&quot;) Creiamo un oggetto che contiene i dati nel formato appropriato per Stan: data_grp &lt;- list( N = nrow(dd), K = 4, x = dd$x, y = dd$y ) Compiliamo il modello: file &lt;- file.path(&quot;code&quot;, &quot;grp_aov.stan&quot;) mod &lt;- cmdstan_model(file) Eseguiamo il campionamento MCMC: fit &lt;- mod$sample( data = data_grp, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) Esaminando i risultati fit$summary() #&gt; # A tibble: 7 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 lp__ -41.2 -40.9 1.85 1.69 -44.7 -38.9 1.00 6774. 9294. #&gt; 2 mu[1] 1.69 1.68 0.175 0.170 1.41 1.99 1.00 21498. 12257. #&gt; 3 mu[2] 2.05 2.05 0.196 0.196 1.73 2.37 1.00 20722. 10892. #&gt; 4 mu[3] 1.52 1.52 0.122 0.120 1.32 1.72 1.00 22671. 11935. #&gt; 5 mu[4] 1.28 1.28 0.125 0.121 1.07 1.49 1.00 21545. 11572. #&gt; 6 sigma 0.476 0.472 0.0753 0.0736 0.358 0.606 1.00 14197. 11182. #&gt; 7 nu 2.55 2.41 0.821 0.724 1.49 4.07 1.00 14336. 9374. ci rendiamo conto che cìè una buona corrispondenza tra le medie a posteriori e le medie campionarie. Trasformiamo l’oggetto fit in un oggetto di classe stanfit: stanfit &lt;- rstan::read_stan_csv(fit$output_files()) La funzione rstan::extract() estrae i campioni a posteriori da un oggetto di classe stanfit: posterior &lt;- extract(stanfit, permuted = TRUE) Una rappresentazione grafica della distribuzione a posteriori delle quattro medie si ottiene con le seguenti istruzioni: temps &lt;- data.frame(posterior$mu) %&gt;% setNames(c(&#39;SO&#39;, &#39;FO&#39;, &#39;SN&#39;, &#39;FN&#39;)) mcmc_areas(temps, prob = 0.95) + xlab(&#39;Gruppi&#39;) I quattro intervalli di credibilità al 95% sono: ci95 &lt;- rstanarm::posterior_interval( as.matrix(stanfit), prob = 0.95 ) round(ci95, 2) #&gt; 2.5% 97.5% #&gt; mu[1] 1.36 2.05 #&gt; mu[2] 1.67 2.44 #&gt; mu[3] 1.28 1.76 #&gt; mu[4] 1.03 1.53 #&gt; sigma 0.34 0.63 #&gt; nu 1.37 4.56 #&gt; lp__ -45.67 -38.67 7.2 I test statistici dell’Analisi della Varianza L’ANOVA include test statistici di due tipi: i test sull’interazione tra i fattori e i test sugli effetti principali. Per chiarire il significato di “interazione” e di “effetto principale” è necessario prima definire il significato di “effetto statistico”. Definizione 7.1 L’effetto di un fattore rappresenta la variazione media della variabile dipendente al variare dei livelli del fattore stesso. Definizione 7.2 Si parla di interazione quando l’effetto di un fattore sulla variabile dipendente varia a seconda dei livelli di un altro fattore. Vengono presentati qui di seguito alcuni esempi. Le figure seguenti mostrano le medie di ciascuna condizione nel caso di un disegno 3 (fattore riga) \\(\\times\\) 2 (fattore colonna). La spiegazione delle figure è presentata nelle didascalie. FIGURA 7.1: Il fattore colonna è indicato dal colore. Sinistra La figura mostra un effetto principale del fattore riga e un effetto principale del fattore colonna. Non c’è interazione tra i fattori riga e colonna. Destra La figura mostra un effetto principale del fattore riga. L’effetto principale del fattore colonna è zero. Non c’è interazione tra i fattori riga e colonna. FIGURA 7.2: Il fattore colonna è indicato dal colore. Sinistra La figura mostra che l’effetto principale del fattore riga è zero, mentre c’è un effetto principale del fattore colonna. Non c’è interazione tra i fattori riga e colonna. Destra Non c’è né un effetto principale del fattore riga, né un effetto pricipale del fattore colonna, né un’interazione tra i fattori riga e colonna. FIGURA 7.3: Il fattore colonna è indicato dal colore. Entrambe le figure mostrano un’interazione tra i fattori riga e colonna. Nella figura di sinistra gli effetti principali non sono interpretabili; nella figura di destra gli effetti principali sono interpretabili in quanto l’interazione è di lieve entità. Dagli esempi precedenti si evince che c’è un’interazione ogni qualvolta i profili delle medie non sono paralleli. Anche se, nella popolazione, non c’è interazione, a causa della variabilità campionaria i profili delle medie non sono mai perfettamente paralleli nel campione. Il problema è quello di stabilire se l’assenza di parallelismo nel campione fornisce sufficiente evidenza di presenza di interazione nella popolazione. 7.2.1 Test sull’interazione Ritorniamo ora ai dati di Horstmann et al. (2018). Nel caso di un disegno 2 \\(\\times\\) 2, con i fattori Interaction type (social, functional) e Robot’s objection (objection, no objection), è possibile verificare la presenza dell’interazione Interaction type \\(\\times\\) Robot’s objection. Nel modello bayesiano, la distribuzione a posteriori fornisce un enorme numero di stime del valore della media in ciascuna delle quattro condizioni. L’effetto di un fattore corrisponde alla differenza tra le stime della media in corrispondenza di ciascuna modalità del fattore. Nel caso presente abbiamo: mu[1] \\(\\rightarrow\\) SO mu[2] \\(\\rightarrow\\) FO mu[3] \\(\\rightarrow\\) SN mu[4] \\(\\rightarrow\\) FN Quindi, mean(posterior$mu[, 1] - posterior$mu[, 3]) corrisponde alla stima a posteriori dell’effetto di Objection nella condizione Social Interaction. Invece, mean(posterior$mu[, 2] - posterior$mu[, 3]) corrisponde alla stima a posteriori dell’effetto di Objection nella condizione Functional Interaction. In assenza di interazione, questi due effetti devono essere (statisticamente) uguali. Per sottoporre a verifica questa ipotesi, calcoliamo la proporzione di volte in cui questo non si verifica nella distribuzione a posteriori: sum( (posterior$mu[, 1] - posterior$mu[, 3]) &gt; (posterior$mu[, 2] - posterior$mu[, 4]) ) / length(posterior$mu[, 1]) #&gt; [1] 0.0314375 La stima di questa probabilità in un test direzionale è molto simile alla probabilità frequentista riportata da Horstmann et al. (2018), ovvero \\(p = 0.016\\). Horstmann et al. (2018) riportano la presenza di un’interazione tra Interaction type e Robot’s objection (com’è stato anche trovato con la presente ANOVA bayesiana). Per interpretare l’interazione è necessario esaminare le mediane dei quattro gruppi.6 L’esame delle mediane indica che l’effetto del fattore Robot’s objection è più grande quando il fattore Interaction type assume la modalità Functional piuttosto che Social. Ma possiamo anche leggere l’interazione nella direzione opposta: l’effetto del fattore Interaction type è più grande quando il fattore Robot’s objection assume la modalità Objection anziché No objection. 7.2.2 Test sugli effetti principali L’effetto principale descrive l’effetto marginale di un fattore. Nel caso presente, in cui ciascun fattore ha solo due modalità, l’effetto principale corrisponde alla differenze tra le medie delle modalità di ciascun fattore. L’effetto principale del fattore Interaction type è la differenza tra le medie di Social e di Functional, ignorando Robot’s objection. Horstmann et al. (2018) riportano che gli individui che avevano avuto un’interazione funzionale con il robot impiegavano più tempo a spegnere il robot di coloro che avevano avuto un’interazione sociale con il robot (\\(p\\) = 0.045). Il presente modello bayesiano offre scarse evidenze di ciò: mean((exp(posterior$mu[, 2]) + exp(posterior$mu[, 4])) / 2) #&gt; [1] 5.765852 mean((exp(posterior$mu[, 1]) + exp(posterior$mu[, 3])) / 2) #&gt; [1] 5.043196 Infatti, all’evento complementare possiamo associare la seguente probabilità: sum( (posterior$mu[, 2] + posterior$mu[, 4]) &lt; (posterior$mu[, 1] + posterior$mu[, 3]) ) / length(posterior$mu[, 1]) #&gt; [1] 0.344125 L’effetto principale del fattore Robot’s objection è la differenza tra le medie di Objection e di No Objection, ignorando Interaction type. Horstmann et al. (2018) riportano che i partecipanti avevano aspettato più a lungo prima di spegnere il robot quando il robot aveva avanzato un’obiezione rispetto a quando non si era opposto ad essere spento: mean( (exp(posterior$mu[, 1]) + exp(posterior$mu[, 2])) / 2 ) #&gt; [1] 6.701133 mean( (exp(posterior$mu[, 3]) + exp(posterior$mu[, 4])) / 2 ) #&gt; [1] 4.107915 In base al modello bayesiano, la probabilità direzionale per l’evento complementare è sum( (posterior$mu[, 1] + posterior$mu[, 2]) &lt; (posterior$mu[, 3] + posterior$mu[, 4]) ) / length(posterior$mu[, 1]) #&gt; [1] 0.0011875 e corrisponde, in ordine di grandezza, alla probabilità frequentista riportata da Horstmann et al. (2018), ovvero \\(p\\) = 0.004. 7.3 Codice Stan (versione 2) È possibile modificare il codice Stan precedente così da avere i dati grezzi in input ed eseguire la standardizzazione all’interno del programma. modelString = &quot; // Comparison of k groups with common variance (ANOVA) data { int&lt;lower=0&gt; N; // number of observations int&lt;lower=0&gt; K; // number of groups int&lt;lower=1,upper=K&gt; x[N]; // discrete group indicators vector[N] y; // real valued observations } transformed data { vector[N] y_std; y_std = (y - mean(y)) / sd(y); } parameters { vector[K] mu_std; // group means real&lt;lower=0&gt; sigma_std; // common standard deviation real&lt;lower=1&gt; nu; } model { mu_std ~ normal(0, 2); sigma_std ~ normal(0, 2); nu ~ gamma(2, 0.1); // Juárez and Steel(2010) y_std ~ student_t(nu, mu_std[x], sigma_std); } generated quantities { vector[K] mu; real&lt;lower=0&gt; sigma; for (i in 1:K) { mu[i] = mu_std[i] * sd(y) + mean(y); } sigma = sd(y) * sigma_std; } &quot; writeLines(modelString, con = &quot;code/grp_aovstd.stan&quot;) file &lt;- file.path(&quot;code&quot;, &quot;grp_aovstd.stan&quot;) mod &lt;- cmdstan_model(file) Eseguiamo il campionamento MCMC usando gli stessi dati discussi in precedenza: fit2 &lt;- mod$sample( data = data_grp, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) I risultati sono equivalenti a quelli trovati in precedenza: fit2$summary(c(&quot;mu&quot;, &quot;sigma&quot;, &quot;nu&quot;)) #&gt; # A tibble: 6 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 mu[1] 1.70 1.70 0.176 0.171 1.42 2.00 1.00 22449. 11510. #&gt; 2 mu[2] 2.07 2.06 0.197 0.196 1.75 2.40 1.00 21774. 12016. #&gt; 3 mu[3] 1.53 1.52 0.122 0.121 1.32 1.73 1.00 21066. 11485. #&gt; 4 mu[4] 1.29 1.28 0.127 0.124 1.08 1.50 1.00 20576. 11730. #&gt; 5 sigma 0.480 0.476 0.0759 0.0744 0.362 0.612 1.00 15958. 12302. #&gt; 6 nu 2.58 2.44 0.831 0.725 1.51 4.13 1.00 15484. 9221. References "],["mod-hier-stan.html", "Capitolo 8 Modello gerarchico 8.1 Modello gerarchico 8.2 Modello ad effetti fissi 8.3 Modello gerarchico", " Capitolo 8 Modello gerarchico 8.1 Modello gerarchico I modelli lineari misti, o modelli lineari gerarchici/multilivello, sono diventati uno strumento fondamentale della ricerca sperimentale in psicologia, linguistica e scienze cognitive, dove i progetti di ricerca a misure ripetute sono la norma. Il presente Capitolo fornisce un’introduzione a tali modelli considerando soltanto il caso più semplice, conosciuto anche col nome di Random Intercept Model. Per fare un esempio concreto useremo il set di dati a misure ripetute con due condizioni di Gibson and Wu (2013; si veda Sorensen and Vasishth 2015). La variabile dipendente rt dell’esperimento di Gibson and Wu (2013) è il tempo di lettura in millisecondi del soggetto di una proposizione relativa in un testo. I tempi di reazione sono stati registrati in due condizioni (ovvero, in presenza di un sostantivo riferito al soggetto oppure riferito all’oggetto della proposizione). I dati di Gibson and Wu (2013) provengono da un esperimento con 37 soggetti e 15 item. Gli item erano presentati in un disegno a quadrato latino, il che produce 37 \\(\\times\\) 15 = 555 dati. Risultano mancanti otto dati di un soggetto (id 27), il che ci porta ad un totale di 555 − 8 = 547 dati. Le prime righe del data.frame sono mostrate di seguito: rdat &lt;- read.table(here::here(&quot;data&quot;, &quot;gibsonwu2012data.txt&quot;)) rdat$so &lt;- ifelse(rdat$type == &quot;subj-ext&quot;, -0.5, 0.5) head(rdat) #&gt; subj item type pos word correct rt region type2 so #&gt; 7 1 13 obj-ext 6 抓住 - 1140 de1 object relative 0.5 #&gt; 20 1 6 subj-ext 6 男孩 - 1197 de1 subject relative -0.5 #&gt; 32 1 5 obj-ext 6 撞 - 756 de1 object relative 0.5 #&gt; 44 1 9 obj-ext 6 監視 - 643 de1 object relative 0.5 #&gt; 60 1 14 subj-ext 6 機師 - 860 de1 subject relative -0.5 #&gt; 73 1 4 subj-ext 6 男孩 - 868 de1 subject relative -0.5 La variabile di interesse che corrisponde alla manipolazione sperimentale è chiamata so ed è stata codificata con -0.5 se il sostantivo era riferito al soggetto e con +0.5 se il sostantivo era riferito all’oggetto della frase. Calcoliamo la media dei tempi di reazione su scala logaritmica e per poi ritrasformare il risultato sulla scala originale: rdat %&gt;% group_by(type2) %&gt;% summarise( avg = exp(mean(log(rt), na.rm = TRUE)) ) #&gt; # A tibble: 2 × 2 #&gt; type2 avg #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 object relative 551. #&gt; 2 subject relative 589. Quando il sostantivo si riferisce al soggetto, i tempi di reazione sono più lenti di circa 30 ms. Questa descrizione dei dati, però non tiene conto né delle differenze tra i soggetti né delle differenze tra gli item. Per tenere in considerazioni queste diverse fonti della variabilità dei dati è necessario utilizzare un modello detto gerarchico. 8.2 Modello ad effetti fissi Iniziamo con il modello “ad effetti fissi” che non tiene conto della struttura gerarchica dei dati, ovvero del fatto che c’è una covariazione all’interno dei cluster di dati definiti dalle variabili “soggetto” e “item”. Assumiamo che la variabile dipendente rt (del tempo di lettura) sia approssimativamente distribuita in modo logaritmico (Rouder 2005). Ciò presuppone che il logaritmo di rt sia distribuito approssimativamente in maniera normale. Il modello per il logaritmo dei tempi di lettura, \\(\\log\\) rt, diventa \\[\\begin{equation} \\log rt_i = \\beta_0 + \\beta_1 so_i + \\varepsilon_i, \\end{equation}\\] ovvero \\[\\begin{equation} rt \\sim LogNormal(\\beta_0 + \\beta_1 so,\\sigma) \\end{equation}\\] dove \\(\\beta_0\\) è la media generale di \\(\\log\\) rt e \\(\\beta_1 so\\) codifica la differenza \\(\\E(\\log rt_{o}) - \\E(\\log rt_{s})\\) quando si passa dalla condizione nella quale il sostantivo è riferito all’oggetto alla condizione nella quale il sostantivo è riferito all’soggetto – valori negativi significano che i tempi di reazioni sono maggiori nella condizione s che nella condizione o. Nel modello useremo le seguenti distribuzioni a priori: \\[\\begin{equation} \\begin{aligned} \\beta[1] &amp;\\sim Normal(6, 1.5) \\\\ \\beta[2] &amp;\\sim Normal(0, 1.0) \\\\ \\sigma &amp;\\sim Cauchy(0, 1)\\\\ \\end{aligned} \\end{equation}\\] In Stan, il modello diventa modelString = &quot; data { int&lt;lower=1&gt; N; //number of data points real rt[N]; //reading time real&lt;lower=-0.5, upper=0.5&gt; so[N]; //predictor } parameters { vector[2] beta; //fixed intercept and slope real&lt;lower=0&gt; sigma_e; //error sd } model { real mu; // likelihood beta[1] ~ normal(6, 1.5); beta[2] ~ normal(0, 1); sigma_e ~ cauchy(0, 1); for (i in 1:N){ mu = beta[1] + beta[2] * so[i]; rt[i] ~ lognormal(mu, sigma_e); } } &quot; writeLines(modelString, con = &quot;code/fixeff_model.stan&quot;) file &lt;- file.path(&quot;code&quot;, &quot;fixeff_model.stan&quot;) mod &lt;- cmdstan_model(file) I dati sono contenuti nella lista stan_dat: stan_dat &lt;- list( rt = rdat$rt, so = rdat$so, N = nrow(rdat) ) Eseguiamo il campionamento MCMC: fit3 &lt;- mod$sample( data = stan_dat, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) Otteniamo un oggetto di classe stanfit: stanfit &lt;- rstan::read_stan_csv(fit3$output_files()) Calcoliamo gli intervalli di credibilità al 95%: ci95 &lt;- rstanarm::posterior_interval( as.matrix(stanfit), prob = 0.95 ) round(ci95, 3) #&gt; 2.5% 97.5% #&gt; beta[1] 6.321 6.369 #&gt; beta[2] -0.113 -0.017 #&gt; sigma_e 0.613 0.646 #&gt; lp__ -2617.020 -2612.420 L’effetto medio, sulla scala in millisecondi, si trova nel modo seguente: posterior &lt;- extract(stanfit, permuted = TRUE) exp(mean(posterior$beta[, 1] + posterior$beta[, 2])) - exp(mean(posterior$beta[, 1])) #&gt; [1] -35.99588 8.3 Modello gerarchico Il modello a effetti fissi è inappropriato per i dati di Gibson and Wu (2013) perché non tiene conto del fatto che abbiamo più misure per ogni soggetto e per ogni item. In altre parole, il modello ad effetti fissi viola l’assunzione di indipendenza degli errori. Inoltre, i coefficienti di effetti fissi \\(\\beta_0\\) e \\(\\beta_1\\) rappresentano le medie calcolate su tutti i soggetti e tutti gli item, ignorando il fatto che alcuni soggetti sono più veloci e altri più lenti della media, e il fatto che alcuni item sono stati letti più velocemente della media e altri più lentamente. Nei modelli lineari misti, teniamo in considerazione la variabilità dovuta alle differenze tra soggetti e tra item aggiungendo al modello i termini \\(u_{0j}\\) e \\(w_{0k}\\) che aggiustano \\(\\beta_0\\) stimando una componente specifica al soggetto \\(j\\) e all’item \\(k\\). Questa formulazione del modello scompone parzialmente \\(\\varepsilon_i\\) in una somma di termini \\(u_{0j}\\) e \\(w_{0k}\\) che, geometricamente, corrispondono a degli aggiustamenti dell’intercetta \\(\\beta_0\\) specifici per il soggetto \\(j\\) e per l’item \\(k\\). Se il soggetto \\(j\\) è più lento della media di tutti i soggetti, \\(u_j\\) sarà un numero positivo; se l’item \\(k\\) viene letto più velocemente del tempo di lettura medio di tutti gli item, allora \\(w_k\\) sarà un numero negativo. Viene stimato un aggiustamento \\(u_{0j}\\) per ogni soggetto \\(j\\) e un aggiustamento \\(w_{0k}\\) per ogni item. Gli aggiustamenti \\(u_{0j}\\) e \\(w_{0k}\\) sono chiamati random intercepts o varying intercepts (Gelman, Hill, and Vehtari 2020). La modifica di \\(\\beta_0\\) mediante \\(u_{0j}\\) e \\(w_{0k}\\) consente dunque di tenere in considerazione la variabilità dovuta ai soggetti e agli item. Il random intercept model assume che gli aggiustamenti \\(u_{0j}\\) e \\(w_{0k}\\) siano distribuiti normalmente attorno allo zero con una deviazione standard sconosciuta: \\(u_0 ∼ \\mathcal{N}(0, \\sigma_u)\\) e \\(w_0 ∼ \\mathcal{N}(0, \\sigma_w)\\). Il modello include dunque tre fonti di varianza: la deviazione standard degli errori \\(\\sigma_e\\), la deviazione standard delle random intercepts per i soggetti, \\(\\sigma_u\\), e la deviazione standard delle random intercepts per gli item, \\(\\sigma_w\\). Queste tre fonti di variabilità sono dette componenti della varianza. Possiamo dunque scrivere: \\[\\begin{equation} \\log rt_{ijk} = \\beta_0 + \\beta_1 so_i + u_{0j} + w_{0k} + \\varepsilon_{ijk}. \\end{equation}\\] Il coefficiente \\(\\beta_1\\) è quello di interesse primario. Come conseguenza della codifica usata, avrà il valore \\(-\\beta_1\\) nella condizione in cui il sostantivo è riferito al soggetto e \\(+\\beta_1\\) nella condizione in cui il sostantivo è riferito all’oggetto della frase. In Stan il modello diventa: modelString = &quot; data { int&lt;lower=1&gt; N; //number of data points real rt[N]; //reading time real&lt;lower=-0.5, upper=0.5&gt; so[N]; //predictor int&lt;lower=1&gt; J; //number of subjects int&lt;lower=1&gt; K; //number of items int&lt;lower=1, upper=J&gt; subj[N]; //subject id int&lt;lower=1, upper=K&gt; item[N]; //item id } parameters { vector[2] beta; //fixed intercept and slope vector[J] u; //subject intercepts vector[K] w; //item intercepts real&lt;lower=0&gt; sigma_e; //error sd real&lt;lower=0&gt; sigma_u; //subj sd real&lt;lower=0&gt; sigma_w; //item sd } model { real mu; //priors u ~ normal(0, sigma_u); //subj random effects w ~ normal(0, sigma_w); //item random effects // likelihood for (i in 1:N){ mu = beta[1] + u[subj[i]] + w[item[i]] + beta[2] * so[i]; rt[i] ~ lognormal(mu, sigma_e); } } &quot; writeLines(modelString, con = &quot;code/random_intercepts_model.stan&quot;) file &lt;- file.path(&quot;code&quot;, &quot;random_intercepts_model.stan&quot;) mod &lt;- cmdstan_model(file) I dati sono stan_dat &lt;- list( subj = as.integer(as.factor(rdat$subj)), item = as.integer(as.factor(rdat$item)), rt = rdat$rt, so = rdat$so, N = nrow(rdat), J = length(unique(rdat$subj)), K = length(unique(rdat$item)) ) Eseguiamo il campionamento MCMC: fit4 &lt;- mod$sample( data = stan_dat, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) Otteniamo un oggetto di classe stanfit: stanfit &lt;- rstan::read_stan_csv(fit4$output_files()) Le medie a posteriori si ottengono con fit4$summary(c(&quot;beta&quot;, &quot;sigma_e&quot;, &quot;sigma_w&quot;, &quot;sigma_u&quot;)) #&gt; # A tibble: 5 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 beta[1] 6.35 6.35 0.0512 0.0511 6.26 6.43 1.00 1413. #&gt; 2 beta[2] -0.0604 -0.0604 0.0220 0.0218 -0.0974 -0.0243 1.00 17390. #&gt; 3 sigma_e 0.577 0.577 0.00792 0.00784 0.564 0.590 1.00 17746. #&gt; 4 sigma_w 0.120 0.115 0.0291 0.0263 0.0806 0.173 1.00 8584. #&gt; 5 sigma_u 0.238 0.235 0.0319 0.0304 0.191 0.293 1.00 11445. #&gt; # … with 1 more variable: ess_tail &lt;dbl&gt; Gli intervalli di credibilità sono: ci95 &lt;- rstanarm::posterior_interval( as.matrix(stanfit), prob = 0.95 ) round(ci95, 3) #&gt; 2.5% 97.5% #&gt; beta[1] 6.247 6.447 #&gt; beta[2] -0.104 -0.017 #&gt; u[1] -0.208 0.081 #&gt; u[2] -0.304 -0.012 #&gt; u[3] -0.127 0.163 #&gt; u[4] -0.212 0.079 #&gt; u[5] -0.079 0.216 #&gt; u[6] -0.049 0.239 #&gt; u[7] -0.162 0.131 #&gt; u[8] -0.124 0.168 #&gt; u[9] -0.097 0.196 #&gt; u[10] -0.009 0.283 #&gt; u[11] 0.450 0.745 #&gt; u[12] 0.149 0.443 #&gt; u[13] -0.169 0.123 #&gt; u[14] -0.151 0.140 #&gt; u[15] 0.035 0.324 #&gt; u[16] -0.199 0.089 #&gt; u[17] -0.716 -0.418 #&gt; u[18] -0.417 -0.127 #&gt; u[19] -0.295 0.003 #&gt; u[20] 0.162 0.452 #&gt; u[21] 0.050 0.341 #&gt; u[22] 0.123 0.418 #&gt; u[23] -0.197 0.096 #&gt; u[24] -0.084 0.293 #&gt; u[25] 0.000 0.292 #&gt; u[26] -0.494 -0.203 #&gt; u[27] -0.233 0.059 #&gt; u[28] -0.332 -0.038 #&gt; u[29] -0.423 -0.127 #&gt; u[30] -0.406 -0.113 #&gt; u[31] -0.100 0.188 #&gt; u[32] -0.178 0.113 #&gt; u[33] -0.239 0.056 #&gt; u[34] 0.257 0.554 #&gt; u[35] -0.396 -0.104 #&gt; u[36] -0.144 0.145 #&gt; u[37] -0.171 0.118 #&gt; w[1] -0.133 0.061 #&gt; w[2] -0.118 0.075 #&gt; w[3] -0.101 0.093 #&gt; w[4] -0.213 -0.015 #&gt; w[5] -0.006 0.190 #&gt; w[6] -0.141 0.056 #&gt; w[7] -0.281 -0.082 #&gt; w[8] 0.115 0.315 #&gt; w[9] -0.185 0.009 #&gt; w[10] -0.041 0.153 #&gt; w[11] -0.136 0.058 #&gt; w[12] -0.030 0.165 #&gt; w[13] -0.176 0.018 #&gt; w[14] 0.036 0.235 #&gt; w[15] -0.041 0.155 #&gt; sigma_e 0.562 0.593 #&gt; sigma_u 0.183 0.309 #&gt; sigma_w 0.076 0.188 #&gt; lp__ -2332.580 -2311.210 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
