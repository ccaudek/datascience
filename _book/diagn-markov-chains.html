<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capitolo 8 Diagnostica delle catene markoviane | A Minimal Book Example</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.26.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Capitolo 8 Diagnostica delle catene markoviane | A Minimal Book Example" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capitolo 8 Diagnostica delle catene markoviane | A Minimal Book Example" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Yihui Xie" />


<meta name="date" content="2022-04-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="stan-beta-binom.html"/>
<link rel="next" href="chapter-sintesi-distr-post.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="part"><span><b>I Inferenza bayesiana</b></span></li>
<li class="chapter" data-level="2" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html"><i class="fa fa-check"></i><b>2</b> Flusso di lavoro bayesiano</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#modellizzazione-bayesiana"><i class="fa fa-check"></i><b>2.1</b> Modellizzazione bayesiana</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#notazione"><i class="fa fa-check"></i><b>2.1.1</b> Notazione</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#distribuzioni-a-priori"><i class="fa fa-check"></i><b>2.2</b> Distribuzioni a priori</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#tipologie-di-distribuzioni-a-priori"><i class="fa fa-check"></i><b>2.2.1</b> Tipologie di distribuzioni a priori</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#selezione-della-distribuzione-a-priori"><i class="fa fa-check"></i><b>2.2.2</b> Selezione della distribuzione a priori</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#unapplicazione-empirica"><i class="fa fa-check"></i><b>2.2.3</b> Un’applicazione empirica</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#la-funzione-di-verosimiglianza"><i class="fa fa-check"></i><b>2.3</b> La funzione di verosimiglianza</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#notazione-1"><i class="fa fa-check"></i><b>2.3.1</b> Notazione</a></li>
<li class="chapter" data-level="2.3.2" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#la-log-verosimiglianza"><i class="fa fa-check"></i><b>2.3.2</b> La log-verosimiglianza</a></li>
<li class="chapter" data-level="2.3.3" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#unapplicazione-empirica-1"><i class="fa fa-check"></i><b>2.3.3</b> Un’applicazione empirica</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#sec:const-normaliz-bino23"><i class="fa fa-check"></i><b>2.4</b> La verosimiglianza marginale</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#unapplicazione-empirica-2"><i class="fa fa-check"></i><b>2.4.1</b> Un’applicazione empirica</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#distribuzione-a-posteriori"><i class="fa fa-check"></i><b>2.5</b> Distribuzione a posteriori</a></li>
<li class="chapter" data-level="2.6" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#distribuzione-predittiva-a-priori"><i class="fa fa-check"></i><b>2.6</b> Distribuzione predittiva a priori</a></li>
<li class="chapter" data-level="2.7" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#distribuzione-predittiva-a-posteriori"><i class="fa fa-check"></i><b>2.7</b> Distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html#commenti-e-considerazioni-finali"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-subj-think-prop.html"><a href="ch-subj-think-prop.html"><i class="fa fa-check"></i><b>3</b> Pensare ad una proporzione in termini soggettivi</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch-subj-think-prop.html"><a href="ch-subj-think-prop.html#ch-prior-discr-binom"><i class="fa fa-check"></i><b>3.1</b> Inferenza bayesiana con una distribuzione a priori discreta</a></li>
<li class="chapter" data-level="3.2" data-path="ch-subj-think-prop.html"><a href="ch-subj-think-prop.html#ch-prior-cont-binom"><i class="fa fa-check"></i><b>3.2</b> Inferenza bayesiana con una distribuzione a priori continua</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ch-subj-think-prop.html"><a href="ch-subj-think-prop.html#quali-parametri-per-la-distribuzione-beta"><i class="fa fa-check"></i><b>3.2.1</b> Quali parametri per la distribuzione Beta?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-subj-think-prop.html"><a href="ch-subj-think-prop.html#commenti-e-considerazioni-finali-1"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html"><i class="fa fa-check"></i><b>4</b> Distribuzioni coniugate</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#lo-schema-beta-binomiale"><i class="fa fa-check"></i><b>4.1</b> Lo schema beta-binomiale</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#la-specificazione-della-distribuzione-a-priori"><i class="fa fa-check"></i><b>4.1.1</b> La specificazione della distribuzione a priori</a></li>
<li class="chapter" data-level="4.1.2" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#la-specificazione-della-distribuzione-a-posteriori"><i class="fa fa-check"></i><b>4.1.2</b> La specificazione della distribuzione a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#inferenza-bayesiana-con-distribuzioni-a-priori-continue"><i class="fa fa-check"></i><b>4.2</b> Inferenza bayesiana con distribuzioni a priori continue</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#approccio-bayesiano-alla-verifica-di-ipotesi"><i class="fa fa-check"></i><b>4.2.1</b> Approccio bayesiano alla verifica di ipotesi</a></li>
<li class="chapter" data-level="4.2.2" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#intervalli-di-credibilità"><i class="fa fa-check"></i><b>4.2.2</b> Intervalli di credibilità</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#principali-distribuzioni-coniugate"><i class="fa fa-check"></i><b>4.3</b> Principali distribuzioni coniugate</a></li>
<li class="chapter" data-level="" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#commenti-e-considerazioni-finali-2"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter-balance.html"><a href="chapter-balance.html"><i class="fa fa-check"></i><b>5</b> L’influenza della distribuzione a priori</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chapter-balance.html"><a href="chapter-balance.html#il-test-di-benchdel"><i class="fa fa-check"></i><b>5.1</b> Il test di Benchdel</a></li>
<li class="chapter" data-level="5.2" data-path="chapter-balance.html"><a href="chapter-balance.html#stessi-dati-ma-diverse-distribuzioni-a-priori"><i class="fa fa-check"></i><b>5.2</b> Stessi dati ma diverse distribuzioni a priori</a></li>
<li class="chapter" data-level="5.3" data-path="chapter-balance.html"><a href="chapter-balance.html#dati-diversi-ma-la-stessa-distribuzione-a-priori"><i class="fa fa-check"></i><b>5.3</b> Dati diversi ma la stessa distribuzione a priori</a></li>
<li class="chapter" data-level="5.4" data-path="chapter-balance.html"><a href="chapter-balance.html#dati-diversi-e-diverse-distribuzioni-a-priori"><i class="fa fa-check"></i><b>5.4</b> Dati diversi e diverse distribuzioni a priori</a></li>
<li class="chapter" data-level="5.5" data-path="chapter-balance.html"><a href="chapter-balance.html#collegare-le-intuizioni-alla-teoria"><i class="fa fa-check"></i><b>5.5</b> Collegare le intuizioni alla teoria</a></li>
<li class="chapter" data-level="" data-path="chapter-balance.html"><a href="chapter-balance.html#commenti-e-considerazioni-finali-3"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch:metropolis.html"><a href="ch:metropolis.html"><i class="fa fa-check"></i><b>6</b> Approssimazione della distribuzione a posteriori</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ch:metropolis.html"><a href="ch:metropolis.html#metodo-basato-su-griglia"><i class="fa fa-check"></i><b>6.1</b> Metodo basato su griglia</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="ch:metropolis.html"><a href="ch:metropolis.html#modello-beta-binomiale"><i class="fa fa-check"></i><b>6.1.1</b> Modello Beta-Binomiale</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ch:metropolis.html"><a href="ch:metropolis.html#chapter-simulazioneMC"><i class="fa fa-check"></i><b>6.2</b> Metodo Monte Carlo</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ch:metropolis.html"><a href="ch:metropolis.html#integration-mc"><i class="fa fa-check"></i><b>6.2.1</b> Integrazione di Monte Carlo</a></li>
<li class="chapter" data-level="6.2.2" data-path="ch:metropolis.html"><a href="ch:metropolis.html#descrizione-intuitiva"><i class="fa fa-check"></i><b>6.2.2</b> Descrizione intuitiva</a></li>
<li class="chapter" data-level="6.2.3" data-path="ch:metropolis.html"><a href="ch:metropolis.html#unapplicazione-empirica-3"><i class="fa fa-check"></i><b>6.2.3</b> Un’applicazione empirica</a></li>
<li class="chapter" data-level="6.2.4" data-path="ch:metropolis.html"><a href="ch:metropolis.html#una-passeggiata-casuale-sui-numeri-naturali"><i class="fa fa-check"></i><b>6.2.4</b> Una passeggiata casuale sui numeri naturali</a></li>
<li class="chapter" data-level="6.2.5" data-path="ch:metropolis.html"><a href="ch:metropolis.html#lalgoritmo-di-metropolis"><i class="fa fa-check"></i><b>6.2.5</b> L’algoritmo di Metropolis</a></li>
<li class="chapter" data-level="6.2.6" data-path="ch:metropolis.html"><a href="ch:metropolis.html#unapplicazione-empirica-4"><i class="fa fa-check"></i><b>6.2.6</b> Un’applicazione empirica</a></li>
<li class="chapter" data-level="6.2.7" data-path="ch:metropolis.html"><a href="ch:metropolis.html#gibbs-sampling"><i class="fa fa-check"></i><b>6.2.7</b> Gibb’s sampling</a></li>
<li class="chapter" data-level="6.2.8" data-path="ch:metropolis.html"><a href="ch:metropolis.html#input"><i class="fa fa-check"></i><b>6.2.8</b> Input</a></li>
<li class="chapter" data-level="6.2.9" data-path="ch:metropolis.html"><a href="ch:metropolis.html#stazionarietà"><i class="fa fa-check"></i><b>6.2.9</b> Stazionarietà</a></li>
<li class="chapter" data-level="6.2.10" data-path="ch:metropolis.html"><a href="ch:metropolis.html#test-di-convergenza"><i class="fa fa-check"></i><b>6.2.10</b> Test di convergenza</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch:metropolis.html"><a href="ch:metropolis.html#commenti-e-considerazioni-finali-4"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html"><i class="fa fa-check"></i><b>7</b> Il modello beta-binomiale in linguaggio Stan</a>
<ul>
<li class="chapter" data-level="7.1" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html#il-presidente-trump-e-lidrossiclorochina"><i class="fa fa-check"></i><b>7.1</b> Il presidente Trump e l’idrossiclorochina</a></li>
<li class="chapter" data-level="7.2" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html#una-proporzione"><i class="fa fa-check"></i><b>7.2</b> Una proporzione</a></li>
<li class="chapter" data-level="7.3" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html#cmdstanr-gautret"><i class="fa fa-check"></i><b>7.3</b> Interfaccia <code>cmdstanr</code></a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html#fase-1"><i class="fa fa-check"></i><b>7.3.1</b> Fase 1</a></li>
<li class="chapter" data-level="7.3.2" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html#fase-2"><i class="fa fa-check"></i><b>7.3.2</b> Fase 2</a></li>
<li class="chapter" data-level="7.3.3" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html#burn-in"><i class="fa fa-check"></i><b>7.3.3</b> Burn-in</a></li>
<li class="chapter" data-level="7.3.4" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html#inferenza"><i class="fa fa-check"></i><b>7.3.4</b> Inferenza</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html#la-critica-di-hulme_2020"><i class="fa fa-check"></i><b>7.4</b> La critica di <span class="citation">Hulme et al. (<span>2020</span>)</span></a></li>
<li class="chapter" data-level="7.5" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html#due-proporzioni"><i class="fa fa-check"></i><b>7.5</b> Due proporzioni</a></li>
<li class="chapter" data-level="" data-path="stan-beta-binom.html"><a href="stan-beta-binom.html#commenti-e-considerazioni-finali-5"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="diagn-markov-chains.html"><a href="diagn-markov-chains.html"><i class="fa fa-check"></i><b>8</b> Diagnostica delle catene markoviane</a>
<ul>
<li class="chapter" data-level="8.1" data-path="diagn-markov-chains.html"><a href="diagn-markov-chains.html#esame-dei-trace-plot"><i class="fa fa-check"></i><b>8.1</b> Esame dei <em>trace plot</em></a></li>
<li class="chapter" data-level="8.2" data-path="diagn-markov-chains.html"><a href="diagn-markov-chains.html#confronto-delle-catene-parallele"><i class="fa fa-check"></i><b>8.2</b> Confronto delle catene parallele</a></li>
<li class="chapter" data-level="8.3" data-path="diagn-markov-chains.html"><a href="diagn-markov-chains.html#numerosita-campionaria-effettiva"><i class="fa fa-check"></i><b>8.3</b> Numerosità campionaria effettiva</a></li>
<li class="chapter" data-level="8.4" data-path="diagn-markov-chains.html"><a href="diagn-markov-chains.html#autocorrelazione"><i class="fa fa-check"></i><b>8.4</b> Autocorrelazione</a></li>
<li class="chapter" data-level="8.5" data-path="diagn-markov-chains.html"><a href="diagn-markov-chains.html#statistica-hatr"><i class="fa fa-check"></i><b>8.5</b> Statistica <span class="math inline">\(\hat{R}\)</span></a></li>
<li class="chapter" data-level="8.6" data-path="diagn-markov-chains.html"><a href="diagn-markov-chains.html#diagnostica-di-convergenza-di-geweke"><i class="fa fa-check"></i><b>8.6</b> Diagnostica di convergenza di Geweke</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html"><i class="fa fa-check"></i><b>9</b> Sintesi a posteriori</a>
<ul>
<li class="chapter" data-level="9.1" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#stima-puntuale"><i class="fa fa-check"></i><b>9.1</b> Stima puntuale</a></li>
<li class="chapter" data-level="9.2" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#intervallo-di-credibilità"><i class="fa fa-check"></i><b>9.2</b> Intervallo di credibilità</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#intervallo-di-credibilità-a-code-uguali"><i class="fa fa-check"></i><b>9.2.1</b> Intervallo di credibilità a code uguali</a></li>
<li class="chapter" data-level="9.2.2" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#intervallo-di-credibilità-a-densità-a-posteriori-più-alta"><i class="fa fa-check"></i><b>9.2.2</b> Intervallo di credibilità a densità a posteriori più alta</a></li>
<li class="chapter" data-level="9.2.3" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#interpretazione"><i class="fa fa-check"></i><b>9.2.3</b> Interpretazione</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#un-esempio-concreto"><i class="fa fa-check"></i><b>9.3</b> Un esempio concreto</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#stime-puntuali-della-distribuzione-a-posteriori"><i class="fa fa-check"></i><b>9.3.1</b> Stime puntuali della distribuzione a posteriori</a></li>
<li class="chapter" data-level="9.3.2" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#intervallo-di-credibilità-1"><i class="fa fa-check"></i><b>9.3.2</b> Intervallo di credibilità</a></li>
<li class="chapter" data-level="9.3.3" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#probabilità-della-distribuzione-a-posteriori"><i class="fa fa-check"></i><b>9.3.3</b> Probabilità della distribuzione a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#la-funzione-di-perdita-attesa"><i class="fa fa-check"></i><b>9.4</b> La funzione di perdita attesa</a></li>
<li class="chapter" data-level="" data-path="chapter-sintesi-distr-post.html"><a href="chapter-sintesi-distr-post.html#commenti-e-considerazioni-finali-6"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-prediction.html"><a href="ch-prediction.html"><i class="fa fa-check"></i><b>10</b> La predizione bayesiana</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ch-prediction.html"><a href="ch-prediction.html#la-distribuzione-predittiva"><i class="fa fa-check"></i><b>10.1</b> La distribuzione predittiva</a></li>
<li class="chapter" data-level="10.2" data-path="ch-prediction.html"><a href="ch-prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-simulazione"><i class="fa fa-check"></i><b>10.2</b> La distribuzione predittiva a posteriori mediante simulazione</a></li>
<li class="chapter" data-level="10.3" data-path="ch-prediction.html"><a href="ch-prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-mcmc"><i class="fa fa-check"></i><b>10.3</b> La distribuzione predittiva a posteriori mediante MCMC</a></li>
<li class="chapter" data-level="10.4" data-path="ch-prediction.html"><a href="ch-prediction.html#i-metodi-per-la-valutazione-del-modello"><i class="fa fa-check"></i><b>10.4</b> I metodi per la valutazione del modello</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="ch-prediction.html"><a href="ch-prediction.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>10.4.1</b> Posterior predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="ch-prediction.html"><a href="ch-prediction.html#distribuzione-predittiva-a-priori-1"><i class="fa fa-check"></i><b>10.5</b> Distribuzione predittiva a priori</a></li>
<li class="chapter" data-level="" data-path="ch-prediction.html"><a href="ch-prediction.html#commenti-e-considerazioni-finali-7"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="normal-normal-mod-stan.html"><a href="normal-normal-mod-stan.html"><i class="fa fa-check"></i><b>11</b> Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</a>
<ul>
<li class="chapter" data-level="11.1" data-path="normal-normal-mod-stan.html"><a href="normal-normal-mod-stan.html#caso-normale-normale-con-varianza-nota"><i class="fa fa-check"></i><b>11.1</b> Caso Normale-Normale con varianza nota</a></li>
<li class="chapter" data-level="11.2" data-path="normal-normal-mod-stan.html"><a href="normal-normal-mod-stan.html#derivazione-analitica-della-distribuzione-a-posteriori-pmu-mid-y"><i class="fa fa-check"></i><b>11.2</b> Derivazione analitica della distribuzione a posteriori <span class="math inline">\(p(\mu \mid y)\)</span></a></li>
<li class="chapter" data-level="11.3" data-path="normal-normal-mod-stan.html"><a href="normal-normal-mod-stan.html#il-modello-normale-con-stan"><i class="fa fa-check"></i><b>11.3</b> Il modello Normale con Stan</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="normal-normal-mod-stan.html"><a href="normal-normal-mod-stan.html#versione-1-sigma-nota"><i class="fa fa-check"></i><b>11.3.1</b> Versione 1 (<span class="math inline">\(\sigma\)</span> nota)</a></li>
<li class="chapter" data-level="11.3.2" data-path="normal-normal-mod-stan.html"><a href="normal-normal-mod-stan.html#versione-2-sigma-incognita"><i class="fa fa-check"></i><b>11.3.2</b> Versione 2 (<span class="math inline">\(\sigma\)</span> incognita)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="normal-normal-mod-stan.html"><a href="normal-normal-mod-stan.html#commenti-e-considerazioni-finali-8"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal Book Example</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="diagn-markov-chains" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Capitolo 8</span> Diagnostica delle catene markoviane<a href="diagn-markov-chains.html#diagn-markov-chains" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Come discusso nel Paragrafo <a href="stan-beta-binom.html#cmdstanr-gautret">7.3</a>, le catene di Markov forniscono un’approssimazione che tende a convergere alla distribuzione a posteriori. “Approssimazione” e “convergenza” sono le parole chiave qui: il punto è che il campionamento MCMC non è perfetto. Questo solleva le seguenti domande:</p>
<ul>
<li>A cosa corrisponde, dal punto di vista grafico, una “buona” catena di Markov?</li>
<li>Come possiamo sapere se il campione prodotto dalla catena di Markov costituisce un’approssimazione adeguata della distribuzione a posteriori?</li>
<li>Quanto deve essere grande la dimensione del campione casuale prodotto dalla catena Markov?</li>
</ul>
<p>Rispondere a queste ed altre domande di questo tipo fa parte di quell’insieme di pratiche che vano sotto il nome di <em>diagnostica delle catene Markoviane</em>.</p>
<p>La diagnostica delle catene Markoviane non è “una scienza esatta”. Ovvero, non sono disponibili procedure che risultano valide in tutti i casi possibili e non sempre siamo in grado di rispondere a tutte le domande precedenti. È piuttosto l’esperienza del ricercatore che consente di riconoscere una “buona” catena di Markov e a suggerire cosa si può fare per riparare una “cattiva” catena di Markov. In questo Capitolo ci concentreremo su alcuni strumenti diagnostici grafici e numerici che possono essere utilizzati per la diagnostica delle catene markoviane. L’utilizzo di questi strumenti diagnostici deve essere eseguito in modo olistico. Nessuna singola diagnostica visiva o numerica è sufficiente: un quadro completo della qualità della catena di Markov si può solo ottenere considerando tutti gli strumenti descritti di seguito.</p>
<div id="esame-dei-trace-plot" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Esame dei <em>trace plot</em><a href="diagn-markov-chains.html#esame-dei-trace-plot" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La convergenza e il “mixing” possono essere controllate mediante il <em>trace plot</em> che mostra l’andamento delle simulazioni e ci dice se stiamo effettivamente utilizzando una distribuzione limite. Consideriamo nuovamente il <em>trace plot</em> del simulazione Beta-Binomiale della figura <a href="diagn-markov-chains.html#fig:trace-plot-gautret-2">8.1</a>:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:trace-plot-gautret-2"></span>
<img src="bookdown-demo_files/figure-html/trace-plot-gautret-2-1.png" alt="Trace plot per il modello Beta-Binomiale dei dati di Gautret et al.(2020)." width="576" />
<p class="caption">
FIGURA 8.1: Trace plot per il modello Beta-Binomiale dei dati di Gautret et al.(2020).
</p>
</div>
<p>La figura <a href="diagn-markov-chains.html#fig:trace-plot-gautret-2">8.1</a> fornisce un esempio perfetto di come dovrebbero apparire i <em>trace plot</em>. Quando le catene markoviane raggiungono uno stato stazionario e sono stabili ciò significa che hanno raggiunto la distribuzione stazionaria e il <em>trace plot</em> rivela un’assenza di struttura e diventa simile alla rappresentazione del rumore bianco, come nella figura <a href="diagn-markov-chains.html#fig:trace-plot-gautret-2">8.1</a>.</p>
<p>Una mancanza di convergenza è invece indicata dalla figura <a href="diagn-markov-chains.html#fig:bad-trace-bayesrules">8.2</a><a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bad-trace-bayesrules"></span>
<img src="images/bad-trace-bayesrules.png" alt="Trace plots (a sinistra) e corrispondenti grafici di densità (a destra) di due ipotetiche catene di Markov. Queste figure forniscono due esempi di come potrebbero apparire delle catene di Markov non stazionarie. Le linee nere sovrapposte alle densità empiriche (a destra) rappresentano una ipotetica distribuzione target Beta(11,3)." width="1181" />
<p class="caption">
FIGURA 8.2: Trace plots (a sinistra) e corrispondenti grafici di densità (a destra) di due ipotetiche catene di Markov. Queste figure forniscono due esempi di come potrebbero apparire delle catene di Markov non stazionarie. Le linee nere sovrapposte alle densità empiriche (a destra) rappresentano una ipotetica distribuzione target Beta(11,3).
</p>
</div>
<p>Nel trace-plot della figura <a href="diagn-markov-chains.html#fig:bad-trace-bayesrules">8.2</a>, la tendenza verso il basso indica che la catena A non è stazionaria, ovvero non si mantiene costante all’evolversi nel tempo. La tendenza verso il basso suggerisce inoltre la presenza di una forte correlazione tra i valori della catena: il trace-plot non fornisce una rappresentazione di rumore indipendente. Tutto questo significa che la catena A “si sta mescolando lentamente”. Sebbene le catene di Markov siano intrinsecamente dipendenti, più si comportano come se fossero dei campioni casuali (rumorosi), minore è l’errore dell’approssimazione alla distribuzione a posteriori.</p>
<p>La catena B presenta un problema diverso. Come evidenziato dalle due linee completamente piatte nel tracciato, essa tende a bloccarsi quando visita valori bassi di <span class="math inline">\(\theta\)</span>.</p>
<p>Gli istogrammi lisciati della figura <a href="diagn-markov-chains.html#fig:bad-trace-bayesrules">8.2</a> (a destra) confermano che entrambe queste catene sono problematiche: infatti producono approssimazioni scadenti della distribuzione a posteriori che, nell’esempio di <span class="citation">Johnson, Ott, and Dogucu (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span>, è una <span class="math inline">\(\mbox{Beta}(11, 3)\)</span> (la curva nera nella figura). Consideriamo la catena A. Dal momento che si sta mescolando lentamente, nelle iterazioni eseguite ha esplorato unicamente i valori <span class="math inline">\(\theta\)</span> nell’intervallo da 0.6 a 0.9. Di conseguenza, la sua approssimazione della distribuzione a posteriori sopravvaluta la plausibilità dei valori <span class="math inline">\(\theta\)</span> in questo intervallo e, nel contempo, sottovaluta la plausibilità dei valori <span class="math inline">\(\theta\)</span> esterni a questo intervallo. Consideriamo ora la catena B. Rimanendo bloccata, la catena B campiona in maniera eccessiva alcuni valori nella coda sinistra della distribuzione a posteriori di <span class="math inline">\(\theta\)</span>. Questo fenomeno produce i picchi che sono presenti nell’approssimazione alla distribuzione a posteriori.</p>
<p>In pratica, al di là dei presenti esempi “scolastici” (in cui disponiamo di una formulazione analitica della distribuzione a posteriori), non abbiamo mai il privilegio di poter confrontare i risultati del campionamento MCMC con la corretta distribuzione a posteriori. Ecco perché la diagnostica delle catene di Markov è così importante: se vediamo trace-plots come quelli della figura <a href="diagn-markov-chains.html#fig:bad-trace-bayesrules">8.2</a>, sappiamo che non abbiamo ottenuto una adeguata approssimazione della distribuzione a posteriori.</p>
<p>In tali circostanze possiamo ricorrere ad alcuni rimedi.</p>
<ol style="list-style-type: decimal">
<li>Controllare il modello. Siamo sicuri che le distribuzioni a priori e la verosimiglianza siano appropriate per i dati osservati?</li>
<li>Utilizzare un numero maggiore di iterazioni. Alcune tendenze indesiderate a breve termine della catena possono appianarsi nel lungo termine.</li>
</ol>
</div>
<div id="confronto-delle-catene-parallele" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Confronto delle catene parallele<a href="diagn-markov-chains.html#confronto-delle-catene-parallele" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Nella simulazione <code>cmdstanr()</code> per il modello beta-binomiale dei dati di <span class="citation">Gautret et al. (<a href="#ref-Gautret_2020" role="doc-biblioref">2020</a>)</span> abbiamo utilizzato quattro catene di Markov parallele. Non solo è necessario che ogni singola catena sia stazionaria (come discusso sopra), ma è anche necessario che le quattro catene siano coerenti tra loro. Sebbene le catene esplorino percorsi diversi nello spazio dei parametri, quando convergono ad uno stato di equilibrio dovrebbero presentare caratteristiche simili e dovrebbero produrre approssimazioni simili alla distribuzione a posteriori. Per il caso beta-binomiale dei dati di <span class="citation">Gautret et al. (<a href="#ref-Gautret_2020" role="doc-biblioref">2020</a>)</span>, gli istogrammi lisciati della figura seguente indicano che le quattro catene producono approssimazioni della distribuzione a posteriori quasi indistinguibili tra loro. Ciò prova che la simulazione è stabile e contiene un nunero sufficiente di valori: l’esecuzione delle catene per un numero maggiore di iterazioni non porterebbe ad un miglioramento della stima della distribuzione a posteriori.</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="diagn-markov-chains.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_dens_overlay</span>(stanfit1, <span class="at">pars =</span> <span class="st">&quot;theta&quot;</span>) <span class="sc">+</span> </span>
<span id="cb127-2"><a href="diagn-markov-chains.html#cb127-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;density&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-123-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Per fare un confronto, per lo stesso modello, consideriamo la simulazione di una catena di Markov più corta. La chiamata seguente richiede quattro catene parallele per sole 100 iterazioni ciascuna:</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="diagn-markov-chains.html#cb128-1" aria-hidden="true" tabindex="-1"></a>bb_short <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb128-2"><a href="diagn-markov-chains.html#cb128-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data1_list,</span>
<span id="cb128-3"><a href="diagn-markov-chains.html#cb128-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> <span class="dv">50</span><span class="sc">*</span>2L,</span>
<span id="cb128-4"><a href="diagn-markov-chains.html#cb128-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">84735</span>,</span>
<span id="cb128-5"><a href="diagn-markov-chains.html#cb128-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb128-6"><a href="diagn-markov-chains.html#cb128-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">parallel_chains =</span> 4L,</span>
<span id="cb128-7"><a href="diagn-markov-chains.html#cb128-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb128-8"><a href="diagn-markov-chains.html#cb128-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">thin =</span> <span class="dv">1</span></span>
<span id="cb128-9"><a href="diagn-markov-chains.html#cb128-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb128-10"><a href="diagn-markov-chains.html#cb128-10" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Running MCMC with <span class="dv">4</span> parallel chains...</span>
<span id="cb128-11"><a href="diagn-markov-chains.html#cb128-11" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> </span>
<span id="cb128-12"><a href="diagn-markov-chains.html#cb128-12" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Chain <span class="dv">1</span> finished <span class="cf">in</span> <span class="fl">0.0</span> seconds.</span>
<span id="cb128-13"><a href="diagn-markov-chains.html#cb128-13" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Chain <span class="dv">2</span> finished <span class="cf">in</span> <span class="fl">0.0</span> seconds.</span>
<span id="cb128-14"><a href="diagn-markov-chains.html#cb128-14" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Chain <span class="dv">3</span> finished <span class="cf">in</span> <span class="fl">0.0</span> seconds.</span>
<span id="cb128-15"><a href="diagn-markov-chains.html#cb128-15" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Chain <span class="dv">4</span> finished <span class="cf">in</span> <span class="fl">0.0</span> seconds.</span>
<span id="cb128-16"><a href="diagn-markov-chains.html#cb128-16" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> </span>
<span id="cb128-17"><a href="diagn-markov-chains.html#cb128-17" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> All <span class="dv">4</span> chains finished successfully.</span>
<span id="cb128-18"><a href="diagn-markov-chains.html#cb128-18" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Mean chain execution time<span class="sc">:</span> <span class="fl">0.0</span> seconds.</span>
<span id="cb128-19"><a href="diagn-markov-chains.html#cb128-19" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Total execution time<span class="sc">:</span> <span class="fl">0.2</span> seconds.</span>
<span id="cb128-20"><a href="diagn-markov-chains.html#cb128-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-21"><a href="diagn-markov-chains.html#cb128-21" aria-hidden="true" tabindex="-1"></a>stanfit_bb_short <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(bb_short<span class="sc">$</span><span class="fu">output_files</span>())</span></code></pre></div>
<p>Di seguito sono riportati i <em>trace-plot</em> e i corrispondenti istogrammi lisciati.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="diagn-markov-chains.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_trace</span>(stanfit_bb_short, <span class="at">pars =</span> <span class="st">&quot;theta&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-125-1.png" width="576" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="diagn-markov-chains.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_dens_overlay</span>(stanfit_bb_short, <span class="at">pars =</span> <span class="st">&quot;theta&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-126-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Anche se i <em>trace plot</em> sembrano tutti mostrare un andamento casuale, gli istogrammi lisciati sono piuttosto diversi tra loro e producono approssimazioni diverse della distribuzione a posteriori. Di fronte a tale instabilità è chiaro che sarebbe un errore interrompere la simulazione dopo solo 100 iterazioni.</p>
</div>
<div id="numerosita-campionaria-effettiva" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Numerosità campionaria effettiva<a href="diagn-markov-chains.html#numerosita-campionaria-effettiva" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Nella simulazione del modello beta-binomiale per i dati di <span class="citation">Gautret et al. (<a href="#ref-Gautret_2020" role="doc-biblioref">2020</a>)</span> abbiamo utilizzato quattro catene di Markov parallele che producono un totale di <span class="math inline">\(N\)</span> = 16000 campioni <em>dipendenti</em> di <span class="math inline">\(\theta\)</span>. Sapendo che l’errore dell’approssimazione alla distribuzione a posteriori è probabilmente più grande di quello che si otterrebbe usando 16000 campioni <em>indipendenti</em>, ci possiamo porre la seguente domanda: quanti campioni indipendenti sarebbero necessari per produrre un’approssimazione della distribuzione a posteriori equivalentemente a quella che abbiamo ottenuto? La numerosità campionaria effettiva (<em>effective sample size</em>, <span class="math inline">\(N_{eff}\)</span>) fornisce una risposta a questa domanda.</p>
<p>Tipicamente, <span class="math inline">\(N_{eff} &lt; N\)</span>, per cui il rapporto campionario effettivo (<em>effective sample size ratio</em>) <span class="math inline">\(\frac{N_{eff}}{N}\)</span> è minore di 1. Come regola euristica, viene considerato problematico un rapporto campionario effettivo minore del 10% del numero totale di campioni ottenuti nella simulazione (più basso è il rapporto campionario effettivo peggiore è il “mixing” della catena). La funzione <code>bayesplot::neff_ratio()</code> consente di calcolare il rapporto campionario effettivo. Per il modello Beta-Binomiale dei dati di <span class="citation">Gautret et al. (<a href="#ref-Gautret_2020" role="doc-biblioref">2020</a>)</span>, questo rapporto è di circa 0.34:</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="diagn-markov-chains.html#cb131-1" aria-hidden="true" tabindex="-1"></a>bayesplot<span class="sc">::</span><span class="fu">neff_ratio</span>(stanfit1, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;theta&quot;</span>))</span>
<span id="cb131-2"><a href="diagn-markov-chains.html#cb131-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.3629411</span></span></code></pre></div>
<p>Ciò indica che l’accuratezza dell’approssimazione della distribuzione a posteriori di <span class="math inline">\(\theta\)</span> ottenuta mediante 16000 campioni dipendenti è approssimativamente simile a quella che si potrebbe ottenere con</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="diagn-markov-chains.html#cb132-1" aria-hidden="true" tabindex="-1"></a>bayesplot<span class="sc">::</span><span class="fu">neff_ratio</span>(</span>
<span id="cb132-2"><a href="diagn-markov-chains.html#cb132-2" aria-hidden="true" tabindex="-1"></a>  stanfit1, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;theta&quot;</span>)</span>
<span id="cb132-3"><a href="diagn-markov-chains.html#cb132-3" aria-hidden="true" tabindex="-1"></a>) <span class="sc">*</span> <span class="dv">16000</span></span>
<span id="cb132-4"><a href="diagn-markov-chains.html#cb132-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 5807.058</span></span></code></pre></div>
<p>campioni <em>indipendenti</em>. In questo esempio, il rapporto campionario effettivo è maggiore di 0.1; dunque non ci sono problemi.</p>
</div>
<div id="autocorrelazione" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Autocorrelazione<a href="diagn-markov-chains.html#autocorrelazione" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Normalmente un algoritmo MCMC genera catene di Markov di campioni, ognuno dei quali è autocorrelato a quelli generati immediatamente prima e dopo di lui. Conseguentemente campioni successivi non sono indipendenti ma formano una catena di Markov con un certo grado di correlazione. Il valore <span class="math inline">\(\theta^{(i)}\)</span> tende ad essere più simile al valore <span class="math inline">\(\theta^{(i-1)}\)</span> che al valore <span class="math inline">\(\theta^{(i-2)}\)</span>, o al valore <span class="math inline">\(\theta^{(i-3)}\)</span>, eccetera. Una misura di ciò è fornita dall’autocorrelazione tra i valori consecutivi della catena.</p>
<p>Il correlogramma per ciascuna delle quattro catene dell’esempio si produce con la seguente chiamata:</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="diagn-markov-chains.html#cb133-1" aria-hidden="true" tabindex="-1"></a>bayesplot<span class="sc">::</span><span class="fu">mcmc_acf</span>(stanfit1, <span class="at">pars =</span> <span class="st">&quot;theta&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-129-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Il correlogramma mostra l’autocorrelazione in funzione di ritardi da 0 a 20. L’autocorrelazione di lag 0 è naturalmente 1 – misura la correlazione tra un valore della catena di Markov e se stesso. L’autocorrelazione di lag 1 è di circa 0.5, indicando una correlazione moderata tra i valori della catena che distano di solo 1 passo l’uno dall’altro. Successivamente, l’autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per un lag di 5. Questo risultato fornisce una conferma del fatto che la catena di Markov costituisce una buona approssimazione di un campione casuale di <span class="math inline">\(p(\theta \mid y)\)</span>.</p>
Al contrario, nella figura <a href="diagn-markov-chains.html#fig:bad-autocorrelation">8.3</a> (a destra) <span class="citation">(riprodotta da <a href="#ref-Johnson2022bayesrules" role="doc-biblioref">Johnson, Ott, and Dogucu 2022</a>)</span> vediamo un esempio nel quale il trace plot rivela una forte tendenza tra i valori di una catena di Markov e, dunque, una forte autocorrelazione.
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bad-autocorrelation"></span>
<img src="images/ch6-acf-2-1.png" alt="Trace plot (a sinistra) e correlogramma (a destra) di una catena di Markow in cui il mixing è lento -- figura riprodotta da @Johnson2022bayesrules." width="1181" />
<p class="caption">
FIGURA 8.3: Trace plot (a sinistra) e correlogramma (a destra) di una catena di Markow in cui il mixing è lento – figura riprodotta da <span class="citation">Johnson, Ott, and Dogucu (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span>.
</p>
</div>
<p>Questa osservazione è confermata nell’correlogramma (a destra). La lenta diminuzione della curva di autocorrelazione indica che la dipendenza tra i valori della catena non svanisce rapidamente. Con un lag di 20 la correlazione è addirittura pari a 0.9. Poiché i valori della catena sono fortemente associati tra loro, il “mixing” è lento: la simulazione richiede un numero molto grande di iterazioni per esplorare adeguatamente l’intera gamma di valori della distribuzione a posteriori.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></p>
<p>In presenza di catene di Markov non <em>rapidly mixing</em> sono possibili due rimedi.</p>
<ul>
<li>Aumentare il numero di iterazioni. Anche una catena non <em>rapidly mixing</em> può produrre eventualmente una buona approssimazione della distribuzione a posteriori se il numero di iterazioni è sufficientemente grande.</li>
<li><em>Thinning</em>. Per esempio, se la catena di Markov è costituita da 16000 valori di <span class="math inline">\(\theta\)</span>, potremmo decidere di conservare solo ogni secondo valore e ignorare gli altri valori: <span class="math inline">\(\{\theta^{(2)}, \theta^{(4)}, \theta^{(6)}, \dots, \theta^{(16000)}\}\)</span>. Oppure, potremmo decidere di conservare ogni decimo valore: <span class="math inline">\(\{\theta^{(10)}, \theta^{(20)}, \theta^{(30)}, \dots, \theta^{(16000)}\}\)</span>. Scartando i campioni intermedi, è possibile rimuovere le forti correlazioni che sono presenti nel caso di lag più piccoli.</li>
</ul>
<p>Vediamo ora come sia possibile estrarre i valodi di una catena dall’oggetto <code>stanfit1</code>.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="diagn-markov-chains.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="co"># valori delle 4 catene</span></span>
<span id="cb134-2"><a href="diagn-markov-chains.html#cb134-2" aria-hidden="true" tabindex="-1"></a>S <span class="ot">&lt;-</span> ggmcmc<span class="sc">::</span><span class="fu">ggs</span>(stanfit1)</span>
<span id="cb134-3"><a href="diagn-markov-chains.html#cb134-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(S)</span>
<span id="cb134-4"><a href="diagn-markov-chains.html#cb134-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 4</span></span>
<span id="cb134-5"><a href="diagn-markov-chains.html#cb134-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Iteration Chain Parameter value</span></span>
<span id="cb134-6"><a href="diagn-markov-chains.html#cb134-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;     &lt;dbl&gt;</span></span>
<span id="cb134-7"><a href="diagn-markov-chains.html#cb134-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1         1     1 theta     0.628</span></span>
<span id="cb134-8"><a href="diagn-markov-chains.html#cb134-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2         2     1 theta     0.758</span></span>
<span id="cb134-9"><a href="diagn-markov-chains.html#cb134-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3         3     1 theta     0.719</span></span>
<span id="cb134-10"><a href="diagn-markov-chains.html#cb134-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4         4     1 theta     0.715</span></span>
<span id="cb134-11"><a href="diagn-markov-chains.html#cb134-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5         5     1 theta     0.856</span></span>
<span id="cb134-12"><a href="diagn-markov-chains.html#cb134-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6         6     1 theta     0.870</span></span></code></pre></div>
<p>La prima catena può essere isolata nel modo seguente:</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="diagn-markov-chains.html#cb135-1" aria-hidden="true" tabindex="-1"></a>S1 <span class="ot">&lt;-</span> S <span class="sc">%&gt;%</span> </span>
<span id="cb135-2"><a href="diagn-markov-chains.html#cb135-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(</span>
<span id="cb135-3"><a href="diagn-markov-chains.html#cb135-3" aria-hidden="true" tabindex="-1"></a>    Chain <span class="sc">==</span> <span class="dv">1</span>,</span>
<span id="cb135-4"><a href="diagn-markov-chains.html#cb135-4" aria-hidden="true" tabindex="-1"></a>    Parameter <span class="sc">==</span> <span class="st">&quot;theta&quot;</span></span>
<span id="cb135-5"><a href="diagn-markov-chains.html#cb135-5" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p>Una serie temporale della catena si ottiene con la funzione <code>ggmcmc::ggs_running</code>:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="diagn-markov-chains.html#cb136-1" aria-hidden="true" tabindex="-1"></a>ggmcmc<span class="sc">::</span><span class="fu">ggs_running</span>(S1)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-132-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Il grafico precedente mostra che, per il modello bayesiano che stiamo discutendo, una condizione di equilibrio della catena di Markov richiederebbe un numero maggiore di iterazioni di quelle che sono state effettivamente simulate.</p>
<p>L’autocorrelazione di ordine 1 si ottiene nel modo seguente (si veda il Paragrafo <a href="ch:metropolis.html#approx-post-autocor">6.2.9.1</a>):</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="diagn-markov-chains.html#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(S1<span class="sc">$</span>value[<span class="sc">-</span><span class="fu">length</span>(S1<span class="sc">$</span>value)], S1<span class="sc">$</span>value[<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb137-2"><a href="diagn-markov-chains.html#cb137-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.3819515</span></span></code></pre></div>
<p>Questo valore corrisponde a ciò che è riportato nel correlogramma mostrato sopra.</p>
</div>
<div id="statistica-hatr" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> Statistica <span class="math inline">\(\hat{R}\)</span><a href="diagn-markov-chains.html#statistica-hatr" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In precedenza abbiamo detto che non solo è necessario che ogni singola catena sia stazionaria, è anche necessario che le diverse catene siano coerenti tra loro. La statistica <span class="math inline">\(\hat{R}\)</span> affronta questo problema calcolando il rapporto tra la varianza tra le catene markoviane e la varianza entro le catene. In una situazione ottimale <span class="math inline">\(\hat{R} = 1\)</span>; se <span class="math inline">\(\hat{R}\)</span> è lontano da 1 questo vuol dire che non è ancora stata raggiunta la convergenza.</p>
<p>È possibile calcolare <span class="math inline">\(\hat{R}\)</span> mediante la chiamata alla funzione <code>bayesplot::rhat()</code>. Per il modello Beta-Binomiale applicato ai dati di <span class="citation">Gautret et al. (<a href="#ref-Gautret_2020" role="doc-biblioref">2020</a>)</span> abbiamo:</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="diagn-markov-chains.html#cb138-1" aria-hidden="true" tabindex="-1"></a>bayesplot<span class="sc">::</span><span class="fu">rhat</span>(stanfit1, <span class="at">pars =</span> <span class="st">&quot;theta&quot;</span>)</span>
<span id="cb138-2"><a href="diagn-markov-chains.html#cb138-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.00039</span></span></code></pre></div>
<p>il che indica che il valore <span class="math inline">\(\hat{R}\)</span> ottenuto è molto simile al valore ottimale.</p>
<p>In maniera euristica, si può affermare che se <span class="math inline">\(\hat{R}\)</span> supera la soglia di 1.05 questo viene interpretato come evidenza che le diverse catene parallele non producono approssimazioni coerenti della distribuzione a posteriori, quindi la simulazione è instabile.</p>
<p>Una rappresentazione grafica dei valori <span class="math inline">\(\hat{R}\)</span> per tutti i parametri del modello si ottiene con la seguente chiamata:</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="diagn-markov-chains.html#cb139-1" aria-hidden="true" tabindex="-1"></a>ggmcmc<span class="sc">::</span><span class="fu">ggs_Rhat</span>(S) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;R_hat&quot;</span>) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="fl">0.95</span>, <span class="fl">1.05</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-135-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="diagnostica-di-convergenza-di-geweke" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> Diagnostica di convergenza di Geweke<a href="diagn-markov-chains.html#diagnostica-di-convergenza-di-geweke" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La statistica diagnostica di convergenza di Geweke è basata su un test per l’uguaglianza delle medie della prima e dell’ultima parte di una catena di Markov (di default il primo 10% e l’ultimo 50% della catena). Se i due campioni sono estratti dalla distribuzione stazionaria della catena, le due medie sono statisticamente uguali e la statistica di Geweke ha una distribuzione asintotica Normale standardizzata.</p>
<p>Utilizzando l’oggetto <code>stanfit1</code>, possiamo recuperare la statistica di Geweke nel modo seguente:</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="diagn-markov-chains.html#cb140-1" aria-hidden="true" tabindex="-1"></a>fit_mcmc <span class="ot">&lt;-</span> <span class="fu">As.mcmc.list</span>(</span>
<span id="cb140-2"><a href="diagn-markov-chains.html#cb140-2" aria-hidden="true" tabindex="-1"></a>  stanfit1,</span>
<span id="cb140-3"><a href="diagn-markov-chains.html#cb140-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;theta&quot;</span>)</span>
<span id="cb140-4"><a href="diagn-markov-chains.html#cb140-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb140-5"><a href="diagn-markov-chains.html#cb140-5" aria-hidden="true" tabindex="-1"></a>coda<span class="sc">::</span><span class="fu">geweke.diag</span>(fit_mcmc, <span class="at">frac1 =</span> .<span class="dv">1</span>, <span class="at">frac2 =</span> .<span class="dv">5</span>) </span>
<span id="cb140-6"><a href="diagn-markov-chains.html#cb140-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [[1]]</span></span>
<span id="cb140-7"><a href="diagn-markov-chains.html#cb140-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-8"><a href="diagn-markov-chains.html#cb140-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Fraction in 1st window = 0.1</span></span>
<span id="cb140-9"><a href="diagn-markov-chains.html#cb140-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Fraction in 2nd window = 0.5 </span></span>
<span id="cb140-10"><a href="diagn-markov-chains.html#cb140-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-11"><a href="diagn-markov-chains.html#cb140-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  theta </span></span>
<span id="cb140-12"><a href="diagn-markov-chains.html#cb140-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -0.017 </span></span>
<span id="cb140-13"><a href="diagn-markov-chains.html#cb140-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-14"><a href="diagn-markov-chains.html#cb140-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-15"><a href="diagn-markov-chains.html#cb140-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [[2]]</span></span>
<span id="cb140-16"><a href="diagn-markov-chains.html#cb140-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-17"><a href="diagn-markov-chains.html#cb140-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Fraction in 1st window = 0.1</span></span>
<span id="cb140-18"><a href="diagn-markov-chains.html#cb140-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Fraction in 2nd window = 0.5 </span></span>
<span id="cb140-19"><a href="diagn-markov-chains.html#cb140-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-20"><a href="diagn-markov-chains.html#cb140-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  theta </span></span>
<span id="cb140-21"><a href="diagn-markov-chains.html#cb140-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.6504 </span></span>
<span id="cb140-22"><a href="diagn-markov-chains.html#cb140-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-23"><a href="diagn-markov-chains.html#cb140-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-24"><a href="diagn-markov-chains.html#cb140-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [[3]]</span></span>
<span id="cb140-25"><a href="diagn-markov-chains.html#cb140-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-26"><a href="diagn-markov-chains.html#cb140-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Fraction in 1st window = 0.1</span></span>
<span id="cb140-27"><a href="diagn-markov-chains.html#cb140-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Fraction in 2nd window = 0.5 </span></span>
<span id="cb140-28"><a href="diagn-markov-chains.html#cb140-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-29"><a href="diagn-markov-chains.html#cb140-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    theta </span></span>
<span id="cb140-30"><a href="diagn-markov-chains.html#cb140-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -0.04024 </span></span>
<span id="cb140-31"><a href="diagn-markov-chains.html#cb140-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-32"><a href="diagn-markov-chains.html#cb140-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-33"><a href="diagn-markov-chains.html#cb140-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [[4]]</span></span>
<span id="cb140-34"><a href="diagn-markov-chains.html#cb140-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-35"><a href="diagn-markov-chains.html#cb140-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Fraction in 1st window = 0.1</span></span>
<span id="cb140-36"><a href="diagn-markov-chains.html#cb140-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Fraction in 2nd window = 0.5 </span></span>
<span id="cb140-37"><a href="diagn-markov-chains.html#cb140-37" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb140-38"><a href="diagn-markov-chains.html#cb140-38" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; theta </span></span>
<span id="cb140-39"><a href="diagn-markov-chains.html#cb140-39" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1.315</span></span></code></pre></div>
<p>Per interpretare questi valori ricordiamo che la statistica di Geweke è uguale a zero quando le medie delle due porzioni della catena di Markov sono uguali. Valori maggiori di <span class="math inline">\(\mid 2 \mid\)</span> suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Gautret_2020" class="csl-entry">
Gautret, P., J. C. Lagier, P. Parola, L. Meddeb, M. Mailhe, B. Doudier, and S. Honoré. 2020. <span>“Hydroxychloroquine and Azithromycin as a Treatment of COVID-19: Results of an Open-Label Non-Randomized Clinical Trial.”</span> <em>International Journal of Antimicrobial Agents</em>.
</div>
<div id="ref-Johnson2022bayesrules" class="csl-entry">
Johnson, Alicia A., Miles Ott, and Mine Dogucu. 2022. <em><span class="nocase">Bayes Rules! An Introduction to Bayesian Modeling with R</span></em>. CRC Press.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="14">
<li id="fn14"><p>Figura riprodotta da <span class="citation">Johnson, Ott, and Dogucu (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span><a href="diagn-markov-chains.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>Una (famiglia di) catene di Markov è <em>rapidly mixing</em> se mostra un comportamento simile a quello di un campione indipendente: i valori delle catene si addensano nell’intervallo dei valori più plausibili della distribuzione a posteriori; l’autocorrelazione tra i valori della catena diminuisce rapidamente; il rapporto campionario effettivo è ragionevolmente grande. Le catene che non sono <em>rapidly mixing</em> non godono delle caratteristiche di un campione indipendente: le catene non si addensano nell’intervallo dei valori più plausibili della distribuzione a posteriori; l’autocorrelazione tra i valori della catena diminuisce molto lentamente; il rapporto campionario effettivo è piccolo.<a href="diagn-markov-chains.html#fnref15" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="stan-beta-binom.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter-sintesi-distr-post.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/041_mcmc_diagnostics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
