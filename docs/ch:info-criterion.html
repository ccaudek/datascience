<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capitolo 4 Criterio di informazione e convalida incrociata | Data Science per psicologi</title>
  <meta name="description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  <meta name="generator" content="bookdown 0.26.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Capitolo 4 Criterio di informazione e convalida incrociata | Data Science per psicologi" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capitolo 4 Criterio di informazione e convalida incrociata | Data Science per psicologi" />
  
  <meta name="twitter:description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2022-04-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="la-divergenza-di-kullback-leibler.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data science per psicologi</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefazione</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#la-psicologia-e-la-data-science"><i class="fa fa-check"></i>La psicologia e la Data science</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#come-studiare"><i class="fa fa-check"></i>Come studiare</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#sviluppare-un-metodo-di-studio-efficace"><i class="fa fa-check"></i>Sviluppare un metodo di studio efficace</a></li>
</ul></li>
<li class="part"><span><b>I Nozioni preliminari</b></span></li>
<li class="chapter" data-level="1" data-path="concetti-chiave.html"><a href="concetti-chiave.html"><i class="fa fa-check"></i><b>1</b> Concetti chiave</a>
<ul>
<li class="chapter" data-level="1.1" data-path="concetti-chiave.html"><a href="concetti-chiave.html#popolazioni-e-campioni"><i class="fa fa-check"></i><b>1.1</b> Popolazioni e campioni</a></li>
<li class="chapter" data-level="1.2" data-path="concetti-chiave.html"><a href="concetti-chiave.html#variabili-e-costanti"><i class="fa fa-check"></i><b>1.2</b> Variabili e costanti</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="concetti-chiave.html"><a href="concetti-chiave.html#variabili-casuali"><i class="fa fa-check"></i><b>1.2.1</b> Variabili casuali</a></li>
<li class="chapter" data-level="1.2.2" data-path="concetti-chiave.html"><a href="concetti-chiave.html#variabili-indipendenti-e-variabili-dipendenti"><i class="fa fa-check"></i><b>1.2.2</b> Variabili indipendenti e variabili dipendenti</a></li>
<li class="chapter" data-level="1.2.3" data-path="concetti-chiave.html"><a href="concetti-chiave.html#la-matrice-dei-dati"><i class="fa fa-check"></i><b>1.2.3</b> La matrice dei dati</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="concetti-chiave.html"><a href="concetti-chiave.html#parametri-e-modelli"><i class="fa fa-check"></i><b>1.3</b> Parametri e modelli</a></li>
<li class="chapter" data-level="1.4" data-path="concetti-chiave.html"><a href="concetti-chiave.html#effetto"><i class="fa fa-check"></i><b>1.4</b> Effetto</a></li>
<li class="chapter" data-level="1.5" data-path="concetti-chiave.html"><a href="concetti-chiave.html#stima-e-inferenza"><i class="fa fa-check"></i><b>1.5</b> Stima e inferenza</a></li>
<li class="chapter" data-level="1.6" data-path="concetti-chiave.html"><a href="concetti-chiave.html#metodi-e-procedure-della-psicologia"><i class="fa fa-check"></i><b>1.6</b> Metodi e procedure della psicologia</a></li>
</ul></li>
<li class="part"><span><b>II Il confronto bayesiano di modelli</b></span></li>
<li class="chapter" data-level="2" data-path="entropia.html"><a href="entropia.html"><i class="fa fa-check"></i><b>2</b> Entropia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="entropia.html"><a href="entropia.html#la-generalizzabilità-dei-modelli"><i class="fa fa-check"></i><b>2.1</b> La generalizzabilità dei modelli</a></li>
<li class="chapter" data-level="2.2" data-path="entropia.html"><a href="entropia.html#capacità-predittiva"><i class="fa fa-check"></i><b>2.2</b> Capacità predittiva</a></li>
<li class="chapter" data-level="2.3" data-path="entropia.html"><a href="entropia.html#il-rasoio-di-ockham"><i class="fa fa-check"></i><b>2.3</b> Il rasoio di Ockham</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="entropia.html"><a href="entropia.html#sovra-adattamento-e-sotto-adattamento"><i class="fa fa-check"></i><b>2.3.1</b> Sovra-adattamento e sotto-adattamento</a></li>
<li class="chapter" data-level="2.3.2" data-path="entropia.html"><a href="entropia.html#stargazing"><i class="fa fa-check"></i><b>2.3.2</b> Stargazing</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="entropia.html"><a href="entropia.html#la-misura-del-disordine"><i class="fa fa-check"></i><b>2.4</b> La misura del disordine</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="entropia.html"><a href="entropia.html#entropia-di-un-singolo-evento"><i class="fa fa-check"></i><b>2.4.1</b> Entropia di un singolo evento</a></li>
<li class="chapter" data-level="2.4.2" data-path="entropia.html"><a href="entropia.html#entropia-di-una-variabile-casuale"><i class="fa fa-check"></i><b>2.4.2</b> Entropia di una variabile casuale</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="entropia.html"><a href="entropia.html#commenti-e-considerazioni-finali"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="la-divergenza-di-kullback-leibler.html"><a href="la-divergenza-di-kullback-leibler.html"><i class="fa fa-check"></i><b>3</b> La divergenza di Kullback-Leibler</a>
<ul>
<li class="chapter" data-level="3.1" data-path="la-divergenza-di-kullback-leibler.html"><a href="la-divergenza-di-kullback-leibler.html#la-perdita-di-informazione"><i class="fa fa-check"></i><b>3.1</b> La perdita di informazione</a></li>
<li class="chapter" data-level="3.2" data-path="la-divergenza-di-kullback-leibler.html"><a href="la-divergenza-di-kullback-leibler.html#la-divergenza-dipende-dalla-direzione"><i class="fa fa-check"></i><b>3.2</b> La divergenza dipende dalla direzione</a></li>
<li class="chapter" data-level="3.3" data-path="la-divergenza-di-kullback-leibler.html"><a href="la-divergenza-di-kullback-leibler.html#confronto-tra-modelli"><i class="fa fa-check"></i><b>3.3</b> Confronto tra modelli</a></li>
<li class="chapter" data-level="3.4" data-path="la-divergenza-di-kullback-leibler.html"><a href="la-divergenza-di-kullback-leibler.html#expected-log-predictive-density"><i class="fa fa-check"></i><b>3.4</b> Expected log predictive density</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="la-divergenza-di-kullback-leibler.html"><a href="la-divergenza-di-kullback-leibler.html#log-pointwise-predictive-density"><i class="fa fa-check"></i><b>3.4.1</b> Log pointwise predictive density</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="la-divergenza-di-kullback-leibler.html"><a href="la-divergenza-di-kullback-leibler.html#commenti-e-considerazioni-finali-1"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch:info-criterion.html"><a href="ch:info-criterion.html"><i class="fa fa-check"></i><b>4</b> Criterio di informazione e convalida incrociata</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch:info-criterion.html"><a href="ch:info-criterion.html#aic-dic-e-waic"><i class="fa fa-check"></i><b>4.1</b> AIC, DIC e WAIC</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ch:info-criterion.html"><a href="ch:info-criterion.html#criterio-dinformazione-di-akaike"><i class="fa fa-check"></i><b>4.1.1</b> Criterio d’informazione di Akaike</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ch:info-criterion.html"><a href="ch:info-criterion.html#convalida-incrociata-k-fold"><i class="fa fa-check"></i><b>4.2</b> Convalida incrociata K-fold</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ch:info-criterion.html"><a href="ch:info-criterion.html#importance-sampling"><i class="fa fa-check"></i><b>4.2.1</b> Importance sampling</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ch:info-criterion.html"><a href="ch:info-criterion.html#confronto-tra-aic-e-loo-cv"><i class="fa fa-check"></i><b>4.3</b> Confronto tra AIC e LOO-CV</a></li>
<li class="chapter" data-level="4.4" data-path="ch:info-criterion.html"><a href="ch:info-criterion.html#confronto-tra-modelli-mediante-loo-cv"><i class="fa fa-check"></i><b>4.4</b> Confronto tra modelli mediante LOO-CV</a></li>
<li class="chapter" data-level="4.5" data-path="ch:info-criterion.html"><a href="ch:info-criterion.html#outlier"><i class="fa fa-check"></i><b>4.5</b> Outlier</a></li>
<li class="chapter" data-level="4.6" data-path="ch:info-criterion.html"><a href="ch:info-criterion.html#regolarizzazione"><i class="fa fa-check"></i><b>4.6</b> Regolarizzazione</a></li>
<li class="chapter" data-level="" data-path="ch:info-criterion.html"><a href="ch:info-criterion.html#commenti-e-considerazioni-finali-2"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science per psicologi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch:info-criterion" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Capitolo 4</span> Criterio di informazione e convalida incrociata<a href="ch:info-criterion.html#ch:info-criterion" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Nel Capitolo precedente abbiamo visto che la <a href="la-divergenza-di-kullback-leibler.html#eq:lppd">(3.6)</a> fornisce una sovrastima della <span class="math inline">\(\elpd\)</span>. Il modo migliore per stimare <span class="math inline">\(\elpd\)</span> è raccogliere un nuovo campione indipendente di dati, che si ritiene condivida lo stesso processo di generazione dei dati del campione corrente, e stimare <span class="math inline">\(\elpd\)</span> sul nuovo campione. Questa procedura è chiamata <em>out-of-sample validation</em>. Il problema, però, è che solitamente non abbiamo le risorse per raccogliere un nuovo campione di osservazioni. Di conseguenza, gli statistici hanno messo a punto vari metodi per evitare la sovrastima della <span class="math inline">\(\elpd\)</span> che deriva dal solo utizzo del campione corrente. Ci sono due approcci generali:</p>
<ul>
<li>l’introduzione di un fattore di correzione;</li>
<li>la convalida incrociata cosiddetta K-fold.</li>
</ul>
<p>Lo scopo del presente Capitolo è di fornire una breve introduzione ai criteri dell’informazione e alla procedura della convalida incrociata.</p>
<div id="aic-dic-e-waic" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> AIC, DIC e WAIC<a href="ch:info-criterion.html#aic-dic-e-waic" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Allo scopo di evitare la sovrastima della <a href="la-divergenza-di-kullback-leibler.html#eq:lppd">(3.6)</a>, le statistiche <em>Akaike Information Criterion</em> (AIC), <em>Deviance Information Criterion</em> (DIC) e <em>Widely Applicable Information Criterion</em> (WAIC) introducono un fattore di correzione. Le statistiche DIC e WAIC sono più complesse di AIC, ma producono un’approssimazione migliore. Tuttavia, i valori AIC, DIC e WAIC sono spesso molto simili tra loro. Per convenienza, dunque, qui ci accontenteremo di esaminare in dettaglio la statistica più semplice, ovvero AIC.</p>
<div id="criterio-dinformazione-di-akaike" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Criterio d’informazione di Akaike<a href="ch:info-criterion.html#criterio-dinformazione-di-akaike" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Il criterio d’informazione di Akaike (in inglese <em>Akaike information criterion</em>, indicato come AIC) fornisce un metodo molto semplice per approssimare <span class="math inline">\(\elpd\)</span>.</p>
<div class="definition">
<p><span id="def:unlabeled-div-14" class="definition"><strong>Definizione 4.1  </strong></span>Il criterio d’informazione di Akaike è definito come</p>
<p><span class="math display">\[\begin{equation}
AIC = -2 \log p(y \mid \hat{\theta}_{MLE}) + 2k,
\end{equation}\]</span></p>
<p>dove <span class="math inline">\(k\)</span> è il numero di parametri stimati nel modello e <span class="math inline">\(p(y \mid \hat{\theta}_{MLE})\)</span> è il valore massimizzato della funzione di verosimiglianza del modello stimato.</p>
</div>
<p>Dividendo per -2, otteniamo <span class="math inline">\(\elpd_{AIC}\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\widehat{\elpd}_{AIC} = \log p(y \mid \hat{\theta}_{MLE}) - k,
\end{equation}\]</span></p>
<p>dove <span class="math inline">\(k\)</span> è il fattore di correzione introdotto per evitare la sovrastima discussa in precedenza.</p>
<p>AIC è di interesse principalmente storico e produce una approssimazione attendibile di <span class="math inline">\(\elpd\)</span> quando:</p>
<ol style="list-style-type: decimal">
<li>le distribuzioni a priori sono non informative;</li>
<li>la distribuzione a posteriori è approssimativamente gaussiana multivariata;</li>
<li>la dimensione <span class="math inline">\(n\)</span> del campione è molto maggiore del numero <span class="math inline">\(k\)</span> dei parametri.</li>
</ol>
<div class="example">
<p><span id="exm:unlabeled-div-15" class="example"><strong>Esempio 4.1  </strong></span>Per meglio comprendere la statistica <span class="math inline">\(\widehat{\elpd}_{AIC}\)</span>, esaminiamo un esempio discusso da <span class="citation">Gelman, Hwang, and Vehtari (<a href="#ref-gelman2014understanding" role="doc-biblioref">2014</a>)</span>. Sia <span class="math inline">\(y_1, \dots, y_n \sim \mathcal{N}(\mu, 1)\)</span> un campione di osservazioni. Nel caso di una distribuzione a priori non-informativa <span class="math inline">\(p(\theta) \propto 1\)</span>, la stima di massima verosimiglianza è <span class="math inline">\(\bar{y}\)</span>. La verosimiglianza è</p>
<p><span class="math display">\[
f(Y \mid \mu, \sigma) = \prod_{i=1}^n f(y \mid \mu, \sigma)
\]</span></p>
<p>e la log-verosimiglianza diventa</p>
<p><span class="math display">\[
\ell(Y \mid \mu, \sigma) = \sum_{i=1}^n \log (f(y \mid \mu, \sigma)).
\]</span>
Ovvero,</p>
<p><span class="math display">\[\begin{align}
\ell(Y \mid \mu, \sigma) &amp;= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi\sigma^2 }}}\exp \left(-{\frac {1}{2}}{\frac {(y_i-\mu )^{2}}{\sigma^{2}}}\right) \right)\notag\\
&amp;= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi \sigma^2}}} \right) - \sum_{i=1}^n{\frac {1}{2}}{\frac {(y_i-\mu )^{2}}{\sigma ^{2}}} \notag\\
&amp;= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi \sigma^2}}} \right) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag \\
&amp;= \sum_{i=1}^n \log (1) - \sum_{i=1}^n\log \sqrt{2\pi \sigma^2} - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag\\
&amp;= - \sum_{i=1}^n\frac{1}{2}  \log (2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag\\
&amp;= - \frac{n}{2}  \log (2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2}. \notag
\end{align}\]</span></p>
<p>Se <span class="math inline">\(y \sim \mathcal{N}(\mu, 1)\)</span>, usando lo stimatore di massima verosimiglianza per <span class="math inline">\(\mu\)</span>, la log-verosimiglianza diventa</p>
<p><span class="math display">\[\begin{align}
\log p(y \mid \hat{\theta}_{MLE}) &amp;= -\frac{n}{2} \log (2\pi) - \frac{1}{2}\sum_{i=1}^n (y_i - \bar{y})^2 \notag\\
&amp;= -\frac{n}{2} \log (2\pi) - \frac{1}{2} (n-1)s_y^2,
\end{align}\]</span></p>
<p>dove <span class="math inline">\(s_y^2\)</span> è la varianza campionaria.</p>
<p>Nel caso di un modello gaussiano con con varianza nota e una distribuzione a priori uniforme viene stimato un solo parametro, per cui</p>
<p><span class="math display">\[\begin{align}
\widehat{\elpd}_{AIC} &amp;= \log p(y \mid \hat{\theta}_{MLE}) - k \notag \\
&amp;= -\frac{n}{2} \log (2\pi) - \frac{1}{2} (n-1)s_y^2 - 1.
\end{align}\]</span></p>
</div>
</div>
</div>
<div id="convalida-incrociata-k-fold" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Convalida incrociata K-fold<a href="ch:info-criterion.html#convalida-incrociata-k-fold" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La sovrastima della <a href="la-divergenza-di-kullback-leibler.html#eq:lppd">(3.6)</a> può anche essere evitata usando una tecnica chiamata <em>K-fold cross-validation</em>. Mediante questo metodo vengono stimati i parametri del modello tralasciando una porzione di osservazioni (chiamata <em>fold</em>) dal campione per poi valutare il modello sulle osservazioni che sono state escluse. Una stima complessiva dell’accuratezza si ottiene poi calcolando la media del punteggio di accuratezza ottenuto in ogni fold. Il numero minimo di fold è 2; all’altro estremo, è possibile impiegare una singola osservazione in ciascun fold e adattare il modello tante volte (<span class="math inline">\(n\)</span>) quante sono le singole osservazioni. Questa strategia è chiamata <em>leave-one-out cross-validation</em> (LOO-CV).</p>
<div id="importance-sampling" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Importance sampling<a href="ch:info-criterion.html#importance-sampling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La strategia LOO-CV è computazionalmente onerosa (ovvero, richiede un tempo di esecuzione molto lungo). È però possibile approssimare LOO-CV mediante un metodo chiamato <em>Pareto-smoothed importance sampling cross-validation</em> [PSIS; <span class="citation">Vehtari, Gelman, and Gabry (<a href="#ref-vehtari2017practical" role="doc-biblioref">2017</a>)</span>]. Tralasciando qui i dettagli matematici, l’intuizione di base è che PSIS fa leva sul punteggio di “importanza” posseduto da ciascuna osservazione all’interno della distribuzione a posteriori. Per “importanza” si intende il fatto che alcune osservazioni hanno un impatto maggiore sulle proprietà della distribuzione a posteriori di altre: se viene rimossa un’osservazione importante, le proprietà della distribuzione a posteriori cambiano molto; se viene rimossa un’osservazione poco importante, la distribuzione a posteriori cambia poco. L’“importanza” così intesa viene chiamata “peso” (<em>weight</em>) e tali pesi vengono utilizzati per stimare l’accuratezza <em>out-of-sample</em> del modello. PSIS-LOO-CV richiede che il modello venga adattato una volta soltanto ai dati e fornisce una stima della devianza <em>out-of-sample</em> che evita la sovrastima della <a href="la-divergenza-di-kullback-leibler.html#eq:lppd">(3.6)</a>. Inoltre, PSIS-LOO-CV fornisce un feedback sulla propria affidabilità identificando le osservazioni i cui pesi molto elevati potrebbero rendere imprecisa la predizione.</p>
<p>Valori <span class="math inline">\(\widehat{\elpd}_{\LOO}\)</span> più grandi indicano una maggiore accuratezza predittiva. In alternativa, anziché considerare <span class="math inline">\(\widehat{\elpd}\)</span>, è possibile usare la quantità <span class="math inline">\(-2 \cdot \widehat{\elpd}\)</span>, la quale è chiamata <em>LOO Information Criterion</em> (LOOIC). In questo secondo caso, valori LOOIC più piccoli sono da preferire.</p>
<p>La quantità <span class="math inline">\(\widehat{\elpd}_{\LOO}\)</span> viene calcolata dai pacchetti <code>loo</code> e <code>brms</code> ed è chiamata <code>elpd_loo</code> o <code>elpd_kfold</code>. È anche possibile calcolare la differenza della quantità <code>elpd_loo</code> per modelli alternativi, insieme alla deviazione standard della distribuzione campionaria di tale differenza.</p>
</div>
</div>
<div id="confronto-tra-aic-e-loo-cv" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Confronto tra AIC e LOO-CV<a href="ch:info-criterion.html#confronto-tra-aic-e-loo-cv" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Per fare un esempio, faremo qui un confronto tra <span class="math inline">\(\widehat{\elpd}_{AIC}\)</span> e <span class="math inline">\(\widehat{\elpd}_{LOO-CV}\)</span>. Esaminiamo nuovamente l’associazione tra il QI dei figli e il QI delle madri nel campione di dati discusso da <span class="citation">Gelman, Hill, and Vehtari (<a href="#ref-gelman2020regression" role="doc-biblioref">2020</a>)</span>. Una tale relazione può essere descritta da un modello di regressione nel quale la <span class="math inline">\(y\)</span> corrisponde al QI dei figli e la <span class="math inline">\(x\)</span> al QI delle madri.</p>
<p>Leggiamo i dati in :</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="ch:info-criterion.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;foreign&quot;</span>)</span>
<span id="cb18-2"><a href="ch:info-criterion.html#cb18-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read.dta</span>(<span class="fu">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;kidiq.dta&quot;</span>))</span>
<span id="cb18-3"><a href="ch:info-criterion.html#cb18-3" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>y <span class="ot">&lt;-</span> <span class="fu">scale</span>(df<span class="sc">$</span>kid_score)[, <span class="dv">1</span>]</span>
<span id="cb18-4"><a href="ch:info-criterion.html#cb18-4" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>x1 <span class="ot">&lt;-</span> <span class="fu">scale</span>(df<span class="sc">$</span>mom_iq)[, <span class="dv">1</span>]</span>
<span id="cb18-5"><a href="ch:info-criterion.html#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df)</span>
<span id="cb18-6"><a href="ch:info-criterion.html#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   kid_score mom_hs    mom_iq mom_work mom_age           y         x1</span></span>
<span id="cb18-7"><a href="ch:info-criterion.html#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1        65      1 121.11753        4      27 -1.06793237  1.4078352</span></span>
<span id="cb18-8"><a href="ch:info-criterion.html#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2        98      1  89.36188        4      25  0.54886757 -0.7092079</span></span>
<span id="cb18-9"><a href="ch:info-criterion.html#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3        85      1 115.44316        4      27 -0.08805362  1.0295443</span></span>
<span id="cb18-10"><a href="ch:info-criterion.html#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4        83      1  99.44964        3      25 -0.18604150 -0.0366907</span></span>
<span id="cb18-11"><a href="ch:info-criterion.html#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5       115      1  92.74571        4      27  1.38176451 -0.4836193</span></span>
<span id="cb18-12"><a href="ch:info-criterion.html#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6        98      0 107.90184        1      18  0.54886757  0.5267892</span></span></code></pre></div>
<p>Dato che AIC non è una statistica bayesiana, può essere calcolata mediante strumenti frequentisti:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="ch:info-criterion.html#cb19-1" aria-hidden="true" tabindex="-1"></a>m1_freq <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> df)</span>
<span id="cb19-2"><a href="ch:info-criterion.html#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(m1_freq) <span class="sc">/</span> <span class="sc">-</span><span class="dv">2</span></span>
<span id="cb19-3"><a href="ch:info-criterion.html#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] -569.6384</span></span></code></pre></div>
<p>Per ottenere LOO-CV adattiamo ai dati un modello di regressione bayesiano:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="ch:info-criterion.html#cb20-1" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">&quot;</span></span>
<span id="cb20-2"><a href="ch:info-criterion.html#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb20-3"><a href="ch:info-criterion.html#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb20-4"><a href="ch:info-criterion.html#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x1;</span></span>
<span id="cb20-5"><a href="ch:info-criterion.html#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y;</span></span>
<span id="cb20-6"><a href="ch:info-criterion.html#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb20-7"><a href="ch:info-criterion.html#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb20-8"><a href="ch:info-criterion.html#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="st">  real alpha;</span></span>
<span id="cb20-9"><a href="ch:info-criterion.html#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta1;</span></span>
<span id="cb20-10"><a href="ch:info-criterion.html#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span id="cb20-11"><a href="ch:info-criterion.html#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb20-12"><a href="ch:info-criterion.html#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="st">transformed parameters {</span></span>
<span id="cb20-13"><a href="ch:info-criterion.html#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] mu;</span></span>
<span id="cb20-14"><a href="ch:info-criterion.html#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1:N){</span></span>
<span id="cb20-15"><a href="ch:info-criterion.html#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="st">    mu[n] = alpha + beta1*x1[n];</span></span>
<span id="cb20-16"><a href="ch:info-criterion.html#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb20-17"><a href="ch:info-criterion.html#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb20-18"><a href="ch:info-criterion.html#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb20-19"><a href="ch:info-criterion.html#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="st">  alpha ~ normal(0, 1);</span></span>
<span id="cb20-20"><a href="ch:info-criterion.html#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="st">  beta1 ~ normal(0, 1);</span></span>
<span id="cb20-21"><a href="ch:info-criterion.html#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma ~ cauchy(0, 1);</span></span>
<span id="cb20-22"><a href="ch:info-criterion.html#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ normal(mu, sigma);</span></span>
<span id="cb20-23"><a href="ch:info-criterion.html#cb20-23" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb20-24"><a href="ch:info-criterion.html#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb20-25"><a href="ch:info-criterion.html#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y_rep;</span></span>
<span id="cb20-26"><a href="ch:info-criterion.html#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] log_lik;</span></span>
<span id="cb20-27"><a href="ch:info-criterion.html#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1:N){</span></span>
<span id="cb20-28"><a href="ch:info-criterion.html#cb20-28" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = normal_rng(mu[n], sigma);</span></span>
<span id="cb20-29"><a href="ch:info-criterion.html#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="st">    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1, sigma);</span></span>
<span id="cb20-30"><a href="ch:info-criterion.html#cb20-30" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb20-31"><a href="ch:info-criterion.html#cb20-31" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb20-32"><a href="ch:info-criterion.html#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb20-33"><a href="ch:info-criterion.html#cb20-33" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">&quot;code/simplereg.stan&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="ch:info-criterion.html#cb21-1" aria-hidden="true" tabindex="-1"></a>data1_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb21-2"><a href="ch:info-criterion.html#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(df<span class="sc">$</span>kid_score),</span>
<span id="cb21-3"><a href="ch:info-criterion.html#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> df<span class="sc">$</span>y,</span>
<span id="cb21-4"><a href="ch:info-criterion.html#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> df<span class="sc">$</span>x1</span>
<span id="cb21-5"><a href="ch:info-criterion.html#cb21-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="ch:info-criterion.html#cb22-1" aria-hidden="true" tabindex="-1"></a>file1 <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">&quot;code&quot;</span>, <span class="st">&quot;simplereg.stan&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="ch:info-criterion.html#cb23-1" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file1)</span></code></pre></div>
<p>Eseguiamo il campionamento MCMC:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="ch:info-criterion.html#cb24-1" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> mod1<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb24-2"><a href="ch:info-criterion.html#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data1_list,</span>
<span id="cb24-3"><a href="ch:info-criterion.html#cb24-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb24-4"><a href="ch:info-criterion.html#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb24-5"><a href="ch:info-criterion.html#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb24-6"><a href="ch:info-criterion.html#cb24-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb24-7"><a href="ch:info-criterion.html#cb24-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">parallel_chains =</span> 2L,</span>
<span id="cb24-8"><a href="ch:info-criterion.html#cb24-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> 4L,</span>
<span id="cb24-9"><a href="ch:info-criterion.html#cb24-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb24-10"><a href="ch:info-criterion.html#cb24-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">thin =</span> <span class="dv">1</span></span>
<span id="cb24-11"><a href="ch:info-criterion.html#cb24-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Calcoliamo infine la quantità <span class="math inline">\(\widehat{\elpd}_{LOO-CV}\)</span>:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="ch:info-criterion.html#cb25-1" aria-hidden="true" tabindex="-1"></a>loo1_result <span class="ot">&lt;-</span> fit1<span class="sc">$</span><span class="fu">loo</span>(<span class="at">cores =</span> <span class="dv">4</span>)</span>
<span id="cb25-2"><a href="ch:info-criterion.html#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(loo1_result)</span>
<span id="cb25-3"><a href="ch:info-criterion.html#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb25-4"><a href="ch:info-criterion.html#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Computed from 16000 by 434 log-likelihood matrix</span></span>
<span id="cb25-5"><a href="ch:info-criterion.html#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb25-6"><a href="ch:info-criterion.html#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          Estimate   SE</span></span>
<span id="cb25-7"><a href="ch:info-criterion.html#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; elpd_loo   -568.6 14.5</span></span>
<span id="cb25-8"><a href="ch:info-criterion.html#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; p_loo         1.9  0.2</span></span>
<span id="cb25-9"><a href="ch:info-criterion.html#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; looic      1137.2 28.9</span></span>
<span id="cb25-10"><a href="ch:info-criterion.html#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ------</span></span>
<span id="cb25-11"><a href="ch:info-criterion.html#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Monte Carlo SE of elpd_loo is 0.0.</span></span>
<span id="cb25-12"><a href="ch:info-criterion.html#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb25-13"><a href="ch:info-criterion.html#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All Pareto k estimates are good (k &lt; 0.5).</span></span>
<span id="cb25-14"><a href="ch:info-criterion.html#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; See help(&#39;pareto-k-diagnostic&#39;) for details.</span></span></code></pre></div>
<p>Si noti la somiglianza tra <span class="math inline">\(\widehat{\elpd}_{LOO-CV}\)</span> e <span class="math inline">\(\widehat{\elpd}_{AIC}\)</span>. In conclusione, possiamo dunque dire che <span class="math inline">\(\widehat{\elpd}_{LOO-CV}\)</span> è la risposta bayesiana allo stesso problema che trova una soluzione frequentista nella statistica <span class="math inline">\(\widehat{\elpd}_{AIC}\)</span>.</p>
</div>
<div id="confronto-tra-modelli-mediante-loo-cv" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Confronto tra modelli mediante LOO-CV<a href="ch:info-criterion.html#confronto-tra-modelli-mediante-loo-cv" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Come menzionato in precedenza, l’obiettivo centrale della misurazione dell’accuratezza predittiva è il confronto di modelli. Una volta capito come calcolare LOO-CV con un condice scritto in linguaggio Stan, svolgeremo ora un confronto di modelli.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<p>Considereremo qui un confronto di modelli di regressione. Il modello di regressione discusso nel Paragrafo precedente prevede il QI dei bambini dal QI delle madri. Aggiungiamo a tale modello un secondo predittore che corrisponde all’età della madre. L’aggiunta di tale predittore migliori l’accuratezza predittiva del modello?</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="ch:info-criterion.html#cb26-1" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">&quot;</span></span>
<span id="cb26-2"><a href="ch:info-criterion.html#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb26-3"><a href="ch:info-criterion.html#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb26-4"><a href="ch:info-criterion.html#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x1;</span></span>
<span id="cb26-5"><a href="ch:info-criterion.html#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x2;</span></span>
<span id="cb26-6"><a href="ch:info-criterion.html#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y;</span></span>
<span id="cb26-7"><a href="ch:info-criterion.html#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb26-8"><a href="ch:info-criterion.html#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb26-9"><a href="ch:info-criterion.html#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="st">  real alpha;</span></span>
<span id="cb26-10"><a href="ch:info-criterion.html#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta1;</span></span>
<span id="cb26-11"><a href="ch:info-criterion.html#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta2;</span></span>
<span id="cb26-12"><a href="ch:info-criterion.html#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span id="cb26-13"><a href="ch:info-criterion.html#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb26-14"><a href="ch:info-criterion.html#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="st">transformed parameters {</span></span>
<span id="cb26-15"><a href="ch:info-criterion.html#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] mu;</span></span>
<span id="cb26-16"><a href="ch:info-criterion.html#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1:N){</span></span>
<span id="cb26-17"><a href="ch:info-criterion.html#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="st">    mu[n] = alpha + beta1*x1[n] + beta2*x2[n];</span></span>
<span id="cb26-18"><a href="ch:info-criterion.html#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb26-19"><a href="ch:info-criterion.html#cb26-19" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb26-20"><a href="ch:info-criterion.html#cb26-20" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb26-21"><a href="ch:info-criterion.html#cb26-21" aria-hidden="true" tabindex="-1"></a><span class="st">  alpha ~ normal(0, 1);</span></span>
<span id="cb26-22"><a href="ch:info-criterion.html#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="st">  beta1 ~ normal(0, 1);</span></span>
<span id="cb26-23"><a href="ch:info-criterion.html#cb26-23" aria-hidden="true" tabindex="-1"></a><span class="st">  beta2 ~ normal(0, 1);</span></span>
<span id="cb26-24"><a href="ch:info-criterion.html#cb26-24" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma ~ cauchy(0, 1);</span></span>
<span id="cb26-25"><a href="ch:info-criterion.html#cb26-25" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ normal(mu, sigma);</span></span>
<span id="cb26-26"><a href="ch:info-criterion.html#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb26-27"><a href="ch:info-criterion.html#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb26-28"><a href="ch:info-criterion.html#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y_rep;</span></span>
<span id="cb26-29"><a href="ch:info-criterion.html#cb26-29" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] log_lik;</span></span>
<span id="cb26-30"><a href="ch:info-criterion.html#cb26-30" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1:N){</span></span>
<span id="cb26-31"><a href="ch:info-criterion.html#cb26-31" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = normal_rng(mu[n], sigma);</span></span>
<span id="cb26-32"><a href="ch:info-criterion.html#cb26-32" aria-hidden="true" tabindex="-1"></a><span class="st">    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x2[n] * beta2, sigma);</span></span>
<span id="cb26-33"><a href="ch:info-criterion.html#cb26-33" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb26-34"><a href="ch:info-criterion.html#cb26-34" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb26-35"><a href="ch:info-criterion.html#cb26-35" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb26-36"><a href="ch:info-criterion.html#cb26-36" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">&quot;code/mreg2.stan&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="ch:info-criterion.html#cb27-1" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>x2 <span class="ot">&lt;-</span> <span class="fu">scale</span>(df<span class="sc">$</span>mom_age)[, <span class="dv">1</span>]</span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="ch:info-criterion.html#cb28-1" aria-hidden="true" tabindex="-1"></a>data2_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb28-2"><a href="ch:info-criterion.html#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(df<span class="sc">$</span>kid_score),</span>
<span id="cb28-3"><a href="ch:info-criterion.html#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> df<span class="sc">$</span>y,</span>
<span id="cb28-4"><a href="ch:info-criterion.html#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> df<span class="sc">$</span>x1,</span>
<span id="cb28-5"><a href="ch:info-criterion.html#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> df<span class="sc">$</span>x2</span>
<span id="cb28-6"><a href="ch:info-criterion.html#cb28-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="ch:info-criterion.html#cb29-1" aria-hidden="true" tabindex="-1"></a>file2 <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">&quot;code&quot;</span>, <span class="st">&quot;mreg2.stan&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="ch:info-criterion.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compile model</span></span>
<span id="cb30-2"><a href="ch:info-criterion.html#cb30-2" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file2)</span></code></pre></div>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="ch:info-criterion.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Running MCMC</span></span>
<span id="cb31-2"><a href="ch:info-criterion.html#cb31-2" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> mod2<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb31-3"><a href="ch:info-criterion.html#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data2_list,</span>
<span id="cb31-4"><a href="ch:info-criterion.html#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb31-5"><a href="ch:info-criterion.html#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb31-6"><a href="ch:info-criterion.html#cb31-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb31-7"><a href="ch:info-criterion.html#cb31-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb31-8"><a href="ch:info-criterion.html#cb31-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">parallel_chains =</span> 2L,</span>
<span id="cb31-9"><a href="ch:info-criterion.html#cb31-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> 4L,</span>
<span id="cb31-10"><a href="ch:info-criterion.html#cb31-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb31-11"><a href="ch:info-criterion.html#cb31-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">thin =</span> <span class="dv">1</span></span>
<span id="cb31-12"><a href="ch:info-criterion.html#cb31-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="ch:info-criterion.html#cb32-1" aria-hidden="true" tabindex="-1"></a>fit2<span class="sc">$</span><span class="fu">summary</span>(<span class="fu">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;beta2&quot;</span>, <span class="st">&quot;sigma&quot;</span>))</span>
<span id="cb32-2"><a href="ch:info-criterion.html#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 × 10</span></span>
<span id="cb32-3"><a href="ch:info-criterion.html#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   variable      mean    median     sd    mad      q5    q95  rhat ess_bulk</span></span>
<span id="cb32-4"><a href="ch:info-criterion.html#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb32-5"><a href="ch:info-criterion.html#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 alpha    -0.000255 -0.000162 0.0431 0.0427 -0.0714 0.0705  1.00   19419.</span></span>
<span id="cb32-6"><a href="ch:info-criterion.html#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 beta1     0.442     0.442    0.0427 0.0427  0.372  0.512   1.00   17850.</span></span>
<span id="cb32-7"><a href="ch:info-criterion.html#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 beta2     0.0515    0.0514   0.0427 0.0428 -0.0179 0.121   1.00   16802.</span></span>
<span id="cb32-8"><a href="ch:info-criterion.html#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 sigma     0.896     0.895    0.0305 0.0303  0.848  0.948   1.00   19032.</span></span>
<span id="cb32-9"><a href="ch:info-criterion.html#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 1 more variable: ess_tail &lt;dbl&gt;</span></span></code></pre></div>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="ch:info-criterion.html#cb33-1" aria-hidden="true" tabindex="-1"></a>loo2_result <span class="ot">&lt;-</span> fit2<span class="sc">$</span><span class="fu">loo</span>(<span class="at">cores =</span> <span class="dv">4</span>)</span>
<span id="cb33-2"><a href="ch:info-criterion.html#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(loo2_result)</span>
<span id="cb33-3"><a href="ch:info-criterion.html#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb33-4"><a href="ch:info-criterion.html#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Computed from 16000 by 434 log-likelihood matrix</span></span>
<span id="cb33-5"><a href="ch:info-criterion.html#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb33-6"><a href="ch:info-criterion.html#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          Estimate   SE</span></span>
<span id="cb33-7"><a href="ch:info-criterion.html#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; elpd_loo   -568.9 14.5</span></span>
<span id="cb33-8"><a href="ch:info-criterion.html#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; p_loo         3.0  0.3</span></span>
<span id="cb33-9"><a href="ch:info-criterion.html#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; looic      1137.8 29.0</span></span>
<span id="cb33-10"><a href="ch:info-criterion.html#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ------</span></span>
<span id="cb33-11"><a href="ch:info-criterion.html#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Monte Carlo SE of elpd_loo is 0.0.</span></span>
<span id="cb33-12"><a href="ch:info-criterion.html#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb33-13"><a href="ch:info-criterion.html#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All Pareto k estimates are good (k &lt; 0.5).</span></span>
<span id="cb33-14"><a href="ch:info-criterion.html#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; See help(&#39;pareto-k-diagnostic&#39;) for details.</span></span></code></pre></div>
<p>Consideriamo infine un terzo modello che utilizza come predittori, oltre al QI della madre, una variabile dicotomica (codificata 0 o 1) che distingue madri che hanno completato le scuole superiori da quelle che non le hanno completate. Nuovamente, la domanda è se l’aggiunta di tale predittore migliori la capacità predittiva del modello.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="ch:info-criterion.html#cb34-1" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">&quot;</span></span>
<span id="cb34-2"><a href="ch:info-criterion.html#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb34-3"><a href="ch:info-criterion.html#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb34-4"><a href="ch:info-criterion.html#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x1;</span></span>
<span id="cb34-5"><a href="ch:info-criterion.html#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x3;</span></span>
<span id="cb34-6"><a href="ch:info-criterion.html#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y;</span></span>
<span id="cb34-7"><a href="ch:info-criterion.html#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-8"><a href="ch:info-criterion.html#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb34-9"><a href="ch:info-criterion.html#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="st">  real alpha;</span></span>
<span id="cb34-10"><a href="ch:info-criterion.html#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta1;</span></span>
<span id="cb34-11"><a href="ch:info-criterion.html#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta3;</span></span>
<span id="cb34-12"><a href="ch:info-criterion.html#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span id="cb34-13"><a href="ch:info-criterion.html#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-14"><a href="ch:info-criterion.html#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="st">transformed parameters {</span></span>
<span id="cb34-15"><a href="ch:info-criterion.html#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] mu;</span></span>
<span id="cb34-16"><a href="ch:info-criterion.html#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1:N){</span></span>
<span id="cb34-17"><a href="ch:info-criterion.html#cb34-17" aria-hidden="true" tabindex="-1"></a><span class="st">    mu[n] = alpha + beta1*x1[n] + beta3*x3[n];</span></span>
<span id="cb34-18"><a href="ch:info-criterion.html#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb34-19"><a href="ch:info-criterion.html#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-20"><a href="ch:info-criterion.html#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb34-21"><a href="ch:info-criterion.html#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="st">  alpha ~ normal(0, 1);</span></span>
<span id="cb34-22"><a href="ch:info-criterion.html#cb34-22" aria-hidden="true" tabindex="-1"></a><span class="st">  beta1 ~ normal(0, 1);</span></span>
<span id="cb34-23"><a href="ch:info-criterion.html#cb34-23" aria-hidden="true" tabindex="-1"></a><span class="st">  beta3 ~ normal(0, 1);</span></span>
<span id="cb34-24"><a href="ch:info-criterion.html#cb34-24" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma ~ cauchy(0, 1);</span></span>
<span id="cb34-25"><a href="ch:info-criterion.html#cb34-25" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ normal(mu, sigma);</span></span>
<span id="cb34-26"><a href="ch:info-criterion.html#cb34-26" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-27"><a href="ch:info-criterion.html#cb34-27" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb34-28"><a href="ch:info-criterion.html#cb34-28" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y_rep;</span></span>
<span id="cb34-29"><a href="ch:info-criterion.html#cb34-29" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] log_lik;</span></span>
<span id="cb34-30"><a href="ch:info-criterion.html#cb34-30" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1:N){</span></span>
<span id="cb34-31"><a href="ch:info-criterion.html#cb34-31" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = normal_rng(mu[n], sigma);</span></span>
<span id="cb34-32"><a href="ch:info-criterion.html#cb34-32" aria-hidden="true" tabindex="-1"></a><span class="st">    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x3[n] * beta3, sigma);</span></span>
<span id="cb34-33"><a href="ch:info-criterion.html#cb34-33" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb34-34"><a href="ch:info-criterion.html#cb34-34" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb34-35"><a href="ch:info-criterion.html#cb34-35" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb34-36"><a href="ch:info-criterion.html#cb34-36" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">&quot;code/mreg3.stan&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="ch:info-criterion.html#cb35-1" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>x3 <span class="ot">&lt;-</span> df<span class="sc">$</span>mom_hs</span></code></pre></div>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="ch:info-criterion.html#cb36-1" aria-hidden="true" tabindex="-1"></a>data3_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb36-2"><a href="ch:info-criterion.html#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(df<span class="sc">$</span>kid_score),</span>
<span id="cb36-3"><a href="ch:info-criterion.html#cb36-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> df<span class="sc">$</span>y,</span>
<span id="cb36-4"><a href="ch:info-criterion.html#cb36-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> df<span class="sc">$</span>x1,</span>
<span id="cb36-5"><a href="ch:info-criterion.html#cb36-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x3 =</span> df<span class="sc">$</span>x3</span>
<span id="cb36-6"><a href="ch:info-criterion.html#cb36-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="ch:info-criterion.html#cb37-1" aria-hidden="true" tabindex="-1"></a>file3 <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">&quot;code&quot;</span>, <span class="st">&quot;mreg3.stan&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="ch:info-criterion.html#cb38-1" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file3)</span></code></pre></div>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="ch:info-criterion.html#cb39-1" aria-hidden="true" tabindex="-1"></a>fit3 <span class="ot">&lt;-</span> mod3<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb39-2"><a href="ch:info-criterion.html#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data3_list,</span>
<span id="cb39-3"><a href="ch:info-criterion.html#cb39-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb39-4"><a href="ch:info-criterion.html#cb39-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb39-5"><a href="ch:info-criterion.html#cb39-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb39-6"><a href="ch:info-criterion.html#cb39-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb39-7"><a href="ch:info-criterion.html#cb39-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">parallel_chains =</span> 2L,</span>
<span id="cb39-8"><a href="ch:info-criterion.html#cb39-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> 4L,</span>
<span id="cb39-9"><a href="ch:info-criterion.html#cb39-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb39-10"><a href="ch:info-criterion.html#cb39-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">thin =</span> <span class="dv">1</span></span>
<span id="cb39-11"><a href="ch:info-criterion.html#cb39-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="ch:info-criterion.html#cb40-1" aria-hidden="true" tabindex="-1"></a>fit3<span class="sc">$</span><span class="fu">summary</span>(<span class="fu">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;beta3&quot;</span>, <span class="st">&quot;sigma&quot;</span>))</span>
<span id="cb40-2"><a href="ch:info-criterion.html#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 × 10</span></span>
<span id="cb40-3"><a href="ch:info-criterion.html#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   variable   mean median     sd    mad     q5     q95  rhat ess_bulk ess_tail</span></span>
<span id="cb40-4"><a href="ch:info-criterion.html#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb40-5"><a href="ch:info-criterion.html#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 alpha    -0.225 -0.224 0.0947 0.0945 -0.382 -0.0705  1.00    8433.    9191.</span></span>
<span id="cb40-6"><a href="ch:info-criterion.html#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 beta1     0.415  0.414 0.0449 0.0450  0.341  0.488   1.00   10941.   10324.</span></span>
<span id="cb40-7"><a href="ch:info-criterion.html#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 beta3     0.286  0.285 0.108  0.108   0.111  0.465   1.00    8452.    8606.</span></span>
<span id="cb40-8"><a href="ch:info-criterion.html#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 sigma     0.890  0.889 0.0302 0.0302  0.842  0.941   1.00   10828.    9623.</span></span></code></pre></div>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="ch:info-criterion.html#cb41-1" aria-hidden="true" tabindex="-1"></a>loo3_result <span class="ot">&lt;-</span> fit3<span class="sc">$</span><span class="fu">loo</span>(<span class="at">cores =</span> <span class="dv">4</span>)</span>
<span id="cb41-2"><a href="ch:info-criterion.html#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(loo3_result)</span>
<span id="cb41-3"><a href="ch:info-criterion.html#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb41-4"><a href="ch:info-criterion.html#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Computed from 16000 by 434 log-likelihood matrix</span></span>
<span id="cb41-5"><a href="ch:info-criterion.html#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb41-6"><a href="ch:info-criterion.html#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          Estimate   SE</span></span>
<span id="cb41-7"><a href="ch:info-criterion.html#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; elpd_loo   -584.2 16.4</span></span>
<span id="cb41-8"><a href="ch:info-criterion.html#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; p_loo         7.5  0.6</span></span>
<span id="cb41-9"><a href="ch:info-criterion.html#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; looic      1168.3 32.8</span></span>
<span id="cb41-10"><a href="ch:info-criterion.html#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ------</span></span>
<span id="cb41-11"><a href="ch:info-criterion.html#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Monte Carlo SE of elpd_loo is 0.0.</span></span>
<span id="cb41-12"><a href="ch:info-criterion.html#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb41-13"><a href="ch:info-criterion.html#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All Pareto k estimates are good (k &lt; 0.5).</span></span>
<span id="cb41-14"><a href="ch:info-criterion.html#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; See help(&#39;pareto-k-diagnostic&#39;) for details.</span></span></code></pre></div>
<p>Per eseguire un confronto tra modelli in termini della loro capacità predittiva esaminiamo la differenza di LOO-CV tra coppie di modelli. Le seguenti istruzioni <span class="math inline">\(\R\)</span> producono la quantità <code>elpd_diff</code>, ovvero la differenza tra stime della <span class="math inline">\(\elpd\)</span> fornite da due modelli. Il primo argomento della funzione <code>loo_compare()</code> specifica il modello che viene usato come confronto. Nella prima riga dell’output, il valore <code>elpd_diff</code> è 0 (cioè, <span class="math inline">\(x − x = 0\)</span>). Nelle righe successive sono riportate le differenze rispetto al modello di confronto (in questo caso, il modello 1). La colonna <code>se_diff</code> riporta l’errore standard di tali differenze.</p>
<p>L’incertezza della stima dell’accuratezza <em>out-of-sample</em> si distribuisce in maniera approssimativamente normale con media uguale al valore riportato dal software e deviazione standard uguale a ciò che è indicato nell’output come errore standard. Quando il campione è piccolo, questa approssimazione produce una forte sottostima dell’incertezza, ma fornisce comunque una stima migliore di AIC, DIC e WAIC.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="ch:info-criterion.html#cb42-1" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">loo_compare</span>(loo1_result, loo2_result, loo3_result)</span>
<span id="cb42-2"><a href="ch:info-criterion.html#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(w)</span>
<span id="cb42-3"><a href="ch:info-criterion.html#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        elpd_diff se_diff</span></span>
<span id="cb42-4"><a href="ch:info-criterion.html#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; model1   0.0       0.0  </span></span>
<span id="cb42-5"><a href="ch:info-criterion.html#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; model2  -0.3       1.3  </span></span>
<span id="cb42-6"><a href="ch:info-criterion.html#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; model3 -15.6       6.0</span></span></code></pre></div>
<p>Per interpretare l’output, usiamo il criterio suggerito da <span class="citation">Gelman et al. (<a href="#ref-gelman1995bayesian" role="doc-biblioref">1995</a>)</span>: consideriamo “credibile” una differenza se <code>elpd_diff</code> è almeno due volte maggiore di <code>se_diff</code>. Nel caso presente, dunque, il confronto tra il modello 2 e il modello 1 indica che la quantità <code>elpd_diff</code> è molto piccola rispetto al suo errore standard.
Questo accade se un predittore è associato in modo trascurabile con la variabile dipendente. I dati presenti, dunque, non offrono alcuna evidenza che aggiungere dell’età della madre come predittore migliori la capacità predittiva del modello. Nel confronto tra modello 3 e modello 1, invece, la quantità <code>elpd_diff</code> è maggiore di due volte il valore dell’errore standard. Questo suggerisce un incremento della capacità predittiva del modello quiando il livello di istruzione della madre viene incluso tra i predittori.</p>
<p>È anche possibile calcolare l’intervallo di credibilità per <code>elpd_diff</code>:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="ch:info-criterion.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fl">15.5</span> <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fu">qnorm</span>(.<span class="dv">95</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fl">6.0</span></span>
<span id="cb43-2"><a href="ch:info-criterion.html#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1]  5.630878 25.369122</span></span></code></pre></div>
</div>
<div id="outlier" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Outlier<a href="ch:info-criterion.html#outlier" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Si è soliti pensare che la maggior parte delle osservazioni del campione sia prodotta da un unico meccanismo generatore dei dati, mentre le rimanenti osservazioni sono la realizzazione di un diverso processo stocastico. Le osservazioni che appartengono a questo secondo gruppo si chiamano <em>outlier</em>. È dunque necessario identificare gli outlier e limitare la loro influenza sull’inferenza.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p>Poniamoci ora il problema di identificare gli outlier con la tecnica PSIS-LOO-CV. Quando PSIS-LOO-CV viene calcolato con il pacchetto <code>loo</code>, l’output riporta il parametro di forma della distribuzione di Pareto (valore <code>k</code>). Tale valore può essere utilizzato per identificare gli outlier. Infatti, il valore <code>k</code> valuta, per ciascun punto del campione, l’approssimazione usata da PSIS-LOO-CV. Se <span class="math inline">\(k &lt; 0.5\)</span>, i pesi di importanza vengono stimati in modo accurato; se il valore <span class="math inline">\(k\)</span> di Pareto di un punto è <span class="math inline">\(&gt; 0.7\)</span>, i pesi di importanza possono essere inaccurati. Le osservazioni con <span class="math inline">\(k &gt; 0.7\)</span> sono dunque osservazioni outlier.</p>
<p>Per fare un esempio concreto, introduciamo nel campione dell’esempio precedente una singola osservazione outlier.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="ch:info-criterion.html#cb44-1" aria-hidden="true" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> df</span>
<span id="cb44-2"><a href="ch:info-criterion.html#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(df1)</span>
<span id="cb44-3"><a href="ch:info-criterion.html#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 434   9</span></span>
<span id="cb44-4"><a href="ch:info-criterion.html#cb44-4" aria-hidden="true" tabindex="-1"></a>df1<span class="sc">$</span>x1[<span class="dv">434</span>] <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb44-5"><a href="ch:info-criterion.html#cb44-5" aria-hidden="true" tabindex="-1"></a>df1<span class="sc">$</span>y[<span class="dv">434</span>] <span class="ot">&lt;-</span> <span class="dv">10</span></span></code></pre></div>
<p>Sistemiamo i dati nel formato appropriato per Stan:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="ch:info-criterion.html#cb45-1" aria-hidden="true" tabindex="-1"></a>data1a_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb45-2"><a href="ch:info-criterion.html#cb45-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(df1<span class="sc">$</span>kid_score),</span>
<span id="cb45-3"><a href="ch:info-criterion.html#cb45-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> df1<span class="sc">$</span>y,</span>
<span id="cb45-4"><a href="ch:info-criterion.html#cb45-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> df1<span class="sc">$</span>x1</span>
<span id="cb45-5"><a href="ch:info-criterion.html#cb45-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Adattiamo nuovamente il modello 1 ad un campione di dati che contiene un outlier.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="ch:info-criterion.html#cb46-1" aria-hidden="true" tabindex="-1"></a>fit1a <span class="ot">&lt;-</span> mod1<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb46-2"><a href="ch:info-criterion.html#cb46-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data1a_list,</span>
<span id="cb46-3"><a href="ch:info-criterion.html#cb46-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb46-4"><a href="ch:info-criterion.html#cb46-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb46-5"><a href="ch:info-criterion.html#cb46-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb46-6"><a href="ch:info-criterion.html#cb46-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb46-7"><a href="ch:info-criterion.html#cb46-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">parallel_chains =</span> 2L,</span>
<span id="cb46-8"><a href="ch:info-criterion.html#cb46-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> 4L,</span>
<span id="cb46-9"><a href="ch:info-criterion.html#cb46-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb46-10"><a href="ch:info-criterion.html#cb46-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">thin =</span> <span class="dv">1</span></span>
<span id="cb46-11"><a href="ch:info-criterion.html#cb46-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="ch:info-criterion.html#cb47-1" aria-hidden="true" tabindex="-1"></a>loo1a_result <span class="ot">&lt;-</span> fit1a<span class="sc">$</span><span class="fu">loo</span>(<span class="at">cores =</span> <span class="dv">4</span>)</span></code></pre></div>
<p>Una tabella diagnostica che riassume le stime dei parametri di forma della distribuzione di Pareto si ottiene nel modo seguente:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="ch:info-criterion.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(loo1a_result)</span>
<span id="cb48-2"><a href="ch:info-criterion.html#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb48-3"><a href="ch:info-criterion.html#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Computed from 16000 by 434 log-likelihood matrix</span></span>
<span id="cb48-4"><a href="ch:info-criterion.html#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb48-5"><a href="ch:info-criterion.html#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          Estimate   SE</span></span>
<span id="cb48-6"><a href="ch:info-criterion.html#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; elpd_loo   -586.2 19.9</span></span>
<span id="cb48-7"><a href="ch:info-criterion.html#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; p_loo         6.6  5.0</span></span>
<span id="cb48-8"><a href="ch:info-criterion.html#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; looic      1172.5 39.8</span></span>
<span id="cb48-9"><a href="ch:info-criterion.html#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ------</span></span>
<span id="cb48-10"><a href="ch:info-criterion.html#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Monte Carlo SE of elpd_loo is NA.</span></span>
<span id="cb48-11"><a href="ch:info-criterion.html#cb48-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb48-12"><a href="ch:info-criterion.html#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Pareto k diagnostic values:</span></span>
<span id="cb48-13"><a href="ch:info-criterion.html#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                          Count Pct.    Min. n_eff</span></span>
<span id="cb48-14"><a href="ch:info-criterion.html#cb48-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (-Inf, 0.5]   (good)     433   99.8%   10708     </span></span>
<span id="cb48-15"><a href="ch:info-criterion.html#cb48-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  (0.5, 0.7]   (ok)         0    0.0%   &lt;NA&gt;      </span></span>
<span id="cb48-16"><a href="ch:info-criterion.html#cb48-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    (0.7, 1]   (bad)        1    0.2%   75        </span></span>
<span id="cb48-17"><a href="ch:info-criterion.html#cb48-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      </span></span>
<span id="cb48-18"><a href="ch:info-criterion.html#cb48-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; See help(&#39;pareto-k-diagnostic&#39;) for details.</span></span></code></pre></div>
<p>Un grafico che riporta le stime dei parametri di forma della distribuzione di Pareto per ciascuna osservazione è dato da:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="ch:info-criterion.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(loo1a_result)</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-53-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Il valore <code>k</code> stimato da PSIS-LOO-CV mette chiaramente in luce il fatto che il valore introdotto nel campione è un outlier. L’indice dell’osservazione outlier è identificato con:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="ch:info-criterion.html#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pareto_k_ids</span>(loo1a_result, <span class="at">threshold =</span> <span class="fl">0.7</span>)</span>
<span id="cb50-2"><a href="ch:info-criterion.html#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 434</span></span></code></pre></div>
</div>
<div id="regolarizzazione" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Regolarizzazione<a href="ch:info-criterion.html#regolarizzazione" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Abbiamo motivato la presente discussione affermando che uno dei problemi più grandi che i ricercatori devono afforntare è quello della generalizzabilità dei loro risultati. <span class="citation">McElreath (<a href="#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span> fa notare che un modo per favorire la capacità del modello di generalizzarsi a nuovi campioni è quello di fare in modo che produca un adattamento <em>peggiore</em> ai dati del campione presente. Il problema del sovra-adattamento (e quindi di una bassa generalizzabilità) dipende dal fatto che tutte le regolarità presenti nei dati del campione (e dunque, anche quelle che costituiscono un aspetto idiosincratico del campione presente) “vengono egualmente prese sul serio” da un modello che utilizza prior uniformi per i parametri. In tali circostanze, <em>qualsiasi</em> valore dei parametri viene considerato plausibile. Un modo per evitare un tale modo di procedere, che sicuramente è inadeguato, è quello di utilizzare dei prior che <span class="citation">McElreath (<a href="#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span> chiama “scettici”. I priori “scettici” più comuni sono quelli che hanno una funzione di regolarizzazione. Tali prior, se calibrati correttamente, riducono il sovra-adattamento pur consentendo al modello di rappresentare le regolarità che emergono dai dati del campione. Se il prior è “troppo scettico”, tuttavia, le regolarità dei dati campionari non vengono rappresentate dal modello; di conseguenza, ciò produce un sotto-adattamento. Il problema è quello di trovare un equilibrio tra gli opposti pericoli del sovra-adattamento e del sotto-adattamento. La buona notizia è che anche un prior “moderatamente scettico” è in grado di fornire un grande aiuto al modello, e questo è tutto quello che possiamo sperare di ottenere dato che, in generale, non ci sono né modelli ottimali né distribuzioni a priori ottimali (ovvero, modelli e distribuzioni a priori che non possono essere migliorati).</p>
<p>Un esempio di una distribuzione a priori di regolarizzazione può essere fornito facendo riferimento al modello lineare, per esempio. Se standardizziamo i dati, un prior <span class="math inline">\(\beta \sim \mathcal{N}(0, 1)\)</span> per il parametro che codifica la pendenza della retta di regressione ci dice che, prima di osservare i dati, il modello “è molto scettico” rispetto ai valori possibili di <span class="math inline">\(\beta\)</span> esterni all’intervallo <span class="math inline">\([-2, 2]\)</span> deviazioni standard. In altri termini, ritiene che sia molto improbabile che un cambiamento di 1 deviazione standard nella <span class="math inline">\(x\)</span> sia associato ad un cambiamento medio superiore a 2 unità di deviazione standard nella <span class="math inline">\(y\)</span>.</p>
<p>Ma potremmo anche usare una distribuzione a priori gaussiana con parametro <span class="math inline">\(\sigma\)</span> uguale a 0.5 oppure a 0.2. Quale prior usare dipende dal modello e dai dati – non c’è una raccomandazione che risulta sempre valida. L’effetto maggiore dei prior “molto scettici” si manifesta nel caso di modelli complessi e nel caso di piccole numerosità campionarie – ovvero, proprio nei casi in cui il rischio del sovra-adattamento è più grande. Se invece il campione è sufficientemente grande e il modello non è eccessivamente complesso, i prior, quali essi siano, hanno invece un effetto trascurabile sulla stima della distribuzione a posteriori.</p>
</div>
<div id="commenti-e-considerazioni-finali-2" class="section level2 unnumbered hasAnchor">
<h2>Commenti e considerazioni finali<a href="ch:info-criterion.html#commenti-e-considerazioni-finali-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In questo Capitolo, utilizzando Stan insieme al pacchetto <code>loo</code>, abbiamo imparato ad usare la convalida incrociata K-fold e la convalida incrociata leave-one-out. Abbiamo esaminato alcuni esempi nei quali la convalida incrociata ci consente di distinguere tra due modelli. In generale, la convalida incrociata si dimostra utile utile quando vengono confrontati modelli piuttosto diversi; quando i modelli sono molto simili, invece, risulta spesso difficile distinguerli con le tecniche qui discusse. In particolare, risulta spesso difficile ottenere risultati conclusivi dal confronto di modelli tramite la convalida incrociata se l’effetto è molto piccolo e/o se il campione di dati è piccolo. In questi casi, alcuni ricercatori ritengono che siano più adatti altri metodi di confronto dei modelli, come ad esempio i fattori di Bayes. L’uso dei fattori di Bayes, tuttavia, è controverso, dato che essi dipendono fortemente dalla scelta delle distribuzioni a priori. Se possibile è preferibile utilizzare le procedure descritte in questa parte della dispensa, con campioni di ampiezza adeguata.</p>

<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
Gelman, Andrew, John B Carlin, Hal S Stern, and Donald B Rubin. 1995. <em>Bayesian Data Analysis</em>. Chapman; Hall/CRC.
</div>
<div class="csl-entry">
Gelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. <em>Regression and Other Stories</em>. Cambridge University Press.
</div>
<div class="csl-entry">
Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014. <span>“Understanding Predictive Information Criteria for Bayesian Models.”</span> <em>Statistics and Computing</em> 24 (6): 997–1016.
</div>
<div class="csl-entry">
Hoeting, Jennifer A, David Madigan, Adrian E Raftery, and Chris T Volinsky. 1999. <span>“Bayesian Model Averaging: A Tutorial (with Comments by m. Clyde, David Draper and EI George, and a Rejoinder by the Authors.”</span> <em>Statistical Science</em> 14 (4): 382–417.
</div>
<div class="csl-entry">
Horn, Samantha, and George Loewenstein. 2021. <span>“Underestimating Learning by Doing.”</span> <em>Available at SSRN 3941441</em>.
</div>
<div class="csl-entry">
Johnson, Alicia A., Miles Ott, and Mine Dogucu. 2022. <em><span class="nocase">Bayes Rules! An Introduction to Bayesian Modeling with R</span></em>. CRC Press.
</div>
<div class="csl-entry">
Lord, Frederic M. 1950. <span>“Efficiency of Prediction When a Regression Equation from One Sample Is Used in a New Sample.”</span> <em>ETS Research Bulletin Series</em> 1950 (2): 1–6.
</div>
<div class="csl-entry">
Martin, Osvaldo A, Ravin Kumar, and Junpeng Lao. 2022. <em>Bayesian Modeling and Computation in Python</em>. CRC Press.
</div>
<div class="csl-entry">
McElreath, Richard. 2020. <em>Statistical Rethinking: <span>A</span> <span>Bayesian</span> Course with Examples in <span>R</span> and <span>Stan</span></em>. 2nd Edition. Boca Raton, Florida: CRC Press.
</div>
<div class="csl-entry">
Navarro, Danielle J. 2019. <span>“Between the Devil and the Deep Blue Sea: Tensions Between Scientific Judgement and Statistical Model Selection.”</span> <em>Computational Brain &amp; Behavior</em> 2 (1): 28–34.
</div>
<div class="csl-entry">
Song, Q Chelsea, Chen Tang, and Serena Wee. 2021. <span>“Making Sense of Model Generalizability: A Tutorial on Cross-Validation in r and Shiny.”</span> <em>Advances in Methods and Practices in Psychological Science</em> 4 (1): 2515245920947067.
</div>
<div class="csl-entry">
Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. <span>“Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and WAIC.”</span> <em>Statistics and Computing</em> 27 (5): 1413–32.
</div>
<div class="csl-entry">
Zetsche, Ulrike, Paul-Christian Bürkner, and Babette Renneberg. 2019. <span>“Future Expectations in Clinical Depression: <span>Biased</span> or Realistic?”</span> <em>Journal of Abnormal Psychology</em> 128 (7): 678–88.
</div>
</div>
</div>
</div>













<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-gelman1995bayesian" class="csl-entry">
Gelman, Andrew, John B Carlin, Hal S Stern, and Donald B Rubin. 1995. <em>Bayesian Data Analysis</em>. Chapman; Hall/CRC.
</div>
<div id="ref-gelman2020regression" class="csl-entry">
Gelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. <em>Regression and Other Stories</em>. Cambridge University Press.
</div>
<div id="ref-gelman2014understanding" class="csl-entry">
Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014. <span>“Understanding Predictive Information Criteria for Bayesian Models.”</span> <em>Statistics and Computing</em> 24 (6): 997–1016.
</div>
<div id="ref-McElreath_rethinking" class="csl-entry">
McElreath, Richard. 2020. <em>Statistical Rethinking: <span>A</span> <span>Bayesian</span> Course with Examples in <span>R</span> and <span>Stan</span></em>. 2nd Edition. Boca Raton, Florida: CRC Press.
</div>
<div id="ref-navarro2019between" class="csl-entry">
Navarro, Danielle J. 2019. <span>“Between the Devil and the Deep Blue Sea: Tensions Between Scientific Judgement and Statistical Model Selection.”</span> <em>Computational Brain &amp; Behavior</em> 2 (1): 28–34.
</div>
<div id="ref-vehtari2017practical" class="csl-entry">
Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. <span>“Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and WAIC.”</span> <em>Statistics and Computing</em> 27 (5): 1413–32.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="7">
<li id="fn7"><p>A questo proposito, è necessario aggiungere una nota di cautela. Come fa notare <span class="citation">McElreath (<a href="#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span>, fare previsioni e inferire i rapporti causali sono due cose molto diverse. Statistiche quali AIC, WAIC e LOO-CV consentono di individuare modelli con buone capacità predittive. Tali modelli, tuttavia, non riflettono necessariamente la struttura causale del fenomeno considerato: la selezione di modelli basata unicamente sull’accuratezza predittiva non garantisce che venga selezionato il modello che riflette la struttura causale del fenomeno <span class="citation">(si veda anche <a href="#ref-navarro2019between" role="doc-biblioref">Navarro 2019</a>)</span>.<a href="ch:info-criterion.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p><span class="citation">McElreath (<a href="#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span> nota che, spesso, i ricercatori eliminano i valori anomali prima di adattare un modello ai dati, basandosi solo sulla distanza dal valore medio della variabile dipendente misurata in termini di unità di deviazione standard. Secondo <span class="citation">McElreath (<a href="#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span> questo non dovrebbe mai essere fatto: un’osservazione può essere considerata come un valore anomalo o un valore influente solo alla luce delle predizioni di un modello (mai prima di avere adattato il modello ai dati). Se ci sono solo pochi valori anomali una strategia possibile è quella di riportare i risultati delle analisi statistiche svolte su tutto il campione dei dati oppure dopo avere eliminato le osservazioni anomale e influenti.<a href="ch:info-criterion.html#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="la-divergenza-di-kullback-leibler.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/092_info_criterion.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ds4psy.pdf", "ds4psy.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
