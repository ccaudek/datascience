<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capitolo 25 Regressione lineare con un singolo predittore | Data Science per psicologi</title>
  <meta name="description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Capitolo 25 Regressione lineare con un singolo predittore | Data Science per psicologi" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  <meta name="github-repo" content="ccaudek/datascience" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capitolo 25 Regressione lineare con un singolo predittore | Data Science per psicologi" />
  
  <meta name="twitter:description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2022-05-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-regr-intro.html"/>
<link rel="next" href="ch-reg-lin-stan.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data science per psicologi</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Benvenuti</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#la-psicologia-e-la-data-science"><i class="fa fa-check"></i>La psicologia e la Data Science</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#come-studiare"><i class="fa fa-check"></i>Come studiare</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="part"><span><b>I Nozioni preliminari</b></span></li>
<li class="chapter" data-level="1" data-path="ch-key-notions.html"><a href="ch-key-notions.html"><i class="fa fa-check"></i><b>1</b> Concetti chiave</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ch-key-notions.html"><a href="ch-key-notions.html#popolazioni-e-campioni"><i class="fa fa-check"></i><b>1.1</b> Popolazioni e campioni</a></li>
<li class="chapter" data-level="1.2" data-path="ch-key-notions.html"><a href="ch-key-notions.html#variabili-e-costanti"><i class="fa fa-check"></i><b>1.2</b> Variabili e costanti</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="ch-key-notions.html"><a href="ch-key-notions.html#variabili-casuali"><i class="fa fa-check"></i><b>1.2.1</b> Variabili casuali</a></li>
<li class="chapter" data-level="1.2.2" data-path="ch-key-notions.html"><a href="ch-key-notions.html#variabili-indipendenti-e-variabili-dipendenti"><i class="fa fa-check"></i><b>1.2.2</b> Variabili indipendenti e variabili dipendenti</a></li>
<li class="chapter" data-level="1.2.3" data-path="ch-key-notions.html"><a href="ch-key-notions.html#la-matrice-dei-dati"><i class="fa fa-check"></i><b>1.2.3</b> La matrice dei dati</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ch-key-notions.html"><a href="ch-key-notions.html#parametri-e-modelli"><i class="fa fa-check"></i><b>1.3</b> Parametri e modelli</a></li>
<li class="chapter" data-level="1.4" data-path="ch-key-notions.html"><a href="ch-key-notions.html#effetto"><i class="fa fa-check"></i><b>1.4</b> Effetto</a></li>
<li class="chapter" data-level="1.5" data-path="ch-key-notions.html"><a href="ch-key-notions.html#stima-e-inferenza"><i class="fa fa-check"></i><b>1.5</b> Stima e inferenza</a></li>
<li class="chapter" data-level="1.6" data-path="ch-key-notions.html"><a href="ch-key-notions.html#metodi-e-procedure-della-psicologia"><i class="fa fa-check"></i><b>1.6</b> Metodi e procedure della psicologia</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html"><i class="fa fa-check"></i><b>2</b> La misurazione in psicologia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#le-scale-di-misura"><i class="fa fa-check"></i><b>2.1</b> Le scale di misura</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-nominale"><i class="fa fa-check"></i><b>2.1.1</b> Scala nominale</a></li>
<li class="chapter" data-level="2.1.2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-ordinale"><i class="fa fa-check"></i><b>2.1.2</b> Scala ordinale</a></li>
<li class="chapter" data-level="2.1.3" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-ad-intervalli"><i class="fa fa-check"></i><b>2.1.3</b> Scala ad intervalli</a></li>
<li class="chapter" data-level="2.1.4" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-di-rapporti"><i class="fa fa-check"></i><b>2.1.4</b> Scala di rapporti</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#gerarchia-dei-livelli-di-scala-di-misura"><i class="fa fa-check"></i><b>2.2</b> Gerarchia dei livelli di scala di misura</a></li>
<li class="chapter" data-level="2.3" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#variabili-discrete-o-continue"><i class="fa fa-check"></i><b>2.3</b> Variabili discrete o continue</a></li>
<li class="chapter" data-level="2.4" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#alcune-misure-sono-migliori-di-altre"><i class="fa fa-check"></i><b>2.4</b> Alcune misure sono migliori di altre</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#tipologie-di-errori"><i class="fa fa-check"></i><b>2.4.1</b> Tipologie di errori</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#commenti-e-considerazioni-finali"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="part"><span><b>II Analisi esplorativa dei dati</b></span></li>
<li class="chapter" data-level="3" data-path="ch-eda.html"><a href="ch-eda.html"><i class="fa fa-check"></i><b>3</b> Variabili e distribuzioni di frequenza</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch-eda.html"><a href="ch-eda.html#chapter-descript"><i class="fa fa-check"></i><b>3.1</b> Introduzione all’esplorazione dei dati</a></li>
<li class="chapter" data-level="3.2" data-path="ch-eda.html"><a href="ch-eda.html#un-excursus-storico"><i class="fa fa-check"></i><b>3.2</b> Un excursus storico</a></li>
<li class="chapter" data-level="3.3" data-path="ch-eda.html"><a href="ch-eda.html#riassumere-i-dati"><i class="fa fa-check"></i><b>3.3</b> Riassumere i dati</a></li>
<li class="chapter" data-level="3.4" data-path="ch-eda.html"><a href="ch-eda.html#i-dati-grezzi"><i class="fa fa-check"></i><b>3.4</b> I dati grezzi</a></li>
<li class="chapter" data-level="3.5" data-path="ch-eda.html"><a href="ch-eda.html#distribuzioni-di-frequenze"><i class="fa fa-check"></i><b>3.5</b> Distribuzioni di frequenze</a></li>
<li class="chapter" data-level="3.6" data-path="ch-eda.html"><a href="ch-eda.html#istogramma"><i class="fa fa-check"></i><b>3.6</b> Istogramma</a></li>
<li class="chapter" data-level="3.7" data-path="ch-eda.html"><a href="ch-eda.html#kernel-density-plot"><i class="fa fa-check"></i><b>3.7</b> Kernel density plot</a></li>
<li class="chapter" data-level="3.8" data-path="ch-eda.html"><a href="ch-eda.html#forma-di-una-distribuzione"><i class="fa fa-check"></i><b>3.8</b> Forma di una distribuzione</a></li>
<li class="chapter" data-level="3.9" data-path="ch-eda.html"><a href="ch-eda.html#indici-di-posizione"><i class="fa fa-check"></i><b>3.9</b> Indici di posizione</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="ch-eda.html"><a href="ch-eda.html#quantili"><i class="fa fa-check"></i><b>3.9.1</b> Quantili</a></li>
<li class="chapter" data-level="3.9.2" data-path="ch-eda.html"><a href="ch-eda.html#diagramma-a-scatola"><i class="fa fa-check"></i><b>3.9.2</b> Diagramma a scatola</a></li>
<li class="chapter" data-level="3.9.3" data-path="ch-eda.html"><a href="ch-eda.html#sina-plot"><i class="fa fa-check"></i><b>3.9.3</b> Sina plot</a></li>
<li class="chapter" data-level="3.9.4" data-path="ch-eda.html"><a href="ch-eda.html#leccellenza-grafica"><i class="fa fa-check"></i><b>3.9.4</b> L’eccellenza grafica</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-eda.html"><a href="ch-eda.html#commenti-e-considerazioni-finali-1"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html"><i class="fa fa-check"></i><b>4</b> Indici di posizione e di scala</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#indici-di-tendenza-centrale"><i class="fa fa-check"></i><b>4.1</b> Indici di tendenza centrale</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#media"><i class="fa fa-check"></i><b>4.1.1</b> Media</a></li>
<li class="chapter" data-level="4.1.2" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#media-spuntata"><i class="fa fa-check"></i><b>4.1.2</b> Media spuntata</a></li>
<li class="chapter" data-level="4.1.3" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#moda-e-mediana"><i class="fa fa-check"></i><b>4.1.3</b> Moda e mediana</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#indici-di-dispersione"><i class="fa fa-check"></i><b>4.2</b> Indici di dispersione</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#indici-basati-sullordinamento-dei-dati"><i class="fa fa-check"></i><b>4.2.1</b> Indici basati sull’ordinamento dei dati</a></li>
<li class="chapter" data-level="4.2.2" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#varianza"><i class="fa fa-check"></i><b>4.2.2</b> Varianza</a></li>
<li class="chapter" data-level="4.2.3" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#precisione"><i class="fa fa-check"></i><b>4.2.3</b> Precisione</a></li>
<li class="chapter" data-level="4.2.4" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#scarto-tipo"><i class="fa fa-check"></i><b>4.2.4</b> Scarto tipo</a></li>
<li class="chapter" data-level="4.2.5" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#deviazione-mediana-assoluta"><i class="fa fa-check"></i><b>4.2.5</b> Deviazione mediana assoluta</a></li>
<li class="chapter" data-level="4.2.6" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#indici-di-variabilità-relativi"><i class="fa fa-check"></i><b>4.2.6</b> Indici di variabilità relativi</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-loc-scale.html"><a href="ch-loc-scale.html#commenti-e-considerazioni-finali-2"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-corr.html"><a href="ch-corr.html"><i class="fa fa-check"></i><b>5</b> Le relazioni tra variabili</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ch-corr.html"><a href="ch-corr.html#diagramma-a-dispersione"><i class="fa fa-check"></i><b>5.1</b> Diagramma a dispersione</a></li>
<li class="chapter" data-level="5.2" data-path="ch-corr.html"><a href="ch-corr.html#covarianza"><i class="fa fa-check"></i><b>5.2</b> Covarianza</a></li>
<li class="chapter" data-level="5.3" data-path="ch-corr.html"><a href="ch-corr.html#correlazione"><i class="fa fa-check"></i><b>5.3</b> Correlazione</a></li>
<li class="chapter" data-level="5.4" data-path="ch-corr.html"><a href="ch-corr.html#correlazione-e-causazione"><i class="fa fa-check"></i><b>5.4</b> Correlazione e causazione</a></li>
<li class="chapter" data-level="5.5" data-path="ch-corr.html"><a href="ch-corr.html#usi-della-correlazione"><i class="fa fa-check"></i><b>5.5</b> Usi della correlazione</a></li>
<li class="chapter" data-level="5.6" data-path="ch-corr.html"><a href="ch-corr.html#correlazione-di-spearman"><i class="fa fa-check"></i><b>5.6</b> Correlazione di Spearman</a></li>
<li class="chapter" data-level="5.7" data-path="ch-corr.html"><a href="ch-corr.html#correlazione-nulla"><i class="fa fa-check"></i><b>5.7</b> Correlazione nulla</a></li>
<li class="chapter" data-level="" data-path="ch-corr.html"><a href="ch-corr.html#commenti-e-considerazioni-finali-3"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="part"><span><b>III Il calcolo delle probabilità</b></span></li>
<li class="chapter" data-level="6" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html"><i class="fa fa-check"></i><b>6</b> La logica dell’incerto</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#che-cosè-la-probabilità"><i class="fa fa-check"></i><b>6.1</b> Che cos’è la probabilità?</a></li>
<li class="chapter" data-level="6.2" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#variabili-casuali-e-probabilità-di-un-evento"><i class="fa fa-check"></i><b>6.2</b> Variabili casuali e probabilità di un evento</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#eventi-e-probabilità"><i class="fa fa-check"></i><b>6.2.1</b> Eventi e probabilità</a></li>
<li class="chapter" data-level="6.2.2" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#spazio-campione-e-risultati-possibili"><i class="fa fa-check"></i><b>6.2.2</b> Spazio campione e risultati possibili</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#variabili-casuali-1"><i class="fa fa-check"></i><b>6.3</b> Variabili casuali</a></li>
<li class="chapter" data-level="6.4" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#usare-la-simulazione-per-stimare-le-probabilità"><i class="fa fa-check"></i><b>6.4</b> Usare la simulazione per stimare le probabilità</a></li>
<li class="chapter" data-level="6.5" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#la-legge-dei-grandi-numeri"><i class="fa fa-check"></i><b>6.5</b> La legge dei grandi numeri</a></li>
<li class="chapter" data-level="6.6" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#variabili-casuali-multiple"><i class="fa fa-check"></i><b>6.6</b> Variabili casuali multiple</a></li>
<li class="chapter" data-level="6.7" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#sec:fun-mass-prob"><i class="fa fa-check"></i><b>6.7</b> Funzione di massa di probabilità</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#funzione-di-ripartizione"><i class="fa fa-check"></i><b>6.7.1</b> Funzione di ripartizione</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-intro-prob-1.html"><a href="ch-intro-prob-1.html#commenti-e-considerazioni-finali-4"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-prob-cond.html"><a href="ch-prob-cond.html"><i class="fa fa-check"></i><b>7</b> Probabilità condizionata</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ch-prob-cond.html"><a href="ch-prob-cond.html#sec:bayes-cancer"><i class="fa fa-check"></i><b>7.1</b> Probabilità condizionata su altri eventi</a></li>
<li class="chapter" data-level="7.2" data-path="ch-prob-cond.html"><a href="ch-prob-cond.html#la-regola-moltiplicativa"><i class="fa fa-check"></i><b>7.2</b> La regola moltiplicativa</a></li>
<li class="chapter" data-level="7.3" data-path="ch-prob-cond.html"><a href="ch-prob-cond.html#lindipendendenza-stocastica"><i class="fa fa-check"></i><b>7.3</b> L’indipendendenza stocastica</a></li>
<li class="chapter" data-level="7.4" data-path="ch-prob-cond.html"><a href="ch-prob-cond.html#il-teorema-della-probabilità-totale"><i class="fa fa-check"></i><b>7.4</b> Il teorema della probabilità totale</a></li>
<li class="chapter" data-level="7.5" data-path="ch-prob-cond.html"><a href="ch-prob-cond.html#il-teorema-della-probabilità-assoluta"><i class="fa fa-check"></i><b>7.5</b> Il teorema della probabilità assoluta</a></li>
<li class="chapter" data-level="7.6" data-path="ch-prob-cond.html"><a href="ch-prob-cond.html#indipendenza-condizionale"><i class="fa fa-check"></i><b>7.6</b> Indipendenza condizionale</a></li>
<li class="chapter" data-level="" data-path="ch-prob-cond.html"><a href="ch-prob-cond.html#commenti-e-considerazioni-finali-5"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-theorem-bayes.html"><a href="ch-theorem-bayes.html"><i class="fa fa-check"></i><b>8</b> Il teorema di Bayes</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ch-theorem-bayes.html"><a href="ch-theorem-bayes.html#il-teorema-di-bayes"><i class="fa fa-check"></i><b>8.1</b> Il teorema di Bayes</a></li>
<li class="chapter" data-level="" data-path="ch-theorem-bayes.html"><a href="ch-theorem-bayes.html#commenti-e-considerazioni-finali-6"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-prob-congiunta.html"><a href="ch-prob-congiunta.html"><i class="fa fa-check"></i><b>9</b> Probabilità congiunta</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ch-prob-congiunta.html"><a href="ch-prob-congiunta.html#funzione-di-probabilità-congiunta"><i class="fa fa-check"></i><b>9.1</b> Funzione di probabilità congiunta</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ch-prob-congiunta.html"><a href="ch-prob-congiunta.html#proprietà"><i class="fa fa-check"></i><b>9.1.1</b> Proprietà</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-prob-congiunta.html"><a href="ch-prob-congiunta.html#eventi"><i class="fa fa-check"></i><b>9.1.2</b> Eventi</a></li>
<li class="chapter" data-level="9.1.3" data-path="ch-prob-congiunta.html"><a href="ch-prob-congiunta.html#sec:marg-distr-discr"><i class="fa fa-check"></i><b>9.1.3</b> Funzioni di probabilità marginali</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-prob-congiunta.html"><a href="ch-prob-congiunta.html#sec:margin-vc-cont"><i class="fa fa-check"></i><b>9.2</b> Marginalizzazione di variabili casuali continue</a></li>
<li class="chapter" data-level="" data-path="ch-prob-congiunta.html"><a href="ch-prob-congiunta.html#commenti-e-considerazioni-finali-7"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-intro-density-function.html"><a href="ch-intro-density-function.html"><i class="fa fa-check"></i><b>10</b> La densità di probabilità</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ch-intro-density-function.html"><a href="ch-intro-density-function.html#spinner-e-variabili-casuali-continue-uniformi"><i class="fa fa-check"></i><b>10.1</b> Spinner e variabili casuali continue uniformi</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="ch-intro-density-function.html"><a href="ch-intro-density-function.html#il-paradosso-delle-variabili-casuali-continue"><i class="fa fa-check"></i><b>10.1.1</b> Il paradosso delle variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="ch-intro-density-function.html"><a href="ch-intro-density-function.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua"><i class="fa fa-check"></i><b>10.2</b> La funzione di ripartizione per una variabile casuale continua</a></li>
<li class="chapter" data-level="10.3" data-path="ch-intro-density-function.html"><a href="ch-intro-density-function.html#la-distribuzione-uniforme"><i class="fa fa-check"></i><b>10.3</b> La distribuzione uniforme</a></li>
<li class="chapter" data-level="10.4" data-path="ch-intro-density-function.html"><a href="ch-intro-density-function.html#dagli-istogrammi-alle-densità"><i class="fa fa-check"></i><b>10.4</b> Dagli istogrammi alle densità</a></li>
<li class="chapter" data-level="10.5" data-path="ch-intro-density-function.html"><a href="ch-intro-density-function.html#funzione-di-densità-di-probabilità"><i class="fa fa-check"></i><b>10.5</b> Funzione di densità di probabilità</a></li>
<li class="chapter" data-level="10.6" data-path="ch-intro-density-function.html"><a href="ch-intro-density-function.html#la-funzione-di-ripartizione"><i class="fa fa-check"></i><b>10.6</b> La funzione di ripartizione</a></li>
<li class="chapter" data-level="10.7" data-path="ch-intro-density-function.html"><a href="ch-intro-density-function.html#media-e-mediana"><i class="fa fa-check"></i><b>10.7</b> Media e mediana</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html"><i class="fa fa-check"></i><b>11</b> Valore atteso e varianza</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#valore-atteso"><i class="fa fa-check"></i><b>11.1</b> Valore atteso</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#interpretazione"><i class="fa fa-check"></i><b>11.1.1</b> Interpretazione</a></li>
<li class="chapter" data-level="11.1.2" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#proprietà-del-valore-atteso"><i class="fa fa-check"></i><b>11.1.2</b> Proprietà del valore atteso</a></li>
<li class="chapter" data-level="11.1.3" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#variabili-casuali-continue"><i class="fa fa-check"></i><b>11.1.3</b> Variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#varianza-1"><i class="fa fa-check"></i><b>11.2</b> Varianza</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#formula-alternativa-per-la-varianza"><i class="fa fa-check"></i><b>11.2.1</b> Formula alternativa per la varianza</a></li>
<li class="chapter" data-level="11.2.2" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#variabili-casuali-continue-1"><i class="fa fa-check"></i><b>11.2.2</b> Variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#deviazione-standard"><i class="fa fa-check"></i><b>11.3</b> Deviazione standard</a></li>
<li class="chapter" data-level="11.4" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#standardizzazione"><i class="fa fa-check"></i><b>11.4</b> Standardizzazione</a></li>
<li class="chapter" data-level="11.5" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#momenti-di-variabili-casuali"><i class="fa fa-check"></i><b>11.5</b> Momenti di variabili casuali</a></li>
<li class="chapter" data-level="11.6" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#covarianza-1"><i class="fa fa-check"></i><b>11.6</b> Covarianza</a></li>
<li class="chapter" data-level="11.7" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#correlazione-1"><i class="fa fa-check"></i><b>11.7</b> Correlazione</a></li>
<li class="chapter" data-level="11.8" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#proprietà-1"><i class="fa fa-check"></i><b>11.8</b> Proprietà</a>
<ul>
<li class="chapter" data-level="11.8.1" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#incorrelazione"><i class="fa fa-check"></i><b>11.8.1</b> Incorrelazione</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-expval-var-rv.html"><a href="ch-expval-var-rv.html#conclusioni"><i class="fa fa-check"></i>Conclusioni</a></li>
</ul></li>
<li class="part"><span><b>IV Distribuzioni teoriche di probabilità</b></span></li>
<li class="chapter" data-level="12" data-path="ch-distr-rv-discr.html"><a href="ch-distr-rv-discr.html"><i class="fa fa-check"></i><b>12</b> Distribuzioni di v.c. discrete</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ch-distr-rv-discr.html"><a href="ch-distr-rv-discr.html#una-prova-bernoulliana"><i class="fa fa-check"></i><b>12.1</b> Una prova Bernoulliana</a></li>
<li class="chapter" data-level="12.2" data-path="ch-distr-rv-discr.html"><a href="ch-distr-rv-discr.html#una-sequenza-di-prove-bernoulliane"><i class="fa fa-check"></i><b>12.2</b> Una sequenza di prove Bernoulliane</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ch-distr-rv-discr.html"><a href="ch-distr-rv-discr.html#valore-atteso-e-deviazione-standard"><i class="fa fa-check"></i><b>12.2.1</b> Valore atteso e deviazione standard</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ch-distr-rv-discr.html"><a href="ch-distr-rv-discr.html#distribuzione-di-poisson"><i class="fa fa-check"></i><b>12.3</b> Distribuzione di Poisson</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="ch-distr-rv-discr.html"><a href="ch-distr-rv-discr.html#alcune-proprietà-della-variabile-di-poisson"><i class="fa fa-check"></i><b>12.3.1</b> Alcune proprietà della variabile di Poisson</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="ch-distr-rv-discr.html"><a href="ch-distr-rv-discr.html#distribuzione-discreta-uniforme"><i class="fa fa-check"></i><b>12.4</b> Distribuzione discreta uniforme</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="ch-distr-rv-discr.html"><a href="ch-distr-rv-discr.html#usiamo-textsfr"><i class="fa fa-check"></i><b>12.4.1</b> Usiamo <span class="math inline">\(\textsf{R}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="ch-distr-rv-discr.html"><a href="ch-distr-rv-discr.html#distribuzione-beta-binomiale"><i class="fa fa-check"></i><b>12.5</b> Distribuzione beta-binomiale</a></li>
<li class="chapter" data-level="" data-path="ch-distr-rv-discr.html"><a href="ch-distr-rv-discr.html#commenti-e-considerazioni-finali-8"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html"><i class="fa fa-check"></i><b>13</b> Distribuzioni di v.c. continue</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#distribuzione-normale"><i class="fa fa-check"></i><b>13.1</b> Distribuzione Normale</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#limite-delle-distribuzioni-binomiali"><i class="fa fa-check"></i><b>13.1.1</b> Limite delle distribuzioni binomiali</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#normal-random-walk"><i class="fa fa-check"></i><b>13.2</b> La Normale prodotta con una simulazione</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#concentrazione"><i class="fa fa-check"></i><b>13.2.1</b> Concentrazione</a></li>
<li class="chapter" data-level="13.2.2" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#funzione-di-ripartizione-1"><i class="fa fa-check"></i><b>13.2.2</b> Funzione di ripartizione</a></li>
<li class="chapter" data-level="13.2.3" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#distribuzione-normale-standard"><i class="fa fa-check"></i><b>13.2.3</b> Distribuzione Normale standard</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#teorema-del-limite-centrale"><i class="fa fa-check"></i><b>13.3</b> Teorema del limite centrale</a></li>
<li class="chapter" data-level="13.4" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#distribuzione-chi-quadrato"><i class="fa fa-check"></i><b>13.4</b> Distribuzione Chi-quadrato</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#proprietà-2"><i class="fa fa-check"></i><b>13.4.1</b> Proprietà</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#distribuzione-t-di-student"><i class="fa fa-check"></i><b>13.5</b> Distribuzione <span class="math inline">\(t\)</span> di Student</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#proprietà-3"><i class="fa fa-check"></i><b>13.5.1</b> Proprietà</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#funzione-beta"><i class="fa fa-check"></i><b>13.6</b> Funzione beta</a></li>
<li class="chapter" data-level="13.7" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#distribuzione-beta"><i class="fa fa-check"></i><b>13.7</b> Distribuzione Beta</a></li>
<li class="chapter" data-level="13.8" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#distribuzione-di-cauchy"><i class="fa fa-check"></i><b>13.8</b> Distribuzione di Cauchy</a></li>
<li class="chapter" data-level="13.9" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#distribuzione-log-normale"><i class="fa fa-check"></i><b>13.9</b> Distribuzione log-normale</a></li>
<li class="chapter" data-level="13.10" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#distribuzione-di-pareto"><i class="fa fa-check"></i><b>13.10</b> Distribuzione di Pareto</a></li>
<li class="chapter" data-level="" data-path="ch-distr-rv-cont.html"><a href="ch-distr-rv-cont.html#commenti-e-considerazioni-finali-9"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="part"><span><b>V Inferenza bayesiana</b></span></li>
<li class="chapter" data-level="14" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html"><i class="fa fa-check"></i><b>14</b> Flusso di lavoro bayesiano</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#modellizzazione-bayesiana"><i class="fa fa-check"></i><b>14.1</b> Modellizzazione bayesiana</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#notazione"><i class="fa fa-check"></i><b>14.1.1</b> Notazione</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#distribuzioni-a-priori"><i class="fa fa-check"></i><b>14.2</b> Distribuzioni a priori</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#tipologie-di-distribuzioni-a-priori"><i class="fa fa-check"></i><b>14.2.1</b> Tipologie di distribuzioni a priori</a></li>
<li class="chapter" data-level="14.2.2" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#selezione-della-distribuzione-a-priori"><i class="fa fa-check"></i><b>14.2.2</b> Selezione della distribuzione a priori</a></li>
<li class="chapter" data-level="14.2.3" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#unapplicazione-empirica"><i class="fa fa-check"></i><b>14.2.3</b> Un’applicazione empirica</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#la-funzione-di-verosimiglianza"><i class="fa fa-check"></i><b>14.3</b> La funzione di verosimiglianza</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#notazione-1"><i class="fa fa-check"></i><b>14.3.1</b> Notazione</a></li>
<li class="chapter" data-level="14.3.2" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#la-log-verosimiglianza"><i class="fa fa-check"></i><b>14.3.2</b> La log-verosimiglianza</a></li>
<li class="chapter" data-level="14.3.3" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#unapplicazione-empirica-1"><i class="fa fa-check"></i><b>14.3.3</b> Un’applicazione empirica</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#sec:const-normaliz-bino23"><i class="fa fa-check"></i><b>14.4</b> La verosimiglianza marginale</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#unapplicazione-empirica-2"><i class="fa fa-check"></i><b>14.4.1</b> Un’applicazione empirica</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#distribuzione-a-posteriori"><i class="fa fa-check"></i><b>14.5</b> Distribuzione a posteriori</a></li>
<li class="chapter" data-level="14.6" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#distribuzione-predittiva-a-priori"><i class="fa fa-check"></i><b>14.6</b> Distribuzione predittiva a priori</a></li>
<li class="chapter" data-level="14.7" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#distribuzione-predittiva-a-posteriori"><i class="fa fa-check"></i><b>14.7</b> Distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="" data-path="ch-bayes-workflow.html"><a href="ch-bayes-workflow.html#commenti-e-considerazioni-finali-10"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ch-subj-think-prop.html"><a href="ch-subj-think-prop.html"><i class="fa fa-check"></i><b>15</b> Pensare ad una proporzione in termini soggettivi</a>
<ul>
<li class="chapter" data-level="15.1" data-path="ch-subj-think-prop.html"><a href="ch-subj-think-prop.html#ch-prior-discr-binom"><i class="fa fa-check"></i><b>15.1</b> Inferenza bayesiana con una distribuzione a priori discreta</a></li>
<li class="chapter" data-level="15.2" data-path="ch-subj-think-prop.html"><a href="ch-subj-think-prop.html#ch-prior-cont-binom"><i class="fa fa-check"></i><b>15.2</b> Inferenza bayesiana con una distribuzione a priori continua</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="ch-subj-think-prop.html"><a href="ch-subj-think-prop.html#quali-parametri-per-la-distribuzione-beta"><i class="fa fa-check"></i><b>15.2.1</b> Quali parametri per la distribuzione Beta?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-subj-think-prop.html"><a href="ch-subj-think-prop.html#commenti-e-considerazioni-finali-11"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html"><i class="fa fa-check"></i><b>16</b> Distribuzioni coniugate</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#lo-schema-beta-binomiale"><i class="fa fa-check"></i><b>16.1</b> Lo schema beta-binomiale</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#la-specificazione-della-distribuzione-a-priori"><i class="fa fa-check"></i><b>16.1.1</b> La specificazione della distribuzione a priori</a></li>
<li class="chapter" data-level="16.1.2" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#la-specificazione-della-distribuzione-a-posteriori"><i class="fa fa-check"></i><b>16.1.2</b> La specificazione della distribuzione a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#inferenza-bayesiana-con-distribuzioni-a-priori-continue"><i class="fa fa-check"></i><b>16.2</b> Inferenza bayesiana con distribuzioni a priori continue</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#approccio-bayesiano-alla-verifica-di-ipotesi"><i class="fa fa-check"></i><b>16.2.1</b> Approccio bayesiano alla verifica di ipotesi</a></li>
<li class="chapter" data-level="16.2.2" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#intervalli-di-credibilità"><i class="fa fa-check"></i><b>16.2.2</b> Intervalli di credibilità</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#principali-distribuzioni-coniugate"><i class="fa fa-check"></i><b>16.3</b> Principali distribuzioni coniugate</a></li>
<li class="chapter" data-level="" data-path="ch-distr-coniugate.html"><a href="ch-distr-coniugate.html#commenti-e-considerazioni-finali-12"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ch-prior-influence.html"><a href="ch-prior-influence.html"><i class="fa fa-check"></i><b>17</b> L’influenza della distribuzione a priori</a>
<ul>
<li class="chapter" data-level="17.1" data-path="ch-prior-influence.html"><a href="ch-prior-influence.html#il-test-di-benchdel"><i class="fa fa-check"></i><b>17.1</b> Il test di Benchdel</a></li>
<li class="chapter" data-level="17.2" data-path="ch-prior-influence.html"><a href="ch-prior-influence.html#stessi-dati-ma-diverse-distribuzioni-a-priori"><i class="fa fa-check"></i><b>17.2</b> Stessi dati ma diverse distribuzioni a priori</a></li>
<li class="chapter" data-level="17.3" data-path="ch-prior-influence.html"><a href="ch-prior-influence.html#dati-diversi-ma-la-stessa-distribuzione-a-priori"><i class="fa fa-check"></i><b>17.3</b> Dati diversi ma la stessa distribuzione a priori</a></li>
<li class="chapter" data-level="17.4" data-path="ch-prior-influence.html"><a href="ch-prior-influence.html#dati-diversi-e-diverse-distribuzioni-a-priori"><i class="fa fa-check"></i><b>17.4</b> Dati diversi e diverse distribuzioni a priori</a></li>
<li class="chapter" data-level="17.5" data-path="ch-prior-influence.html"><a href="ch-prior-influence.html#collegare-le-intuizioni-alla-teoria"><i class="fa fa-check"></i><b>17.5</b> Collegare le intuizioni alla teoria</a></li>
<li class="chapter" data-level="" data-path="ch-prior-influence.html"><a href="ch-prior-influence.html#commenti-e-considerazioni-finali-13"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ch-post-approx.html"><a href="ch-post-approx.html"><i class="fa fa-check"></i><b>18</b> Approssimazione della distribuzione a posteriori</a>
<ul>
<li class="chapter" data-level="18.1" data-path="ch-post-approx.html"><a href="ch-post-approx.html#metodo-basato-su-griglia"><i class="fa fa-check"></i><b>18.1</b> Metodo basato su griglia</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="ch-post-approx.html"><a href="ch-post-approx.html#modello-beta-binomiale"><i class="fa fa-check"></i><b>18.1.1</b> Modello Beta-Binomiale</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="ch-post-approx.html"><a href="ch-post-approx.html#chapter-simulazioneMC"><i class="fa fa-check"></i><b>18.2</b> Metodo Monte Carlo</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="ch-post-approx.html"><a href="ch-post-approx.html#integration-mc"><i class="fa fa-check"></i><b>18.2.1</b> Integrazione di Monte Carlo</a></li>
<li class="chapter" data-level="18.2.2" data-path="ch-post-approx.html"><a href="ch-post-approx.html#descrizione-intuitiva"><i class="fa fa-check"></i><b>18.2.2</b> Descrizione intuitiva</a></li>
<li class="chapter" data-level="18.2.3" data-path="ch-post-approx.html"><a href="ch-post-approx.html#unapplicazione-empirica-3"><i class="fa fa-check"></i><b>18.2.3</b> Un’applicazione empirica</a></li>
<li class="chapter" data-level="18.2.4" data-path="ch-post-approx.html"><a href="ch-post-approx.html#una-passeggiata-casuale-sui-numeri-naturali"><i class="fa fa-check"></i><b>18.2.4</b> Una passeggiata casuale sui numeri naturali</a></li>
<li class="chapter" data-level="18.2.5" data-path="ch-post-approx.html"><a href="ch-post-approx.html#lalgoritmo-di-metropolis"><i class="fa fa-check"></i><b>18.2.5</b> L’algoritmo di Metropolis</a></li>
<li class="chapter" data-level="18.2.6" data-path="ch-post-approx.html"><a href="ch-post-approx.html#unapplicazione-empirica-4"><i class="fa fa-check"></i><b>18.2.6</b> Un’applicazione empirica</a></li>
<li class="chapter" data-level="18.2.7" data-path="ch-post-approx.html"><a href="ch-post-approx.html#gibbs-sampling"><i class="fa fa-check"></i><b>18.2.7</b> Gibb’s sampling</a></li>
<li class="chapter" data-level="18.2.8" data-path="ch-post-approx.html"><a href="ch-post-approx.html#input"><i class="fa fa-check"></i><b>18.2.8</b> Input</a></li>
<li class="chapter" data-level="18.2.9" data-path="ch-post-approx.html"><a href="ch-post-approx.html#stazionarietà"><i class="fa fa-check"></i><b>18.2.9</b> Stazionarietà</a></li>
<li class="chapter" data-level="18.2.10" data-path="ch-post-approx.html"><a href="ch-post-approx.html#test-di-convergenza"><i class="fa fa-check"></i><b>18.2.10</b> Test di convergenza</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-post-approx.html"><a href="ch-post-approx.html#commenti-e-considerazioni-finali-14"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ch-stan-beta-binom.html"><a href="ch-stan-beta-binom.html"><i class="fa fa-check"></i><b>19</b> Il modello beta-binomiale in linguaggio Stan</a>
<ul>
<li class="chapter" data-level="19.1" data-path="ch-stan-beta-binom.html"><a href="ch-stan-beta-binom.html#il-presidente-trump-e-lidrossiclorochina"><i class="fa fa-check"></i><b>19.1</b> Il presidente Trump e l’idrossiclorochina</a></li>
<li class="chapter" data-level="19.2" data-path="ch-stan-beta-binom.html"><a href="ch-stan-beta-binom.html#una-proporzione"><i class="fa fa-check"></i><b>19.2</b> Una proporzione</a></li>
<li class="chapter" data-level="19.3" data-path="ch-stan-beta-binom.html"><a href="ch-stan-beta-binom.html#cmdstanr-gautret"><i class="fa fa-check"></i><b>19.3</b> Interfaccia <code>cmdstanr</code></a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="ch-stan-beta-binom.html"><a href="ch-stan-beta-binom.html#fase-1"><i class="fa fa-check"></i><b>19.3.1</b> Fase 1</a></li>
<li class="chapter" data-level="19.3.2" data-path="ch-stan-beta-binom.html"><a href="ch-stan-beta-binom.html#fase-2"><i class="fa fa-check"></i><b>19.3.2</b> Fase 2</a></li>
<li class="chapter" data-level="19.3.3" data-path="ch-stan-beta-binom.html"><a href="ch-stan-beta-binom.html#fase-3"><i class="fa fa-check"></i><b>19.3.3</b> Fase 3</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="ch-stan-beta-binom.html"><a href="ch-stan-beta-binom.html#la-critica-di-hulme_2020"><i class="fa fa-check"></i><b>19.4</b> La critica di <span class="citation">Hulme et al. (<span>2020</span>)</span></a></li>
<li class="chapter" data-level="19.5" data-path="ch-stan-beta-binom.html"><a href="ch-stan-beta-binom.html#due-proporzioni"><i class="fa fa-check"></i><b>19.5</b> Due proporzioni</a></li>
<li class="chapter" data-level="" data-path="ch-stan-beta-binom.html"><a href="ch-stan-beta-binom.html#commenti-e-considerazioni-finali-15"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="ch-diagn-markov-chains.html"><a href="ch-diagn-markov-chains.html"><i class="fa fa-check"></i><b>20</b> Diagnostica delle catene markoviane</a>
<ul>
<li class="chapter" data-level="20.1" data-path="ch-diagn-markov-chains.html"><a href="ch-diagn-markov-chains.html#esame-dei-trace-plot"><i class="fa fa-check"></i><b>20.1</b> Esame dei <em>trace plot</em></a></li>
<li class="chapter" data-level="20.2" data-path="ch-diagn-markov-chains.html"><a href="ch-diagn-markov-chains.html#confronto-delle-catene-parallele"><i class="fa fa-check"></i><b>20.2</b> Confronto delle catene parallele</a></li>
<li class="chapter" data-level="20.3" data-path="ch-diagn-markov-chains.html"><a href="ch-diagn-markov-chains.html#numerosita-campionaria-effettiva"><i class="fa fa-check"></i><b>20.3</b> Numerosità campionaria effettiva</a></li>
<li class="chapter" data-level="20.4" data-path="ch-diagn-markov-chains.html"><a href="ch-diagn-markov-chains.html#autocorrelazione"><i class="fa fa-check"></i><b>20.4</b> Autocorrelazione</a></li>
<li class="chapter" data-level="20.5" data-path="ch-diagn-markov-chains.html"><a href="ch-diagn-markov-chains.html#statistica-hatr"><i class="fa fa-check"></i><b>20.5</b> Statistica <span class="math inline">\(\hat{R}\)</span></a></li>
<li class="chapter" data-level="20.6" data-path="ch-diagn-markov-chains.html"><a href="ch-diagn-markov-chains.html#diagnostica-di-convergenza-di-geweke"><i class="fa fa-check"></i><b>20.6</b> Diagnostica di convergenza di Geweke</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html"><i class="fa fa-check"></i><b>21</b> Sintesi a posteriori</a>
<ul>
<li class="chapter" data-level="21.1" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#stima-puntuale"><i class="fa fa-check"></i><b>21.1</b> Stima puntuale</a></li>
<li class="chapter" data-level="21.2" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#intervallo-di-credibilità"><i class="fa fa-check"></i><b>21.2</b> Intervallo di credibilità</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#intervallo-di-credibilità-a-code-uguali"><i class="fa fa-check"></i><b>21.2.1</b> Intervallo di credibilità a code uguali</a></li>
<li class="chapter" data-level="21.2.2" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#intervallo-di-credibilità-a-densità-a-posteriori-più-alta"><i class="fa fa-check"></i><b>21.2.2</b> Intervallo di credibilità a densità a posteriori più alta</a></li>
<li class="chapter" data-level="21.2.3" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#interpretazione-1"><i class="fa fa-check"></i><b>21.2.3</b> Interpretazione</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#un-esempio-concreto"><i class="fa fa-check"></i><b>21.3</b> Un esempio concreto</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#stime-puntuali-della-distribuzione-a-posteriori"><i class="fa fa-check"></i><b>21.3.1</b> Stime puntuali della distribuzione a posteriori</a></li>
<li class="chapter" data-level="21.3.2" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#intervallo-di-credibilità-1"><i class="fa fa-check"></i><b>21.3.2</b> Intervallo di credibilità</a></li>
<li class="chapter" data-level="21.3.3" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#probabilità-della-distribuzione-a-posteriori"><i class="fa fa-check"></i><b>21.3.3</b> Probabilità della distribuzione a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#la-funzione-di-perdita-attesa"><i class="fa fa-check"></i><b>21.4</b> La funzione di perdita attesa</a></li>
<li class="chapter" data-level="" data-path="ch-sintesi-distr-post.html"><a href="ch-sintesi-distr-post.html#commenti-e-considerazioni-finali-16"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="ch-prediction.html"><a href="ch-prediction.html"><i class="fa fa-check"></i><b>22</b> La predizione bayesiana</a>
<ul>
<li class="chapter" data-level="22.1" data-path="ch-prediction.html"><a href="ch-prediction.html#la-distribuzione-predittiva-a-posteriori"><i class="fa fa-check"></i><b>22.1</b> La distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="22.2" data-path="ch-prediction.html"><a href="ch-prediction.html#soluzione-analitica"><i class="fa fa-check"></i><b>22.2</b> Soluzione analitica</a></li>
<li class="chapter" data-level="22.3" data-path="ch-prediction.html"><a href="ch-prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-simulazione"><i class="fa fa-check"></i><b>22.3</b> La distribuzione predittiva a posteriori mediante simulazione</a></li>
<li class="chapter" data-level="22.4" data-path="ch-prediction.html"><a href="ch-prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-mcmc"><i class="fa fa-check"></i><b>22.4</b> La distribuzione predittiva a posteriori mediante MCMC</a></li>
<li class="chapter" data-level="22.5" data-path="ch-prediction.html"><a href="ch-prediction.html#i-metodi-per-la-valutazione-del-modello"><i class="fa fa-check"></i><b>22.5</b> I metodi per la valutazione del modello</a>
<ul>
<li class="chapter" data-level="22.5.1" data-path="ch-prediction.html"><a href="ch-prediction.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>22.5.1</b> Posterior predictive checks</a></li>
</ul></li>
<li class="chapter" data-level="22.6" data-path="ch-prediction.html"><a href="ch-prediction.html#distribuzione-predittiva-a-priori-1"><i class="fa fa-check"></i><b>22.6</b> Distribuzione predittiva a priori</a></li>
<li class="chapter" data-level="" data-path="ch-prediction.html"><a href="ch-prediction.html#commenti-e-considerazioni-finali-17"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="ch-normal-normal-mod-stan.html"><a href="ch-normal-normal-mod-stan.html"><i class="fa fa-check"></i><b>23</b> Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</a>
<ul>
<li class="chapter" data-level="23.1" data-path="ch-normal-normal-mod-stan.html"><a href="ch-normal-normal-mod-stan.html#caso-normale-normale-con-varianza-nota"><i class="fa fa-check"></i><b>23.1</b> Caso Normale-Normale con varianza nota</a></li>
<li class="chapter" data-level="23.2" data-path="ch-normal-normal-mod-stan.html"><a href="ch-normal-normal-mod-stan.html#derivazione-analitica-della-distribuzione-a-posteriori-pmu-mid-y"><i class="fa fa-check"></i><b>23.2</b> Derivazione analitica della distribuzione a posteriori <span class="math inline">\(p(\mu \mid y)\)</span></a></li>
<li class="chapter" data-level="23.3" data-path="ch-normal-normal-mod-stan.html"><a href="ch-normal-normal-mod-stan.html#il-modello-normale-con-stan"><i class="fa fa-check"></i><b>23.3</b> Il modello Normale con Stan</a>
<ul>
<li class="chapter" data-level="23.3.1" data-path="ch-normal-normal-mod-stan.html"><a href="ch-normal-normal-mod-stan.html#versione-1-sigma-nota"><i class="fa fa-check"></i><b>23.3.1</b> Versione 1 (<span class="math inline">\(\sigma\)</span> nota)</a></li>
<li class="chapter" data-level="23.3.2" data-path="ch-normal-normal-mod-stan.html"><a href="ch-normal-normal-mod-stan.html#versione-2-sigma-incognita"><i class="fa fa-check"></i><b>23.3.2</b> Versione 2 (<span class="math inline">\(\sigma\)</span> incognita)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-normal-normal-mod-stan.html"><a href="ch-normal-normal-mod-stan.html#commenti-e-considerazioni-finali-18"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="part"><span><b>VI Il modello lineare</b></span></li>
<li class="chapter" data-level="24" data-path="ch-regr-intro.html"><a href="ch-regr-intro.html"><i class="fa fa-check"></i><b>24</b> Introduzione</a>
<ul>
<li class="chapter" data-level="24.1" data-path="ch-regr-intro.html"><a href="ch-regr-intro.html#la-funzione-lineare"><i class="fa fa-check"></i><b>24.1</b> La funzione lineare</a></li>
<li class="chapter" data-level="24.2" data-path="ch-regr-intro.html"><a href="ch-regr-intro.html#una-media-per-ciascuna-osservazione"><i class="fa fa-check"></i><b>24.2</b> Una media per ciascuna osservazione</a></li>
<li class="chapter" data-level="24.3" data-path="ch-regr-intro.html"><a href="ch-regr-intro.html#relazione-lineare-tra-la-media-y-mid-x-e-il-predittore"><i class="fa fa-check"></i><b>24.3</b> Relazione lineare tra la media <span class="math inline">\(y \mid x\)</span> e il predittore</a></li>
<li class="chapter" data-level="24.4" data-path="ch-regr-intro.html"><a href="ch-regr-intro.html#il-modello-lineare"><i class="fa fa-check"></i><b>24.4</b> Il modello lineare</a></li>
<li class="chapter" data-level="" data-path="ch-regr-intro.html"><a href="ch-regr-intro.html#commenti-e-considerazioni-finali-19"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="ch-regr-model-lm.html"><a href="ch-regr-model-lm.html"><i class="fa fa-check"></i><b>25</b> Regressione lineare con un singolo predittore</a>
<ul>
<li class="chapter" data-level="25.1" data-path="ch-regr-model-lm.html"><a href="ch-regr-model-lm.html#stima-dei-coefficienti-di-regressione"><i class="fa fa-check"></i><b>25.1</b> Stima dei coefficienti di regressione</a>
<ul>
<li class="chapter" data-level="25.1.1" data-path="ch-regr-model-lm.html"><a href="ch-regr-model-lm.html#trasformazione-dei-dati"><i class="fa fa-check"></i><b>25.1.1</b> Trasformazione dei dati</a></li>
<li class="chapter" data-level="25.1.2" data-path="ch-regr-model-lm.html"><a href="ch-regr-model-lm.html#il-metodo-dei-minimi-quadrati"><i class="fa fa-check"></i><b>25.1.2</b> Il metodo dei minimi quadrati</a></li>
<li class="chapter" data-level="25.1.3" data-path="ch-regr-model-lm.html"><a href="ch-regr-model-lm.html#lerrore-standard-della-regressione"><i class="fa fa-check"></i><b>25.1.3</b> L’errore standard della regressione</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="ch-regr-model-lm.html"><a href="ch-regr-model-lm.html#indice-di-determinazione"><i class="fa fa-check"></i><b>25.2</b> Indice di determinazione</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="ch-regr-model-lm.html"><a href="ch-regr-model-lm.html#inferenza-sul-modello-di-regressione"><i class="fa fa-check"></i><b>25.2.1</b> Inferenza sul modello di regressione</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-regr-model-lm.html"><a href="ch-regr-model-lm.html#commenti-e-considerazioni-finali-20"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="ch-reg-lin-stan.html"><a href="ch-reg-lin-stan.html"><i class="fa fa-check"></i><b>26</b> Modello di regressione in linguaggio Stan</a>
<ul>
<li class="chapter" data-level="26.1" data-path="ch-reg-lin-stan.html"><a href="ch-reg-lin-stan.html#specificazione-del-modello"><i class="fa fa-check"></i><b>26.1</b> Specificazione del modello</a></li>
<li class="chapter" data-level="26.2" data-path="ch-reg-lin-stan.html"><a href="ch-reg-lin-stan.html#stima-bayesiana-in-linguaggio-stan"><i class="fa fa-check"></i><b>26.2</b> Stima bayesiana in linguaggio Stan</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="ch-reg-lin-stan.html"><a href="ch-reg-lin-stan.html#standardizzare-i-dati"><i class="fa fa-check"></i><b>26.2.1</b> Standardizzare i dati</a></li>
<li class="chapter" data-level="26.2.2" data-path="ch-reg-lin-stan.html"><a href="ch-reg-lin-stan.html#interpretazione-dei-parametri"><i class="fa fa-check"></i><b>26.2.2</b> Interpretazione dei parametri</a></li>
<li class="chapter" data-level="26.2.3" data-path="ch-reg-lin-stan.html"><a href="ch-reg-lin-stan.html#centrare-i-predittori"><i class="fa fa-check"></i><b>26.2.3</b> Centrare i predittori</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-reg-lin-stan.html"><a href="ch-reg-lin-stan.html#commenti-e-considerazioni-finali-21"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="ch-inference-reg-lin-stan.html"><a href="ch-inference-reg-lin-stan.html"><i class="fa fa-check"></i><b>27</b> Inferenza sul modello lineare</a>
<ul>
<li class="chapter" data-level="27.1" data-path="ch-inference-reg-lin-stan.html"><a href="ch-inference-reg-lin-stan.html#rappresentazione-grafica-dellincertezza-della-stima"><i class="fa fa-check"></i><b>27.1</b> Rappresentazione grafica dell’incertezza della stima</a></li>
<li class="chapter" data-level="27.2" data-path="ch-inference-reg-lin-stan.html"><a href="ch-inference-reg-lin-stan.html#intervalli-di-credibilità-1"><i class="fa fa-check"></i><b>27.2</b> Intervalli di credibilità</a>
<ul>
<li class="chapter" data-level="27.2.1" data-path="ch-inference-reg-lin-stan.html"><a href="ch-inference-reg-lin-stan.html#quale-soglia-usare"><i class="fa fa-check"></i><b>27.2.1</b> Quale soglia usare?</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="ch-inference-reg-lin-stan.html"><a href="ch-inference-reg-lin-stan.html#test-di-ipotesi"><i class="fa fa-check"></i><b>27.3</b> Test di ipotesi</a></li>
<li class="chapter" data-level="27.4" data-path="ch-inference-reg-lin-stan.html"><a href="ch-inference-reg-lin-stan.html#modello-lineare-robusto"><i class="fa fa-check"></i><b>27.4</b> Modello lineare robusto</a></li>
<li class="chapter" data-level="" data-path="ch-inference-reg-lin-stan.html"><a href="ch-inference-reg-lin-stan.html#commenti-e-considerazioni-finali-22"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="ch-comp-two-means-stan.html"><a href="ch-comp-two-means-stan.html"><i class="fa fa-check"></i><b>28</b> Confronto tra due gruppi indipendenti</a>
<ul>
<li class="chapter" data-level="28.1" data-path="ch-comp-two-means-stan.html"><a href="ch-comp-two-means-stan.html#modello-lineare-con-una-variabile-dicotomica"><i class="fa fa-check"></i><b>28.1</b> Modello lineare con una variabile dicotomica</a>
<ul>
<li class="chapter" data-level="28.1.1" data-path="ch-comp-two-means-stan.html"><a href="ch-comp-two-means-stan.html#confronti-non-effetti"><i class="fa fa-check"></i><b>28.1.1</b> Confronti, non effetti</a></li>
<li class="chapter" data-level="28.1.2" data-path="ch-comp-two-means-stan.html"><a href="ch-comp-two-means-stan.html#un-esempio-concreto-1"><i class="fa fa-check"></i><b>28.1.2</b> Un esempio concreto</a></li>
</ul></li>
<li class="chapter" data-level="28.2" data-path="ch-comp-two-means-stan.html"><a href="ch-comp-two-means-stan.html#la-dimensione-delleffetto"><i class="fa fa-check"></i><b>28.2</b> La dimensione dell’effetto</a></li>
<li class="chapter" data-level="" data-path="ch-comp-two-means-stan.html"><a href="ch-comp-two-means-stan.html#commenti-e-considerazioni-finali-23"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="ch-pred-checks.html"><a href="ch-pred-checks.html"><i class="fa fa-check"></i><b>29</b> Predictive checks</a>
<ul>
<li class="chapter" data-level="29.1" data-path="ch-pred-checks.html"><a href="ch-pred-checks.html#distribuzione-predittiva-a-posteriori-1"><i class="fa fa-check"></i><b>29.1</b> Distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="29.2" data-path="ch-pred-checks.html"><a href="ch-pred-checks.html#distribuzione-predittiva-a-priori-2"><i class="fa fa-check"></i><b>29.2</b> Distribuzione predittiva a priori</a></li>
<li class="chapter" data-level="" data-path="ch-pred-checks.html"><a href="ch-pred-checks.html#commenti-e-considerazioni-finali-24"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="ch-anova.html"><a href="ch-anova.html"><i class="fa fa-check"></i><b>30</b> Confronto tra le medie di tre o più gruppi</a>
<ul>
<li class="chapter" data-level="30.1" data-path="ch-anova.html"><a href="ch-anova.html#le-abilità-sociali-di-un-robot"><i class="fa fa-check"></i><b>30.1</b> Le abilità sociali di un robot</a></li>
<li class="chapter" data-level="30.2" data-path="ch-anova.html"><a href="ch-anova.html#anova-ad-una-via"><i class="fa fa-check"></i><b>30.2</b> ANOVA ad una via</a>
<ul>
<li class="chapter" data-level="30.2.1" data-path="ch-anova.html"><a href="ch-anova.html#interpretazione-2"><i class="fa fa-check"></i><b>30.2.1</b> Interpretazione</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="ch-anova.html"><a href="ch-anova.html#anova-ad-due-vie"><i class="fa fa-check"></i><b>30.3</b> ANOVA ad due vie</a>
<ul>
<li class="chapter" data-level="30.3.1" data-path="ch-anova.html"><a href="ch-anova.html#test-sullinterazione"><i class="fa fa-check"></i><b>30.3.1</b> Test sull’interazione</a></li>
<li class="chapter" data-level="30.3.2" data-path="ch-anova.html"><a href="ch-anova.html#test-sugli-effetti-principali"><i class="fa fa-check"></i><b>30.3.2</b> Test sugli effetti principali</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path="ch-anova.html"><a href="ch-anova.html#codice-stan-versione-2"><i class="fa fa-check"></i><b>30.4</b> Codice Stan (versione 2)</a></li>
<li class="chapter" data-level="" data-path="ch-anova.html"><a href="ch-anova.html#commenti-e-considerazioni-finali-25"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html"><i class="fa fa-check"></i><b>31</b> Modello gerarchico</a>
<ul>
<li class="chapter" data-level="31.1" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#la-struttura-dei-dati"><i class="fa fa-check"></i><b>31.1</b> La struttura dei dati</a></li>
<li class="chapter" data-level="31.2" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#struttura-nested"><i class="fa fa-check"></i><b>31.2</b> Struttura Nested</a></li>
<li class="chapter" data-level="31.3" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#struttura-non-nested"><i class="fa fa-check"></i><b>31.3</b> Struttura Non-Nested</a></li>
<li class="chapter" data-level="31.4" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#ragioni-di-utilizzo-della-struttura-gerarchica"><i class="fa fa-check"></i><b>31.4</b> Ragioni di utilizzo della struttura gerarchica</a></li>
<li class="chapter" data-level="31.5" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#il-problema-delle-8-scuole"><i class="fa fa-check"></i><b>31.5</b> Il problema delle 8 scuole</a>
<ul>
<li class="chapter" data-level="31.5.1" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#modello-di-complete-pooling"><i class="fa fa-check"></i><b>31.5.1</b> Modello di <em>complete pooling</em></a></li>
<li class="chapter" data-level="31.5.2" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#modello-no-pooling"><i class="fa fa-check"></i><b>31.5.2</b> Modello <em>no pooling</em></a></li>
<li class="chapter" data-level="31.5.3" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#modello-partial-pooling"><i class="fa fa-check"></i><b>31.5.3</b> Modello <em>partial pooling</em></a></li>
<li class="chapter" data-level="31.5.4" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#modello-gerarchico"><i class="fa fa-check"></i><b>31.5.4</b> Modello gerarchico</a></li>
<li class="chapter" data-level="31.5.5" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#interpretazione-3"><i class="fa fa-check"></i><b>31.5.5</b> Interpretazione</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#modelli-lineari-ad-intercetta-casuale"><i class="fa fa-check"></i><b>31.6</b> Modelli lineari ad intercetta casuale</a>
<ul>
<li class="chapter" data-level="31.6.1" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#modello-ad-effetti-fissi"><i class="fa fa-check"></i><b>31.6.1</b> Modello ad effetti fissi</a></li>
<li class="chapter" data-level="31.6.2" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#modello-gerarchico-1"><i class="fa fa-check"></i><b>31.6.2</b> Modello gerarchico</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-mod-hier-stan.html"><a href="ch-mod-hier-stan.html#commenti-e-considerazioni-finali-26"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="ch-hier-sim.html"><a href="ch-hier-sim.html"><i class="fa fa-check"></i><b>32</b> Modello gerarchico: simulazioni</a>
<ul>
<li class="chapter" data-level="32.1" data-path="ch-hier-sim.html"><a href="ch-hier-sim.html#modello-generativo-dei-dati"><i class="fa fa-check"></i><b>32.1</b> Modello generativo dei dati</a></li>
<li class="chapter" data-level="32.2" data-path="ch-hier-sim.html"><a href="ch-hier-sim.html#modello-gerarchico-2"><i class="fa fa-check"></i><b>32.2</b> Modello gerarchico</a></li>
<li class="chapter" data-level="" data-path="ch-hier-sim.html"><a href="ch-hier-sim.html#commenti-e-considerazioni-finali-27"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="part"><span><b>VII Il confronto bayesiano di modelli</b></span></li>
<li class="chapter" data-level="33" data-path="ch-entropy.html"><a href="ch-entropy.html"><i class="fa fa-check"></i><b>33</b> Entropia</a>
<ul>
<li class="chapter" data-level="33.1" data-path="ch-entropy.html"><a href="ch-entropy.html#la-generalizzabilità-dei-modelli"><i class="fa fa-check"></i><b>33.1</b> La generalizzabilità dei modelli</a></li>
<li class="chapter" data-level="33.2" data-path="ch-entropy.html"><a href="ch-entropy.html#capacità-predittiva"><i class="fa fa-check"></i><b>33.2</b> Capacità predittiva</a></li>
<li class="chapter" data-level="33.3" data-path="ch-entropy.html"><a href="ch-entropy.html#il-rasoio-di-ockham"><i class="fa fa-check"></i><b>33.3</b> Il rasoio di Ockham</a>
<ul>
<li class="chapter" data-level="33.3.1" data-path="ch-entropy.html"><a href="ch-entropy.html#sovra-adattamento-e-sotto-adattamento"><i class="fa fa-check"></i><b>33.3.1</b> Sovra-adattamento e sotto-adattamento</a></li>
<li class="chapter" data-level="33.3.2" data-path="ch-entropy.html"><a href="ch-entropy.html#stargazing"><i class="fa fa-check"></i><b>33.3.2</b> Stargazing</a></li>
</ul></li>
<li class="chapter" data-level="33.4" data-path="ch-entropy.html"><a href="ch-entropy.html#la-misura-del-disordine"><i class="fa fa-check"></i><b>33.4</b> La misura del disordine</a>
<ul>
<li class="chapter" data-level="33.4.1" data-path="ch-entropy.html"><a href="ch-entropy.html#entropia-di-un-singolo-evento"><i class="fa fa-check"></i><b>33.4.1</b> Entropia di un singolo evento</a></li>
<li class="chapter" data-level="33.4.2" data-path="ch-entropy.html"><a href="ch-entropy.html#entropia-di-una-variabile-casuale"><i class="fa fa-check"></i><b>33.4.2</b> Entropia di una variabile casuale</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-entropy.html"><a href="ch-entropy.html#commenti-e-considerazioni-finali-28"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="ch-kl.html"><a href="ch-kl.html"><i class="fa fa-check"></i><b>34</b> La divergenza di Kullback-Leibler</a>
<ul>
<li class="chapter" data-level="34.1" data-path="ch-kl.html"><a href="ch-kl.html#la-perdita-di-informazione"><i class="fa fa-check"></i><b>34.1</b> La perdita di informazione</a></li>
<li class="chapter" data-level="34.2" data-path="ch-kl.html"><a href="ch-kl.html#la-divergenza-dipende-dalla-direzione"><i class="fa fa-check"></i><b>34.2</b> La divergenza dipende dalla direzione</a></li>
<li class="chapter" data-level="34.3" data-path="ch-kl.html"><a href="ch-kl.html#confronto-tra-modelli"><i class="fa fa-check"></i><b>34.3</b> Confronto tra modelli</a></li>
<li class="chapter" data-level="34.4" data-path="ch-kl.html"><a href="ch-kl.html#expected-log-predictive-density"><i class="fa fa-check"></i><b>34.4</b> Expected log predictive density</a>
<ul>
<li class="chapter" data-level="34.4.1" data-path="ch-kl.html"><a href="ch-kl.html#log-pointwise-predictive-density"><i class="fa fa-check"></i><b>34.4.1</b> Log pointwise predictive density</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-kl.html"><a href="ch-kl.html#commenti-e-considerazioni-finali-29"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="ch-info-crit.html"><a href="ch-info-crit.html"><i class="fa fa-check"></i><b>35</b> Criterio di informazione e convalida incrociata</a>
<ul>
<li class="chapter" data-level="35.1" data-path="ch-info-crit.html"><a href="ch-info-crit.html#aic-dic-e-waic"><i class="fa fa-check"></i><b>35.1</b> AIC, DIC e WAIC</a>
<ul>
<li class="chapter" data-level="35.1.1" data-path="ch-info-crit.html"><a href="ch-info-crit.html#criterio-dinformazione-di-akaike"><i class="fa fa-check"></i><b>35.1.1</b> Criterio d’informazione di Akaike</a></li>
</ul></li>
<li class="chapter" data-level="35.2" data-path="ch-info-crit.html"><a href="ch-info-crit.html#convalida-incrociata-k-fold"><i class="fa fa-check"></i><b>35.2</b> Convalida incrociata K-fold</a>
<ul>
<li class="chapter" data-level="35.2.1" data-path="ch-info-crit.html"><a href="ch-info-crit.html#importance-sampling"><i class="fa fa-check"></i><b>35.2.1</b> Importance sampling</a></li>
</ul></li>
<li class="chapter" data-level="35.3" data-path="ch-info-crit.html"><a href="ch-info-crit.html#confronto-tra-aic-e-loo-cv"><i class="fa fa-check"></i><b>35.3</b> Confronto tra AIC e LOO-CV</a></li>
<li class="chapter" data-level="35.4" data-path="ch-info-crit.html"><a href="ch-info-crit.html#confronto-tra-modelli-mediante-loo-cv"><i class="fa fa-check"></i><b>35.4</b> Confronto tra modelli mediante LOO-CV</a></li>
<li class="chapter" data-level="35.5" data-path="ch-info-crit.html"><a href="ch-info-crit.html#outlier"><i class="fa fa-check"></i><b>35.5</b> Outlier</a></li>
<li class="chapter" data-level="35.6" data-path="ch-info-crit.html"><a href="ch-info-crit.html#regolarizzazione"><i class="fa fa-check"></i><b>35.6</b> Regolarizzazione</a></li>
<li class="chapter" data-level="" data-path="ch-info-crit.html"><a href="ch-info-crit.html#commenti-e-considerazioni-finali-30"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="part"><span><b>VIII Approccio frequentista all’inferenza statistica</b></span></li>
<li class="chapter" data-level="36" data-path="ch-ttest.html"><a href="ch-ttest.html"><i class="fa fa-check"></i><b>36</b> Inferenza sulla media</a>
<ul>
<li class="chapter" data-level="36.1" data-path="ch-ttest.html"><a href="ch-ttest.html#la-ripetizione-dellesperimento-casuale"><i class="fa fa-check"></i><b>36.1</b> La ripetizione dell’esperimento casuale</a></li>
<li class="chapter" data-level="36.2" data-path="ch-ttest.html"><a href="ch-ttest.html#la-distribuzione-campionaria-della-media"><i class="fa fa-check"></i><b>36.2</b> La distribuzione campionaria della media</a></li>
<li class="chapter" data-level="36.3" data-path="ch-ttest.html"><a href="ch-ttest.html#inferenza-frequentista"><i class="fa fa-check"></i><b>36.3</b> Inferenza frequentista</a>
<ul>
<li class="chapter" data-level="36.3.1" data-path="ch-ttest.html"><a href="ch-ttest.html#il-test-dellipotesi-nulla"><i class="fa fa-check"></i><b>36.3.1</b> Il test dell’ipotesi nulla</a></li>
<li class="chapter" data-level="36.3.2" data-path="ch-ttest.html"><a href="ch-ttest.html#lintervallo-di-fiducia"><i class="fa fa-check"></i><b>36.3.2</b> L’Intervallo di fiducia</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch-ttest.html"><a href="ch-ttest.html#commenti-e-considerazioni-finali-31"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><i class="fa fa-check"></i><b>37</b> La crisi della replicabilità dei risultati della ricerca</a>
<ul>
<li class="chapter" data-level="37.1" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html#che-cosè-un-valore-p"><i class="fa fa-check"></i><b>37.1</b> Che cos’è un valore-<span class="math inline">\(p\)</span>?</a></li>
<li class="chapter" data-level="37.2" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html#luso-del-valore-p-nel-mondo-della-ricerca"><i class="fa fa-check"></i><b>37.2</b> L’uso del valore-<span class="math inline">\(p\)</span> nel mondo della ricerca</a></li>
<li class="chapter" data-level="37.3" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html#p-hacking"><i class="fa fa-check"></i><b>37.3</b> <span class="math inline">\(P\)</span>-hacking</a></li>
<li class="chapter" data-level="37.4" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html#critiche-al-valore-p"><i class="fa fa-check"></i><b>37.4</b> Critiche al valore-<span class="math inline">\(p\)</span></a></li>
<li class="chapter" data-level="37.5" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html#leffetto-sperimentale-è-esattamente-nullo"><i class="fa fa-check"></i><b>37.5</b> L’effetto sperimentale è esattamente nullo?</a></li>
<li class="chapter" data-level="37.6" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html#simulazione"><i class="fa fa-check"></i><b>37.6</b> Simulazione</a>
<ul>
<li class="chapter" data-level="37.6.1" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html#la-dimensione-delleffetto-1"><i class="fa fa-check"></i><b>37.6.1</b> La dimensione dell’effetto</a></li>
<li class="chapter" data-level="37.6.2" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html#una-piccola-dimensione-delleffetto-nella-popolazione"><i class="fa fa-check"></i><b>37.6.2</b> Una piccola dimensione dell’effetto nella popolazione</a></li>
<li class="chapter" data-level="37.6.3" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html#una-soluzione-sbagliata"><i class="fa fa-check"></i><b>37.6.3</b> Una soluzione (sbagliata)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html"><a href="la-crisi-della-replicabilità-dei-risultati-della-ricerca.html#commenti-e-considerazioni-finali-32"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="bibliografia.html"><a href="bibliografia.html"><i class="fa fa-check"></i><b>38</b> Bibliografia</a></li>
<li class="appendix"><span><b>Appendici</b></span></li>
<li class="chapter" data-level="A" data-path="simbologia-di-base.html"><a href="simbologia-di-base.html"><i class="fa fa-check"></i><b>A</b> Simbologia di base</a></li>
<li class="chapter" data-level="B" data-path="numeri-binari-interi-razionali-irrazionali-e-reali.html"><a href="numeri-binari-interi-razionali-irrazionali-e-reali.html"><i class="fa fa-check"></i><b>B</b> Numeri binari, interi, razionali, irrazionali e reali</a>
<ul>
<li class="chapter" data-level="B.1" data-path="numeri-binari-interi-razionali-irrazionali-e-reali.html"><a href="numeri-binari-interi-razionali-irrazionali-e-reali.html#numeri-binari"><i class="fa fa-check"></i><b>B.1</b> Numeri binari</a></li>
<li class="chapter" data-level="B.2" data-path="numeri-binari-interi-razionali-irrazionali-e-reali.html"><a href="numeri-binari-interi-razionali-irrazionali-e-reali.html#numeri-interi"><i class="fa fa-check"></i><b>B.2</b> Numeri interi</a></li>
<li class="chapter" data-level="B.3" data-path="numeri-binari-interi-razionali-irrazionali-e-reali.html"><a href="numeri-binari-interi-razionali-irrazionali-e-reali.html#numeri-razionali"><i class="fa fa-check"></i><b>B.3</b> Numeri razionali</a></li>
<li class="chapter" data-level="B.4" data-path="numeri-binari-interi-razionali-irrazionali-e-reali.html"><a href="numeri-binari-interi-razionali-irrazionali-e-reali.html#numeri-irrazionali"><i class="fa fa-check"></i><b>B.4</b> Numeri irrazionali</a></li>
<li class="chapter" data-level="B.5" data-path="numeri-binari-interi-razionali-irrazionali-e-reali.html"><a href="numeri-binari-interi-razionali-irrazionali-e-reali.html#numeri-reali"><i class="fa fa-check"></i><b>B.5</b> Numeri reali</a></li>
<li class="chapter" data-level="B.6" data-path="numeri-binari-interi-razionali-irrazionali-e-reali.html"><a href="numeri-binari-interi-razionali-irrazionali-e-reali.html#intervalli"><i class="fa fa-check"></i><b>B.6</b> Intervalli</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="insiemistica.html"><a href="insiemistica.html"><i class="fa fa-check"></i><b>C</b> Insiemi</a>
<ul>
<li class="chapter" data-level="C.1" data-path="insiemistica.html"><a href="insiemistica.html#operazioni-tra-insiemi"><i class="fa fa-check"></i><b>C.1</b> Operazioni tra insiemi</a></li>
<li class="chapter" data-level="C.2" data-path="insiemistica.html"><a href="insiemistica.html#diagrammi-di-eulero-venn"><i class="fa fa-check"></i><b>C.2</b> Diagrammi di Eulero-Venn</a></li>
<li class="chapter" data-level="C.3" data-path="insiemistica.html"><a href="insiemistica.html#coppie-ordinate-e-prodotto-cartesiano"><i class="fa fa-check"></i><b>C.3</b> Coppie ordinate e prodotto cartesiano</a></li>
<li class="chapter" data-level="C.4" data-path="insiemistica.html"><a href="insiemistica.html#cardinalità"><i class="fa fa-check"></i><b>C.4</b> Cardinalità</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="sommatorie.html"><a href="sommatorie.html"><i class="fa fa-check"></i><b>D</b> Simbolo di somma (sommatorie)</a>
<ul>
<li class="chapter" data-level="D.1" data-path="sommatorie.html"><a href="sommatorie.html#manipolazione-di-somme"><i class="fa fa-check"></i><b>D.1</b> Manipolazione di somme</a>
<ul>
<li class="chapter" data-level="D.1.1" data-path="sommatorie.html"><a href="sommatorie.html#proprietà-1-1"><i class="fa fa-check"></i><b>D.1.1</b> Proprietà 1</a></li>
<li class="chapter" data-level="D.1.2" data-path="sommatorie.html"><a href="sommatorie.html#proprietà-2-proprietà-distributiva"><i class="fa fa-check"></i><b>D.1.2</b> Proprietà 2 (proprietà distributiva)</a></li>
<li class="chapter" data-level="D.1.3" data-path="sommatorie.html"><a href="sommatorie.html#proprietà-3-proprietà-associativa"><i class="fa fa-check"></i><b>D.1.3</b> Proprietà 3 (proprietà associativa)</a></li>
<li class="chapter" data-level="D.1.4" data-path="sommatorie.html"><a href="sommatorie.html#proprietà-4"><i class="fa fa-check"></i><b>D.1.4</b> Proprietà 4</a></li>
<li class="chapter" data-level="D.1.5" data-path="sommatorie.html"><a href="sommatorie.html#proprietà-5"><i class="fa fa-check"></i><b>D.1.5</b> Proprietà 5</a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="sommatorie.html"><a href="sommatorie.html#doppia-sommatoria"><i class="fa fa-check"></i><b>D.2</b> Doppia sommatoria</a></li>
<li class="chapter" data-level="D.3" data-path="sommatorie.html"><a href="sommatorie.html#sommatorie-e-produttorie-e-operazioni-vettoriali-in-r"><i class="fa fa-check"></i><b>D.3</b> Sommatorie (e produttorie) e operazioni vettoriali in <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="appendix:future-exp.html"><a href="appendix:future-exp.html"><i class="fa fa-check"></i><b>E</b> Le aspettative future dei pazienti depressi</a>
<ul>
<li class="chapter" data-level="E.1" data-path="appendix:future-exp.html"><a href="appendix:future-exp.html#app:zet"><i class="fa fa-check"></i><b>E.1</b> La ricerca di <span class="citation">Zetsche, Bürkner, and Renneberg (<span>2019</span>)</span></a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="appendix:beta-binom.html"><a href="appendix:beta-binom.html"><i class="fa fa-check"></i><b>F</b> Modello Beta-binomiale</a>
<ul>
<li class="chapter" data-level="F.1" data-path="appendix:beta-binom.html"><a href="appendix:beta-binom.html#funzione-per-il-modello-beta-binomiale"><i class="fa fa-check"></i><b>F.1</b> Funzione per il modello Beta-binomiale</a></li>
</ul></li>
<li class="chapter" data-level="G" data-path="appendix:const-norm-bino23.html"><a href="appendix:const-norm-bino23.html"><i class="fa fa-check"></i><b>G</b> Verosimiglianza marginale</a>
<ul>
<li class="chapter" data-level="G.1" data-path="appendix:const-norm-bino23.html"><a href="appendix:const-norm-bino23.html#derivazione-analitica-della-costante-di-normalizzazione"><i class="fa fa-check"></i><b>G.1</b> Derivazione analitica della costante di normalizzazione</a></li>
</ul></li>
<li class="chapter" data-level="H" data-path="markov-chains.html"><a href="markov-chains.html"><i class="fa fa-check"></i><b>H</b> Le catene di Markov</a>
<ul>
<li class="chapter" data-level="H.1" data-path="markov-chains.html"><a href="markov-chains.html#simulare-una-catena-di-markov"><i class="fa fa-check"></i><b>H.1</b> Simulare una catena di Markov</a></li>
</ul></li>
<li class="chapter" data-level="I" data-path="regr-ml.html"><a href="regr-ml.html"><i class="fa fa-check"></i><b>I</b> Adattare il modello lineare ai dati</a>
<ul>
<li class="chapter" data-level="I.1" data-path="regr-ml.html"><a href="regr-ml.html#minimi-quadrati"><i class="fa fa-check"></i><b>I.1</b> Minimi quadrati</a>
<ul>
<li class="chapter" data-level="I.1.1" data-path="regr-ml.html"><a href="regr-ml.html#stima-della-deviazione-standard-dei-residui-sigma"><i class="fa fa-check"></i><b>I.1.1</b> Stima della deviazione standard dei residui <span class="math inline">\(\sigma\)</span></a></li>
</ul></li>
<li class="chapter" data-level="I.2" data-path="regr-ml.html"><a href="regr-ml.html#calcolare-la-somma-dei-quadrati"><i class="fa fa-check"></i><b>I.2</b> Calcolare la somma dei quadrati</a></li>
<li class="chapter" data-level="" data-path="regr-ml.html"><a href="regr-ml.html#commenti-e-considerazioni-finali-33"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="J" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html"><i class="fa fa-check"></i><b>J</b> Introduzione al linguaggio R</a>
<ul>
<li class="chapter" data-level="J.1" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#prerequisiti"><i class="fa fa-check"></i><b>J.1</b> Prerequisiti</a>
<ul>
<li class="chapter" data-level="J.1.1" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#installare-r-e-rstudio"><i class="fa fa-check"></i><b>J.1.1</b> Installare R e RStudio</a></li>
<li class="chapter" data-level="J.1.2" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#utilizzare-rstudio-per-semplificare-il-lavoro"><i class="fa fa-check"></i><b>J.1.2</b> Utilizzare RStudio per semplificare il lavoro</a></li>
<li class="chapter" data-level="J.1.3" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#eseguire-il-codice"><i class="fa fa-check"></i><b>J.1.3</b> Eseguire il codice</a></li>
</ul></li>
<li class="chapter" data-level="J.2" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#installare-cmdstan"><i class="fa fa-check"></i><b>J.2</b> Installare <code>cmdstan</code></a></li>
<li class="chapter" data-level="J.3" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#chapter-sintassi"><i class="fa fa-check"></i><b>J.3</b> Sintassi di base</a>
<ul>
<li class="chapter" data-level="J.3.1" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#utilizzare-la-console-mathsfr-come-calcolatrice"><i class="fa fa-check"></i><b>J.3.1</b> Utilizzare la console <span class="math inline">\(\mathsf{R}\)</span> come calcolatrice</a></li>
<li class="chapter" data-level="J.3.2" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#espressioni"><i class="fa fa-check"></i><b>J.3.2</b> Espressioni</a></li>
<li class="chapter" data-level="J.3.3" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#oggetti"><i class="fa fa-check"></i><b>J.3.3</b> Oggetti</a></li>
<li class="chapter" data-level="J.3.4" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#variabili"><i class="fa fa-check"></i><b>J.3.4</b> Variabili</a></li>
<li class="chapter" data-level="J.3.5" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#r-console"><i class="fa fa-check"></i><b>J.3.5</b> R console</a></li>
<li class="chapter" data-level="J.3.6" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#parentesi"><i class="fa fa-check"></i><b>J.3.6</b> Parentesi</a></li>
<li class="chapter" data-level="J.3.7" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#i-nomi-degli-oggetti"><i class="fa fa-check"></i><b>J.3.7</b> I nomi degli oggetti</a></li>
<li class="chapter" data-level="J.3.8" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#permanenza-dei-dati-e-rimozione-di-oggetti"><i class="fa fa-check"></i><b>J.3.8</b> Permanenza dei dati e rimozione di oggetti</a></li>
<li class="chapter" data-level="J.3.9" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#chiudere-r"><i class="fa fa-check"></i><b>J.3.9</b> Chiudere R</a></li>
<li class="chapter" data-level="J.3.10" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#creare-ed-eseguire-uno-script-r-con-un-editore"><i class="fa fa-check"></i><b>J.3.10</b> Creare ed eseguire uno script R con un editore</a></li>
<li class="chapter" data-level="J.3.11" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#commentare-il-codice"><i class="fa fa-check"></i><b>J.3.11</b> Commentare il codice</a></li>
<li class="chapter" data-level="J.3.12" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#cambiare-la-cartella-di-lavoro"><i class="fa fa-check"></i><b>J.3.12</b> Cambiare la cartella di lavoro</a></li>
<li class="chapter" data-level="J.3.13" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#loggetto-base-di-r-il-vettore"><i class="fa fa-check"></i><b>J.3.13</b> L’oggetto base di R: il vettore</a></li>
<li class="chapter" data-level="J.3.14" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#operazioni-vettorializzate"><i class="fa fa-check"></i><b>J.3.14</b> Operazioni vettorializzate</a></li>
<li class="chapter" data-level="J.3.15" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#vettori-aritmetici"><i class="fa fa-check"></i><b>J.3.15</b> Vettori aritmetici</a></li>
<li class="chapter" data-level="J.3.16" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#generazione-di-sequenze-regolari"><i class="fa fa-check"></i><b>J.3.16</b> Generazione di sequenze regolari</a></li>
<li class="chapter" data-level="J.3.17" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#generazione-di-numeri-casuali"><i class="fa fa-check"></i><b>J.3.17</b> Generazione di numeri casuali</a></li>
<li class="chapter" data-level="J.3.18" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#vettori-logici"><i class="fa fa-check"></i><b>J.3.18</b> Vettori logici</a></li>
<li class="chapter" data-level="J.3.19" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#dati-mancanti"><i class="fa fa-check"></i><b>J.3.19</b> Dati mancanti</a></li>
<li class="chapter" data-level="J.3.20" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#vettori-di-caratteri-e-fattori"><i class="fa fa-check"></i><b>J.3.20</b> Vettori di caratteri e fattori</a></li>
<li class="chapter" data-level="J.3.21" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#funzioni-1"><i class="fa fa-check"></i><b>J.3.21</b> Funzioni</a></li>
<li class="chapter" data-level="J.3.22" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#scrivere-proprie-funzioni"><i class="fa fa-check"></i><b>J.3.22</b> Scrivere proprie funzioni</a></li>
<li class="chapter" data-level="J.3.23" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#pacchetti"><i class="fa fa-check"></i><b>J.3.23</b> Pacchetti</a></li>
<li class="chapter" data-level="J.3.24" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#istallazione-e-upgrade-dei-pacchetti"><i class="fa fa-check"></i><b>J.3.24</b> Istallazione e upgrade dei pacchetti</a></li>
<li class="chapter" data-level="J.3.25" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#caricare-un-pacchetto-in-r"><i class="fa fa-check"></i><b>J.3.25</b> Caricare un pacchetto in R</a></li>
</ul></li>
<li class="chapter" data-level="J.4" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#chapter-strutture-dati"><i class="fa fa-check"></i><b>J.4</b> Strutture di dati</a>
<ul>
<li class="chapter" data-level="J.4.1" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#classi-e-modi-degli-oggetti"><i class="fa fa-check"></i><b>J.4.1</b> Classi e modi degli oggetti</a></li>
<li class="chapter" data-level="J.4.2" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#vettori"><i class="fa fa-check"></i><b>J.4.2</b> Vettori</a></li>
<li class="chapter" data-level="J.4.3" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#matrici"><i class="fa fa-check"></i><b>J.4.3</b> Matrici</a></li>
<li class="chapter" data-level="J.4.4" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#array"><i class="fa fa-check"></i><b>J.4.4</b> Array</a></li>
<li class="chapter" data-level="J.4.5" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#operazioni-aritmetiche-su-vettori-matrici-e-array"><i class="fa fa-check"></i><b>J.4.5</b> Operazioni aritmetiche su vettori, matrici e array</a></li>
<li class="chapter" data-level="J.4.6" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#liste"><i class="fa fa-check"></i><b>J.4.6</b> Liste</a></li>
<li class="chapter" data-level="J.4.7" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#data-frame"><i class="fa fa-check"></i><b>J.4.7</b> Data frame</a></li>
<li class="chapter" data-level="J.4.8" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#giochi-di-carte"><i class="fa fa-check"></i><b>J.4.8</b> Giochi di carte</a></li>
<li class="chapter" data-level="J.4.9" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#variabili-locali"><i class="fa fa-check"></i><b>J.4.9</b> Variabili locali</a></li>
</ul></li>
<li class="chapter" data-level="J.5" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#chapter-strut-contr"><i class="fa fa-check"></i><b>J.5</b> Strutture di controllo</a>
<ul>
<li class="chapter" data-level="J.5.1" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#il-ciclo-for"><i class="fa fa-check"></i><b>J.5.1</b> Il ciclo <code>for</code></a></li>
</ul></li>
<li class="chapter" data-level="J.6" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#chapter-input-output"><i class="fa fa-check"></i><b>J.6</b> Input/Output</a>
<ul>
<li class="chapter" data-level="J.6.1" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#la-funzione-read.table"><i class="fa fa-check"></i><b>J.6.1</b> La funzione <code>read.table()</code></a></li>
<li class="chapter" data-level="J.6.2" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#file-di-dati-forniti-da-r"><i class="fa fa-check"></i><b>J.6.2</b> File di dati forniti da R</a></li>
<li class="chapter" data-level="J.6.3" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#esportazione-di-un-file"><i class="fa fa-check"></i><b>J.6.3</b> Esportazione di un file</a></li>
<li class="chapter" data-level="J.6.4" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#pacchetto-rio"><i class="fa fa-check"></i><b>J.6.4</b> Pacchetto <code>rio</code></a></li>
<li class="chapter" data-level="J.6.5" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#dove-sono-i-miei-file"><i class="fa fa-check"></i><b>J.6.5</b> Dove sono i miei file?</a></li>
</ul></li>
<li class="chapter" data-level="J.7" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#manipolazione-dei-dati"><i class="fa fa-check"></i><b>J.7</b> Manipolazione dei dati</a>
<ul>
<li class="chapter" data-level="J.7.1" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#motivazione"><i class="fa fa-check"></i><b>J.7.1</b> Motivazione</a></li>
<li class="chapter" data-level="J.7.2" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#trattamento-dei-dati-con-dplyr"><i class="fa fa-check"></i><b>J.7.2</b> Trattamento dei dati con <code>dplyr</code></a></li>
<li class="chapter" data-level="J.7.3" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#dati-categoriali-in-r"><i class="fa fa-check"></i><b>J.7.3</b> Dati categoriali in <code>R</code></a></li>
<li class="chapter" data-level="J.7.4" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#creare-grafici-con-ggplot2"><i class="fa fa-check"></i><b>J.7.4</b> Creare grafici con <code>ggplot2()</code></a></li>
<li class="chapter" data-level="J.7.5" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#diagramma-a-dispersione-1"><i class="fa fa-check"></i><b>J.7.5</b> Diagramma a dispersione</a></li>
<li class="chapter" data-level="J.7.6" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#scrivere-il-codice-r-con-stile"><i class="fa fa-check"></i><b>J.7.6</b> Scrivere il codice <code>R</code> con stile</a></li>
</ul></li>
<li class="chapter" data-level="J.8" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#flusso-di-lavoro-riproducibile"><i class="fa fa-check"></i><b>J.8</b> Flusso di lavoro riproducibile</a>
<ul>
<li class="chapter" data-level="J.8.1" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#la-crisi-della-riproducibilità"><i class="fa fa-check"></i><b>J.8.1</b> La crisi della riproducibilità</a></li>
<li class="chapter" data-level="J.8.2" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#r-markdown"><i class="fa fa-check"></i><b>J.8.2</b> R-markdown</a></li>
<li class="chapter" data-level="J.8.3" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#compilare-la-presentazione-r-markdown"><i class="fa fa-check"></i><b>J.8.3</b> Compilare la presentazione R-markdown</a></li>
</ul></li>
<li class="chapter" data-level="J.9" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#dati-mancanti-1"><i class="fa fa-check"></i><b>J.9</b> Dati mancanti</a>
<ul>
<li class="chapter" data-level="J.9.1" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#motivazione-1"><i class="fa fa-check"></i><b>J.9.1</b> Motivazione</a></li>
<li class="chapter" data-level="J.9.2" data-path="introduzione-al-linguaggio-r.html"><a href="introduzione-al-linguaggio-r.html#trattamento-dei-dati-mancanti"><i class="fa fa-check"></i><b>J.9.2</b> Trattamento dei dati mancanti</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science per psicologi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-regr-model-lm" class="section level1 hasAnchor" number="25">
<h1><span class="header-section-number">Capitolo 25</span> Regressione lineare con un singolo predittore<a href="ch-regr-model-lm.html#ch-regr-model-lm" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>La regressione è un metodo statistico che consente di predire un esito <span class="math inline">\(y\)</span> sulla base della conoscenza delle variabili <span class="math inline">\(x_1, x_2, \dots\)</span>. In questo Capitolo verrà introdotto il modello di regressione che predice una variabile continua <span class="math inline">\(y\)</span> a partire da un unico predittore continuo <span class="math inline">\(x\)</span>. Ciò corrisponde ad adattare ai dati (<span class="math inline">\(x_i, y_i\)</span>) la retta di regressione <span class="math inline">\(y_i = a + bx_i + e_i\)</span>, con <span class="math inline">\(i=1, \dots, n\)</span>. Usando dei dati reali, vedremo come stimare i coefficienti di regressione <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> e come essi possano essere interpretati. Vedremo anche di descrivere la bontà di adattamento del modello ai dati.</p>
<p>Nell’esempio che discuteremo in questo Capitolo verranno usati i dati <code>kidiq</code>. Riporto qui di seguito la descrizione delle variabili che sono state misurate in questo campione.</p>
<blockquote>
<p>Data from a survey of adult American women and their children (a subsample from the National Longitudinal Survey of Youth).</p>
</blockquote>
<blockquote>
<p>Source: Gelman and Hill (2007)</p>
</blockquote>
<blockquote>
<p>434 obs. of 4 variables</p>
</blockquote>
<blockquote>
<ul>
<li>kid_score Child’s IQ score</li>
<li>mom_hs Indicator for whether the mother has a high school degree</li>
<li>mom_iq Mother’s IQ score</li>
<li>mom_age Mother’s age</li>
</ul>
</blockquote>
<p>In questo esercizio sulla regressione lineare considererò la relazione tra l’intelligenza del bambino (<code>kid_score</code>) e l’intelligenza della madre (<code>mom_iq</code>). Mi chiederò se l’intelligenza della madre sia in grado di predire l’intelligenza del bambino e in che misura lo faccia.</p>
<p>Leggo i dati in <span class="math inline">\(\mathsf{R}\)</span>.</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="ch-regr-model-lm.html#cb308-1" aria-hidden="true" tabindex="-1"></a>kidiq <span class="ot">&lt;-</span> rio<span class="sc">::</span><span class="fu">import</span>(here<span class="sc">::</span><span class="fu">here</span>(</span>
<span id="cb308-2"><a href="ch-regr-model-lm.html#cb308-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;data&quot;</span>, <span class="st">&quot;kidiq.dta&quot;</span></span>
<span id="cb308-3"><a href="ch-regr-model-lm.html#cb308-3" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb308-4"><a href="ch-regr-model-lm.html#cb308-4" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(kidiq)</span>
<span id="cb308-5"><a href="ch-regr-model-lm.html#cb308-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Rows: 434</span></span>
<span id="cb308-6"><a href="ch-regr-model-lm.html#cb308-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Columns: 5</span></span>
<span id="cb308-7"><a href="ch-regr-model-lm.html#cb308-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ kid_score &lt;dbl&gt; 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78, 1…</span></span>
<span id="cb308-8"><a href="ch-regr-model-lm.html#cb308-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ mom_hs    &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, …</span></span>
<span id="cb308-9"><a href="ch-regr-model-lm.html#cb308-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ mom_iq    &lt;dbl&gt; 121.11753, 89.36188, 115.44316, 99.44964, 92.74571, 107.9018…</span></span>
<span id="cb308-10"><a href="ch-regr-model-lm.html#cb308-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ mom_work  &lt;dbl&gt; 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, 3, …</span></span>
<span id="cb308-11"><a href="ch-regr-model-lm.html#cb308-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ mom_age   &lt;dbl&gt; 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 24, …</span></span></code></pre></div>
<p>I dati rappresentati in un diagramma a dispersione suggeriscono che, in questo campione, sembra effettivamente esserci un’associazione positiva tra l’intelligenza del bambino (<code>kid_score</code>) e l’intelligenza della madre (<code>mom_iq</code>).</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="ch-regr-model-lm.html#cb309-1" aria-hidden="true" tabindex="-1"></a>kidiq <span class="sc">%&gt;%</span> </span>
<span id="cb309-2"><a href="ch-regr-model-lm.html#cb309-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mom_iq, <span class="at">y =</span> kid_score)) <span class="sc">+</span></span>
<span id="cb309-3"><a href="ch-regr-model-lm.html#cb309-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-308-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>La regressione lineare descrive questa associazione mediante una retta.</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="ch-regr-model-lm.html#cb310-1" aria-hidden="true" tabindex="-1"></a>kidiq <span class="sc">%&gt;%</span> </span>
<span id="cb310-2"><a href="ch-regr-model-lm.html#cb310-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mom_iq, <span class="at">y =</span> kid_score)) <span class="sc">+</span> </span>
<span id="cb310-3"><a href="ch-regr-model-lm.html#cb310-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb310-4"><a href="ch-regr-model-lm.html#cb310-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-309-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Ci sono infinite rette che, in linea di principio, possono essere usate per “approssimare” la nube di punti nel diagramma a dispersione. È dunque necessario introdurre dei vincoli per selezionare una di queste possibili rette. Un vincolo che viene introdotto dal modello di regressione è quello di costringere la retta a passare per il punto <span class="math inline">\((\bar{x}, \bar{y})\)</span>.</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="ch-regr-model-lm.html#cb311-1" aria-hidden="true" tabindex="-1"></a>kidiq <span class="sc">%&gt;%</span> </span>
<span id="cb311-2"><a href="ch-regr-model-lm.html#cb311-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mom_iq, <span class="at">y =</span> kid_score)) <span class="sc">+</span> </span>
<span id="cb311-3"><a href="ch-regr-model-lm.html#cb311-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb311-4"><a href="ch-regr-model-lm.html#cb311-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb311-5"><a href="ch-regr-model-lm.html#cb311-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(</span>
<span id="cb311-6"><a href="ch-regr-model-lm.html#cb311-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">mean</span>(mom_iq), <span class="at">y=</span><span class="fu">mean</span>(kid_score)), </span>
<span id="cb311-7"><a href="ch-regr-model-lm.html#cb311-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">colour=</span><span class="st">&quot;red&quot;</span>, <span class="at">size =</span> <span class="dv">4</span></span>
<span id="cb311-8"><a href="ch-regr-model-lm.html#cb311-8" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-310-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Una retta che passa per il punto <span class="math inline">\((\bar{x}, \bar{y})\)</span> ha delle desiderabili proprietà statistiche che verranno descritte in seguito.</p>
<p>Il campione è costituito da <span class="math inline">\(n\)</span> coppie di osservazioni (<span class="math inline">\(x, y\)</span>). Per ciascuna coppia di valori <span class="math inline">\(x_i, y_i\)</span>, il modello di regressione si aspetta che il valore <span class="math inline">\(y_i\)</span> sia associato al corrispondente valore <span class="math inline">\(x_i\)</span> come indicato dalla seguente equazione:</p>
<p><span class="math display">\[
y_i = a + b x_i + e_i
\]</span></p>
<p>I valori <span class="math inline">\(y_i\)</span> corrispondono, nell’esempio che stiamo discutendo, alla variabile <code>kid_score</code>. I primi 10 valori della variabile <span class="math inline">\(y\)</span> sono i seguenti:</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="ch-regr-model-lm.html#cb312-1" aria-hidden="true" tabindex="-1"></a>kidiq<span class="sc">$</span>kid_score[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span>
<span id="cb312-2"><a href="ch-regr-model-lm.html#cb312-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1]  65  98  85  83 115  98  69 106 102  95</span></span></code></pre></div>
<p>Per fare riferimento a ciascuna osservazione usiamo l’indice <span class="math inline">\(i\)</span>. Quindi, ad esempio, <span class="math inline">\(y_3\)</span> è uguale a</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="ch-regr-model-lm.html#cb313-1" aria-hidden="true" tabindex="-1"></a>kidiq<span class="sc">$</span>kid_score[<span class="dv">3</span>]</span>
<span id="cb313-2"><a href="ch-regr-model-lm.html#cb313-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 85</span></span></code></pre></div>
<p>Nel caso presente, la variabile <span class="math inline">\(x\)</span> è <code>mom_iq</code>. I primi 10 valori di <span class="math inline">\(x\)</span> sono</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="ch-regr-model-lm.html#cb314-1" aria-hidden="true" tabindex="-1"></a>kidiq<span class="sc">$</span>mom_iq[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span>
<span id="cb314-2"><a href="ch-regr-model-lm.html#cb314-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 121.11753  89.36188 115.44316  99.44964  92.74571 107.90184 138.89311</span></span>
<span id="cb314-3"><a href="ch-regr-model-lm.html#cb314-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [8] 125.14512  81.61953  95.07307</span></span></code></pre></div>
<p>In maniera corrispondente alla <span class="math inline">\(y\)</span>, uso un indice per fare riferimento ai singoli valori della variabile. Ad esempio, <span class="math inline">\(x_3\)</span> è</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="ch-regr-model-lm.html#cb315-1" aria-hidden="true" tabindex="-1"></a>kidiq<span class="sc">$</span>mom_iq[<span class="dv">3</span>]</span>
<span id="cb315-2"><a href="ch-regr-model-lm.html#cb315-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 115.4432</span></span></code></pre></div>
<p>L’equazione precedente ci dice che ciascun valore <span class="math inline">\(y\)</span> è dato dalla somma di due componenti: una componente deterministica e una componente aleatoria. Consideriamo il primo valore <span class="math inline">\(y\)</span> del campione. Per esso, il modello di regressione ci dice che</p>
<p><span class="math display">\[
y_1 = a + b x_1 + e_1,
\]</span></p>
<p>laddove <span class="math inline">\(a + b x_1\)</span> è la componente deterministica, denotata con <span class="math inline">\(\hat{y}\)</span>, e <span class="math inline">\(e_1\)</span> è la componente aleatoria.</p>
<p>La componente deterministica è la <em>componente</em> di ciascun valore <span class="math inline">\(y_i\)</span> che è possibile prevedere conoscendo <span class="math inline">\(x_i\)</span>. Tuttavia, non è possibile prevedere <em>perfettamente</em> i valori <span class="math inline">\(y\)</span> – ciò si verificherebbe soltanto se tutti punti del diagramma a dispersione fossero disposti su una retta. Ma non lo sono mai nella pratica concreta: la retta è solo un’approssimazione della relazione (lineare) tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. Pertanto, conoscendo <span class="math inline">\(x_i\)</span> possiamo solo prevedere una “componente” del corrispondente valore <span class="math inline">\(y_i\)</span>.</p>
<p>Cosa significa che possiamo prevedere una componente di ciascuna osservazione <span class="math inline">\(y_i\)</span>? Significa che il valore osservato <span class="math inline">\(y_i\)</span> sarà diverso dal valore <span class="math inline">\(\hat{y}_i\)</span> previsto dal modello. Ciascun valore <span class="math inline">\(y_i\)</span> sarà dunque dato dalla seguente somma: <span class="math inline">\(y_i = \hat{y}_i + e_i\)</span>, laddove <span class="math inline">\(e_i\)</span>, detto “residuo” è la componente di <span class="math inline">\(y_i\)</span> non predicibile dal modello lineare.</p>
<p>Ci possiamo dunque porre due domande:</p>
<ul>
<li>come possiamo trovare i coefficienti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> che consentono di predire una componente della <span class="math inline">\(y\)</span> conoscendo <span class="math inline">\(x\)</span>?</li>
<li>quant’è grande la porzione della <span class="math inline">\(y\)</span> che può essere predetta conoscendo <span class="math inline">\(x\)</span>? In altre parole, quant’è accurata la predizione della <span class="math inline">\(y\)</span> che può essere fornita dal modello di regressione lineare?</li>
</ul>
<p>Rispondere a tali due domanda definisce i primi due obiettivi del modello statistico della regressione lineare. Il terzo obiettivo è quello dell’inferenza, ovvero quello di capire che relazioni ci sono tra la relazione tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> osservata nel campione e la la relazione tra le due variabili nella popolazione.</p>
<div id="stima-dei-coefficienti-di-regressione" class="section level2 hasAnchor" number="25.1">
<h2><span class="header-section-number">25.1</span> Stima dei coefficienti di regressione<a href="ch-regr-model-lm.html#stima-dei-coefficienti-di-regressione" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Iniziamo con il primo obiettivo, ovvero quello di trovare i coefficienti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> che consentono di predire una componente di ciascuna osservazione <span class="math inline">\(y\)</span> conoscendo <span class="math inline">\(x\)</span>. Quindi, nel caso presente, ci chiediamo quanto segue. Il primo bambino del campione ha un QI uguale a 65. Sua madre ha un QI di 121.12. Qual è la predizione migliore del QI del bambino che possiamo ottenere conoscendo il QI della madre?</p>
<p>È chiaro, guardando i dati del campione, che non c’è una corrispondenza perfetta tra QI della madre e QI del bambino, tutt’altro! Infatti, se guardiamo il diagramma di dispersione ci rendiamo conto che i punti sono piuttosto lontani dalla retta che abbiamo sovrapposto alla nube di punti <span class="math inline">\(x_i, y_i\)</span>. Tuttavia, il diagramma di dispersione ci suggerisce che, al di là del rumore, c’è comunque una relazione tra le due variabili. Il nostro obiettivo è trovare un metodo quantitativo per descrivere una tale relazione.</p>
<p>Abbiamo detto che è possibile prevedere una componente di <span class="math inline">\(y_i\)</span> conoscendo <span class="math inline">\(x_i\)</span>. La componente <span class="math inline">\(y_i\)</span> predicibile da <span class="math inline">\(x_i\)</span> viene denotata da <span class="math inline">\(\hat{y}_i\)</span> e, nei termini del modello di regressione lineare è uguale a</p>
<p><span class="math display">\[
\hat{y}_i = a_i + bx_i.
\]</span></p>
<p>L’equazione precedente è un’<em>equazione lineare</em> e, dal punto di vista geometrico, corrisponde ad una retta. Ci sono infinite equazioni che, in linea di principio, possiamo usare per descrivere la relazione tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. Abbiamo scelto la relazione lineare perché è la più semplice. Se guardiamo il diagramma di dispersione, infatti, non ci sono ragioni per descrivere la relazione tra il QI del bambino e il QI della madre con qualche curva, anziché con una retta. In altri campioni, una curva potrebbe essere più sensata di una retta, quale descrizione della relazione <em>media</em> tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>, ma non nel caso presente. Ricordiamo il principio del rasoio di Occam (ovvero, il principio che sta alla base del pensiero scientifico moderno): se un modello semplice funziona, non c’è ragione di usare un modello più complesso.</p>
<p>Dunque, abbiamo capito che vogliamo descrivere la <em>relazione media</em> tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> con una retta, ovvero, mediante l’equazione lineare</p>
<p><span class="math display">\[
\hat{y}_i = a + b x_i.
\]</span></p>
<p>L’equazione precedente ci dice che il modello lineare <span class="math inline">\(a + b x_i\)</span> <em>non è in grado di prevedere completamente</em> i valori <span class="math inline">\(y_i\)</span>. Questo, in generale, non è mai possibile (ovvero, è possibile solo in un caso specifico che, nella realtà empirica, non si verifica mai). L’equazione precedente ci dice che possiamo prevedere solo una componente di ciascuna osservazione <span class="math inline">\(y_i\)</span>, ovvero quella componente che abbiamo denotato con <span class="math inline">\(\hat{y}_i\)</span>. La componente che non possiamo prevedere con l’equazione <span class="math inline">\(a + b x_i\)</span> viene detta <em>residuo</em> e si denota con <span class="math inline">\(e_i\)</span>:</p>
<p><span class="math display">\[
e_i = y_i - \hat{y}_i = y_i - (a + bx_i).
\]</span></p>
<p>Dal punto di vista geometrico, la componente erratica del modello, <span class="math inline">\(e_i\)</span>, corrisponde alla distanza verticale tra ciascun punto del diagramma a dispersione e la retta di regressione <span class="math inline">\(a + bx\)</span>. Diciamo che <em>scomponiamo</em> il valore di ciascuna osservazione <span class="math inline">\(y_i\)</span> in due componenti nel senso che</p>
<p><span class="math display">\[
y_i = \hat{y}_i + e_i = (a + bx_i) + e_i.
\]</span></p>
<p>Il primo obiettivo del modello di regressione è quello di trovare i coefficienti dell’equazione</p>
<p><span class="math display">\[
a + b x_i
\]</span></p>
<p>che consente di trovare <span class="math inline">\(\hat{y}_i\)</span> conoscendo <span class="math inline">\(x_i\)</span>. Questi due coefficienti sono detti <em>coefficienti di regressione</em>.</p>
<p>Per trovare i coefficienti di regressione dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo di tali vincoli è stato introdotto in precedenza: vogliamo che la retta <span class="math inline">\(\hat{y}_i = a + b x_i\)</span> passi per il punto <span class="math inline">\((\bar{x}, \bar{y})\)</span>. Il punto <span class="math inline">\((\bar{x}, \bar{y})\)</span> corrisponde al <em>baricentro</em> del diagramma a dispersione.</p>
<p>Ci sono però infinite rette che passano per i punto <span class="math inline">\((\bar{x}, \bar{y})\)</span>. Tutte queste rette soddisfano la seguente proprietà:</p>
<p><span class="math display">\[
\sum_{i=1}^n e_i = 0,
\]</span></p>
<p>ovvero, fanno in modo che la somma dei residui (positivi, per i punti che si trovano al di sopra della retta di regressione, negativi, per punti che si trovano al di sotto della retta di regressione) sia uguale a zero.</p>
<p>Questo significa che non possiamo selezionare una tra le infinite rette che passano per il punto <span class="math inline">\((\bar{x}, \bar{y})\)</span> usando il criterio che ci porta a scegliere la retta che rende la più piccola possibile (ovvero, minimizza) la somma dei residui. Infatti, tutte le rette passanti per il punto <span class="math inline">\((\bar{x}, \bar{y})\)</span> soddisfano questo requisito (rendono uguale a zero la somma dei residui). Dunque, dobbiamo trovare qualche altri criterio per scegliere una tra le infinite rette che passano per il punto <span class="math inline">\((\bar{x}, \bar{y})\)</span>.</p>
<p>Il criterio che viene normalmente scelto è quello di <em>minimizzare la somma dei quadrati dei residui</em> <span class="math inline">\((y_i - \hat{y}_i)^2\)</span>. In altri termini, vogliamo trovare i coefficienti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> tali per cui la quantità</p>
<p><span class="math display">\[
\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}
\]</span></p>
<p>assume il suo valore minimo. I coefficienti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> che soddisfano questa proprietà si chiamano <em>coefficienti dei minimi quadrati</em>.</p>
<p>Questo problema ha una soluzione analitica. La soluzione analitica si trova riconoscendo il fatto che l’equazione precedente definisce una superficie e il problema diventa quello di trovare il punto di minimo di questa superficie. Per trovare la soluzione ci si deve rendere conto che il punto cercato è quello per cui il piano tangente alla superficie (nelle due direzioni <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>) è piatto (le tangenti nelle due direzioni sono uguali a zero). Rendere uguale a zero la tangente ad una curva significa porre uguali a zero la derivata della curva. Nel caso presente, abbiamo una superficie, dunque due tangenti ortogonali e quindi abbiamo il problema di rendere uguali a zero le derivate parziali rispetto ad <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>. Così facendo si definisce un sistema di equazioni lineari con due incognite, <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>. La soluzione di tali equazioni, che si chiamano <em>equazioni normali</em>, è la seguente:</p>
<p><span class="math display">\[
a = \bar{y} - b \bar{x},
\]</span></p>
<p><span class="math display">\[
b = \frac{\mbox{Cov}(x, y)}{\mbox{Var}(x)}.
\]</span></p>
<p>Le due precedenti equazioni corrispondono alla <em>stima dei minimi quadrati</em> dei coefficienti di regressione della retta che minimizza la somma dei quadrati dei residui.</p>
<p>Nel caso dell’esempio presente, tali coefficienti sono uguali a:</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="ch-regr-model-lm.html#cb316-1" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">cov</span>(kidiq<span class="sc">$</span>kid_score, kidiq<span class="sc">$</span>mom_iq) <span class="sc">/</span> <span class="fu">var</span>(kidiq<span class="sc">$</span>mom_iq)</span>
<span id="cb316-2"><a href="ch-regr-model-lm.html#cb316-2" aria-hidden="true" tabindex="-1"></a>b</span>
<span id="cb316-3"><a href="ch-regr-model-lm.html#cb316-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.6099746</span></span></code></pre></div>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="ch-regr-model-lm.html#cb317-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">mean</span>(kidiq<span class="sc">$</span>kid_score) <span class="sc">-</span> b <span class="sc">*</span> <span class="fu">mean</span>(kidiq<span class="sc">$</span>mom_iq)</span>
<span id="cb317-2"><a href="ch-regr-model-lm.html#cb317-2" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb317-3"><a href="ch-regr-model-lm.html#cb317-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 25.79978</span></span></code></pre></div>
<p>In <span class="math inline">\(\mathsf{R}\)</span> li possiamo facilmente trovare con la seguente funzione:</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="ch-regr-model-lm.html#cb318-1" aria-hidden="true" tabindex="-1"></a>fm <span class="ot">&lt;-</span> <span class="fu">lm</span>(kid_score <span class="sc">~</span> mom_iq, <span class="at">data =</span> kidiq)</span>
<span id="cb318-2"><a href="ch-regr-model-lm.html#cb318-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fm)</span>
<span id="cb318-3"><a href="ch-regr-model-lm.html#cb318-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)      mom_iq </span></span>
<span id="cb318-4"><a href="ch-regr-model-lm.html#cb318-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  25.7997778   0.6099746</span></span></code></pre></div>
<p>In precedenza abbiamo soltanto accennato al problema di come si possono trovano i coefficienti dei minimi quadrati; ritorneremo su questo punto in seguito, con una simulazione. Per ora, chiediamoci cosa significano i due coefficienti che abbiamo appena trovato.</p>
<p>Il coefficiente <span class="math inline">\(a\)</span> si chiama <em>intercetta</em>. L’intercetta, all’interno del diagramma a dispersione, specifica il punto in cui la retta di regressione interseca l’asse <span class="math inline">\(y\)</span> del sistema di assi cartesiani.</p>
<p>Nel caso presente questo valore non è di alcun interesse, perché corrisponde al valore della retta di regressione quando <span class="math inline">\(x = 0\)</span>, ovvero quando l’intelligenza della madre è uguale a 0. Vedremo in seguito come, trasformando i dati, è possibile assegnare al coefficiente <span class="math inline">\(a\)</span> un’interpretazione più utile. Per ora mi limito a fornire l’interpretazione del coefficiente.</p>
<p>Passando a <span class="math inline">\(b\)</span>, possiamo dire che questo secondo coefficiente va sotto il nome di <em>pendenza</em> della retta di regressione. Ovvero ci dice di quanto aumenta (se <span class="math inline">\(b\)</span> è positivo) o diminuisce (se <span class="math inline">\(b\)</span> è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile <span class="math inline">\(x\)</span>.</p>
<p>Nel caso presente, il coefficiente <span class="math inline">\(b\)</span> ci dice che, se il QI delle madri aumenta di 1 punto, il QI dei bambini aumenta <strong>in media</strong> di 0.61 punti.</p>
<p>È importante capire cosa significa che, in base ai risultati della regressione, <span class="math inline">\(y\)</span> aumenta <em>in media</em> di <span class="math inline">\(b\)</span> punti per ciascun aumento unitario di <span class="math inline">\(x\)</span>.</p>
<p>Il modello statistico di regressione <em>ipotizza</em> che, per ciascun valore osservato <span class="math inline">\(x\)</span> (per esempio, il valore del QI della prima madre del campione, ovvero <span class="math inline">\(x = 121.11753\)</span>) ci sia una distribuzione di valori <span class="math inline">\(y\)</span> nella popolazione, di cui solo uno è stato osservato nel campione. Possiamo facilmente capire che, se consideriamo tutte le madri con QI di 121.12, il punteggio del QI dei loro figli non sia costante, ma assuma tanti valori possibili. Questa distribuzione di valori possibili si chiama distribuzione <span class="math inline">\(y\)</span> condizionata a <span class="math inline">\(x\)</span>, ovvero <span class="math inline">\(p(y \mid x_i)\)</span>.</p>
<p>Il modello statistico della regressione lineare non può in alcun modo prevedere il valore assunto da ciascuna delle possibili osservazioni che fanno parte della distribuzione <span class="math inline">\(p(y \mid x_i)\)</span>. Il modello della regressione lineare ha un obiettivo più limitato, ovvero si propone di prevedere <em>le medie</em> delle distribuzioni <span class="math inline">\(p(y \mid x_i)\)</span> conoscendo i valori <span class="math inline">\(x\)</span>.</p>
<p>Dunque, quando il coefficiente <span class="math inline">\(b\)</span> è uguale a 0.61, questo significa che il modello di regressione predice che <em>la medie</em> della distribuzione condizionata <span class="math inline">\(p(y \mid x_i)\)</span> aumenta di 0.61 punti se la variabile <span class="math inline">\(x\)</span> (QI delle madri) aumenta di un punto. Questo significa che il modello di regressione non fa una predizione sul punteggio di ciascun valore <span class="math inline">\(y_i\)</span> (in funzione di <span class="math inline">\(x\)</span>), ma solo della media delle distribuzioni condizionate <span class="math inline">\(p(y \mid x_i)\)</span> di cui il valore osservato <span class="math inline">\(y_i\)</span> è una realizzazione casuale.</p>
<p>Possiamo dire la stessa cosa con parole diverse dicendo che il modello di regressione fa delle predizioni sulla componente deterministica di ciascuna osservazione. È più semplice capire questo aspetto se rappresentiamo in maniera grafica la componente “deterministica” <span class="math inline">\(\hat{y}_i = a + b x_i\)</span> predetta dal modello di regressione.</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="ch-regr-model-lm.html#cb319-1" aria-hidden="true" tabindex="-1"></a>kidiq<span class="sc">$</span>yhat <span class="ot">&lt;-</span> fm<span class="sc">$</span>fitted.values</span>
<span id="cb319-2"><a href="ch-regr-model-lm.html#cb319-2" aria-hidden="true" tabindex="-1"></a>kidiq <span class="sc">%&gt;%</span> </span>
<span id="cb319-3"><a href="ch-regr-model-lm.html#cb319-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mom_iq, <span class="at">y =</span> yhat)) <span class="sc">+</span> </span>
<span id="cb319-4"><a href="ch-regr-model-lm.html#cb319-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb319-5"><a href="ch-regr-model-lm.html#cb319-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb319-6"><a href="ch-regr-model-lm.html#cb319-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(</span>
<span id="cb319-7"><a href="ch-regr-model-lm.html#cb319-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">mean</span>(mom_iq), <span class="at">y=</span><span class="fu">mean</span>(kid_score)), </span>
<span id="cb319-8"><a href="ch-regr-model-lm.html#cb319-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">colour=</span><span class="st">&quot;red&quot;</span>, <span class="at">size =</span> <span class="dv">4</span></span>
<span id="cb319-9"><a href="ch-regr-model-lm.html#cb319-9" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-318-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Il diagramma precedente presenta ciascun valore <span class="math inline">\(\hat{y}_i = a + b x_i\)</span> in funzione di <span class="math inline">\(x_i\)</span>. Si vede che i valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.</p>
<p>In precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione <span class="math inline">\(y_i\)</span> che non viene predetta dal modello di regressione, corrisponde alla <em>distanza verticale</em> tra il valore <span class="math inline">\(y_i\)</span> osservato e il valore <span class="math inline">\(\hat{y}_i\)</span> predetto dal modello di regressione:</p>
<p><span class="math display">\[
e_i = y_i - (a + b x_i).
\]</span></p>
<p>Nel caso nella prima osservazione, ad esempio abbiamo:</p>
<p><span class="math display">\[
y_1 = (a + b x_1) + e_1
\]</span></p>
<p>Abbiamo</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="ch-regr-model-lm.html#cb320-1" aria-hidden="true" tabindex="-1"></a>kidiq<span class="sc">$</span>kid_score[<span class="dv">1</span>]</span>
<span id="cb320-2"><a href="ch-regr-model-lm.html#cb320-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 65</span></span></code></pre></div>
<p>Dunque</p>
<p><span class="math display">\[
e_1 = (a + b x_1) - y_1
\]</span></p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="ch-regr-model-lm.html#cb321-1" aria-hidden="true" tabindex="-1"></a>e_1 <span class="ot">&lt;-</span> kidiq<span class="sc">$</span>kid_score[<span class="dv">1</span>] <span class="sc">-</span> (a <span class="sc">+</span> b <span class="sc">*</span> kidiq<span class="sc">$</span>mom_iq[<span class="dv">1</span>])</span>
<span id="cb321-2"><a href="ch-regr-model-lm.html#cb321-2" aria-hidden="true" tabindex="-1"></a>e_1</span>
<span id="cb321-3"><a href="ch-regr-model-lm.html#cb321-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] -34.67839</span></span></code></pre></div>
<p>Ciò significa che il valore osservato <span class="math inline">\(y_1 = 65\)</span> viene scomposto dal modello di regressione in due componenti. La componente deterministica <span class="math inline">\(\hat{y}_1\)</span>, predicibile da <span class="math inline">\(x_1\)</span>, è</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="ch-regr-model-lm.html#cb322-1" aria-hidden="true" tabindex="-1"></a>yhat_1 <span class="ot">&lt;-</span> a <span class="sc">+</span> b <span class="sc">*</span> kidiq<span class="sc">$</span>mom_iq[<span class="dv">1</span>]</span>
<span id="cb322-2"><a href="ch-regr-model-lm.html#cb322-2" aria-hidden="true" tabindex="-1"></a>yhat_1</span>
<span id="cb322-3"><a href="ch-regr-model-lm.html#cb322-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 99.67839</span></span></code></pre></div>
<p>La somma della componente deterministica e della componente erratica, ovviamente, riproduce il valore osservato.</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="ch-regr-model-lm.html#cb323-1" aria-hidden="true" tabindex="-1"></a>yhat_1 <span class="sc">+</span> e_1</span>
<span id="cb323-2"><a href="ch-regr-model-lm.html#cb323-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 65</span></span></code></pre></div>
<p>Se sommiamo tutti i residui calcolati rispetto alla retta di regressione dei minimi quadrati otteniamo zero:</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="ch-regr-model-lm.html#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(fm<span class="sc">$</span>res)</span>
<span id="cb324-2"><a href="ch-regr-model-lm.html#cb324-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 5.373479e-13</span></span></code></pre></div>
<div id="trasformazione-dei-dati" class="section level3 hasAnchor" number="25.1.1">
<h3><span class="header-section-number">25.1.1</span> Trasformazione dei dati<a href="ch-regr-model-lm.html#trasformazione-dei-dati" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In generale, per variabili a livello di scala ad intervalli, non è possibile assegnare un’interpretazione utile all’intercetta del modello di regressione lineare. L’intercetta ci dice infatti qual è il valore atteso della <span class="math inline">\(y\)</span> quando <span class="math inline">\(x = 0\)</span>. Ma, se la variabile <span class="math inline">\(x\)</span> è misurata su scala ad intervalli, il valore <span class="math inline">\(x = 0\)</span> è arbitrario e non corrisponde “all’assenza di intensità” della variabile <span class="math inline">\(x\)</span>. Un valore pari a 0 del QI della madre non vuol dire che l’intelligenza della madre sia nulla (un’affermazione, questa, che è difficile da capire), ma semplicemente che il punteggio del test usato per misurare il QI della madre assume valore 0 (qualcosa che, comunque, in pratica non succederà mai). Quindi è di poco interesse sapere qual è il valore medio del QI del bambino quando test usato per misurare il QI della madre ha valore 0. Per potere fornire all’intercetta del modello di regressione un’interpretazione più utile dobbiamo trasformare le osservazioni <span class="math inline">\(x\)</span>.</p>
<p>Esprimiamo <span class="math inline">\(x\)</span> come differenza dalla media. Chiamiamo questa nuova variabile <span class="math inline">\(xd\)</span>:</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="ch-regr-model-lm.html#cb325-1" aria-hidden="true" tabindex="-1"></a>kidiq<span class="sc">$</span>xd <span class="ot">&lt;-</span> kidiq<span class="sc">$</span>mom_iq <span class="sc">-</span> <span class="fu">mean</span>(kidiq<span class="sc">$</span>mom_iq)</span></code></pre></div>
<p>Se ora usiamo le coppie di osservazioni <span class="math inline">\(xd_i, y_i\)</span>, il diagramma a dispersione assume la forma seguente.</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="ch-regr-model-lm.html#cb326-1" aria-hidden="true" tabindex="-1"></a>kidiq <span class="sc">%&gt;%</span> </span>
<span id="cb326-2"><a href="ch-regr-model-lm.html#cb326-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> xd, <span class="at">y =</span> kid_score)) <span class="sc">+</span> </span>
<span id="cb326-3"><a href="ch-regr-model-lm.html#cb326-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb326-4"><a href="ch-regr-model-lm.html#cb326-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb326-5"><a href="ch-regr-model-lm.html#cb326-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(</span>
<span id="cb326-6"><a href="ch-regr-model-lm.html#cb326-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">mean</span>(xd), <span class="at">y=</span><span class="fu">mean</span>(kid_score)), </span>
<span id="cb326-7"><a href="ch-regr-model-lm.html#cb326-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">colour=</span><span class="st">&quot;red&quot;</span>, <span class="at">size =</span> <span class="dv">4</span></span>
<span id="cb326-8"><a href="ch-regr-model-lm.html#cb326-8" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-325-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Quello che abbiamo fatto è stato di <em>traslare rigidamente</em> la nube di punti sul piano cartesiano di una quantità pari alla distanza tra <span class="math inline">\(\bar{x}\)</span> e l’origine. Dunque, le <em>relazioni spaziali</em> tra i punti del diagramma a dispersione restano immutate. Di conseguenza, la pendenza della retta di regressione calcolata sui dati trasformati è uguale a quella che si trova nel caso dei dati non trasformati. Ciò che cambia è il valore dell’intercetta.</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="ch-regr-model-lm.html#cb327-1" aria-hidden="true" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(kid_score <span class="sc">~</span> xd, <span class="at">data =</span> kidiq)</span>
<span id="cb327-2"><a href="ch-regr-model-lm.html#cb327-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fm1)</span>
<span id="cb327-3"><a href="ch-regr-model-lm.html#cb327-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)          xd </span></span>
<span id="cb327-4"><a href="ch-regr-model-lm.html#cb327-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  86.7972350   0.6099746</span></span></code></pre></div>
<p>L’intercetta corrisponde al punto sull’asse <span class="math inline">\(y\)</span> dove la retta di regressione interseca l’ordinata. Ma, nel caso dei dati trasformati, dato che abbiamo traslato i punti di una quantità pari a <span class="math inline">\(x - \bar{x}\)</span>, il valore <span class="math inline">\(xd = 0\)</span> corrisponde a <span class="math inline">\(x = \bar{x}\)</span> nel caso dei dati grezzi. Dunque, per i dati trasformati <span class="math inline">\(xd_i, y_i\)</span>, l’intercetta corrisponderà al valore atteso della <span class="math inline">\(y\)</span> in corrispondenza del valore medio della variabile <span class="math inline">\(x\)</span> sulla scala dei dati non trasformati (ovvero <span class="math inline">\(\bar{x}\)</span>). In altre parole, l’intercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al QI medio dei bambini in corrispondenza del QI medio delle madri.</p>
</div>
<div id="il-metodo-dei-minimi-quadrati" class="section level3 hasAnchor" number="25.1.2">
<h3><span class="header-section-number">25.1.2</span> Il metodo dei minimi quadrati<a href="ch-regr-model-lm.html#il-metodo-dei-minimi-quadrati" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ora che abbiamo visto come interpretare il coefficienti di regressione, chiediamoci come vengono calcolati. La procedura generale è stata brevemente descritta in precedenza. Vediamo ora come si giunge alla conclusione descritta sopra usando una simulazione.</p>
<p>Il problema è di trovare i valori <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> tali per cui la quantità <span class="math inline">\(\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\)</span> assume il valore minore possibile. Questo è un problema di minimizzazione rispetto a due parametri. Per dare un’idea di come si fa, semplifichiamo il problema e supponiamo che uno dei due parametri sia noto, ad esempio <span class="math inline">\(a\)</span>, così ci resta una sola incognita.</p>
<p>Credo una griglia di valori <code>b_grid</code> possibili, ad esempio:</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="ch-regr-model-lm.html#cb328-1" aria-hidden="true" tabindex="-1"></a>nrep <span class="ot">&lt;-</span> <span class="fl">1e5</span></span>
<span id="cb328-2"><a href="ch-regr-model-lm.html#cb328-2" aria-hidden="true" tabindex="-1"></a>b_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> nrep)</span></code></pre></div>
<p>Definisco una funzione che calcola la quantità <span class="math inline">\(\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\)</span>:</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="ch-regr-model-lm.html#cb329-1" aria-hidden="true" tabindex="-1"></a>sse <span class="ot">&lt;-</span> <span class="cf">function</span>(a, b, x, y) {</span>
<span id="cb329-2"><a href="ch-regr-model-lm.html#cb329-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>((y <span class="sc">-</span> (a <span class="sc">+</span> b <span class="sc">*</span> x))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb329-3"><a href="ch-regr-model-lm.html#cb329-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Calcolo la somma degli errori quadratici per ciascun possibile valore <code>b_grid</code>, fissando <span class="math inline">\(a = 25.79978\)</span>.</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="ch-regr-model-lm.html#cb330-1" aria-hidden="true" tabindex="-1"></a>sse_res <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nrep)</span>
<span id="cb330-2"><a href="ch-regr-model-lm.html#cb330-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nrep) {</span>
<span id="cb330-3"><a href="ch-regr-model-lm.html#cb330-3" aria-hidden="true" tabindex="-1"></a>  sse_res[i] <span class="ot">&lt;-</span> <span class="fu">sse</span>(<span class="at">a =</span> <span class="fl">25.79978</span>, <span class="at">b =</span> b_grid[i], <span class="at">x =</span> kidiq<span class="sc">$</span>mom_iq, <span class="at">y =</span> kidiq<span class="sc">$</span>kid_score)</span>
<span id="cb330-4"><a href="ch-regr-model-lm.html#cb330-4" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Esaminiamo il risultato ottenuto.</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="ch-regr-model-lm.html#cb331-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb331-2"><a href="ch-regr-model-lm.html#cb331-2" aria-hidden="true" tabindex="-1"></a>  b_grid, sse_res, <span class="at">type =</span> <span class="st">&#39;l&#39;</span></span>
<span id="cb331-3"><a href="ch-regr-model-lm.html#cb331-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-330-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Il risultato ottenuto con la simulazione</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="ch-regr-model-lm.html#cb332-1" aria-hidden="true" tabindex="-1"></a>b_grid[<span class="fu">which.min</span>(sse_res)]</span>
<span id="cb332-2"><a href="ch-regr-model-lm.html#cb332-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.6099761</span></span></code></pre></div>
<p>riproduce quello ottenuto per via analitica:</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="ch-regr-model-lm.html#cb333-1" aria-hidden="true" tabindex="-1"></a>b</span>
<span id="cb333-2"><a href="ch-regr-model-lm.html#cb333-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.6099746</span></span></code></pre></div>
<p>Una simulazione simile, ma computazionalmente più complessa, può essere usata per stimare simultaneamente entrambi i parametri. Ci siamo limitati qui ad una <em>proof of concept</em> del caso più semplice.</p>
</div>
<div id="lerrore-standard-della-regressione" class="section level3 hasAnchor" number="25.1.3">
<h3><span class="header-section-number">25.1.3</span> L’errore standard della regressione<a href="ch-regr-model-lm.html#lerrore-standard-della-regressione" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Il secondo obiettivo del modello statistico di regressione lineare è quello di stabilire <em>quanto sia grande la componente <span class="math inline">\(y\)</span> predicibile da <span class="math inline">\(x\)</span>, per ciascuna osservazione</em>.</p>
<p>Un indice assoluto della bontà di adattamento è fornito dalla deviazione standard dei residui, <span class="math inline">\(s_e\)</span>, chiamata anche <em>errore standard della stima</em>. Uno stimatore non distorto della varianza dei residui nella popolazione è dato da</p>
<p><span class="math display">\[
s^2_e = \frac{1}{n-2}\sum e_i^2
\]</span></p>
<p>e quindi l’errore standard della stima sarà</p>
<p><span class="math display">\[\begin{equation}
s_e = \sqrt{\frac{1}{n-2}\sum e_i^2}.
\end{equation}\]</span></p>
<p>Si noti che questa è la stessa formula della varianza (dato che la media dei residui è zero), tranne per il fatto che al denominatore abbiamo <span class="math inline">\(n-2\)</span>. Dato che, per calcolare <span class="math inline">\(\hat{y}\)</span> abbiamo usato due coefficienti (<span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>), si dice che “abbiamo perso due gradi di libertà”.</p>
<p>Dato che <span class="math inline">\(s_e\)</span> possiede la stessa unità di misura della variabile <span class="math inline">\(y\)</span>, l’errore standard della stima può essere considerato come una sorta di “residuo medio.” – usando la stessa interpretazione che diamo alla deviazione standard in generale.</p>
<p>Si noti che la formula precedente non fornisce la “deviazione standard dei residui nel campione” (quella formula avrebbe <span class="math inline">\(n\)</span> al denominatore). Invece, fornisce una <em>stima</em> della deviazione standard dei residui nella popolazione da cui il campione è stato estratto.</p>
<p>Verifichiamo quanto detto con i dati a disposizione.</p>
<p>I residui possono essere trovati nel modo seguente.</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="ch-regr-model-lm.html#cb334-1" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> kidiq<span class="sc">$</span>kid_score <span class="sc">-</span> (a <span class="sc">+</span> b <span class="sc">*</span> kidiq<span class="sc">$</span>mom_iq)</span>
<span id="cb334-2"><a href="ch-regr-model-lm.html#cb334-2" aria-hidden="true" tabindex="-1"></a>e[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span>
<span id="cb334-3"><a href="ch-regr-model-lm.html#cb334-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] -34.678390  17.691747 -11.217173  -3.461529  32.627697   6.382845</span></span>
<span id="cb334-4"><a href="ch-regr-model-lm.html#cb334-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] -41.521041   3.864881  26.414387  11.208068</span></span></code></pre></div>
<p>Oppure nel modo seguente.</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="ch-regr-model-lm.html#cb335-1" aria-hidden="true" tabindex="-1"></a>fm<span class="sc">$</span>residuals[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span>
<span id="cb335-2"><a href="ch-regr-model-lm.html#cb335-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          1          2          3          4          5          6          7 </span></span>
<span id="cb335-3"><a href="ch-regr-model-lm.html#cb335-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -34.678390  17.691747 -11.217173  -3.461529  32.627697   6.382845 -41.521041 </span></span>
<span id="cb335-4"><a href="ch-regr-model-lm.html#cb335-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          8          9         10 </span></span>
<span id="cb335-5"><a href="ch-regr-model-lm.html#cb335-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   3.864881  26.414387  11.208068</span></span></code></pre></div>
<p>Calcolo il residuo medio, prendendo il valore assoluto.</p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="ch-regr-model-lm.html#cb336-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">abs</span>(e))</span>
<span id="cb336-2"><a href="ch-regr-model-lm.html#cb336-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 14.4686</span></span></code></pre></div>
<p>L’errore standard della regressione è</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="ch-regr-model-lm.html#cb337-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">sum</span>(e<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (<span class="fu">length</span>(e) <span class="sc">-</span> <span class="dv">2</span>))</span>
<span id="cb337-2"><a href="ch-regr-model-lm.html#cb337-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 18.26612</span></span></code></pre></div>
<p>I due numeri non sono uguali, ma possiamo dire che hanno lo stesso ordine di grandezza.</p>
<p>Se usiamo la funzione <code>lm()</code> otteniamo lo stesso valore, chiamato <code>Residual standard error</code>.</p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="ch-regr-model-lm.html#cb338-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fm)</span>
<span id="cb338-2"><a href="ch-regr-model-lm.html#cb338-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb338-3"><a href="ch-regr-model-lm.html#cb338-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb338-4"><a href="ch-regr-model-lm.html#cb338-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; lm(formula = kid_score ~ mom_iq, data = kidiq)</span></span>
<span id="cb338-5"><a href="ch-regr-model-lm.html#cb338-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb338-6"><a href="ch-regr-model-lm.html#cb338-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb338-7"><a href="ch-regr-model-lm.html#cb338-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span id="cb338-8"><a href="ch-regr-model-lm.html#cb338-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -56.753 -12.074   2.217  11.710  47.691 </span></span>
<span id="cb338-9"><a href="ch-regr-model-lm.html#cb338-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb338-10"><a href="ch-regr-model-lm.html#cb338-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb338-11"><a href="ch-regr-model-lm.html#cb338-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb338-12"><a href="ch-regr-model-lm.html#cb338-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***</span></span>
<span id="cb338-13"><a href="ch-regr-model-lm.html#cb338-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; mom_iq       0.60997    0.05852   10.42  &lt; 2e-16 ***</span></span>
<span id="cb338-14"><a href="ch-regr-model-lm.html#cb338-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb338-15"><a href="ch-regr-model-lm.html#cb338-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb338-16"><a href="ch-regr-model-lm.html#cb338-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb338-17"><a href="ch-regr-model-lm.html#cb338-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 18.27 on 432 degrees of freedom</span></span>
<span id="cb338-18"><a href="ch-regr-model-lm.html#cb338-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 </span></span>
<span id="cb338-19"><a href="ch-regr-model-lm.html#cb338-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; F-statistic: 108.6 on 1 and 432 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
</div>
</div>
<div id="indice-di-determinazione" class="section level2 hasAnchor" number="25.2">
<h2><span class="header-section-number">25.2</span> Indice di determinazione<a href="ch-regr-model-lm.html#indice-di-determinazione" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Un importante risultato dei minimi quadrati riguarda la cosiddetta <em>scomposizione della devianza</em> mediante la quale si definisce l’indice di determinazione, il quale fornisce una misura relativa della bontà di adattamento del modello di regressione ai dati del campione. Per una generica osservazione <span class="math inline">\(x_i, y_i\)</span>, la variazione di <span class="math inline">\(y_i\)</span> rispetto alla media <span class="math inline">\(\bar{y}\)</span> può essere descritta come la somma di due componenti: il residuo <span class="math inline">\(e_i=y_i- \hat{y}_i\)</span> e lo scarto di <span class="math inline">\(\hat{y}_i\)</span> rispetto alla media <span class="math inline">\(\bar{y}\)</span>:</p>
<p><span class="math display">\[
y_i - \bar{y} = (y_i- \hat{y}_i) + (\hat{y}_i - \bar{y}) = e_i + (\hat{y}_i - \bar{y}).
\]</span></p>
<p>Se consideriamo tutte le osservazioni, la devianza delle <span class="math inline">\(y\)</span> può essere scomposta nel seguente modo:</p>
<p><span class="math display">\[\begin{align}
\sum (y_i - \bar{y})^2 &amp;= \sum \left[ e_i + (\hat{y}_i - \bar{y})
\right]^2
= \sum e_i^2 + \sum (\hat{y}_i - \bar{y})^2 + 2 \sum e_i (\hat{y}_i -
\bar{y}) \notag
\end{align}\]</span></p>
<p>Per i vincoli imposti sul modello statistico di regressione, il doppio prodotto si annulla, infatti</p>
<p><span class="math display">\[\begin{align}
\sum e_i (\hat{y}_i - \bar{y}) &amp;= \sum e_i \hat{y}_i - \bar{y}\sum e_i = \sum e_i (a + b x_i) \notag \\
&amp;= a \sum e_i + b \sum e_i x_i = 0 \notag
\end{align}\]</span></p>
<p>Il termine <span class="math inline">\(b \sum e_i x_i\)</span> è uguale a zero perché, come vedremo in seguito, i coefficienti di regressione vengono calcolati in modo tale da rendere nulla <span class="math inline">\(\mbox{Cov}(e, x)\)</span>. Di conseguenza, il termine precedente deve essere nullo.</p>
<p>Possiamo dunque concludere che la devianza totale (<span class="math inline">\(\mbox{dev}_T\)</span>) si scompone nella somma di devianza d’errore (o devianza non spiegata) (<span class="math inline">\(\mbox{dev}_E\)</span>) e devianza di regressione (o devianza spiegata) (<span class="math inline">\(\mbox{dev}_T\)</span>):</p>
<p><span class="math display">\[\begin{align}
\underbrace{\sum_{i=1}^n (y_i - \bar{y})^2}_{\tiny{\text{Devianza
totale}}} &amp;= \underbrace{\sum_{i=1}^n e_i^2}_{\tiny{\text{Devianza
di dispersione}}} + \underbrace{\sum_{i=1}^n  (\hat{y}_i -
\bar{y})^2}_{\tiny{\text{Devianza di regressione}}} \notag
\end{align}\]</span></p>
<p>La devianza di regressione, <span class="math inline">\(\mbox{dev_R} \triangleq \mbox{dev_T} - \mbox{dev_E}\)</span>, indica dunque la riduzione degli errori al quadrato che è imputabile alla regressione lineare. Il rapporto <span class="math inline">\(\mbox{dev_R}/\mbox{dev_T}\)</span>, detto <em>indice di determinazione</em>, esprime tale riduzione degli errori in termini proporzionali e definisce il coefficiente di correlazione al quadrato:</p>
<p><span class="math display">\[\begin{equation}
R^2 \triangleq \frac{\mbox{dev_R}}{\mbox{dev_T}} = 1 - \frac{\mbox{dev_E}}{\mbox{dev_T}}.
\end{equation}\]</span></p>
<p>Quando l’insieme di tutte le deviazioni della <span class="math inline">\(y\)</span> dalla media è spiegato dall’insieme di tutte le deviazioni della variabile teorica <span class="math inline">\(\hat{y}\)</span> dalla media, si ha che l’adattamento (o accostamento) del modello al campione di dati è perfetto, la
devianza residua è nulla ed <span class="math inline">\(r^2 = 1\)</span>; nel caso opposto, la variabilità totale coincide con quella residua, per cui <span class="math inline">\(r^2 = 0\)</span>.
Tra questi due estremi, <span class="math inline">\(r\)</span> indica l’intensità della relazione lineare tra le due variabili e <span class="math inline">\(r^2\)</span>, con <span class="math inline">\(0 \leq r^2 \leq 1\)</span>, esprime la porzione della devianza totale della <span class="math inline">\(y\)</span> che è spiegata dalla regressione lineare sulla <span class="math inline">\(x\)</span>.</p>
<p>Per l’esempio in discussione abbiamo quanto segue. La devianza totale è</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="ch-regr-model-lm.html#cb339-1" aria-hidden="true" tabindex="-1"></a>dev_t <span class="ot">&lt;-</span> <span class="fu">sum</span>((kidiq<span class="sc">$</span>kid_score <span class="sc">-</span> <span class="fu">mean</span>(kidiq<span class="sc">$</span>kid_score))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb339-2"><a href="ch-regr-model-lm.html#cb339-2" aria-hidden="true" tabindex="-1"></a>dev_t</span>
<span id="cb339-3"><a href="ch-regr-model-lm.html#cb339-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 180386.2</span></span></code></pre></div>
<p>La devianza spiegata è</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="ch-regr-model-lm.html#cb340-1" aria-hidden="true" tabindex="-1"></a>dev_r <span class="ot">&lt;-</span> <span class="fu">sum</span>((fm<span class="sc">$</span>fitted.values <span class="sc">-</span> <span class="fu">mean</span>(kidiq<span class="sc">$</span>kid_score))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb340-2"><a href="ch-regr-model-lm.html#cb340-2" aria-hidden="true" tabindex="-1"></a>dev_r</span>
<span id="cb340-3"><a href="ch-regr-model-lm.html#cb340-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 36248.82</span></span></code></pre></div>
<p>L’indice di determinazione è</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="ch-regr-model-lm.html#cb341-1" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">&lt;-</span> dev_r <span class="sc">/</span> dev_t</span>
<span id="cb341-2"><a href="ch-regr-model-lm.html#cb341-2" aria-hidden="true" tabindex="-1"></a>R2</span>
<span id="cb341-3"><a href="ch-regr-model-lm.html#cb341-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.2009512</span></span></code></pre></div>
<p>Nell’output di <code>lm()</code> un tale valore è chiamato <code>Multiple R-squared</code>.</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="ch-regr-model-lm.html#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fm)</span>
<span id="cb342-2"><a href="ch-regr-model-lm.html#cb342-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb342-3"><a href="ch-regr-model-lm.html#cb342-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb342-4"><a href="ch-regr-model-lm.html#cb342-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; lm(formula = kid_score ~ mom_iq, data = kidiq)</span></span>
<span id="cb342-5"><a href="ch-regr-model-lm.html#cb342-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb342-6"><a href="ch-regr-model-lm.html#cb342-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb342-7"><a href="ch-regr-model-lm.html#cb342-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span id="cb342-8"><a href="ch-regr-model-lm.html#cb342-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -56.753 -12.074   2.217  11.710  47.691 </span></span>
<span id="cb342-9"><a href="ch-regr-model-lm.html#cb342-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb342-10"><a href="ch-regr-model-lm.html#cb342-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb342-11"><a href="ch-regr-model-lm.html#cb342-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb342-12"><a href="ch-regr-model-lm.html#cb342-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***</span></span>
<span id="cb342-13"><a href="ch-regr-model-lm.html#cb342-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; mom_iq       0.60997    0.05852   10.42  &lt; 2e-16 ***</span></span>
<span id="cb342-14"><a href="ch-regr-model-lm.html#cb342-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb342-15"><a href="ch-regr-model-lm.html#cb342-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb342-16"><a href="ch-regr-model-lm.html#cb342-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb342-17"><a href="ch-regr-model-lm.html#cb342-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 18.27 on 432 degrees of freedom</span></span>
<span id="cb342-18"><a href="ch-regr-model-lm.html#cb342-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 </span></span>
<span id="cb342-19"><a href="ch-regr-model-lm.html#cb342-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; F-statistic: 108.6 on 1 and 432 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
<p>Il risultato ottenuto si può interpretare dicendo che circa il 20% della variabilità dei punteggi del QI dei bambini può essere predetto conoscendo il QI delle madri.</p>
<div id="inferenza-sul-modello-di-regressione" class="section level3 hasAnchor" number="25.2.1">
<h3><span class="header-section-number">25.2.1</span> Inferenza sul modello di regressione<a href="ch-regr-model-lm.html#inferenza-sul-modello-di-regressione" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La discussione precedente era tutta basata sulla trattazione “classica” del modello lineare, ovvero una trattazione basata sulle stime di massima verosimiglianza (se <span class="math inline">\(y \sim \mathcal{N}(\alpha + \beta x, \sigma)\)</span>, allora le stime dei minimi quadrati coincidono con le stime di massima verosimiglianza). In altre parole, nella discussione precedente non abbiamo considerato in alcun modo le distribuzioni a priori dei parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>. I risultati precedenti si confermano, in un contesto bayesiano, se e solo se imponiamo sui parametri delle distribuzioni a priori non informative (cioè, uniformi). In tali circostanze, le stime di massima verosimiglianza risultano identiche al massimo a posteriori bayesiano.</p>
<p>Detto questo, il tema dell’inferenza viene trattato dall’approccio frequentista costruendo la “distribuzione campionaria” dei parametri (ovvero la distribuzione dei valori che i parametri otterrebbero in infiniti campioni casuali (<span class="math inline">\(x, y\)</span>) di ampiezza <span class="math inline">\(n\)</span> estratti dalla medesima popolazione) e poi calcolando gli errori standard dei parametri e gli intervalli di fiducia dei parametri. Una domanda frequente è, per esempio, se la pendenza della retta di regressione sia maggiore di zero. Per rispondere a tale domanda l’approccio frequentista calcola l’intervallo di fiducia al 95% per il parametro <span class="math inline">\(\beta\)</span>. Se tale intervallo non include lo zero, e se il limite inferiore di tale intervallo è maggiore di zero, allora si conclude, con un grado di confidenza del 95%, che il vero parametro <span class="math inline">\(\beta\)</span> nella popolazione è maggiore di zero. Ovvero, si conclude che vi sono evidenze di un’associazione lineare positiva tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</p>
<p>Alla stessa conclusione si può arrivare calcolando, in un ottica bayesiana, l’intervallo di credibilità al 95% per il parametro <span class="math inline">\(\beta\)</span>. I due intervalli sono identici se usiamo una distribuzione a priori piatta. Sono invece diversi se usiamo una distribuzione a priori debolmente informativa, oppure informativa.</p>
<p>Solitamente si usa una distribuzione a priori debolmente informativa centrata sullo zero. In tali circostanze, l’uso della distribuzione a priori ha solo un effetto di <em>regolarizzazione</em>, ovvero di riduzione del peso delle osservazioni estreme – un tale risultato statistico è molto desiderabile, ma è difficile da ottenere in un contesto frequentista. Vedremo nel prossimo capitolo come può essere svolta l’inferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano.</p>
</div>
</div>
<div id="commenti-e-considerazioni-finali-20" class="section level2 unnumbered hasAnchor">
<h2>Commenti e considerazioni finali<a href="ch-regr-model-lm.html#commenti-e-considerazioni-finali-20" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Il modello lineare bivariato viene usato per descrivere la relazione tra due variabili e per determinare il segno e l’intensità di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base al valore assunto dalla variabile indipendente.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-regr-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-reg-lin-stan.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ccaudek/datascience/edit/master/052_reglin2.Rmd",
"text": "Suggest an edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ds4psy.pdf", "ds4psy.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
