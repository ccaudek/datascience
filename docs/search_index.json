[["index.html", "Data Science per psicologi Prefazione La psicologia e la Data science Come studiare Sviluppare un metodo di studio efficace", " Data Science per psicologi Corrado Caudek 2022-04-28 Prefazione Data Science per psicologi contiene il materiale delle lezioni dell’insegnamento di Psicometria B000286 (A.A. 2021/2022) rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze. Psicometria si propone di fornire agli studenti un’introduzione all’analisi dei dati in psicologia. Le conoscenze/competenze che verranno sviluppate in questo insegnamento sono quelle della Data science, ovvero un insieme di conoscenze/competenze che si pongono all’intersezione tra statistica (ovvero, richiedono la capacità di comprendere teoremi statistici) e informatica (ovvero, richiedono la capacità di sapere utilizzare un software). La psicologia e la Data science Sembra sensato spendere due parole su un tema che è importante per gli studenti: quello indicato dal titolo di questo Capitolo. È ovvio che agli studenti di psicologia la statistica non piace. Se piacesse, forse studierebbero Data science e non psicologia; ma non lo fanno. Di conseguenza, gli studenti di psicologia si chiedono: “perché dobbiamo perdere tanto tempo a studiare queste cose quando in realtà quello che ci interessa è tutt’altro?” Questa è una bella domanda. C’è una ragione molto semplice che dovrebbe farci capire perché la Data science è così importante per la psicologia. Infatti, a ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia gli individui ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, in certi casi, predire. In questo senso, la psicologia è molto diversa dall’ingegneria, per esempio. Le proprietà di un determinato ponte sotto certe condizioni, ad esempio, sono molto simili a quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non può dirsi degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l’oggetto di studio proprio della psicologia: è dunque chiaro che i problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri. Questa è la ragione per cui abbiamo tanto bisogno della Data science in psicologia: perché la Data science ci consente di descrivere la variazione e il cambiamento. E queste sono appunto le caratteristiche di base dei fenomeni psicologici. Sono sicuro che, leggendo queste righe, a molti studenti sarà venuta in mente la seguente domanda: perché non chiediamo a qualche esperto di fare il “lavoro sporco” (ovvero le analisi statistiche) per noi, mentre noi (gli psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli “tecnici” della Data science? La risposta a questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della Data science. Le tematiche della Data science non possono essere ignorate né dai ricercatori in psicologia né da coloro che svolgono la professione di psicologo al di fuori dell’Università. Infatti, anche i professionisti al di fuori dall’università non possono fare a meno di leggere la letteratura psicologica più recente: il continuo aggiornamento delle conoscenze è infatti richiesto dalla deontologia della professione. Ma per potere fare questo è necessario conoscere un bel po’ di Data science! Basta aprire a caso una rivista specialistica di psicologia per rendersi conto di quanto ciò sia vero: gli articoli che riportano i risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. E la comprensione della letteratura psicologica rappresenta un requisito minimo nel bagaglio professionale dello psicologo. Le considerazioni precedenti cercano di chiarire il seguente punto: la Data science non è qualcosa da studiare a malincuore, in un singolo insegnamento universitario, per poi poterla tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano gli strumenti della Data science in tantissimi ambiti della loro attività professionale: in particolare quando costruiscono, somministrano e interpretano i test psicometrici. È dunque chiaro che possedere delle solide basi di Data science è un tassello imprescindibile del bagaglio professionale dello psicologo. In questo insegnamento verrano trattati i temi base della Data science e verrà adottato un punto di vista bayesiano, che corrisponde all’approccio più recente e sempre più diffuso in psicologia. Come studiare Il giusto metodo di studio per prepararsi all’esame di Psicometria è quello di seguire attivamente le lezioni, assimilare i concetti via via che essi vengono presentati e verificare in autonomia le procedure presentate a lezione. Incoraggio gli studenti a farmi domande per chiarire ciò che non è stato capito appieno. Incoraggio gli studenti a utilizzare i forum attivi su Moodle e, soprattutto, a svolgere gli esercizi proposti su Moodle. I problemi forniti su Moodle rappresentano il livello di difficoltà richiesto per superare l’esame e consentono allo studente di comprendere se le competenze sviluppate fino a quel punto sono sufficienti rispetto alle richieste dell’esame. La prima fase dello studio, che è sicuramente individuale, è quella in cui è necessario acquisire le conoscenze teoriche relative ai problemi che saranno presentati all’esame. La seconda fase di studio, che può essere facilitata da scambi con altri e da incontri di gruppo, porta ad acquisire la capacità di applicare le conoscenze: è necessario capire come usare un software (\\(\\textsf{R}\\)) per applicare i concetti statistici alla specifica situazione del problema che si vuole risolvere. Le due fasi non sono però separate: il saper fare molto spesso ci aiuta a capire meglio. Sviluppare un metodo di studio efficace Avendo insegnato molte volte in passato un corso introduttivo di analisi dei dati ho notato nel corso degli anni che gli studenti con l’atteggiamento mentale che descriverò qui sotto generalmente ottengono ottimi risultati. Alcuni studenti sviluppano naturalmente questo approccio allo studio, ma altri hanno bisogno di fare uno sforzo per maturarlo. Fornisco qui sotto una breve descrizione del “metodo di studio” che, nella mia esperienza, è il più efficace per affrontare le richieste di questo insegnamento. Dedicate un tempo sufficiente al materiale di base, apparentemente facile; assicuratevi di averlo capito bene. Cercate le lacune nella vostra comprensione. Leggere presentazioni diverse dello stesso materiale (in libri o articoli diversi) può fornire nuove intuizioni. Gli errori che facciamo sono i nostri migliori maestri. Istintivamente cerchiamo di dimenticare subito i nostri errori. Ma il miglior modo di imparare è apprendere dagli errori che commettiamo. In questo senso, una soluzione corretta è meno utile di una soluzione sbagliata. Quando commettiamo un errore questo ci fornisce un’informazione importante: ci fa capire qual è il materiale di studio sul quale dobbiamo ritornare e che dobbiamo capire meglio. C’è ovviamente un aspetto “psicologico” nello studio. Quando un esercizio o problema ci sembra incomprensibile, la cosa migliore da fare è dire: “mi arrendo”, “non ho idea di cosa fare!”. Questo ci rilassa: ci siamo già arresi, quindi non abbiamo niente da perdere, non dobbiamo più preoccuparci. Ma non dobbiamo fermarci qui. Le cose “migliori” che faccio (se ci sono) le faccio quando non ho voglia di lavorare. Alle volte, quando c’è qualcosa che non so fare e non ho idea di come affontare, mi dico: “oggi non ho proprio voglia di fare fatica”, non ho voglia di mettermi nello stato mentale per cui “in 10 minuti devo risolvere il problema perché dopo devo fare altre cose”. Però ho voglia di divertirmi con quel problema e allora mi dedico a qualche aspetto “marginale” del problema, che so come affrontare, oppure considero l’aspetto più difficile del problema, quello che non so come risolvere, ma invece di cercare di risolverlo, guardo come altre persone hanno affrontato problemi simili, opppure lo stesso problema in un altro contesto. Non mi pongo l’obiettivo “risolvi il problema in 10 minuti”, ma invece quello di farmi un’idea “generale” del problema, o quello di capire un caso più specifico e più semplice del problema. Senza nessuna pressione. Infatti, in quel momento ho deciso di non lavorare (ovvero, di non fare fatica). Va benissimo se “parto per la tangente”, ovvero se mi metto a leggere del materiale che sembra avere poco a che fare con il problema centrale (le nostre intuizioni e la nostra curiosità solitamente ci indirizzano sulla strada giusta). Quando faccio così, molto spesso trovo la soluzione del problema che mi ero posto e, paradossalmente, la trovo in un tempo minore di quello che, in precedenza, avevo dedicato a “lavorare” al problema. Allora perché non faccio sempre così? C’è ovviamente l’aspetto dei “10 minuti” che non è sempre facile da dimenticare. Sotto pressione, possiamo solo agire in maniera automatica, ovvero possiamo solo applicare qualcosa che già sappiamo fare. Ma se dobbiamo imparare qualcosa di nuovo, la pressione è un impedimento. È utile farsi da soli delle domande sugli argomenti trattati, senza limitarsi a cercare di risolvere gli esercizi che vengono assegnati. Quando studio qualcosa mi viene in mente: “se questo è vero, allora deve succedere quest’altra cosa”. Allora verifico se questo è vero, di solito con una simulazione. Se i risultati della simulazione sono quelli che mi aspetto, allora vuol dire che ho capito. Se i risultati sono diversi da quelli che mi aspettavo, allora mi rendo conto di non avere capito e ritorno indietro a studiare con più attenzione la teoria che pensavo di avere capito – e ovviamente mi rendo conto che c’era un aspetto che avevo frainteso. Questo tipo di verifica è qualcosa che dobbiamo fare da soli, in prima persona: nessun altro può fare questo al posto nostro. Non aspettatevi di capire tutto la prima volta che incontrate un argomento nuovo.1 È utile farsi una nota mentalmente delle lacune nella vostra comprensione e tornare su di esse in seguito per carcare di colmarle. L’atteggiamento naturale, quando non capiamo i dettagli di qualcosa, è quello di pensare: “non importa, ho capito in maniera approssimativa questo punto, non devo preoccuparmi del resto”. Ma in realtà non è vero: se la nostra comprensione è superficiale, quando il problema verrà presentato in una nuova forma, non riusciremo a risolverlo. Per cui i dubbi che ci vengono quando studiamo qualcosa sono il nostro alleato più prezioso: ci dicono esattamente quali sono gli aspetti che dobbiamo approfondire per potere migliorare la nostra preparazione. È utile sviluppare una visione d’insieme degli argomenti trattati, capire l’obiettivo generale che si vuole raggiungere e avere chiaro il contributo che i vari pezzi di informazione forniscono al raggiungimento di tale obiettivo. Questa organizzazione mentale del materiale di studio facilita la comprensione. È estremamente utile creare degli schemi di ciò che si sta studiando. Non aspettate che sia io a fornirvi un riepilogo di ciò che dovete imparare: sviluppate da soli tali schemi e tali riassunti. Tutti noi dobbiamo imparare l’arte di trovare le informazioni, non solo nel caso di questo insegnamento. Quando vi trovate di fronte a qualcosa che non capite, o ottenete un oscuro messaggio di errore da un software, ricordatevi: “Google is your friend”! Corrado Caudek Marzo 2022 References "],["ch-key-notions.html", "Capitolo 1 Concetti chiave 1.1 Popolazioni e campioni 1.2 Variabili e costanti 1.3 Parametri e modelli 1.4 Effetto 1.5 Stima e inferenza 1.6 Metodi e procedure della psicologia", " Capitolo 1 Concetti chiave La data science si pone all’intersezione tra statistica e informatica. La statistica è un insieme di metodi ugilizzati per estrarre informazioni dai dati; l’informatica implementa tali procedure in un software. In questo Capitolo vengono introdotti i concetti fondamentali. 1.1 Popolazioni e campioni Popolazione. L’analisi dei dati inizia con l’individuazione delle unità portatrici di informazioni circa il fenomeno di interesse. Si dice popolazione (o universo) l’insieme \\(\\Omega\\) delle entità capaci di fornire informazioni sul fenomeno oggetto dell’indagine statistica. Possiamo scrivere \\(\\Omega = \\{\\omega_i\\}_{i=1, \\dots, n}= \\{\\omega_1, \\omega_2, \\dots, \\omega_n\\}\\), oppure \\(\\Omega = \\{\\omega_1, \\omega_2, \\dots \\}\\) nel caso di popolazioni finite o infinite, rispettivamente. L’obiettivo principale della ricerca psicologica è conoscere gli esiti psicologici e i loro fattori trainanti nella popolazione. Questo è l’obiettivo delle sperimentazioni psicologiche e della maggior parte degli studi osservazionali in psicologia. È quindi necessario essere molto chiari sulla popolazione a cui si applicano i risultati della ricerca. La popolazione può essere ben definita, ad esempio, tutte le persone che si trovavano nella città di Hiroshima al momento del bombardamento atomico e sono sopravvissute per un anno, o può essere ipotetica, ad esempio, tutte le persone depresse che hanno subito o saranno sottoposte ad un intervento psicologico. Il ricercatore deve sempre essere in grado di determinare se un soggetto appartiene alla popolazione oggetto di interesse. Una sotto-popolazione è una popolazione che soddisfa proprietà ben definite. Ad esempio, potremmo essere interessati alla sotto-popolazione di uomini di età inferiore ai 20 anni o alla sotto-popolazione di pazienti depressi sottoposti ad uno specifico intervento psicologico. Molte domande scientifiche riguardano le differenze tra sotto-popolazioni; ad esempio, il confronto tra un gruppo sottoposto a psicoterapia e un gruppo di controllo per determinare se il trattamento è stato efficace. Campione. Gli elementi \\(\\omega_i\\) dell’insieme \\(\\Omega\\) sono detti unità statistiche. Un sottoinsieme della popolazione, ovvero un insieme di elementi \\(\\omega_i\\), viene chiamato campione. Ciascuna unità statistica \\(\\omega_i\\) (abbreviata con u.s.) è portatrice dell’informazione che verrà rilevata mediante un’operazione di misurazione. Un campione è dunque un sottoinsieme della popolazione utilizzato per conoscere tale popolazione. A differenza di una sotto-popolazione definita in base a chiari criteri, un campione viene generalmente selezionato tramite un procedura casuale. Il campionamento casuale consente allo scienziato di trarre conclusioni sulla popolazione e, soprattutto, di quantificare l’incertezza sui risultati. I campioni di un sondaggio sono esempi di campioni casuali, ma molti studi osservazionali non sono campionati casualmente. Possono essere campioni di convenienza, come coorti di studenti in un unico istituto, che consistono di tutti gli studenti sottoposti ad un certo intervento psicologico in quell’istituto. Indipendentemente da come vengono ottenuti i campioni, il loro uso al fine di conoscere una popolazione target significa che i problemi di rappresentatività sono inevitabili e devono essere affrontati. 1.2 Variabili e costanti Una variabile è qualsiasi proprietà o descrittore che può assumere più valori (numerici o categoriali). Una variabile può essere pensata come una domanda a cui il valore è la risposta. Ad esempio, “Quanti anni ha questo partecipante?” “38 anni”. Qui, “età” è la variabile e “38” è il suo valore. La probabilità che la variabile \\(X\\) assuma valore \\(x\\) si scrive \\(P(X = x)\\). Questo è spesso abbreviato in \\(P(x)\\). Possiamo anche esaminare la probabilità di più valori contemporaneamente; per esempio, la probabilità che \\(X = x\\) e \\(Y = y\\) è scritta \\(P(X = x, Y = y)\\) o \\(P(x, y)\\). Si noti che \\(P(X = 38)\\) è interpretato come la probabilità che un individuo selezionato casualmente dalla popolazione abbia 38 anni. Il termine “variabile” si contrappone al termine “costante” che descrive una proprietà invariante di tutte le unità statistiche. Si dice modalità ciascuna delle varianti con cui una variabile statistica può presentarsi. Definiamo insieme delle modalità di una variabile statistica l’insieme \\(M\\) di tutte le possibili espressioni con cui la variabile può manifestarsi. Le modalità osservate e facenti parte del campione si chiamano dati (si veda la Tabella 1.1). Esempio 1.1 Supponiamo che il fenomeno studiato sia l’intelligenza. In uno studio, la popolazione potrebbe corrispondere all’insieme di tutti gli italiani adulti. La variabile considerata potrebbe essere il punteggio del test standardizzato WAIS-IV. Le modalità di tale variabile potrebbero essere \\(112, 92, 121, \\dots\\). Tale variabile è di tipo quantitativo discreto. Esempio 1.2 Supponiamo che il fenomeno studiato sia il compito Stroop. La popolazione potrebbe corrispondere all’insieme dei bambini dai 6 agli 8 anni. La variabile considerata potrebbe essere il reciproco dei tempi di reazione in secondi. Le modalità di tale variabile potrebbero essere \\(1.93, 2.35, 1.32, 1.49, 1.62, 2.93, \\dots\\). La variabile è di tipo quantitativo continuo. Esempio 1.3 Supponiamo che il fenomeno studiato sia il disturbo di personalità. La popolazione potrebbe corrispondere all’insieme dei detenuti nelle carceri italiane. La variabile considerata potrebbe essere l’assessment del disturbo di personalità tramite interviste cliniche strutturate. Le modalità di tale variabile potrebbero essere i Cluster A, Cluster B, Cluster C descritti dal DSM-V. Tale variabile è di tipo qualitativo. 1.2.1 Variabili casuali Il termine variabile usato nella statistica è equivalente al termine variabile casuale usato nella teoria delle probabilità. Lo studio dei risultati degli interventi psicologici è lo studio delle variabili casuali che misurano questi risultati. Una variabile casuale cattura una caratteristica specifica degli individui nella popolazione e i suoi valori variano tipicamente tra gli individui. Ogni variabile casuale può assumere in teoria una gamma di valori sebbene, in pratica, osserviamo un valore specifico per ogni individuo. Quando faremo riferiremo alle variabili casuali considerate in termini generali useremo lettere maiuscole come \\(X\\) e \\(Y\\); quando faremo riferimento ai valori che una variabile casuale assume in determinate circostanze useremo lettere minuscole come \\(x\\) e \\(y\\). 1.2.2 Variabili indipendenti e variabili dipendenti Un primo compito fondamentale in qualsiasi analisi dei dati è l’identificazione delle variabili dipendenti (\\(Y\\)) e delle variabili indipendenti (\\(X\\)). Le variabili dipendenti sono anche chiamate variabili di esito o di risposta e le variabili indipendenti sono anche chiamate predittori o covariate. Ad esempio, nell’analisi di regressione, che esamineremo in seguito, la domanda centrale è quella di capire come \\(Y\\) cambia al variare di \\(X\\). Più precisamente, la domanda che viene posta è: se il valore della variabile indipendente \\(X\\) cambia, qual è la conseguenza per la variabile dipendente \\(Y\\)? In parole povere, le variabili indipendenti e dipendenti sono analoghe a “cause” ed “effetti”, laddove le virgolette usate qui sottolineano che questa è solo un’analogia e che la determinazione delle cause può avvenire soltanto mediante l’utilizzo di un appropriato disegno sperimentale e di un’adeguata analisi statistica. Se una variabile è una variabile indipendente o dipendente dipende dalla domanda di ricerca. A volte può essere difficile decidere quale variabile è dipendente e quale è indipendente, in particolare quando siamo specificamente interessati ai rapporti di causa/effetto. Ad esempio, supponiamo di indagare l’associazione tra esercizio fisico e insonnia. Vi sono evidenze che l’esercizio fisico (fatto al momento giusto della giornata) può ridurre l’insonnia. Ma l’insonnia può anche ridurre la capacità di una persona di fare esercizio fisico. In questo caso, dunque, non è facile capire quale sia la causa e quale l’effetto, quale sia la variabile dipendente e quale la variabile indipendente. La possibilità di identificare il ruolo delle variabili (dipendente/indipendente) dipende dalla nostra comprensione del fenomeno in esame. Esempio 1.4 Uno psicologo convoca 120 studenti universitari per un test di memoria. Prima di iniziare l’esperimento, a metà dei soggetti viene detto che si tratta di un compito particolarmente difficile; agli altri soggetti non viene data alcuna indicazione. Lo psicologo misura il punteggio nella prova di memoria di ciascun soggetto. In questo esperimento, la variabile indipendente è l’informazione sulla difficoltà della prova. La variabile indipendente viene manipolata dallo sperimentatore assegnando i soggetti (di solito in maniera causale) o alla condizione (modalità) “informazione assegnata” o “informazione non data”. La variabile dipendente è ciò che viene misurato nell’esperimento, ovvero il punteggio nella prova di memoria di ciascun soggetto. 1.2.3 La matrice dei dati Le realizzazioni delle variabili esaminate in una rilevazione statistica vengono organizzate in una matrice dei dati. Le colonne della matrice dei dati contengono gli insiemi dei dati individuali di ciascuna variabile statistica considerata. Ogni riga della matrice contiene tutte le informazioni relative alla stessa unità statistica. Una generica matrice dei dati ha l’aspetto seguente: \\[ D_{m,n} = \\begin{pmatrix} \\omega_1 &amp; a_{1} &amp; b_{1} &amp; \\cdots &amp; x_{1} &amp; y_{1}\\\\ \\omega_2 &amp; a_{2} &amp; b_{2} &amp; \\cdots &amp; x_{2} &amp; y_{2}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ \\omega_n &amp; a_{n} &amp; b_{n} &amp; \\cdots &amp; x_{n} &amp; y_{n} \\end{pmatrix} \\] dove, nel caso presente, la prima colonna contiene il nome delle unità statistiche, la seconda e la terza colonna si riferiscono a due mutabili statistiche (variabili categoriali; \\(A\\) e \\(B\\)) e ne presentano le modalità osservate nel campione mentre le ultime due colonne si riferiscono a due variabili statistiche (\\(X\\) e \\(Y\\)) e ne presentano le modalità osservate nel campione. Generalmente, tra le unità statistiche \\(\\omega_i\\) non esiste un ordine progressivo; l’indice attribuito alle unità statistiche nella matrice dei dati si riferisce semplicemente alla riga che esse occupano. 1.3 Parametri e modelli Ogni variabile casuale ha una distribuzione che descrive la probabilità che la variabile assuma qualsiasi valore in un dato intervallo.2 Senza ulteriori specificazioni, una distribuzione può fare riferimento a un’intera famiglia di distribuzioni. I parametri, tipicamente indicati con lettere greche come \\(\\mu\\) e \\(\\alpha\\), ci permettono di specificare di quale membro della famiglia stiamo parlando. Quindi, si può parlare di una variabile casuale con una distribuzione Normale, ma se viene specificata la media \\(\\mu\\) = 100 e la varianza \\(\\sigma^2\\) = 15, viene individuata una specifica distribuzione Normale – nell’esempio, la distribuzione del quoziente di intelligenza. I metodi statistici parametrici specificano la famiglia delle distribuzioni e quindi utilizzano i dati per individuare, stimando i parametri, una specifica distribuzione all’interno della famiglia di distribuzioni ipotizzata. Se \\(f\\) è la PDF di una variabile casuale \\(Y\\), l’interesse può concentrarsi sulla sua media e varianza. Nell’analisi di regressione, ad esempio, cerchiamo di spiegare come i parametri di \\(f\\) dipendano dalle covariate \\(X\\). Nella regressione lineare classica, assumiamo che \\(Y\\) abbia una distribuzione normale con media \\(\\mu = \\mathbb{E}(Y)\\), e stimiamo come \\(\\mathbb{E}(Y)\\) dipenda da \\(X\\). Poiché molti esiti psicologici non seguono una distribuzione normale, verranno introdotte distribuzioni più appropriate per questi risultati. I metodi non parametrici, invece, non specificano una famiglia di distribuzioni per \\(f\\). In queste dispense faremo riferimento a metodi non parametrici quando discuteremo della statistica descrittiva. Il termine modello è onnipresente in statistica e nella data science. Il modello statistico include le ipotesi e le specifiche matematiche relative alla distribuzione della variabile casuale di interesse. Il modello dipende dai dati e dalla domanda di ricerca, ma raramente è unico; nella maggior parte dei casi, esiste più di un modello che potrebbe ragionevolmente usato per affrontare la stessa domanda di ricerca e avendo a disposizione i dati osservati. Nella previsione delle aspettative future dei pazienti depressi che discuteremo in seguito (Zetsche, Bürkner, and Renneberg 2019), ad esempio, la specifica del modello include l’insieme delle covariate candidate, l’espressione matematica che collega i predittori con le aspettative future e qualsiasi ipotesi sulla distribuzione della variabile dipendente. La domanda di cosa costituisca un buon modello è una domanda su cui torneremo ripetutamente in questo insegnamento. 1.4 Effetto L’effetto è una qualche misura dei dati. Dipende dal tipo di dati e dal tipo di test statistico che si vuole utilizzare. Ad esempio, se viene lanciata una moneta 100 volte e esce testa 66 volte, l’effetto sarà 66/100. Diventa poi possibile confrontare l’effetto ottenuto con l’effetto nullo che ci si aspetterebbe da una moneta bilanciata (50/100), o con qualsiasi altro effetto che può essere scelto. La dimensione dell’effetto si riferisce alla differenza tra l’effetto misurato nei dati e l’effetto nullo (di solito un valore che ci si aspetta di ottenere in base al caso soltanto). 1.5 Stima e inferenza La stima è il processo mediante il quale il campione viene utilizzato per conoscere le proprietà di interesse della popolazione. La media campionaria è una stima naturale della media della popolazione e la mediana campionaria è una stima naturale della mediana della popolazione. Quando parliamo di stimare una proprietà della popolazione (a volte indicata come parametro della popolazione) o di stimare la distribuzione di una variabile casuale, stiamo parlando dell’utilizzo dei dati osservati per conoscere le proprietà di interesse della popolazione. L’inferenza statistica è il processo mediante il quale le stime campionarie vengono utilizzate per rispondere a domande di ricerca e per valutare specifiche ipotesi relative alla popolazione. Discuteremo le procedure bayesiane dell’inferenza nell’ultima parte di queste dispense. 1.6 Metodi e procedure della psicologia Un modello psicologico di un qualche aspetto del comportamento umano o della mente ha le seguenti proprietà: descrive le caratteristiche del comportamento in questione, formula predizioni sulle caratteristiche future del comportamento, è sostenuto da evidenze empiriche, deve essere falsificabile (ovvero, in linea di principio, deve potere fare delle predizioni su aspetti del fenomeno considerato che non sono ancora noti e che, se venissero indagati, potrebbero portare a rigettare il modello, se si dimostrassero incompatibili con esso). L’analisi dei dati valuta un modello psicologico utilizzando strumenti statistici. Questa dispensa è strutturata in maniera tale da rispecchiare la suddivisione tra i temi della misurazione, dell’analisi descrittiva e dell’inferenza. Nel prossimo Capitolo sarà affrontato il tema della misurazione e, nell’ultima parte della dispensa verrà discusso l’argomento più difficile, quello dell’inferenza. Prima di affrontare il secondo tema, l’analisi descrittiva dei dati, sarà necessario introdurre il linguaggio di programmazione statistica R (un’introduzione a R è fornita in Appendice). Inoltre, prima di potere discutere l’inferenza, dovranno essere introdotti i concetti di base della teoria delle probabilità, in quanto l’inferenza non è che l’applicazione della teoria delle probabilità all’analisi dei dati. References "],["chapter-misurazione.html", "Capitolo 2 La misurazione in psicologia 2.1 Le scale di misura 2.2 Gerarchia dei livelli di scala di misura 2.3 Variabili discrete o continue 2.4 Alcune misure sono migliori di altre Commenti e considerazioni finali", " Capitolo 2 La misurazione in psicologia Introduco il problema della misurazione in psicologia parlando dell’intelligenza. In quanto psicologi, siamo abituati a pensare alla misurazione dell’intelligenza, ma anche le persone che non sono psicologi sono ben familiari con la misurazione dell’intelligenza: tra le misurazioni delle caratteristiche psicologiche, infatti, la misurazione dell’intelligenza è forse la più conosciuta. I test di intelligenza consistono in una serie di problemi di carattere verbale, numerico o simbolico. Come ci si può aspettare, alcune persone riescono a risolvere correttamente un numero maggiore di problemi di altre. Possiamo contare il numero di risposte corrette e osservare le differenze individuali nei punteggi calcolati. Scopriamo in questo modo che le differenze individuali nell’abilità di risolvere tali problemi risultano sorprendentemente stabili nell’età adulta. Inoltre, diversi test di intelligenza tendono ad essere correlati positivamente: le persone che risolvono un maggior numero di problemi verbali, in media, tenderanno anche a risolvere correttamente un numero più grande di numerici e simbolici. Esiste quindi una notevole coerenza delle differenze osservate tra le persone, sia nel tempo sia considerando diverse procedure di test e valutazione. Avendo stabilito che ci sono differenze individuali tra le persone, è possibile esaminare le associazioni tra i punteggi dei test di intelligenza e altre variabili. Possiamo indagare se le persone con punteggi più alti nei test di intelligenza, rispetto a persone che ottengono punteggi più bassi, hanno più successo sul lavoro; se guadagnano di più; se votano in modo diverso; o se hanno un’aspettativa di vita più alta. Possiamo esaminare le differenze nei punteggi dei test di intelligenza in funzione di variabili come il genere, il gruppo etnico-razziale o lo stato socio-economico. Possiamo fare ricerche sull’associazione tra i punteggi dei test di intelligenza e l’efficienza dell’elaborazione neuronale, i tempi di reazione o la quantità di materia grigia all’interno della scatola cranica. Tutte queste ricerche sono state condotte e gli psicologi hanno scoperto una vasta gamma di associazioni tra le misure dell’intelligenza e altre variabili. Alcune di queste associazioni sono grandi e stabili, altre sono piccole e difficili da replicare. In riferimento all’intelligenza, dunque, gli psicologi hanno condotto un enorme numero di ricerche ponendosi domande diverse. In quali condizioni si verificano determinati effetti? Quali variabili mediano o moderano le relazioni tra i punteggi dei test di intelligenza e altre variabili? Queste relazioni si mantengono stabili in diversi gruppi di persone? Le ricerche sull’intelligenza umana sono un campo in continuo sviluppo. Tuttavia, tuttavia una domanda sorge spontanea: i test di intelligenza misurano davvero qualcosa e, in caso affermativo, che cos’è questo qualcosa? Infatti, dopo un secolo di teoria e ricerca sui punteggi dei test di intelligenza e, in generale, sui test psicologici, non sappiamo ancora con precisione cosa effettivamente questi test misurano. Queste considerazioni relative ai test di intelligenza ci conducono dunque alla domanda che ha motivato le precedenti considerazioni: cosa significa misurare un attributo psicologico? Questa è una domanda a cui è difficile rispondere, una domanda a cui è dedicata un’intera area di ricerca, quella della teoria della misurazione psicologica. Non possiamo qui entrare nel merito delle complessità formali della teoria della misurazione psicologica – questo argomento verrà approfondito nei successivi insegnamenti sulla testistica psicologica. Ci limiteremo invece a presentare alcune nozioni di base su un tema centrale della teoria della misurazione psicologica: il tema delle scale delle misure psicologiche. 2.1 Le scale di misura In generale possiamo dire che la teoria della misurazione si occupa dello studio delle relazioni esistenti tra due domini: il “mondo fisico” e il “mondo psicologico”. Secondo la teoria della misurazione, la misurazione è un’attività rappresentativa, cioè è un processo di assegnazione di numeri in modo tale da preservare, all’interno del dominio numerico, le relazioni qualitative che sono state osservate nel mondo empirico. La teoria della misurazione ha lo scopo di specificare le condizioni necessarie per la costruzione di una rappresentazione adeguata delle relazioni empiriche all’interno di un sistema numerico. Da una prospettiva formale, le operazioni descritte dalla teoria della misurazione possono essere concettualizzate in termini di mappatura tra le relazioni esistenti all’interno di due insiemi (quello empirico e quello numerico). Il risultato di questa attività è chiamato “scala di misurazione”. Una famosa teoria delle scale di misura è stata proposta da Stevens (1946). Stevens ci fa notare che, in linea di principio, le variabili psicologiche sono in grado di rappresentare (preservare) con diversi gradi di accuratezza le relazioni qualitative che sono state osservate nei fenomeni psicologici. Secondo la teoria di Stevens, possiamo distinguere tra quattro scale di misura: le scale nominali (nominal scales), ordinali (ordinal scales), a intervalli (interval scales), di rapporti (ratio scales). Tali scale di misura consentono operazioni aritmetiche diverse, come indicato nella tabella successiva, in quanto ciasuna di esse è in grado di “catturare” soltanto alcune delle proprietà dei fenomeni psicologici che intende misurare. 2.1.1 Scala nominale Il livello di misurazione più semplice è quello della scala nominale. Questa scala di misurazione corrisponde ad una tassonomia. I simoboli o numeri che costituiscono questa scala non sono altro che i nomi delle categorie che utilizziamo per classificare i fenomeni psicologici. In base alle misure fornite da una scala nominale, l’unica cosa che siamo in grado di dire a proposito di una caratteristica psicologica è se essa è uguale o no ad un’altra caratteristica psicologica. La scala nominale raggruppa dunque i dati in categorie qualitative mutuamente esclusive (cioè nessun dato si può collocare in più di una categoria). Esiste la sola relazione di equivalenza tra le misure delle u.s., cioè nella scala nominale gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti: \\(x_i = x_j\\) oppure \\(x_i \\neq x_j\\). L’unica operazione algebrica che possiamo compiere sulle modalità della scala nominale è quella di contare le u.s. che appartengono ad ogni modalità e contare il numero delle modalità (classi di equivalenza). Dunque la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative. A partire da una scala nominale è possibile costruire altre scale nominali che sono equivalenti alla prima trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle modalità, ma lasciando però inalterata la suddivisione u.s. nelle medesime classi di equivalenza. Questo significa che prendendo una variabile misurata su scala nominale e cambiando i nomi delle sue categorie otteniamo una nuova variabile esattamente corrispondente alla prima. 2.1.2 Scala ordinale La scala ordinale conserva la proprietà della scala nominale di classificare ciascuna u.s. all’interno di una e una sola categoria, ma alla relazione di equivalenza tra elementi di una stessa classe aggiunge la relazione di ordinamento tra le classi di equivalenza. Essendo basata su una relazione d’ordine, una scala ordinale descrive soltanto l’ordine di rango tra le modalità, ma non ci dà alcuna informazione su quanto una modalità sia più grande di un’altra. Non ci dice, per esempio, se la distanza tra le modalità \\(a\\) e \\(b\\) sia uguale, maggiore o minore della distanza tra le modalità \\(b\\) e \\(c\\). Esempio 2.1 Un esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore. 2.1.3 Scala ad intervalli La scala ad intervalli include le proprietà di quella nominale e di quella ordinale, e in più consente di misurare le distanze tra le coppie di u.s. nei termini di un intervallo costante, chiamato unità di misura, a cui viene attribuito il valore “1”. La posizione dell’origine della scala, cioè il punto zero, è scelta arbitrariamente, nel senso che non indica l’assenza della quantità che si sta misurando. Avendo uno zero arbitrario, questa scala di misura consente valori negativi. Lo zero, infatti, non viene attribuito all’u.s. in cui la proprietà misurata risulta assente. La scala a intervalli equivalenti ci consente di effettuare operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non era possibile eseguire nel caso di misure a livello di scala ordinale o nominale. Il limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Possiamo dire, per esempio, che la distanza tra \\(a\\) e \\(b\\) è la metà della distanza tra \\(c\\) e \\(d\\). Oppure che la distanza tra \\(a\\) e \\(b\\) è uguale alla distanza tra \\(c\\) e \\(d\\). Non possiamo dire, però, che \\(a\\) possiede la proprietà misurata in quantità doppia rispetto \\(b\\). Non possiamo cioè stabilire dei rapporti diretti tra le misure ottenute. Solo per le differenze tra le modalità sono dunque permesse tutte le operazioni aritmetiche: le differenze possono essere tra loro sommate, elevate a potenza oppure divise, determinando così le quantità che stanno alla base della statistica inferenziale. Nelle scale ad intervalli equivalenti, l’unità di misura è arbitraria, ovvero può essere cambiata attraverso una dilatazione, operazione che consiste nel moltiplicare tutti i valori della scala per una costante positiva. Poiché l’aggiunta di una costante non altera le differenze tra i valori della scala, è anche ammessa la traslazione, operazione che consiste nel sommare una costante a tutti i valori della scala. Essendo la scala invariate rispetto alla traslazione e alla dilatazione, le trasformazioni ammissibili sono le trasformazioni lineari: \\[ y&#39; = a + by, \\quad b &gt; 0. \\] L’aspetto che rimane invariante a seguito di una trasformazione lineare è l’uguaglianza dei rapporti fra intervalli. Esempio 2.2 Esempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c’è una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili. Il limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non è il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit. Consideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\). È facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta: \\[ \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} = \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2. \\] 2.1.4 Scala di rapporti Nella scala a rapporti equivalenti la posizione dello zero non è arbitraria, ma corrisponde all’elemento dotato di intensità nulla rispetto alla proprietà misurata. Una scala a rapporti equivalenti si costruisce associando il numero 0 all’elemento con intensità nulla; viene poi scelta un’unità di misura \\(u\\) e, ad ogni elemento, si assegna un numero \\(a\\) definito come: \\[a = \\frac{d}{u}\\] dove \\(d\\) rappresenta la distanza dall’origine. Alle u.s. vengono dunque assegnati dei numeri tali per cui le differenze e i rapporti tra i numeri riflettono le differenze e i rapporti tra le intensità della proprietà misurata. Operazioni aritmetiche sono possibili non solo sulle differenze tra i valori della scala (come per la scala a intervalli equivalenti), ma anche sui valori stessi della scala. L’unica arbitrarietà riguarda l’unità di misura che si utilizza. L’unità di misura può cambiare, ma qualsiasi unità di misura si scelga, lo zero deve sempre indicare l’intensità nulla della proprietà considerata. Le trasformazioni ammissibili a questo livello di scala sono dette trasformazioni di similarità: \\[y&#39; = by, \\quad b &gt; 0.\\] A questo livello di scala, a seguito delle trasformazioni ammissibili, rimangono invariati anche i rapporti: \\[\\frac{y_i}{y_j} = \\frac{y&#39;_i}{y&#39;_j}.\\] 2.2 Gerarchia dei livelli di scala di misura Stevens (1946) parla di livelli di scala poiché i quattro tipi di scala di misura stanno in una precisa gerarchia: la scala nominale rappresenta il livello più basso della misurazione, la scala a rapporti equivalenti è invece il livello più alto. Scale di modalità Operazioni aritmetiche nominali enumerare le classi di equivalenza e/o le frequenze per ciascuna classe di equivalenza ordinali enumerare le classi di equivalenza e/o le frequenze per ciascuna classe di equivalenza intervallari differenze (rapporti tra differenze) di rapporti rapporti diretti tra le misure Passando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente. Per ciò che riguarda le trasformazioni ammissibili, più il livello di scala è basso, più le funzioni sono generali (sono minori cioè i vincoli per passare da una rappresentazione numerica ad un’altra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa più restrittiva. 2.3 Variabili discrete o continue Le variabili a livello di intervalli e di rapporti possono essere discrete o continue. Le variabili discrete possono assumere alcuni valori ma non altri. Una volta che l’elenco di valori accettabili è stato specificato, non ci sono casi che cadono tra questi valori. Le variabili discrete di solito assumono valori interi. Quando una variabile può assumere qualsiasi valore entro un intervallo specificato, allora si dice che la variabile è continua. In teoria, ciò significa che frazioni e decimali possono essere utilizzati per raggiungere un livello di precisione qualsiasi. In pratica, a un certo punto dobbiamo arrotondare i numeri, rendendo tecnicamente la variabile discreta. In variabili veramente discrete, tuttavia, non è possibile aumentare a piacimento il livello di precisione della misurazione. Esempio 2.3 Il numero di biciclette possedute da una persona è una variabile discreta poiché tale variabile può assumere come modalità solo i numeri interi non negativi. Frazioni di bicicletta non hanno senso. 2.4 Alcune misure sono migliori di altre In psicologia, ciò che vogliamo misurare non è una caratteristica fisica, ma invece è un concetto teorico inosservabile, ovvero un costrutto. Un costrutto rappresenta il risultato di una fondata riflessione scientifica, non è per definizione accessibile all’osservazione diretta, ma viene inferito dall’osservazione di opportuni indicatori (Sartori, 2005). Ad esempio, supponiamo che un docente voglia valutare quanto bene uno studente comprenda la distinzione tra le quattro diverse scale di misura che sono state descritte sopra. Il docente potrebbe predisporre un test costituito da un insieme di domande e potrebbe contare a quante domande lo studente risponde correttamente. Questo test, però, può o può non essere una buona misura del costrutto relativo alla conoscenza effettiva delle quattro scale di misura. Per esempio, se il docente scrive le domande del test in modo ambiguo o se usa una linguaggio troppo tecnico che lo studente non conosce, allora i risultati del test potrebbero suggerire che lo studente non conosce la materia in questione anche se in realtà questo non è vero. D’altra parte, se il docente prepara un test a scelta multipla con risposte errate molto ovvie, allora lo studente può ottenere dei buoni risultati al test anche senza essere in grado di comprendere adeguatamente le proprietà delle quattro scale di misura. In generale non è possibile misurare un costrutto senza una certa quantità di errore. Poniamoci dunque il problema di determinare in che modo una misurazione possa dirsi adeguata. 2.4.1 Tipologie di errori L’errore è, per definizione, la differenza tra il valore vero e il valore misurato della grandezza in esame. Gli errori sono classificati come sistematici (o determinati) e casuali (o indeterminati). Gli errori casuali sono fluttuazioni, in eccesso o in difetto rispetto al valore reale, delle singole determinazioni e sono dovuti alle molte variabili incontrollabili che influenzano ogni misura psicologica. Gli errori sistematici, invece, influiscono sulla misurazione sempre nello stesso senso e, solitamente, per una stessa quantità (possono essere additivi o proporzionali). Le differenze tra le due tipologie di errori, sistematici e casuali, introducono i concetti di accuratezza e di precisione della misura. Una misura viene definita: accurata, quando vi è un accordo tra la misura effettuata ed il valore reale; precisa quando, ripetendo più volte la misura, i risultati ottenuti sono concordanti, cioè differiscono in maniera irrilevante tra loro. La metafora del tiro a bersaglio illustra la relazione tra precisione e accuratezza. FIGURA 2.1: Metafora del tiro al bersaglio. Per tenere sotto controllo l’incidenza degli errori, sono stati introdotti in psicologia i concetti di attendibilità e validità. Uno strumento si dice attendibile quando valuta in modo coerente e stabile la stessa variabile: i risultati ottenuti si mantengono costanti dopo ripetute somministrazione ed in assenza di variazioni psicologiche e fisiche dei soggetti sottoposti al test o cambiamenti dell’ambiente in cui ha luogo la somministrazione. L’attendibilità di uno strumento, però, non è sufficiente: in primo luogo uno strumento di misura deve essere valido, laddove la validità rappresenta il grado in cui uno strumento misura effettivamente ciò che dovrebbe misurare. In genere, si fa riferimento ad almeno quattro tipi di validità. La validità di costrutto riguarda il grado in cui un test misura ciò per cui è stato costruito. Essa si suddivide in: validità convergente e validità divergente. La validità convergente fa riferimento alla concordanza tra uno strumento e un altro che misura lo stesso costrutto. La validità divergente, al contrario, valuta il grado di discriminazione tra strumenti che misurano costrutti differenti. Senza validità di costrutto le altre forme di validità non hanno senso. In base alla validità di contenuto, un test fornisce una misura valida di un attributo psicologico se il dominio dell’attributo è rappresentato in maniera adeguata dagli item del test. Un requisito di base della validità di contenuto è la rilevanza e la rappresentatività del contenuto degli item in riferimento all’attributo che il test intende misurare. La validità di criterio valuta il grado di concordanza tra i risultati dello strumento considerato e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto, o tra i risultati dello strumento considerato e un criterio esterno. Nella validità concorrente, costrutto e criterio vengono misurati contestualmente, consentendo un confronto immediato. Nella validità predittiva, il costrutto viene misurato prima e il criterio in un momento successivo, consentendo la valutazione della capacità dello strumento di predire un evento futuro. Infine, la validità di facciata fa riferimento al grado in cui il test appare valido ai soggetti a cui esso è diretto. La validità di facciata è importante in ambiti particolari, quali ad esempio la selezione del personale per una determinata occupazione. In questo caso è ovviamente importante che chi si sottopone al test ritenga che il test vada a misurare quegli aspetti che sono importanti per le mansioni lavorative che dovranno essere svolte, piuttosto che altre cose. In generale, la validità di facciata non è utile, tranne in casi particolari. Commenti e considerazioni finali Una domanda che uno psicologo spesso si pone è: “sulla base delle evidenze osservate, possiamo concludere dicendo che l’intervento psicologico è efficace nel trattamento e nella cura del disturbo?” Le considerazioni svolte in questo capitolo dovrebbero farci capire che, prima di cercare di rispondere a questa domanda con l’analisi statistica dei dati, devono essere affrontati i problemi della validità e dell’attendibilità delle misure (oltre a stabilire l’appropriato livello di scala di misura delle osservazioni). L’attendibilità è un prerequisito della validità. Se gli errori di misurazione sono troppo grandi, i dati sono inutili. Inoltre, uno strumento di misurazione può essere preciso ma non valido. La validità e l’attendibilità delle misurazioni sono dunque entrambe necessarie. In generale, l’attendibilità e la validità delle misure devono essere valutate per capire se i dati raccolti da un ricercatore siano adeguati (1) per fornire una risposta alla domanda della ricerca, e (2) per giungere alla conclusione proposta dal ricercatore alla luce dei risultati dell’analisi statistica che è stata eseguita. È chiaro che le informazioni fornite in questo capitolo si limitano a scalfire la superficie di questi problemi. I concetti qui introdotti, però, devono sempre essere tenuti a mente e costituiscono il fondamento di quanto verrà esposto nei capitoli successivi. References "],["ch-eda.html", "Capitolo 3 Variabili e distribuzioni di frequenza 3.1 Introduzione all’esplorazione dei dati 3.2 Un excursus storico 3.3 Riassumere i dati 3.4 I dati grezzi 3.5 Distribuzioni di frequenze 3.6 Istogramma 3.7 Kernel density plot 3.8 Forma di una distribuzione 3.9 Indici di posizione Commenti e considerazioni finali", " Capitolo 3 Variabili e distribuzioni di frequenza Le analisi esplorative dei dati e la statistica descrittiva costituiscono la prima fase dell’analisi dei dati psicologici. Consentono di capire come i dati sono distribuiti, ci aiutano ad individuare le osservazioni anomale e gli errori di tabulazione. Consentono di riassumere le distribuzioni dei dati mediante indici sintetici. Consentono di visualizzare e di studiare le relazioni tra le variabili. In questo Capitolo, dopo avere presentato gli obiettivi dell’analisi esplorative dei dati, discuteremo il problema della descrizione numerica e della rappresentazione grafica delle distribuzioni di frequenza. 3.1 Introduzione all’esplorazione dei dati Le analisi esplorative dei dati sono indispensabili per condurre in modo corretto una qualsiasi analisi statistica, dal livello base a quello avanzato. Si parla di analisi descrittiva se l’obiettivo è quello di descrivere le caratteristiche di un campione. Si parla di analisi esplorativa dei dati (Exploratory Data Analysis o EDA) se l’obiettivo è quello di esplorare i dati alla ricerca di nuove informazioni e relazioni tra variabili. Questa distinzione, seppur importante a livello teorico, nella pratica è più fumosa perché spesso entrambe le situazioni si verificano contemporaneamente nella stessa indagine statistica e le metodologie di analisi che si utilizzano sono molto simili. Né il calcolo delle statistiche descrittive né l’analisi esplorativa dei dati possono essere condotte senza utilizzare un software. Le descrizioni dei concetti di base della EDA saranno dunque fornite di pari passo alla spiegazione di come le quantità discusse possono essere calcolate in pratica utilizzando \\(\\mathsf{R}\\). 3.2 Un excursus storico Nel 1907 Francis Galton, cugino di Charles Darwin, matematico e statistico autodidatta, geografo, esploratore, teorico della dattiloscopia (ovvero, dell’uso delle impronte digitali a fini identificativi) e dell’eugenetica, scrisse una lettera alla rivista scientifica Nature sulla sua visita alla Fat Stock and Poultry Exhibition di Plymouth. Lì vide alcuni membri del pubblico partecipare ad un gioco il cui scopo era quello di indovinare il peso della carcassa di un grande bue che era appena stato scuoiato. Galton si procurò i 787 dei biglietti che erano stati compilati dal pubblico e considerò il valore medio di 547 kg come la “scelta democratica” dei partecipanti, in quanto “ogni altra stima era stata giudicata troppo alta o troppo bassa dalla maggioranza dei votanti”. Il punto interessante è che il peso corretto di 543 kg si dimostrò essere molto simile alla “scelta democratica” basata sulle stime dei 787 partecipanti. Galton intitolò la sua lettera a Nature Vox Populi (voce del popolo), ma questo processo decisionale è ora meglio conosciuto come la “saggezza delle folle” (wisdom of crowds). Possiamo dire che, nel suo articolo del 1907, Galton effettuò quello che ora chiamiamo un riepilogo dei dati, ovvero calcolò un indice sintetico a partire da un insieme di dati. In questo capitolo esamineremo le tecniche che sono state sviluppate nel secolo successivo per riassumere le grandi masse di dati con cui sempre più spesso ci dobbiamo confrontare. Vedremo come calcolare e interpretare gli indici di posizione e di dispersione, discuteremo le distribuzioni di frequenze e le relazioni tra variabili. Vedremo inoltre quali sono le tecniche di visualizzazione che ci consentono di rappresentare questi sommari dei dati mediante dei grafici. Ma prima di entrare nei dettagli, prendiamoci un momento per capire perché abbiamo bisogno della statistica e, per ciò che stiamo discutendo qui, della statistica descrittiva. In generale, che cos’è la statistica? Ci sono molte definizioni. Fondamentalmente, la statistica è un insieme di tecniche che ci consentono di dare un senso al mondo attraverso i dati. Ciò avviene tramite il processo di analisi statistica. L’analisi statistica traduce le domande che abbiamo a proposito del mondo in modelli matematici, utilizza i dati per scegliere i modelli matematici che sono apppropriati per descrivere il mondo e, infine, applica tali modelli per trovare una risposta alle domande che ci siamo posti. La statistica consente quindi di collegare le nostre domande a proposito del mondo ai dati, di utilizzare i dati per trovare le risposte alle domande che ci siamo posti e di valutare l’impatto delle risposte che abbiamo trovato. 3.3 Riassumere i dati Iniziamo a porci una domanda. Quando riassumiamo i dati, necessariamente buttiamo via delle informazioni; ma è una buona idea procedere in questo modo? Non sarebbe meglio conservare le informazioni specifiche di ciascun soggetto che partecipa ad un esperimento psicologico, al di là di ciò che viene trasmesso dagli indici riassuntivi della statistica descrittiva? Che dire delle informazioni che descrivono come sono stati raccolti i dati, come l’ora del giorno o l’umore del partecipante? Tutte queste informazioni vengono perdute quando riassumiamo i dati. La risposta alla domanda che ci siamo posti è che, in generale, non è una buona idea conservare tutti i dettagli di ciò che sappiamo. È molto più utile riassumere le informazioni perché la semplificazione risultante consente i processi di generalizzazione. In un contesto letterario, l’importanza della generalizzazione è stata sottolineata da Jorge Luis Borges nel suo racconto “Funes o della memoria”, che descrive un individuo che perde la capacità di dimenticare. Borges si concentra sulla relazione tra generalizzazione e pensiero: “Pensare è dimenticare una differenza, generalizzare, astrarre. Nel mondo troppo pieno di Funes, c’erano solo dettagli.” Come possiamo ben capire, la vita di Funes non è facile. Se facciamo riferimento alla psicologia possiamo dire che gli psicologi hanno studiato a lungo l’utilità della generalizzazione per il pensiero. Un esempio è fornito dal fenomeno della formazione dei concetti e lo psicologo che viene in mente a questo proposito è sicuramente Eleanor Rosch, la quale ha studiato i principi di base della categorizzazione. I concetti ci forniscono uno strumento potente per organizzare le conoscenze. Noi siamo in grado di riconoscere facilmente i diversi esemplare di un concetto – per esempio, “gli uccelli” – anche se i singoli esemplari che fanno parte di una categoria sono molto diversi tra loro (l’aquila, il gabbiano, il pettirosso). L’uso dei concetti, cioè la generalizzazione, è utile perché ci consente di fare previsioni sulle proprietà dei singoli esemplari che appartengono ad una categoria, anche se non abbiamo mai avuto esperienza diretta con essi – per esempio, possiamo fare la predizione che tutti gli uccelli possono volare e mangiare vermi, ma non possono guidare un’automobile o parlare in inglese. Queste previsioni non sono sempre corrette, ma sono utili. Le statistiche descrittive, in un certo senso, ci fornisco l’analogo dei “prototipi” che, secondo Eleanor Rosch, stanno alla base del processo psicologico di creazione dei concetti. Un prototipo è l’esemplare più rappresentativo di una categoria. In maniera simile, una statistica descrittiva come la media, ad esempio, potrebbe essere intesa come l’osservazione “tipica”. La statistica descrittiva ci fornisce gli strumenti per riassumere i dati che abbiamo a disposizione in una forma visiva o numerica. Le rappresentazioni grafiche più usate della statistica descrittiva sono gli istogrammi, i diagrammi a dispersione o i box-plot, e gli indici sintetici più comuni sono la media, la mediana, la varianza e la deviazione standard. 3.4 I dati grezzi Per introdurre i principali strumenti della statistica descrittiva considereremo qui i dati raccolti da Zetsche, Bürkner, and Renneberg (2019). Questi ricercatori hanno studiato le aspettative negative quale meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello studio, Zetsche, Bürkner, and Renneberg (2019) si sono chiesti se individui depressi maturino delle aspettative accurate sul loro umore futuro, oppure se tali aspettative sono distorte negativamente.3. In uno studio viene esaminato un campione costituito da 30 soggetti con almeno un episodio depressivo maggiore e da 37 controlli sani. Gli autori hanno misurato il livello depressivo con il Beck Depression Inventory (BDI-II). Questi sono i dati che considereremo qui. Esercizio 3.1 Qual è la la gravità della depressione riportata dai soggetti nel campione esaminato da Zetsche, Bürkner, and Renneberg (2019)? Per rispondere a questa domanda, iniziamo a leggere in \\(\\mathsf{R}\\) i dati, assumendo che il file data.mood.csv si trovi nella cartella data contenuta nella working directory. library(&quot;rio&quot;) df &lt;- rio::import( here(&quot;data&quot;, &quot;data.mood.csv&quot;), header = TRUE ) C’è un solo valore BDI-II per ciascun soggetto ma tale valore viene ripetuto tante volte quante volte sono le righe del data.frame associate ad ogni soggetto (ciascuna riga corrispondente ad una prova diversa). È dunque necessario trasformare il data.frame in modo tale da avere un’unica riga per ciascun soggetto, ovvero un unico valore BDI-II per soggetto. bysubj &lt;- df %&gt;% group_by(esm_id) %&gt;% summarise( bdi = mean(bdi) ) %&gt;% na.omit() Ci sono dunque 66 soggetti i quali hanno ottenuto i valori sulla scala del BDI-II stampati di seguito. Per semplicità, li presentiamo ordinati dal più piccolo al più grande. sort(bysubj$bdi) #&gt; [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 #&gt; [26] 2 2 2 2 3 3 3 5 7 9 12 19 22 22 24 25 25 26 26 26 27 27 28 28 30 #&gt; [51] 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44 3.5 Distribuzioni di frequenze È chiaro che i dati grezzi sono di difficile lettura. Poniamoci dunque il problema di creare una rappresentazione sintetica e comprensibile di questo insieme di valori. Uno dei modi che ci consentono di effettuare una sintesi dei dati è quello di generare una distribuzione di frequenze. Definizione 3.1 Una distribuzione di frequenze è un riepilogo del conteggio della frequenza con cui le modalità osservate in un insieme di dati si verificano in un intervallo di valori. In altre parole, la distribuzione di frequenze della variabile \\(X\\) corrisponde all’insieme delle frequenze assegnate a ciascun possibile valore di \\(X\\). Per creare una distribuzione di frequenze possiamo procedere effettuando una partizione delle modalità della variabile di interesse in \\(m\\) classi (denotate con \\(\\Delta_i\\)) tra loro disgiunte. In tale partizione, la classe \\(i\\)-esima coincide con un intervallo di valori aperto a destra \\([a_i, b_i)\\) o aperto a sinistra \\((a_i, b_i]\\). Ad ogni classe \\(\\Delta_i\\) avente \\(a_i\\) e \\(b_i\\) come limite inferiore e superiore associamo l’ampiezza \\(b_i - a_i\\) (non necessariamente uguale per ogni classe) e il valore centrale \\(\\bar{x}_i\\). La scelta delle classi è arbitraria, ma è buona norma non definire classi con un numero troppo piccolo (&lt; 5) di osservazioni. Poiché ogni elemento dell’insieme \\(\\{x_i\\}_{i=1}^n\\) appartiene ad una ed una sola classe \\(\\Delta_i\\), possiamo calcolare le quantità elencate di seguito. La frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\). Proprietà: \\(n_1 + n_2 + \\dots + n_m = n\\). La frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe. Proprietà: \\(f_1+f_2+\\dots+f_m =1\\). La frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(i\\)-esima compresa: \\(N_i = \\sum_{i=1}^m n_i.\\) La frequenza cumulata relativa \\(F_i\\), ovvero \\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{i=1}^m f_i.\\) Esercizio 3.2 Si calcoli la distribuzione di frequenza assoluta e la distribuzione di frequenza relativa per i valori del BDI-II del campione clinico di Zetsche, Bürkner, and Renneberg (2019). Per costruire una distribuzione di frequenza è innanzitutto necessario scegliere gli intervalli delle classi. Facendo riferimento ai cut-off usati per l’interpretazione del BDI-II, definiamo i seguenti intervalli aperti a destra: depressione minima: [0, 13.5), depressione lieve: [13.5, 19.5), depressione moderata: [19.5, 28.5), depressione severa: [28.5, 63). Esaminando i dati, possiamo notare che 36 soggetti cadono nella prima classe, uno nella seconda classe, e così via. La distribuzione di frequenza della variabile bdi2 è riportata nella tabella seguente. Questa distribuzione di frequenza ci aiuta a capire meglio cosa sta succedendo. Se consideriamo la frequenza relativa, ad esempio, possiamo notare che ci sono due valori maggiormente ricorrenti e tali valori corrispondono alle due classi più estreme. Questo ha senso nel caso presente, in quanto il campione esaminato da Zetsche, Bürkner, and Renneberg (2019) includeva due gruppi di soggetti: soggetti sani (con valori BDI-II bassi) e soggetti depressi (con valori BDI-II alti).4 In una distribuzione di frequenza tali valori tipici vanno sotto il nome di mode della distribuzione. Lim. classi Fr. ass. Fr. rel. Fr. ass. cum. Fr. rel. cum. \\([0, 13.5)\\) 36 36/66 36 36/66 \\([13.5, 19.5)\\) 1 1/66 37 37/66 \\([19.5, 28.5)\\) 12 12/66 49 49/66 \\([28.5, 63)\\) 17 17/66 66 66/66 Poniamoci ora il problema di costruire la tabella precedente utilizzando \\(\\mathsf{R}\\). Usando la funzione cut(), dividiamo il campo di variazione (ovvero, la differenza tra il valore massimo di una distribuzione ed il valore minimo) di una variabile continua x in intervalli e codifica ciascun valore x nei termini dell’intervallo a cui appartiene. Così facendo otteniamo: bysubj$bdi_level &lt;- cut( bysubj$bdi, breaks = c(0, 13.5, 19.5, 28.5, 63), include.lowest = TRUE, labels = c( &quot;minimal&quot;, &quot;mild&quot;, &quot;moderate&quot;, &quot;severe&quot; ) ) bysubj$bdi_level #&gt; [1] moderate severe severe moderate severe severe severe severe #&gt; [9] moderate severe moderate mild severe minimal minimal minimal #&gt; [17] severe moderate minimal minimal minimal minimal minimal moderate #&gt; [25] minimal minimal minimal minimal minimal minimal minimal severe #&gt; [33] minimal minimal severe minimal moderate minimal minimal minimal #&gt; [41] severe minimal minimal severe severe moderate severe severe #&gt; [49] minimal moderate minimal moderate severe moderate moderate minimal #&gt; [57] minimal minimal minimal minimal minimal minimal minimal minimal #&gt; [65] minimal minimal #&gt; Levels: minimal mild moderate severe Possiamo ora usare la funzione table() la quale ritorna un elenco che associa la frequenza assoluta a ciascuna modalità della variabile – ovvero, ritorna la distribuzione di frequenza assoluta. table(bysubj$bdi_level) #&gt; #&gt; minimal mild moderate severe #&gt; 36 1 12 17 La distribuzione di frequenza relativa si ottiene dividendo ciascuna frequenza assoluta per il numero totale di osservazioni: table(bysubj$bdi_level) / sum(table(bysubj$bdi_level)) #&gt; #&gt; minimal mild moderate severe #&gt; 0.54545455 0.01515152 0.18181818 0.25757576 Limiti delle classi Frequenza assoluta Frequenza relativa [0, 13.5) 36 36/66 [13.5, 19.5) 1 1/66 [19.5, 28.5) 12 12/66 [28.5, 63] 17 17/66 Insiemi di variabili possono anche avere distribuzioni di frequenze, dette distribuzioni congiunte. La distribuzione congiunta di un insieme di variabili \\(V\\) è l’insieme delle frequenze di ogni possibile combinazione di valori delle variabili in \\(V\\). Ad esempio, se \\(V\\) è un insieme di due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali può assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) è \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), \\(f(X = 2, Y = 2) = 0.2\\). Proprio come con le distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1. 3.6 Istogramma I dati che sono stati sintetizzati in una distribuzione di frequenze possono essere rappresentati graficamente in un istogramma. Un istogramma si costruisce riportando sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate i valori della funzione costante a tratti \\[ \\varphi_n(x)= \\frac{f_i}{b_i-a_i}, \\quad x\\in \\Delta_i,\\, i=1, \\dots, m \\] che misura la densità della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\), ovvero il rapporto fra la frequenza relativa \\(f_i\\) e l’ampiezza (\\(b_i - a_i\\)) della classe. In questo modo il rettangolo dell’istogramma associato alla classe \\(\\Delta_i\\) avrà un’area proporzionale alla frequenza relativa \\(f_i\\). Si noti che l’area totale dell’istogramma delle frequenze relative è data della somma delle aree dei singoli rettangoli e quindi vale 1.0. Esercizio 3.3 Si utilizzi \\(\\mathsf{R}\\) per costruire un istogramma per i valori BDI-II riportati da Zetsche, Bürkner, and Renneberg (2019). Con i quattro intervalli individuati dai cut-off del BDI-II otteniamo la rappresentazione riportata nella figura 3.1. Per chiarezza, precisiamo che ggplot() utilizza intervalli aperti a destra. Nel caso della prima barra dell’istogramma, l’ampiezza dell’intervallo è pari a 13.5 e l’area della barra (ovvero, la frequenza relativa) è uguale a 36/66. Dunque l’altezza della barra è uguale a \\((36 / 66) / 13.5 = 0.040\\). Lo stesso procedimento si applica per il calcolo dell’altezza degli altri rettangoli. bysubj %&gt;% ggplot(aes(x = bdi)) + geom_histogram( aes(y = ..density..), breaks = c(0, 13.5, 19.5, 28.5, 44.1) # il valore BDI-II massimo è 44 ) + scale_x_continuous( breaks = c(0, 13.5, 19.5, 28.5, 44.1) ) + labs( x = &quot;BDI-II&quot;, y = &quot;Densità di frequenza&quot; ) FIGURA 3.1: Istogramma per i valori BDI-II riportati da Zetsche et al. (2019). Anche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale. Questo è il caso dell’istogramma della figura 3.2. bysubj %&gt;% ggplot(aes(x = bdi)) + geom_histogram( aes(y = ..density..), breaks = seq(0, 44.1, length.out = 7) ) + scale_x_continuous( breaks = c(0.00, 7.35, 14.70, 22.05, 29.40, 36.75, 44.10) ) + labs( x = &quot;BDI-II&quot;, y = &quot;Densità di frequanza&quot; ) FIGURA 3.2: Una rappresentazione più comune per l’istogramma dei valori BDI-II nella quale gli intervalli delle classi hanno ampiezze uguali. 3.7 Kernel density plot Il confronto tra le figure 3.1 e 3.2 rende chiaro il limite dell’istogramma: il profilo dell’istogramma è arbitrario, in quanto dipende dal numero e dall’ampiezza delle classi. Questo rende difficile l’interpretazione. Il problema precedente può essere alleviato utilizzando una rappresentazione alternativa della distribuzione di frequenza, ovvero la stima della densità della frequenza dei dati (detta anche stima kernel di densità). Un modo semplice per pensare a tale rappresentazione, che in inglese va sotto il nome di kernel density plot (cioè i grafici basati sulla stima kernel di densità), è quello di immaginare un grande campione di dati, in modo che diventi possibile definire un enorme numero di classi di equivalenza di ampiezza molto piccola, le quali non risultino vuote. In tali circostanze, la funzione di densità empirica non è altro che il profilo lisciato dell’istogramma. La stessa idea si applica anche quando il campione è piccolo. In tali circostanze, invece di raccogliere le osservazioni in barre come negli istogrammi, lo stimatore di densità kernel colloca una piccola “gobba” (bump), determinata da un fattore \\(K\\) (kernel) e da un parametro \\(h\\) di smussamento detto ampiezza di banda (bandwidth), in corrispondenza di ogni osservazione, quindi somma le gobbe risultanti generando una curva smussata. L’interpretazione che possiamo attribuire al kernel density plot è simile a quella che viene assegnata agli istogrammi: l’area sottesa al kernel density plot in un certo intervallo rappresenta la proporzione di casi della distribuzione che hanno valori compresi in quell’intervallo. Esercizio 3.4 All’istogramma dei valori BDI-II di Zetsche, Bürkner, and Renneberg (2019) si sovrapponga un kernel density plot. bysubj %&gt;% ggplot(aes(x = bdi)) + geom_histogram( aes(y = ..density..), breaks = seq(0, 44.1, length.out = 7) ) + geom_density( aes(x = bdi), adjust = 0.5, size = 0.8, #fill = colors[2], alpha = 0.5 ) + labs( x = &quot;BDI-II&quot;, y = &quot;Densità di frequenza&quot; ) FIGURA 3.3: Kernel density plot e corrispondente istogramma per i valori BDI-II. 3.8 Forma di una distribuzione In generale, la forma di una distribuzione descrive come i dati si distribuiscono intorno ai valori centrali. Distinguiamo tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali o multimodali. Un’illustrazione grafica è fornita nella figura 3.4. Nel pannello 1 la distribuzione è unimodale con asimmetria negativa; nel pannello 2 la distribuzione è unimodale con asimmetria positiva; nel pannello 3 la distribuzione è simmetrica e unimodale; nel pannello 4 la distribuzione è bimodale. FIGURA 3.4: 1: Asimmetria negativa. 2: Asimmetria positiva. 3: Distribuzione unimodale. 4: Distribuzione bimodale. Esercizio 3.5 Il kernel density plot della figura 3.3 indica che la distribuzione dei valori del BDI-II nel campione di Zetsche, Bürkner, and Renneberg (2019) è bimodale. Ciò indica che le osservazioni della distribuzione si addensano in due cluster ben distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l’altro gruppo tende ad avere BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche, Bürkner, and Renneberg (2019). 3.9 Indici di posizione Nuovamente, se preferite un’introduzione “soft” alla nozione di “tendenza centrale” di una distribuzione statistica, vi rimando nuovamentew al link che ho già suggerito in precedenza. 3.9.1 Quantili La descrizione della distribuzione dei valori BDI-II di Zetsche, Bürkner, and Renneberg (2019) può essere facilitata dalla determinazione di alcuni valori caratteristici che sintetizzano le informazioni contenute nella distribuzione di frequenze. Si dicono quantili (o frattili) quei valori caratteristici che hanno le seguenti proprietà. I quartili sono quei valori che ripartiscono i dati \\(x_i\\) in quattro parti ugualmente numerose (pari ciascuna al 25% del totale). Il primo quartile, \\(q_1\\), lascia alla sua sinistra il 25% del campione pensato come una fila ordinata (a destra quindi il 75%). Il secondo quartile \\(q_2\\) lascia a sinistra il 50% del campione (a destra quindi il 50%). Esso viene anche chiamato mediana. Il terzo quartile lascia a sinistra il 75% del campione (a destra quindi il 25%). Secondo lo stesso criterio, si dicono decili i quantili di ordine \\(p\\) multiplo di 0.10 e percentili i quantili di ordine \\(p\\) multiplo di 0.01. Come si calcolano i quantili? Consideriamo la definizione di quantile non interpolato di ordine \\(p\\) \\((0 &lt; p &lt; 1)\\). Si procede innanzitutto ordinando i dati in ordine crescente, \\(\\{x_1, x_2, \\dots, x_n\\}\\). Ci sono poi due possibilità. Se il valore \\(np\\) non è intero, sia \\(k\\) l’intero tale che \\(k &lt; np &lt; k + 1\\) – ovvero, la parte intera di \\(np\\). Allora \\(q_p = x_{k+1}.\\) Se \\(np = k\\) con \\(k\\) intero, allora \\(q_p = \\frac{1}{2}(x_{k} + x_{k+1}).\\) Se vogliamo calcolare il primo quartile \\(q_1\\), ad esempio, utilizziamo \\(p = 0.25\\). Dovendo calcolare gli altri quantili basta sostituire a \\(p\\) il valore appropriato. Gli indici di posizione, tra le altre cose, hanno un ruolo importante, ovvero vengono utilizzati per creare una rappresentazione grafica di una distribuzione di valori che è molto popolare e può essere usata in alternativa ad un istogramma (in realtà vedremo poi come possa essere combinata con un istogramma). Tale rappresentazione va sotto il nome di box-plot. Esercizio 3.6 Per fare un esempio, consideriamo i nove soggetti del campione clinico di Zetsche, Bürkner, and Renneberg (2019) che hanno riportato un unico episodio di depressione maggiore. Per tali soggetti i valori ordinati del BDI-II (per semplicità li chiameremo \\(x\\)) sono i seguenti: 19, 26, 27, 28, 28, 33, 33, 41, 43. Per il calcolo del secondo quartile (non interpolato), ovvero per il calcolo della mediana, dobbiamo considerare la quantità \\(np = 9 \\cdot 0.5 = 4.5\\), non intero. Quindi, \\(q_1 = x_{4 + 1} = 27\\). Per il calcolo del quantile (non interpolato) di ordine \\(p = 2/3\\) dobbiamo considerare la quantità \\(np = 9 \\cdot 2/3 = 6\\), intero. Quindi, \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\). 3.9.2 Diagramma a scatola Il diagramma a scatola (o box plot) è uno strumento grafico utile al fine di ottenere informazioni circa la dispersione e l’eventuale simmetria o asimmetria di una distribuzione. Per costruire un box-plot si rappresenta sul piano cartesiano un rettangolo (cioè la “scatola”) di altezza arbitraria la cui base corrisponde alla dist intanza interquartile (IQR = \\(q_{0.75} - q_{0.25}\\)). La linea interna alla scatola rappresenta la mediana \\(q_{0.5}\\). Si tracciano poi ai lati della scatola due segmenti di retta i cui estremi sono detti “valore adiacente” inferiore e superiore. Il valore adiacente inferiore è il valore più piccolo tra le osservazioni che risulta maggiore o uguale al primo quartile meno la distanza corrispondente a 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più grande tra le osservazioni che risulta minore o uguale a \\(Q_3+1.5\\) IQR. I valori esterni ai valori adiacenti (chiamati valori anomali) vengono rappresentati individualmente nel box-plot per meglio evidenziarne la presenza e la posizione. FIGURA 3.5: Box-plot: \\(M\\) è la mediana, \\(\\bar{x}\\) è la media aritmetica e IQR è la distanza interquartile (\\(Q_3 - Q_1\\)). Esercizio 3.7 Per i dati di Zetsche, Bürkner, and Renneberg (2019), si utilizzi un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo. Nella figura 3.6 sinistra sono rappresentati i dati grezzi. La linea curva che circonda (simmetricamente) le osservazioni è l’istogramma lisciato (kernel density plot) che abbiamo descritto in precedenza. Nella figura 3.6 destra sono rappresentanti gli stessi dati: il kernel density plot è lo stesso di prima, ma al suo interno è stato collocato un box-plot. Entrambe le rappresentazioni suggeriscono che la distribuzione dei dati è all’incirca simmetrica nel gruppo clinico. Il gruppo di controllo mostra invece un’asimmetria positiva. bysubj &lt;- df %&gt;% group_by(esm_id, group) %&gt;% summarise( bdi = mean(bdi), nr_of_episodes = mean(nr_of_episodes, na.rm = TRUE) ) %&gt;% na.omit() %&gt;% ungroup() bysubj$group &lt;- forcats::fct_recode( bysubj$group, &quot;Controlli\\n sani&quot; = &quot;ctl&quot;, &quot;Depressione\\n maggiore&quot; = &quot;mdd&quot; ) p1 &lt;- bysubj %&gt;% ggplot(aes(x = group, y = bdi)) + geom_violin(trim = FALSE) + geom_dotplot(binaxis = &quot;y&quot;, stackdir = &quot;center&quot;, dotsize = 0.7) + labs( x = &quot;&quot;, y = &quot;BDI-II&quot; ) p2 &lt;- bysubj %&gt;% ggplot(aes(x = group, y = bdi)) + geom_violin(trim = FALSE) + geom_boxplot(width = 0.05) + labs( x = &quot;&quot;, y = &quot;BDI-II&quot; ) p1 + p2 FIGURA 3.6: Due versioni di un violin plot per i valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al. (2019). 3.9.3 Sina plot Si noti che i box plot non sono necessariamente la rappresentazione migliore della distribuzione di una variabile. Infatti, richiedono la comprensione di concetti complessi (quali i quantili e la differenza interquantile) che non sono necessari se vogliamo presentare in maniera grafica la distribuzione della variabile e, in generale, non sono compresi da un pubblico di non specialisti. Inoltre, i box plot nascondono informazioni che di solito sono cruciali da vedere. È dunque preferibile presentare direttamente i dati. Nella figura 3.7 viene presentato un cosiddetto “sina plot”. In tale rappresentazione grafica vengono mostrate le singole osservazioni divise in classi. Ai punti viene aggiunto un jitter, così da evitare sovrapposizioni. L’ampiezza del jitter lungo l’asse \\(x\\) è determinata dalla distribuzione della densità dei dati all’interno di ciascuna classe; quindi il grafico mostra lo stesso contorno di un violin plot, ma trasmette informazioni sia sul numero di punti dati, sia sulla distribuzione della densità, sui valori anomali e sulla distribuzione dei dati in un formato molto semplice, comprensibile e sintetico. Esercizio 3.8 Si generi un sina plot per i dati della figura 3.6. Si aggiunga alla figura una rappresentazione della mediana. zetsche_summary &lt;- bysubj %&gt;% group_by(group) %&gt;% summarize( bdi_mean = mean(bdi), bdi_sd = sd(bdi), bdi_median = median(bdi) ) %&gt;% ungroup() bysubj %&gt;% ggplot( aes(x = group, y = bdi, color = group) ) + ggforce::geom_sina(aes(color = group, size = 1, alpha = .5)) + geom_errorbar( aes(y = bdi_median, ymin = bdi_median, ymax = bdi_median), data = zetsche_summary, width = 0.3, size = 1 ) + labs( x = &quot;&quot;, y = &quot;BDI-II&quot;, color = &quot;Gruppo&quot; ) + theme(legend.position = &quot;none&quot;) + scale_colour_grey(start = 0.7, end = 0) FIGURA 3.7: Sina plot per i valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al. (2019) con l’indicazione della mediana per ciascun gruppo. Per un esempio in una recente pubblicazione, possiamo considerare le figure 3 e 6 di Lazic, Semenova, and Williams (2020). 3.9.4 L’eccellenza grafica Non c’è un unico modo “corretto” per la rappresentazione grafica dei dati. Ciascuno dei grafici che abbiamo discusso in precedenza ha i suoi pregi e i suoi difetti. Un ricercatore che ha molto influenzato il modo in cui viene realizzata la visualizzazione dei dati scientifici è Edward Tufte, soprannominato dal New York Times il “Leonardo da Vinci dei dati.” Secondo Tufte, “l’eccellenza nella grafica consiste nel comunicare idee complesse in modo chiaro, preciso ed efficiente”. Nella visualizzazione delle informazioni, l’“eccellenza grafica” ha l’obiettivo di comunicare al lettore il maggior numero di idee nella maniera più diretta e semplice possibile. Secondo Tufte (2001), le rappresentazioni grafiche dovrebbero: mostrare i dati; indurre l’osservatore a riflettere sulla sostanza piuttosto che sulla progettazione grafica, o qualcos’altro; evitare di distorcere quanto i dati stanno comunicando (“integrità grafica”); presentare molte informazioni in forma succinta; rivelare la coerenza tra le molte dimensioni dei dati; incoraggiare l’osservatore a confrontare differenti sottoinsiemi di dati; rivelare i dati a diversi livelli di dettaglio, da una visione ampia alla struttura di base; servire ad uno scopo preciso (descrizione, esplorazione, o la risposta a qualche domanda); essere fortemente integrate con le descrizioni statistiche e verbali dei dati fornite nel testo. In base a questi principi, figura 3.7 sembra fornire la rappresentazione migliore dei dati di @zetschefuture2019. Il seguente link fornisce diverse interessanti illustrazioni dei principi elencati sopra. Commenti e considerazioni finali Una distribuzione è una rappresentazione del modo in cui le diverse modalità di una variabile \\(X\\) si distribuiscono nelle unità statistiche che compongono il campione o la popolazione oggetto di studio. Il modo più diretto per trasmettere descrivere le proprietà della distribuzione di una variabile discreta è quello di fornire una rappresentazione grafica della distribuzione di frequenza. In seguito vedremo la corrispondente rappresentazione che viene usata nel caso delle variabili continue. References "],["ch-loc-scale.html", "Capitolo 4 Indici di posizione e di scala 4.1 Indici di tendenza centrale 4.2 Indici di dispersione Commenti e considerazioni finali", " Capitolo 4 Indici di posizione e di scala L’analisi grafica, esaminata in precedenza, costituisce la base di partenza di qualsivoglia analisi quantitativa dei dati. Tramite opportune rappresentazioni grafiche possiamo individuare alcune caratteristiche importanti di una distribuzione: per esempio, è possibile capire se la distribuzione è simmetrica o asimmetrica; oppure se è unimodale o multimodale. Successivamente, possiamo calcolare degli indici numerici che descrivono in modo sintetico le caratteristiche di base dei dati esaminati. 4.1 Indici di tendenza centrale Tra le misure di tendenza centrale, ovvero tra gli indici che forniscono un’idea dei valori attorno ai quali sono prevalentemente concentrati i dati di un campione, quella più comunemente usata è la media. 4.1.1 Media Tutti conosciamo la media aritmetica di \\(\\{x_1, x_2, \\dots, x_n\\}\\), ovvero il numero reale \\(\\bar{x}\\) definito da \\[\\begin{equation} \\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i. \\tag{4.1} \\end{equation}\\] Nella (4.1) abbiamo usato la notazione delle sommatorie per descrivere una somma di valori. Questa notazione è molto usata in statistica e viene descritta in Appendice. La media gode della seguente importante proprietà: la somma degli scarti tra ciascuna modalità \\(x_i\\) e la media aritmetica \\(\\bar{x}\\) è nulla, cioè \\[\\begin{equation} \\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag \\label{eq:diffmeansumzero} \\end{equation}\\] Infatti, \\[ \\begin{aligned} \\sum_{i=1}^n (x_i - \\bar{x}) &amp;= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\ &amp;= \\sum_i x_i - n \\bar{x}\\notag\\\\ &amp;= \\sum_i x_i - \\sum_i x_i = 0.\\notag \\end{aligned} \\] Ciò ci consente di pensare alla media come al baricentro della distribuzione. Un’altra proprietà della media è la seguente. La somma dei quadrati degli scarti tra ciascuna modalità \\(x_i\\) e una costante arbitraria \\(a\\), cioè \\[\\begin{equation} \\varphi(a) = \\sum_{i=1}^n (x_i - a)^2,\\notag \\end{equation}\\] è minima per \\(a = \\bar{x}\\). Osservazione. Il concetto statistico di media ha suscitato molte battute. Per esempio, il fatto che, in media, ciascuno di noi ha un numero di gambe circa pari a 1.9999999. Oppure, il fatto che, in media, ciascuno di noi ha un testicolo. Ma la media ha altri problemi, oltre al fatto di ispirare battute simili alle precedenti. In particolare, dobbiamo notare che la media non è sempre l’indice che meglio rappresenta la tendenza centrale di una distribuzione. In particolare, ciò non accade quando la distribuzione è asimmetrica, o in presenza di valori anomali (outlier) – si veda il pannello di destra della figura 3.6. In tali circostanze, la tendenza centrale della distribuzione è meglio rappresentata dalla mediana o dalla media spuntata. Esercizio 4.1 Si calcoli la media dei valori BDI-II per i due gruppi di soggetti di Zetsche, Bürkner, and Renneberg (2019). df &lt;- rio::import( here(&quot;data&quot;, &quot;data.mood.csv&quot;), header = TRUE ) bysubj &lt;- df %&gt;% group_by(group, esm_id) %&gt;% summarise( bdi = mean(bdi) ) %&gt;% na.omit() bysubj %&gt;% group_by(group) %&gt;% summarise( avg_bdi = mean(bdi) ) #&gt; # A tibble: 2 × 2 #&gt; group avg_bdi #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 ctl 1.61 #&gt; 2 mdd 30.9 4.1.2 Media spuntata La media spuntata \\(\\bar{x}_t\\) (trimmed mean) non è altro che la media dei dati calcolata considerando solo il 90% (o altra percentuale) dei dati centrali. Per calcolare \\(\\bar{x}_t\\) si ordinando i dati secondo una sequenza crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), per poi eliminare il primo 5% e l’ultimo 5% dei dati della serie così ordinata. La media spuntata è data dalla media aritmetica dei dati rimanenti. Esercizio 4.2 Si calcoli la media spuntata dei valori BDI-II per i due gruppi di soggetti di Zetsche, Bürkner, and Renneberg (2019) escludendo il 10% dei valori più estremi in ciascun gruppo. bysubj %&gt;% group_by(group) %&gt;% summarise( avg_trim_bdi = mean(bdi, trim = 0.1) ) #&gt; # A tibble: 2 × 2 #&gt; group avg_trim_bdi #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 ctl 1 #&gt; 2 mdd 30.6 4.1.3 Moda e mediana In precedenza abbiamo già incontrato altri due popolari indici di tendenza centrale: la moda (Mo), ovvero il valore centrale della classe con la frequenza massima (può succedere che una distribuzione abbia più mode; in tal caso si dice multimodale e questo operatore perde il suo significato di indice di tendenza centrale) e la mediana \\(\\tilde{x}\\). Esercizio 4.3 Si calcolino i quantili di ordine 0.25, 0.5 e 0.75 dei valori BDI-II per i due gruppi di soggetti di Zetsche, Bürkner, and Renneberg (2019). bysubj %&gt;% group_by(group) %&gt;% summarise( q25 = quantile(bdi, probs = 0.25), q50 = quantile(bdi, probs = 0.50), q75 = quantile(bdi, probs = 0.75) ) #&gt; # A tibble: 2 × 4 #&gt; group q25 q50 q75 #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 ctl 0 1 2 #&gt; 2 mdd 26 30 35 Osservazione. Si noti che solitamente i software restituiscono un valore interpolato del \\(p\\)-esimo quantile \\(q_p\\) \\((0 &lt; p &lt; 1)\\), il quale viene calcolato mediante specifiche procedure. Il risultato fornito dai software, dunque, non sarà identico a quello trovato utilizzando la definizione non interpolata di quantile che abbiamo presentato qui. Se, per qualche ragione, vogliamo conoscere l’algoritmo usato per la determinazione dei quantili interpolati, dobbiamo leggere la documentazione del software. 4.2 Indici di dispersione Le medie e gli indici di posizione descritti in precedenza forniscono delle sintesi dei dati che mettono in evidenza la tendenza centrale delle osservazioni. Tali indici, tuttavia, non considerano un aspetto importante della distribuzione dei dati, ovvero la variabilità dei valori numerici della variabile statistica. È dunque necessario sintetizzare la distribuzione di una variabile statistica oltre che con le misure di posizione anche tramite l’utilizzo di indicatori che valutino la dispersione delle unità statistice. Osservazione. Un’introduzione “soft” al tema degli indici di posizione è fornita nel seguente link. 4.2.1 Indici basati sull’ordinamento dei dati È possibile calcolare degli indici di variabilità basati sull’ordinamento dei dati. L’indice più ovvio è l’intervallo di variazione, ovvero la distanza tra il valore massimo e il valore minimo di una distribuzione di modalità, mentre in precedenza abbiamo già incontrato la differenza interquartile. Questi due indici, però, hanno il limite di essere calcolati sulla base di due soli valori della distribuzione (\\(x_{\\text{max}}\\) e \\(x_{\\text{mini}}\\), oppure \\(x_{0.25}\\) e \\(x_{0.75}\\)). Pertanto non utilizzano tutte le informazioni che sono disponibili. Inoltre, l’intervallo di variazione ha il limite di essere pesantemente influenzato dalla presenza di valori anomali. 4.2.2 Varianza Dati i limiti delle statistiche precedenti è più comune misurare la variabilità di una variabile statistica come la dispersione dei dati attorno ad un indice di tendenza centrale. Infatti, la misura di variabilità di gran lunga più usata per valutare la variabilità di una variabile statistica è senza dubbio la varianza. La varianza \\[\\begin{equation} s^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2 \\tag{4.2} \\end{equation}\\] è la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione. La varianza è una misura di dispersione più complessa di quelle esaminate in precedenza. È appropriata solo nel caso di distribuzioni simmetriche e, anch’essa, è fortemente influenzata dai valori anomali. Inoltre, è espressa in un’unità di misura che è il quadrato dell’unità di misura dei dati originari e quindi ad essa non può essere assegnata un’interpretazione intuitiva. Esercizio 4.4 Si calcoli la varianza dei valori BDI-II per i dati di Zetsche, Bürkner, and Renneberg (2019). Applicando la formula precedente, per tutto il campione abbiamo var(bysubj$bdi) #&gt; [1] 239.8732 4.2.3 Precisione Si definisce precisione l’inverso della varianza: \\[\\begin{equation} \\tau = \\frac{1}{\\sigma^2}. \\tag{4.3} \\end{equation}\\] Alcuni ritengono che la precisione sia più “intuitiva” della varianza perché dice quanto sono concentrati i valori attorno alla media piuttosto che quanto sono dispersi. In altri termini, si potrebbe argomentare che siamo più interessati a quanto sia precisa una misurazione piuttosto che a quanto sia imprecisa. Più sono dispersi i valori attorno alla media (alta varianza), meno sono precisi (poca precisione); minore è la varianza, maggiore è la precisione. La precisione è uno dei due parametri naturali della distribuzione gaussiana. Nei termini della (4.3), la distribuzione gaussiana (si veda il Capitolo ??) può essere espressa nel modo seguente \\[ {\\displaystyle f(y)=\\sqrt{\\frac{\\tau}{2\\pi}} e^{-{\\frac {1}{2}}\\tau\\left({y-\\mu }\\right)^{2}}}, \\] anziché come \\[ {\\displaystyle f(y)={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {y-\\mu }{\\sigma }}\\right)^{2}}}. \\] 4.2.4 Scarto tipo Per le ragioni espresse sopra, la misura più usata della dispersione di una distribuzione di dati è lo scarto quadratico medio (o scarto tipo, o deviazione standard), ovvero la radice quadrata della varianza5. A differenza della varianza, dunque, lo scarto tipo è espresso nella stessa unità di misura dei dati. Come nel caso della varianza, anche lo scarto tipo \\(s\\) dovrebbe essere usato soltanto quando la media è adeguata per misurare il centro della distribuzione, ovvero, nel caso di distribuzioni simmetriche. Come nel caso della media \\(\\bar{x}\\), anche lo scarto tipo è fortemente influenzato dai dati anomali (outlier), ovvero dalla presenza di uno o di pochi dati che sono molto più distanti dalla media rispetto agli altri valori della distribuzione. Quando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\). Allo scarto tipo può essere assegnata una semplice interpretazione: lo scarto tipo è simile (ma non identico) allo scarto semplice medio campionario, ovvero alla media aritmetica dei valori assoluti degli scarti dalla media. Lo scarto tipo ci dice, dunque, quanto sono distanti, in media, le singole osservazioni dal centro della distribuzione. Un’interpretazione più precisa del significato dello scarto tipo è fornita nel Paragrafo successivo. Esercizio 4.5 Si calcoli lo scarto tipo per i valori BDI-II di dati di Zetsche, Bürkner, and Renneberg (2019). Applicando la formula precedente, per tutto il campione abbiamo sd(bysubj$bdi) #&gt; [1] 15.48784 4.2.5 Deviazione mediana assoluta Una misura robusta della dispersione statistica di un campione è la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana, ovvero: \\[ {\\displaystyle \\operatorname {MAD} =\\operatorname {median} \\left(\\ \\left|X_{i}-\\operatorname {median} (X)\\right|\\ \\right)} \\] Nel caso di una distribuzione dei dati unimodale simmetrica di forma campanulare (ovvero, normale) si ha che \\[ {\\displaystyle \\text{deviazione standard} \\approx 1.4826\\ \\operatorname {MAD} .\\,} \\] Pertanto, solitamente i software restituiscono il valore MAD moltiplicato per una tale costante. Esercizio 4.6 Si calcoli il valore MAD per i valori BDI-II riportati da Zetsche, Bürkner, and Renneberg (2019). Applicando la formula precedente, per tutto il campione abbiamo 1.4826 * median(abs(bysubj$bdi - median(bysubj$bdi))) #&gt; [1] 8.8956 Nel caso presente, i dati seguono una distribuzione bimodale, dunque \\(1.4826\\ \\operatorname {MAD}\\) produce un valore piuttosto diverso dalla deviazione standard. 4.2.6 Indici di variabilità relativi A volte può essere interessante effettuare un confronto fra due misure di variabilità di grandezze incommensurabili, ovvero di caratteri rilevati mediante differenti unità di misura. In questi casi, le misure di variabilità precedentemente descritte si rivelano inadeguate in quanto dipendono dall’unità di misura adottata. Diventa dunque necessario ricorrere a particolari numeri adimensionali detti indici relativi di variabilità. Il più importante di tali indici è il coefficiente di variazione, ovvero il numero puro \\[ C_v = \\frac{\\sigma}{\\bar{x}} \\] ottenuto dal rapporto tra la deviazione standard e la media dei dati. Un altro indice relativo di variabilità è la differenza interquartile rapportata al primo quartile oppure al terzo quartile oppure alla mediana, cioè: \\[ \\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}. \\] Commenti e considerazioni finali Le statistiche descrittive ci forniscono degli indici sintetici che riassumono i dati, ovvero le nostre misurazioni dell’intera popolazione o di un campione estratto da una popolazione. Le statistiche descrittive comprendono gli indici di tendenza centrale e gli indici di dispersione. Gli indici di tendenza centrale includono la media, la mediana e la moda, mentre gli indici di dispersione includono lo scarto tipo, la varianza, la curtosi e l’asimmetria. References "],["ch-corr.html", "Capitolo 5 Le relazioni tra variabili 5.1 Diagramma a dispersione 5.2 Covarianza 5.3 Correlazione 5.4 Correlazione e causazione 5.5 Usi della correlazione 5.6 Correlazione di Spearman 5.7 Correlazione nulla Commenti e considerazioni finali", " Capitolo 5 Le relazioni tra variabili Nella loro ricerca, Zetsche, Bürkner, and Renneberg (2019) hanno misurato il livello di depressione dei soggetti utilizzando due scale psicometriche: il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D). Il BDI-II è uno strumento self-report che valutare la presenza e l’intensità di sintomi depressivi in pazienti adulti e adolescenti di almeno 13 anni di età con diagnosi psichiatrica mentre la CES-D è una scala self-report progettata per misurare i sintomi depressivi che sono stati vissuti nella settimana precedente nella popolazione generale, specialmente quella degli adolescenti/giovani adulti. Una domanda ovvia che ci può venire in mente è: quanto sono simili le misure ottenute mediante queste due scale? È chiaro che i numeri prodotti dalle scale BDI-II e CES-D non possono essere identici, e questo per due motivi: (1) la presenza degli errori di misurazione e (2) l’unità di misura delle due variabili. L’errore di misurazione corrompe sempre, almeno in parte, qualunque operazione di misurazione. E questo è vero specialmente in psicologia dove l’attendibilità degli strumenti di misurazione è minore che in altre discipline (quali la fisica, ad esempio). Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere uguali è che l’unità di misura delle due scale è arbitraria. Infatti, qual è l’unità di misura della depressione? Chi può dirlo! Ma, al di là delle differenze derivanti dall’errore di misurazione e dalla differente unità di misura, ci aspettiamo che, se le due scale misurano entrambe lo stesso costrutto, allora i valori prodotti dalle due scale dovranno essere tra loro linearmente associati. Per capire cosa si intende con “associazione lineare” iniziamo a guardare i dati. Per fare questo utilizziamo una rappresentazione grafica che va sotto il nome di diagramma a dispersione. 5.1 Diagramma a dispersione Il diagramma di dispersione è la rappresentazione grafica delle coppie di punti individuati da due variabili \\(X\\) e \\(Y\\). Per fare un esempio concreto, consideriamo le variabili BDI-II e CES-D di Zetsche, Bürkner, and Renneberg (2019). Il diagramma di dispersione per tali variabili si ottiene ponendo, ad esempio, i valori BDI-II sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate. In tale grafico, fornito dalla figura 5.1, cascun punto corrisponde ad un individuo del quale, nel caso presente, conosciamo il livello di depressione misurato dalle due scale psicometriche. Dalla figura 5.1 possiamo vedere che i dati mostrano una tendenza a disporsi attorno ad una retta – nel gergo statistico, questo fatto viene espresso dicendo che i punteggi CES-D tendono ad essere linearmente associati ai punteggi BDI-II. È ovvio, tuttavia, che tale relazione lineare è lungi dall’essere perfetta – se fosse perfetta, tutti i punti del diagramma a dispersione si disporrebbero esattamente lungo una retta. df &lt;- rio::import( here(&quot;data&quot;, &quot;data.mood.csv&quot;), header = TRUE ) bysubj &lt;- df %&gt;% group_by(esm_id, group) %&gt;% summarise( bdi = mean(bdi), cesd = mean(cesd_sum) ) %&gt;% na.omit() %&gt;% ungroup() m_cesd &lt;- bysubj %&gt;% dplyr::pull(cesd) %&gt;% mean() m_bdi &lt;- bysubj %&gt;% dplyr::pull(bdi) %&gt;% mean() FONT_SIZE &lt;- 9 bysubj %&gt;% ggplot( aes(x = bdi, y = cesd, color = group) ) + geom_point(size = 3, alpha = .9) + geom_hline(yintercept = m_cesd, linetype = &quot;dashed&quot;, color = &quot;gray&quot;) + geom_vline(xintercept = m_bdi, linetype = &quot;dashed&quot;, color = &quot;gray&quot;) + geom_text(x = -1, y = 16, label = &quot;I&quot;, color = &quot;gray&quot;, size = FONT_SIZE) + geom_text(x = 0, y = 46, label = &quot;IV&quot;, color = &quot;gray&quot;, size = FONT_SIZE) + geom_text(x = 18, y = 46, label = &quot;III&quot;, color = &quot;gray&quot;, size = FONT_SIZE) + geom_text(x = 18, y = 16, label = &quot;II&quot;, color = &quot;gray&quot;, size = FONT_SIZE) + labs( x = &quot;BDI-II&quot;, y = &quot;CESD&quot; ) + theme(legend.position = &quot;none&quot;) + scale_colour_grey(start = 0.7, end = 0) FIGURA 5.1: Associazione tra le variabili BDI-II e CES-D nello studio di Zetsche et al. (2019). In grigio sono rappresentate le osservazioni del gruppo di controllo; in nero quelle dei pazienti. 5.2 Covarianza Il problema che ci poniamo ora è quello di trovare un indice numerico che descrive di quanto la nube di punti si discosta da una perfetta relazione lineare tra le due variabili, ovvero che descrive la direzione e la forza della relazione lineare tra le due variabili. Ci sono vari indici statistici che possono essere utilizzati a questo scopo. Iniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrato in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media: \\[\\begin{equation} S_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}). \\tag{5.1} \\end{equation}\\] Infatti, la varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa”. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, chiediamoci come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa: \\[\\begin{equation} S_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}). \\tag{5.2} \\end{equation}\\] L’eq. (5.2) ci fornisce dunque la definizione della covarianza. Per capire il significato dell’eq. (5.2), supponiamo di dividere il grafico della figura 5.1 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario. Se prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa. Il segno della covarianza ci informa sulla direzione della relazione, ma invece il valore assoluto della covarianza ci dice ben poco. Esso, infatti, dipende dall’unità di misura delle variabili. Nel caso presente questo concetto è difficile da comprendere, dato che le due variabili in esame non hanno un’unità di misura (ovvero, hanno un’unità di misura arbitraria e priva di significato). Ma quest’idea diventa chiara se pensiamo alla relazione lineare tra l’altezza e il peso delle persone, ad esempio. La covarianza tra queste due quantità è certamente positiva, ma il valore assoluto della covarianza diventa più grande se l’altezza viene misurata in millimetri e il peso in grammi, e diventa più piccolo l’altezza viene misurata in metri e il peso in chilogrammi. Dunque, il valore della covarianza cambia al mutare dell’unità di misura delle variabili anche se l’associazione tra le variabili resta costante. 5.3 Correlazione Dato che il valore assoluto della covarianza è di difficile interpretazione – in pratica, non viene mai interpretato – è necessario trasformare la covarianza in modo tale da renderla immune alle trasformazioni dell’unità di misura delle variabili. Questa operazione si dice standardizzazione e corrisponde alla divisione della covarianza per le deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili: \\[\\begin{equation} r_{XY} = \\frac{S_{XY}}{s_X s_Y}. \\tag{5.3} \\end{equation}\\] La quantià che si ottiene in questo modo viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, la hanno introdotta). Il coefficiente di correlazione ha le seguenti proprietà: ha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi; è un numero puro, cioè non dipende dall’unità di misura delle variabili; assume valori compresi tra -1 e +1. Ad esso possiamo assegnare la seguente interpretazione: \\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra); \\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra); \\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa; \\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\). Esercizio 5.1 Per i dati della figura 5.1, la covarianza è 207.426. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire qual è l’intensità della relazione lineare tra le due variabili calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva. 5.4 Correlazione e causazione Facendo riferimento nuovamente alla figura 5.1, possiamo dire che, in molte applicazioni (ma non nel caso presente!) l’asse \\(x\\) rappresenta una quantità nota come variabile indipendente e l’interesse si concentra sulla sua influenza sulla variabile dipendente tracciata sull’asse \\(y\\). Ciò presuppone però che sia nota la direzione in cui l’influenza causale potrebbe risiedere. È importante tenere bene a mente che la correlazione è soltanto un indice descrittivo della relazione lineare tra due variabili e in nessun caso può essere usata per inferire alcunché sulle relazioni causali che legano le variabili. È ben nota l’espressione: “correlazione non significa causazione”. Di opinione diversa era invece Karl Pearson (1911), il quale ha affermato: “Quanto spesso, quando è stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‘qual è la sua causa?’. Questa è una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, può essere più facile rispondere alla domanda: ‘in che misura altri fenomeni sono associati con esso?’. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.” Che alla seconda domanda posta da Pearson sia facile rispondere è indubbio. Che la nostra comprensione di un fenomeno possa aumentare sulla base delle informazioni fornite unicamente dalle correlazioni, invece, è molto dubbio e quasi certamente falso. 5.5 Usi della correlazione Anche se non può essere usata per studiare le relazioni causali, la correlazione viene usata per molti altri scopi tra i quali, per esempio, quello di misurare la validità concorrente di un test psiologico. Se un test psicologico misura effettivamente ciò che ci si aspetta che misuri (nel caso dell’esempio presente, la depressione), allora dovremo aspettarci che fornisca una correlazione alta con risultati di altri test che misurano lo stesso costrutto – come nel caso dei dati di (Zetsche, Bürkner, and Renneberg 2019). Un’altra proprietà desiderabile di un test psicometrico è la validità divergente: i risultati di test psicometrici che misurano costrutti diversi dovrebbero essere poco associati tra loro. In altre parole, in questo secondo caso dovremmo aspettarci che la correlazione sia bassa. 5.6 Correlazione di Spearman Una misura alternativa della relazione lineare tra due variabili è fornita dal coefficiente di correlazione di Spearman e dipende soltanto dalla relazione d’ordine dei dati, non dagli specifici valori dei dati. Tale misura di associazione è appropriata quando, del fenomeno in esame, gli psicologi sono stati in grado di misurare soltanto le relazioni d’ordine tra le diverse modalità della risposta dei soggetti, non l’intensità della risposta. Le variabili psicologiche che hanno questa proprietà si dicono ordinali. Nel caso di variabili ordinali, non è possibile sintetizzare i dati mediante le statistiche descrittive che abbiamo introdotto in questo capitolo, quali ad esempio la media e la varianza, ma è invece solo possibile riassumere i dati mediante una distribuzione di frequenze per le varie modalità della risposta. 5.7 Correlazione nulla Un ultimo aspetto da mettere in evidenza a proposito della correlazione riguarda il fatto che la correlazione descrive la direzione e l’intensità della relazione lineare tra due variabili. Relazioni non lineari tra le variabili, anche se sono molto forti, non vengono catturate dalla correlazione. È importante rendersi conto che una correlazione pari a zero non significa che non c’è relazione tra le due variabili, ma solo che tra esse non c’è una relazione lineare. Esercizio 5.2 La figura 5.2 fornisce un esempio di correlazione nulla in presenza di una chiara relazione (non lineare) tra due variabili. FIGURA 5.2: Due insiemi di dati (fittizi) per i quali i coefficienti di correlazione di Pearson sono entrambi 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili. Commenti e considerazioni finali La prima fase dell’analisi dei dati riassume i dati mediante gli strumenti della statistica descrittiva. Le tipiche domande che vengono affrontate in questa fase sono: qual è la distribuzione delle variabili di interesse? Quali relazioni a coppie si possono osservare nel campione? Ci sono delle osservazioni ‘anomale’, ovvero estremamente discrepanti rispetto alle altre, sia quando si esaminano le statistiche descrittive univariate (ovvero, quelle che riguardano le caratteristiche di una variabile presa singolarmente), sia quando vengono esaminate le statistiche bivariate (ovvero, le statistiche che descrivono l’associazione tra le variabili)? È importante avere ben chiare le idee su questi punti prima di procedere con qualsiasi procedura statistica di tipo inferenziale. Per rispondere alle domande che abbiamo elencato sopra, ed ad altre simili, è molto utile procedere con delle rappresentazioni grafiche dei dati. È chiaro che, quando disponiamo di grandi moli di dati (come è sempre il caso in psicologia), l’analisi descrittiva dei dati deve essere svolta mediante un software statistico. References "],["ch-intro-prob-1.html", "Capitolo 6 La logica dell’incerto 6.1 Che cos’è la probabilità? 6.2 Variabili casuali e probabilità di un evento 6.3 Variabili casuali 6.4 Usare la simulazione per stimare le probabilità 6.5 La legge dei grandi numeri 6.6 Variabili casuali multiple 6.7 Funzione di massa di probabilità Commenti e considerazioni finali", " Capitolo 6 La logica dell’incerto In questa parte della dispensa verrà introdotta la teoria delle probabilità. Prima di entrare nei dettagli, cerchiamo di capire perché la probabilità sia cruciale per la ricerca scientifica. La teoria delle probabilità è cruciale per la scienza perché la ricerca procede mediante l’inferenza induttiva. Non siamo mai completamente sicuri della verità di una proposizione (ipotesi, teoria): al valore di verità di una proposizione possiamo solo assegnare un giudizio probabilistico. L’approccio bayesiano è una scuola di pensiero che usa la probabilità per quantificare il grado di fiducia che può essere attribuito ad una proposizione. L’inferenza statistica bayesiana è un tipo di inferenza induttiva che ha lo scopo di quantificare la fiducia che si ha nell’ipotesi \\(H\\) dopo il verificarsi del dato d’evidenza \\(E\\). Per quantificare un tale grado di fiducia l’inferenza statistica bayesiana utilizza la teoria delle probabilità. Una comprensione dell’inferenza statistica bayesiana richiede dunque, preliminarmente, la conoscenze della teoria delle probabilità. 6.1 Che cos’è la probabilità? La definizione della probabilità è un problema estremamente dibattuto ed aperto. Sono state fornite due possibili soluzioni al problema di definire il concetto di probabilità. La natura della probabilità è “ontologica” (ovvero, basata sulla metafisica): la probabilità è una proprietà della della realtà, del mondo, di come sono le cose, indipendentemente dalla nostra esperienza. È una visione che qualcuno chiama “oggettiva”. La natura della probabilità è “epistemica” (ovvero, basata sulla conoscenza): la probabilità si riferisce alla conoscenza che abbiamo del mondo, non al mondo in sé. Di conseguenza è detta, in contrapposizione alla precedente definizione, “soggettiva”. In termini epistemici, la probabilità fornisce una misura della nostra incertezza sul verificarsi di un fenomeno, alla luce delle informazioni disponibili. Potremmo dire che c’è una “scala” naturale che ha per estremi il vero (1: evento certo) da una parte ed il falso (0: evento impossibile) dall’altra. La probabilità è la quantificazione di questa scala: descrive lo stato della nostra incertezza rispetto al contenuto di verità di una proposizione. L’incertezza nelle nostre previsioni può sorgere per due ragioni fondamentalmente diverse. Il primo è dovuto alla nostra ignoranza delle cause nascoste sottostanti o dei meccanismi che generano i dati. Questa è appunto un’incertezza epistemica. Il secondo tipo di incertezza deriva dalla variabilità intrinseca dei fenomeni, che non può essere ridotta anche se raccogliamo più dati. Questa seconda forma di incertezza è talvolta chiamata aleatoria. Come esempio concreto, consideriamo il lancio di una moneta equilibrata. Sappiamo con certezza che la probabilità di testa è \\(P = 0.5\\), quindi non c’è incertezza epistemica, ma non questo non è sufficiente per prevedere con certezza il risultato – ovvero, l’incertezza aleatoria persiste anche in assenza di incertezza epistemica. Nell’interpretazione frequentista, la probabilità \\(P(E)\\) rappresenta la frequenza relativa a lungo termine di un grande numero di ripetizioni di un esperimento casuale sotto le medesime condizioni. Viene stressata qui l’idea che ciò di cui parliamo è qualcosa che emerge nel momento in cui è possibile ripetere l’esperimento casuale tante volte sotto le medesime condizioni – sono invece esclusi gli eventi unici e irripetibili. L’interpretazione bayesiana della probabilità fa invece ricorso ad una concezione più ampia, non legata al solo evento in sé ma che include anche il soggetto assegnante la funzione di probabilità. In pratica l’assegnazione di probabilità bayesiana viene effettuata dal decisore, in base alle proprie conoscenze a priori integrate con tutto il generico bagaglio culturale personale. In questo modo, la probabilità non sarà obbligatoriamente la stessa per tutti i soggetti, ma variarierà a seconda delle informazioni a disposizione, dell’esperienza personale e soprattutto del punto di vista proprio di ogni decisore ed è dunque assimilabile al “grado di fiducia” – in inglese degree of belief – di un dato soggetto, in un dato istante e con un dato insieme d’informazioni, circa l’accadere dell’evento \\(E\\). “[N]essuna scienza ci permetterà di dire: il tale fatto accadrà, andrà così e così, perché ciò è conseguenza di tale legge, e tale legge è una verità assoluta, ma tanto meno ci condurrà a concludere scetticamente: la verità assoluta non esiste, e quindi tale fatto può accadere e può non accadere, può andare così e può andare in tutt’altro modo, nulla io ne so. Quel che si potrà dire è questo: io prevedo che il tale fatto avverrà, e avverrà nel tal modo, perché l’esperienza del passato e l’elaborazione scientifica cui il pensiero dell’uomo l’ha sottoposta mi fanno sembrare ragionevole questa previsione” (Finetti 1931). L’impostazione bayesiana, sviluppata da Ramsey e de Finetti, riconduce l’assegnazione di probabilità allo scommettere sul verificarsi di un evento: la probabilità di un evento \\(E\\) è la quota \\(p(E)\\) che un individuo reputa di dover pagare ad un banco per ricevere “1” ovvero “0” verificandosi o non verificandosi \\(E\\). Secondo De Finetti, le valutazioni di probabilità degli eventi devono rispondere ai principi di equità e coerenza. Una scommessa risponde al principio di equità se il ruolo di banco e giocatore sono scambiabili in ogni momento del gioco e sempre alle stesse condizioni. Una scommessa risponde al principio di coerenza se non vi sono combinazioni di scommesse che consentano (sia al banco che al giocatore) di realizzare perdite o vincite certe. L’approccio definettiano dell’impostazione della scommessa si basa dunque sulle assunzioni di razionalità e coerenza del decisore, al quale è fatto esplicito divieto di effettuare scommesse a perdita o guadagno certo. Il decisore, proponendo la scommessa, deve essere disposto a scambiare il posto dello scommettitore con quello del banco. Il metodo della scommessa, oltre che una definizione, fornisce un mezzo operativo di assegnazione della probabilità. Sulla base di questa definizione operativa, che si può ritenere ragionevolmente soddisfatta dal comportamento di un qualunque individuo che agisca in modo razionale in condizioni di incertezza, possono essere agevolmente dimostrate tutte le proprietà classiche della probabilità: essa non può assumere valori negativi, né può essere superiore all’unità; se \\(E\\) è un evento certo, la sua probabilità è 1; se invece \\(E\\) è un evento impossibile, la sua probabilità è 0. I problemi posti dall’approccio definettiano riguardano l’arbitrarietà dell’assegnazione soggettività di probabilità la quale sembra negare la validità dell’intero costrutto teorico. In risposta a tale critica, i bayesiani sostengono che gli approcci oggettivisti alla probabilità nascondono scelte arbitrarie preliminari e sono basate su assunzioni implausibili. È molto più onesto esplicitare subito tutte le scelte arbitrarie effettuate nel corso dell’analisi in modo da controllarne coerenza e razionalità. 6.2 Variabili casuali e probabilità di un evento Esaminiamo qui di seguito alcuni concetti di base della teoria delle probabilità, la quale può essere vista come un’estensione della logica. 6.2.1 Eventi e probabilità Nella teoria delle probabilità il risultato “testa” nel lancio di una moneta è chiamato evento.6 Un evento, denotato da una variabile binaria, corrisponde ad uno stato del mondo che si verifica oppure no. Ad esempio, \\(Y\\) = 1 può denotare l’evento per cui il lancio di una moneta produce il risultato testa. Il funzionale \\(P(Y)\\) denota la probabilità con cui si ritiene che l’evento \\(Y\\) sia vero (o la proporzione di volte che si verifica tale evento osservando a lungo termine delle ripetizioni indipendenti di un esperimento casuale). Ad esempio, per il lancio di una moneta equilibrata, la probabilità dell’evento “il risultato del lancio della moneta è testa” è scritta come \\(P(Y = 1) = 0.5.\\) Se la moneta è equilibrata dobbiamo anche avere \\(P(Y = 0) = 0.5\\). I due eventi Y = 1 e \\(Y\\) = 0 sono mutuamente esclusivi nel senso che non possono entrambi verificarsi contemporaneamente: \\(P(Y = 1\\; \\land \\; Y = 0) = 0.\\) Gli eventi \\(Y\\) = 1 e \\(Y\\) = 0 di dicono esaustivi, nel senso che almeno uno di essi deve verificarsi e nessun altro tipo di evento è possibile. Nella notazione probabilistica, \\(P(Y = 1\\; \\lor \\; Y = 0) = 1.\\) Il connettivo logico “o” (\\(\\lor\\)) specifica eventi disgiunti, ovvero eventi che non possono verificarsi contemporaneamente (eventi incompatibili) e per i quali, perciò, la probabilità della loro congiunzione è \\(P(A \\; \\land \\; B) = 0\\). Il connettivo logico “e” (\\(\\land\\)), invece, specifica eventi congiunti, ovvero eventi che possono verificarsi contemporaneamente (eventi compatibili) e per i quali, perciò, la probabilità della loro congiunzione è \\(P(A \\; \\land \\; B) &gt; 0\\). La probabilità del verificarsi di due eventi congiunti \\(A\\) e \\(B\\) si può denotare, in maniera equivalente, con la notazione precedente, oppure con \\(P(A \\cap B)\\), oppure con \\(P(A, B)\\). Si richiede che \\(0 \\leq P(A) \\leq 1\\), dove \\(P(A) = 0\\) denota l’evento impossibile e \\(P(A) = 1\\) denota l’evento certo. Scriviamo \\(P(\\lnot A)\\) o \\(P(\\bar{A})\\) per denotare la probabilità che l’evento \\(A\\) non avvenga; questa probabilità è definita come \\(P(\\bar{A}) = 1 − P(A)\\). 6.2.2 Spazio campione e risultati possibili Anche se il lancio di una moneta produce sempre uno specifico risultato nel mondo reale, possiamo anche immaginare i possibili risultati alternativi che si sarebbero potuti osservare. Quindi, anche se in uno specifico lancio la moneta dà testa (\\(Y\\) = 1), possiamo immaginare la possibilità che il lancio possa avere prodotto croce (\\(Y\\) = 0). Tale ragionamento controfattuale è la chiave per comprendere la teoria delle probabilità e l’inferenza statistica. I risultati possibili che si possono osservare come conseguenza del lancio di una moneta determinano i valori possibili che la variabile casuale può assumere. L’insieme \\(\\Omega\\) di tutti i risultati possibili è chiamato spazio campione (sample space). Lo spazio campione può essere concettualizzato come un’urna contenente una pallina per ogni possibile risultato del lancio della moneta. Su ogni pallina è scritto il valore della variabile casuale. Uno specifico lancio di una moneta – ovvero, l’osservazione di uno specifico valore di una variabile casuale – è chiamato esperimento casuale. Il lancio di un dado ci fornisce l’esempio di un altro esperimento casuale. Supponiamo di essere interessati all’evento “il lancio del dado produce un numero dispari”. Un evento seleziona un sottoinsieme dello spazio campione: in questo caso, l’insieme dei risultati \\(\\{1, 3, 5\\}\\). Se esce 3, per esempio, diciamo che si è verificato l’evento “dispari” (ma l’evento “dispari” si sarebbe anche verificato anche se fosse uscito 1 o 5). 6.3 Variabili casuali Sia \\(Y\\) il risultato del lancio di moneta equilibrata, non di un generico lancio di una moneta, ma un’istanza specifica del lancio di una specifica moneta in un dato momento. Definita in questo modo, \\(Y\\) è una variabile casuale, ovvero una variabile i cui valori non possono essere previsti con esattezza. Se la moneta è equilibrata, c’è una probabilità del 50% che il lancio della moneta dia come risultato “testa” e una probabilità del 50% che dia come risultato “croce”. Per facilitare la trattazione, le variabili casuali assumono solo valori numerici. Per lo specifico lancio della moneta in questione, diciamo, ad esempio, che la variabile casuale \\(Y\\) assume il valore 1 se esce testa e il valore 0 se esce croce. Una variabile casuale può essere discreta o continua. Una variabile casuale discreta può assumere un numero finito di valori \\(x_1, \\dots ,x_n\\), in corrispondenza degli eventi \\(E_i, \\dots, E_n\\) che si verificano con le rispettive probabilità \\(p_1, \\dots, p_n\\). Un esempio è il punteggio totale di un test psicometrico costituito da item su scala Likert. Invece un esempio di una variabile casuale continua è la distanza tra due punti, che può assumere infiniti valori all’interno di un certo intervallo. L’insieme \\(S\\) dei valori che la variabile casuale può assumere è detto spazio dei valori o spazio degli stati. La caratteristica fondamentale di una variabile casuale è data dall’insieme delle probabilità dei suoi valori, detta distribuzione di probabilità. Nel seguito useremo la notazione \\(P(\\cdot)\\) per fare riferimento alle distribuzioni di probabilità delle variabili casuali discrete e \\(p(\\cdot)\\) per fare riferimento alla densità di probabilità delle variabili casuali continue. In questo contesto, l’insieme dei valori che la variabile casuale può assumere è detto supporto della sua distribuzione di probabilità. Il supporto di una variabile casuale può essere finito (come nel caso di una variabile casuale uniforme di supporto \\([a, b]\\)) o infinito (nel caso di una variabile causale gaussiana il cui supporto coincide con la retta reale). 6.4 Usare la simulazione per stimare le probabilità In questa dispensa verrà adottata l’interpretazione bayesiana delle probabilità. Tuttavia, le regole di base della teoria delle probabilità sono le stesse, indipendentemente dall’interpretazione adottata. Pertanto, negli esempi seguenti, possiamo utilizzare la simulazione per stimare le probabilità degli eventi in un modo diretto, ovvero mediante la generazione di molteplici osservazioni delle variabili casuali derivate dagli eventi di interesse. Ad esempio, per simulare in \\(\\R\\) il lancio di una moneta equilibrata iniziamo con il definire un vettore che contiene i risultati possibili del lancio della moneta (ovvero i valori possibili della variabile casuale \\(Y\\)): coin &lt;- c(0, 1) L’estrazione casuale di uno di questi due possibili valori (ovvero, la simulazione di uno specifico lancio di una moneta) si realizza con la funzione sample(): sample(coin, size = 1) #&gt; [1] 0 In maniera equivalente, la stessa operazione si può realizzare mediante l’istruzione rbinom(1, 1, 0.5) #&gt; [1] 1 Supponiamo di ripetere questo esperimento casuale 100 volte e di registrare i risultati così ottenuti. La stima della probabilità dell’evento \\(P(Y = 1)\\) è data dalla frequenza relativa del numero di volte in cui abbiamo osservato l’evento di interesse (\\(Y = 1\\)): M &lt;- 100 y &lt;- rep(NA, M) for (m in 1:M) { y[m] = rbinom(1, 1, 0.5) } estimate = sum(y) / M cat(&quot;estimated P[Y = 1] =&quot;, estimate) #&gt; estimated P[Y = 1] = 0.53 Ripetiamo questa procedura 10 volte. flip_coin &lt;- function(M) { y &lt;- rep(NA, M) for (m in 1:M) { y[m] = rbinom(1, 1, 0.5) } estimate &lt;- sum(y) / M cat(&quot;estimated P[Y = 1] =&quot;, estimate, &quot;\\n&quot;) } for(i in 1:10) { flip_coin(100) } #&gt; estimated P[Y = 1] = 0.44 #&gt; estimated P[Y = 1] = 0.52 #&gt; estimated P[Y = 1] = 0.46 #&gt; estimated P[Y = 1] = 0.57 #&gt; estimated P[Y = 1] = 0.47 #&gt; estimated P[Y = 1] = 0.46 #&gt; estimated P[Y = 1] = 0.48 #&gt; estimated P[Y = 1] = 0.49 #&gt; estimated P[Y = 1] = 0.47 #&gt; estimated P[Y = 1] = 0.62 Dato che la moneta è equilibrata, la stima delle probabilità dell’evento \\(P(Y = 1)\\) è simile a al valore che ci aspettiamo, ovvero \\(P(Y = 1) = 0.5\\), ma il risultato ottenuto nelle simulazioni non è esatto. Proviamo ad aumentare il numero di lanci in ciascuna simulazione: for(i in 1:10) { flip_coin(1000) } #&gt; estimated P[Y = 1] = 0.497 #&gt; estimated P[Y = 1] = 0.529 #&gt; estimated P[Y = 1] = 0.493 #&gt; estimated P[Y = 1] = 0.511 #&gt; estimated P[Y = 1] = 0.506 #&gt; estimated P[Y = 1] = 0.52 #&gt; estimated P[Y = 1] = 0.49 #&gt; estimated P[Y = 1] = 0.495 #&gt; estimated P[Y = 1] = 0.489 #&gt; estimated P[Y = 1] = 0.496 In questo secondo caso, gli errori tendono ad essere più piccoli che nel caso precedente. Cosa succede se in ciascuna simulazione esaminiamo i risultati di 10,000 lanci della moneta? for(i in 1:10) { flip_coin(1e4) } #&gt; estimated P[Y = 1] = 0.4885 #&gt; estimated P[Y = 1] = 0.4957 #&gt; estimated P[Y = 1] = 0.4902 #&gt; estimated P[Y = 1] = 0.5032 #&gt; estimated P[Y = 1] = 0.5048 #&gt; estimated P[Y = 1] = 0.4931 #&gt; estimated P[Y = 1] = 0.4965 #&gt; estimated P[Y = 1] = 0.499 #&gt; estimated P[Y = 1] = 0.4979 #&gt; estimated P[Y = 1] = 0.4973 Ora le stime ottenute sono molto vicine alla vera probabilità che vogliamo stimare (cioè 0.5, perché la moneta è equilibrata). I risultati delle simulazioni precedenti pongono dunque il problema di determinare quale sia il numero di lanci di cui abbiamo bisogno per assicurarci che le stime siano accurate (ovvero, vicine al valore corretto della probabilità) 6.5 La legge dei grandi numeri La visualizzazione mediante grafici contribuisce alla comprensione dei concetti della statistica e della teoria delle probabilità. Un modo per descrivere ciò che accade all’aumentare del numero \\(M\\) di ripetizioni del lancio della moneta consiste nel registrare la stima della probabilità dell’evento \\(P(Y = 1)\\) in funzione del numero di ripetizioni dell’esperimento casuale per ogni \\(m \\in 1:M\\). Possiamo ottenere un grafico dell’andamento della stima di \\(P(Y = 1)\\) in funzione di \\(m\\) nel modo seguente: nrep &lt;- 1e4 estimate &lt;- rep(NA, nrep) flip_coin &lt;- function(m) { y &lt;- rbinom(m, 1, 0.5) phat &lt;- sum(y) / m phat } for(i in 1:nrep) { estimate[i] &lt;- flip_coin(i) } d &lt;- tibble( n = 1:nrep, estimate ) d %&gt;% ggplot(aes(x = n, y = estimate)) + geom_line() + labs( x = &quot;Numero di lanci della moneta&quot;, y = &quot;Stima di P(Y = 1)&quot; ) FIGURA 6.1: Stima della probabilità di successo in funzione del numero dei lanci di una moneta. La figura 6.1, quando è espressa su una scala lineare, non rivela chiaramente l’andamento della simulazione. Imponiamo dunque una scala logaritmica sull’asse delle ascisse (\\(x\\)). Su scala logaritmica, i valori tra 1 e 10 vengono tracciati all’incirca con la stessa ampiezza che si osserva tra i valori 50 e 700, eccetera. d %&gt;% ggplot(aes(x = n, y = estimate)) + geom_line() + geom_hline( yintercept = 0.5, color = &quot;gray&quot;, size = 1 ) + scale_x_log10( breaks = c( 1, 3, 10, 50, 200, 700, 2500, 10000 ) ) + labs( x = &quot;Numero dei lanci della moneta (scala logaritmica)&quot;, y = &quot;Stima di P(Y = 1)&quot; ) FIGURA 6.2: Stima della probabilità di successo in funzione del numero dei lanci di una moneta. La legge dei grandi numeri ci dice che, all’aumentare del numero di ripetizioni dell’esperimento casuale, la media dei risultati ottenuti tende al valore atteso, man mano che vengono eseguite più prove. Nella figura 6.2 vediamo infatti che, all’aumentare del numero M di lanci della moneta, la stima di \\(P(Y = 1)\\) converge al valore 0.5. 6.6 Variabili casuali multiple Le variabili casuali non esistono isolatamente. Abbiamo iniziato con una sola variabile casuale \\(Y\\) che rappresenta il risultato di un singolo, specifico lancio di una moneta equlibrata. Ma supponiamo ora di lanciare la moneta tre volte. I risultati di ciascuno dei tre lanci possono essere rappresentati da una diversa variabile casuale, ad esempio, \\(Y_1 , Y_2 , Y_3\\). Possiamo assumere che ogni lancio sia indipendente, ovvero che non dipenda dal risultato degli altri lanci. Per ciascuna di queste variabili \\(Y_n\\), con \\(n \\in 1:3\\), abbiamo che \\(P(Y_n =1)=0.5\\) e \\(P(Y_n =0)=0.5\\). È possibile combinare più variabili casuali usando le operazioni aritmetiche. Se \\(Y_1 , Y_2, Y_3\\) sono variabili casuali che rappresentano tre lanci di una moneta equilibrata (o un lancio di tre monete equilibrate), possiamo definire la somma di tali variabili casuali come \\[ Z = Y_1 + Y_2 + Y_3. \\] Possiamo simulare i valori assunti dalla variabile casuale Z simulando i valori di \\(Y_1, Y_2, Y_3\\) per poi sommarli. y1 &lt;- rbinom(1, 1, 0.5) y2 &lt;- rbinom(1, 1, 0.5) y3 &lt;- rbinom(1, 1, 0.5) c(y1, y2, y3) #&gt; [1] 1 0 1 z &lt;- sum(c(y1, y2, y3)) cat(&quot;z =&quot;, z, &quot;\\n&quot;) #&gt; z = 2 ovvero, y &lt;- rep(NA, 3) for (i in 1:3) { y[i] &lt;- rbinom(1, 1, 0.5) } y #&gt; [1] 0 1 1 z &lt;- sum(y) cat(&quot;z =&quot;, z, &quot;\\n&quot;) #&gt; z = 2 oppure, ancora più semplicemente: y &lt;- rbinom(3, 1, 0.5) y #&gt; [1] 1 0 1 z &lt;- sum(y) cat(&quot;z =&quot;, z, &quot;\\n&quot;) #&gt; z = 2 Possiamo ripetere questa simulazione \\(M = 1e5\\) volte: M &lt;- 1e5 z &lt;- rep(NA, M) for(i in 1:M) { y &lt;- rbinom(3, 1, 0.5) z[i] &lt;- sum(y) } e calcolare una stima della probabilità che la variabile casuale \\(Z\\) assuma ciascuno dei possibili valori 0, 1, 2, 3: table(z) / M #&gt; z #&gt; 0 1 2 3 #&gt; 0.12585 0.37495 0.37480 0.12440 Nel caso di 4 monete equilibrate, avremo: M &lt;- 1e5 z &lt;- rep(NA, M) for(i in 1:M) { y &lt;- rbinom(4, 1, 0.5) z[i] &lt;- sum(y) } table(z) / M #&gt; z #&gt; 0 1 2 3 4 #&gt; 0.06340 0.24917 0.37360 0.25022 0.06361 Una variabile casuale le cui modalità possono essere costituite solo da numeri interi è detta variabile casuale discreta: \\[ \\mathbb{Z} = \\dots, -2, -1, 0, 1, 2, \\dots \\] 6.7 Funzione di massa di probabilità È conveniente avere una funzione che associa una probabilità a ciascun possibile valore di una variabile casuale. In generale, ciò è possibile se e solo se la variabile casuale è discreta, così com’è stata definita nel Paragrafo precedente. Ad esempio, se consideriamo \\(Z = Y_1 + \\dots + Y_4\\) come, ad esempio, il numero di risultati “testa” in 4 lanci della moneta, allora possiamo definire la seguente funzione: \\[ \\begin{array}{rclll} p_Z(0) &amp; = &amp; 1/16 &amp; &amp; \\mathrm{TTTT} \\\\ p_Z(1) &amp; = &amp; 4/16 &amp; &amp; \\mathrm{HTTT, THTT, TTHT, TTTH} \\\\ p_Z(2) &amp; = &amp; 6/16 &amp; &amp; \\mathrm{HHTT, HTHT, HTTH, THHT, THTH, TTTH} \\\\ p_Z(3) &amp; = &amp; 4/16 &amp; &amp; \\mathrm{HHHT, HHTH, HTHH, THHH} \\\\ p_Z(4) &amp; = &amp; 1/16 &amp; &amp; \\mathrm{HHHH} \\end{array} \\] Il lancio di quattro monete può produrre 16 risultati possibili. Dato che i lanci sono indipendenti, se le monete sono equilibrate ogni possibile risultato è ugualmente probabile. Nella tabella in alto, le sequenze dei risultati possibili del lancio delle 4 monete sono riportate nella colonna più a destra. Le probabilità si ottengono dividendo il numero di sequenze che producono lo stesso numero di eventi testa per il numero dei risultati possibili. Le sequenze come \\(\\mathrm{TTTT}\\), \\(\\mathrm{HTTT}\\), ecc. sono chiamate “eventi elementari” (corrispondono ad un possibile esito dell’esperimento casuale). L’evento \\(Z = u\\), con \\(u \\in 0 \\dots, 4\\) è un “evento composto”, il quale può essere costituito da più eventi elementari. La funzione \\(p_Z\\) è stata costruita per associare a ciascun valore \\(u\\) della variabile casuale \\(Z\\) la probabilità dell’evento \\(Z = u\\). Convenzionalmente, queste probabilità sono scritte come \\[ P_Z(z) = P(Z = z). \\] La parte a destra dell’uguale si può leggere come: “la probabilità che la variabile casuale \\(Z\\) assuma il valore \\(z\\)”. Una funzione definita come sopra è detta funzione di massa di probabilità della variabile casuale \\(Z\\). Ad ogni variabile casuale discreta è associata un’unica funzione di massa di probabilità. Una rappresentazione grafica della stima della funzione di massa di probabilità per l’esperimento casuale del lancio di quattro monete equilibrate è fornita nella figura 6.3. set.seed(1234) M &lt;- 1e5 nflips &lt;- 4 u &lt;- rbinom(M, nflips, 0.5) x &lt;- 0:nflips y &lt;- rep(NA, nflips + 1) for (n in 0:nflips) { y[n + 1] &lt;- sum(u == n) / M } bar_plot &lt;- data.frame(Z = x, count = y) %&gt;% ggplot(aes(x = Z, y = count)) + geom_bar(stat = &quot;identity&quot;) + scale_x_continuous( breaks = 0:4, labels = c(0, 1, 2, 3, 4) ) + labs( y = &quot;Probabilità stimata P(Z = z)&quot; ) bar_plot FIGURA 6.3: Grafico di \\(M = 100,000\\) simulazioni della funzione di massa di probabilità di una variabile casuale definita come il numero di teste in quattro lanci di una moneta equilibrata. Se \\(A\\) è un sottoinsieme della variabile casuale \\(Z\\), allora denotiamo con \\(P_{z}(A)\\) la probabilità assegnata ad \\(A\\) dalla distribuzione \\(P_{z}\\). Mediante una distribuzione di probabilità \\(P_{z}\\) è dunque possibile determinare la probabilità di ciascun sottoinsieme \\(A \\subset Z\\) come \\[\\begin{equation} P_{z}(A) = \\sum_{z \\in A} P_{z}(Z = z). \\end{equation}\\] Una funzione di massa di probabilità soddisfa le proprietà \\(0 \\leq P(X=x) \\leq 1\\), \\(\\sum_{x \\in X} P(x) = 1\\). Esempio 6.1 Nel caso dell’esempio discusso nel Paragrafo 6.7, la probabilità che la variabile casuale \\(Z\\) sia un numero dispari è \\[ P(\\text{Z è un numero dispari}) = P_{z}(Z = 1) + P_{z}(Z = 3) = \\frac{4}{16} + \\frac{4}{16} = \\frac{1}{2}. \\] 6.7.1 Funzione di ripartizione Data una variabile casuale discreta \\(X\\) possiamo calcolare la probabilità che \\(X\\) non superi un certo valore \\(x\\), ossia la sua funzione di ripartizione. Poichè \\(X\\) assume valori discreti possiamo cumulare le probabilità mediante una somma: \\[\\begin{equation} F(x_k) = P(X \\leq x_k) = \\sum_{x \\leq x_k} P(x). \\end{equation}\\] Commenti e considerazioni finali In questo capitolo abbiamo visto come si costruisce lo spazio campione di un esperimento casuale, quali sono le proprietà di base della probabilità e come si assegnano le probabilità agli eventi definiti sopra uno spazio campione discreto. Abbiamo anche introdotto le nozioni di variabile casuale, ovvero di una variabile che assume i suoi valori in maniera casuale. Abbiamo descritto il modo di specificare la probabilità con cui sono una variabile casuale assume i suoi differenti valori, ovvero la funzione di ripartizione \\(F(X) = P(X &lt; x)\\) e la funzione di massa di probabilità. References "],["ch-prob-cond.html", "Capitolo 7 Probabilità condizionata 7.1 Probabilità condizionata su altri eventi 7.2 La regola moltiplicativa 7.3 L’indipendendenza stocastica 7.4 Il teorema della probabilità totale 7.5 Il teorema della probabilità assoluta 7.6 Indipendenza condizionale Commenti e considerazioni finali", " Capitolo 7 Probabilità condizionata Il fondamento della statistica bayesiana è il teorema di Bayes e il teorema di Bayes è una semplice ridescrizione della probabilità condizionata. Esaminiamo dunque la nozione di probabilità condizionata. 7.1 Probabilità condizionata su altri eventi L’attribuzione di una probabilità ad un evento è sempre condizionata dalle conoscenze che abbiamo a disposizione. Per un determinato stato di conoscenze, attribuiamo ad un dato evento una certa probabilità di verificarsi; ma se il nostro stato di conoscenze cambia, allora cambierà anche la probabilità che attribuiremo all’evento in questione. Infatti, si può pensare che tutte le probabilità siano probabilità condizionate, anche se l’evento condizionante non è sempre esplicitamente menzionato. Per introdurre la probabilità condizionata, Albert and Hu (2019) utilizzando il famoso paradosso delle tre carte. “Ci sono tre carte, delle quali la prima (\\(A\\)) è rossa su entrambi i lati, la seconda (\\(B\\)) su un lato è rossa e sull’altro è bianca e la terza (\\(C\\)) è bianca su entrambi i lati. Ponendo su un tavolo una delle tre carte, scelta a caso, ottengo che il lato visibile è di colore rosso. Qual è la probabilità che anche il lato non visibile sia di colore rosso? La risposta intuitiva porta solitamente a rispondere che la probabilità ricercata sia pari al 50%, in quanto solo due carte (la \\(A\\) e la \\(B\\)) possono mostrare il colore rosso e solo una di queste (la \\(A\\)) può mostrare anche sull’altro lato il colore rosso; tuttavia si dimostra che la risposta giusta è 2/3.” (da Wikipedia) Albert and Hu (2019) propongono di risolvere il problema con una simulazione in \\(\\textsf{R}\\): prima di tutto si sceglie una carta a caso, e poi si sceglie un lato della carta. Ci sono tre carte possibili, che chiamiamo “c_rossa”, “c_bianca”, e “c_entrambi”. Per la carta rossa, ci sono due lati rossi; per la carta bianca ci sono due lati bianchi e la carta “entrambi” ha un lato rosso e un lato bianco. df &lt;- tibble( Carta = c( &quot;c_rossa&quot;, &quot;c_rossa&quot;, &quot;c_bianca&quot;, &quot;c_bianca&quot;, &quot;c_entrambi&quot;, &quot;c_entrambi&quot; ), Lato = c( &quot;rosso&quot;, &quot;rosso&quot;, &quot;bianco&quot;, &quot;bianco&quot;, &quot;rosso&quot;, &quot;bianco&quot; ) ) df #&gt; # A tibble: 6 × 2 #&gt; Carta Lato #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 c_rossa rosso #&gt; 2 c_rossa rosso #&gt; 3 c_bianca bianco #&gt; 4 c_bianca bianco #&gt; 5 c_entrambi rosso #&gt; 6 c_entrambi bianco Estraiamo una carta a caso e classifichiamo il risultato ottenuto in base al tipo di carta e lato osservato. Ripetiamo l’esperimento 1,000 volte: set.seed(84735) carte &lt;- sample_n(df, 1e3, replace = TRUE) table(carte$Carta, carte$Lato) #&gt; #&gt; bianco rosso #&gt; c_bianca 353 0 #&gt; c_entrambi 143 160 #&gt; c_rossa 0 344 Se si osserva il colore rosso (seconda colonna nella tabella precedente), questo risultato è dovuto ad una carta \\(A\\) (“rossa”) in 344 casi e ad una carta \\(B\\) (“entrambi”) in 160 casi. Quindi, nella simulazione il risultato per cui è stato osservato un colore rosso (344 + 160) è associato ad una carta \\(A\\) (“rossa”) in circa 2/3 dei casi – se il lato visibile è di colore rosso, allora c’è una probabilità di 2/3 che anche il lato non visibile sia di colore rosso. Questo esempio dimostra come le nostre intuizioni a proposito della probabilità condizionata non sono sempre corrette. Consideriamo un altro problema più articolato. Esercizio 7.1 Supponiamo che lo screening per la diagnosi precoce del tumore mammario si avvalga di un test che è accurato al 90%, nel senso che classifica correttamente il 90% delle donne colpite dal cancro e il 90% delle donne che non hanno il cancro al seno. Supponiamo che l’1% delle donne sottoposte allo screening abbia effettivamente il cancro al seno (e d’altra parte, il 99% non lo ha). Ci chiediamo: (1) qual è la probabilità che una donna scelta a caso ottenga una mammografia positiva, e (2) se la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno? Per risolvere questo problema, supponiamo che il test in questione venga somministrato ad un grande campione di donne, diciamo a 1000 donne. Di queste 1000 donne, 10 (ovvero, l’1%) hanno il cancro al seno. Per queste 10 donne, il test darà un risultato positivo in 9 casi (ovvero, nel 90% dei casi). Per le rimanenti 990 donne che non hanno il cancro al seno, il test darà un risultato positivo in 99 casi (se la probabilità di un vero positivo è del 90%, la probabilità di un falso positivo è del 10%). Questa situazione è rappresentata nella figura 7.1. Combinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non ce l’hanno, per un totale di 108 risultati positivi. Dunque, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 11%. Ma delle 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno il cancro al seno. Dunque, la probabilità di essere una donna che ha veramente il cancro al seno, dato un risultato positivo al test (che ha le proprietà descritte sopra), è pari a \\(\\frac{9}{108}\\) = 8%. FIGURA 7.1: Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia in un campione di 1,000 donne. Nell’esercizio precedente, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, mentre la probabilità dell’evento “avere il cancro al seno, dato che il test ha prodotto un risultato positivo” è una probabilità condizionata. In termini generali, la probabilità condizionata \\(P(A \\mid B)\\) rappresenta la probabilità che si verifichi l’evento \\(A\\) sapendo che si è verificato l’evento \\(B\\). Arriviamo dunque alla seguente definizione. Definizione 7.1 Dato un qualsiasi evento \\(A\\), si chiama probabilità condizionata di \\(A\\) dato \\(B\\) il numero \\[\\begin{equation} P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{con}\\, P(B) &gt; 0, \\tag{7.1} \\end{equation}\\] dove \\(P(A\\cap B)\\) è la probabilità congiunta dei due eventi, ovvero la probabilità che si verifichino entrambi. Concludiamo con un problema molto semplice per consolidare la nostra comprensione del concetto di probabilità condizionata. Esercizio 7.2 Da un mazzo di 52 carte (13 carte per ciascuno dei 4 semi) ne viene estratta una in modo casuale. Qual è la probabilità che esca una figura di cuori? Sapendo che la carta estratta ha il seme di cuori, qual è la probabilità che il valore numerico della carta sia 7, 8 o 9? Ci sono 13 carte di cuori, dunque la risposta alla prima domanda è 1/4. Questa è una probabilità non condizionata, dunque il suo calcolo non presenta alcuna difficoltà. La seconda probabilità cercata è una probabilità condizionata. Anche in questo secondo caso dobbiamo solo contare, ma, in questo caso, considerando solo un sottoinsieme di carte, ovvero le 13 carte di cuori. In questo modo è facile arrivare al risultato cercato, ovvero 3/13. Applicando la formula (7.1), con \\(A\\) = 7, 8, o 9, e \\(B\\) = cuori arriviamo allo stesso risulato: \\[ P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{3/52}{13/52} = \\frac{3}{13}. \\] 7.2 La regola moltiplicativa Dalla definizione di probabilità condizionata è possibile esprimere la probabilità congiunta tramite le condizionate. La regola moltiplicativa (o legge delle probabilità composte, o regola della catena) afferma che la probabilità che si verifichino due eventi \\(A\\) e \\(B\\) è pari alla probabilità di uno dei due eventi moltiplicato con la probabilità dell’altro evento condizionato al verificarsi del primo: \\[\\begin{equation} P(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A). \\tag{7.2} \\end{equation}\\] La (7.2) si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente: \\[\\begin{equation} P\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left( A_k \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right) \\tag{7.3} \\end{equation}\\] Per esempio, nel caso di quattro eventi abbiamo \\[\\begin{equation} \\begin{split} P(A_1 \\cap A_2 \\cap A_3 \\cap A_4) = {}&amp; P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot P(A_3 \\mid A_1 \\cap A_2) \\cdot \\\\ &amp; P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag \\end{split} \\end{equation}\\] Esercizio 7.3 Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e la sua probabilità vale, per la (7.2) \\[ P(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1). \\] \\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto: \\[ P(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}. \\] In modo analogo si ha che \\[ P(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}. \\] Se l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche vale, per la (7.3): \\[ P(B_1 \\cap B_2 \\cap B_3)=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2), \\] dove la probabilità \\(P(B_3 \\mid B_1 \\cap B_2)\\) si calcola supponendo che si sia verificato l’evento condizionante \\(\\{B_1 \\cap B_2\\}\\). Lo spazio campionario per questa probabilità condizionata è costituito da 4 palline bianche e 4 nere, per cui \\(P(B_3 \\mid B_1 \\cap B_2) = 1/2\\) e quindi: \\[ P (B_1 \\cap B_2 \\cap B_3) = \\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} = \\frac{1}{6}. \\] La probabilità dell’estrazione di tre palline nere è invece: \\[ \\begin{aligned} P(N_1 \\cap N_2 \\cap N_3) &amp;= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\ &amp;= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} = \\frac{1}{30}.\\notag \\end{aligned} \\] 7.3 L’indipendendenza stocastica Un concetto molto importante per le applicazioni statistiche della probabilità è quello dell’indipendenza stocastica. La definizione (7.1) consente di esprimere il concetto di indipendenza di un evento da un altro in forma intuitiva: se \\(A\\) e \\(B\\) sono eventi indipendenti, allora il verificarsi di \\(A\\) non influisce sulla probabilità del verificarsi di \\(B\\), ovvero non la condiziona, e il verificarsi di \\(B\\) non influisce sulla probabilità del verificarsi di \\(A\\). Infatti, per la (7.1), si ha che, se \\(A\\) e \\(B\\) sono due eventi indipendenti, risulta: \\[ P(A \\mid B) = \\frac{P(A)P(B)}{P(B)} = P(A), \\] \\[ P(B \\mid A) = \\frac{P(A)P(B)}{P(A)} = P(B). \\] Possiamo dunque dire che due eventi \\(A\\) e \\(B\\) sono indipendenti se \\[\\begin{equation} \\begin{split} P(A \\mid B) &amp;= P(A), \\\\ P(B \\mid A) &amp;= P(B). \\end{split} \\end{equation}\\] Esercizio 7.4 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = {esce un 1 o un 2 nel primo lancio} e \\(B\\) = {il punteggio totale è 8}. Gli eventi \\(A\\) e \\(B\\) sono indipendenti? Rappresentiamo qui sotto lo spazio campione dell’esperimento casuale. FIGURA 7.2: Rappresentazione dello spazio campionario dei risultati dell’esperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l’evento \\(B\\): ‘il punteggio totale è 8’. Gli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti. Infatti, le loro probabilità valgono \\(P(A) = 12/36\\) e \\(P(B) = 5/36\\) e la probabilità della loro intersezione è \\[ P(A \\cap B) = 1/36 = 3/108 \\neq P(A)P(B) = 5/108. \\] Osservazione. Il concetto di indipendenza è del tutto differente da quello di incompatibilità. Si noti infatti che due eventi A e B incompatibili (per i quali si ha \\(A \\cap B = \\emptyset\\)) sono statisticamente dipendenti, poiché il verificarsi dell’uno esclude il verificarsi dell’altro: \\(P(A \\cap B)=0 \\neq P(A)P(B)\\). 7.4 Il teorema della probabilità totale Dato un insieme finito \\(A_i\\) di eventi, nel calcolo della probabilità dell’unione di tutti gli eventi, se gli eventi considerati non sono a due a due incompatibili, si deve tenere conto delle loro intersezioni. In particolare, la probabilità dell’unione di due eventi \\(A\\) e \\(B\\) è pari alla somma delle singole probabilità \\(P(A)\\) e \\(P(B)\\) diminuita della probabilità della loro intersezione: \\[\\begin{equation} P(A \\cup B) = P(A) + P(B) - P(A \\cap B). \\tag{7.4} \\end{equation}\\] Nel caso di tre eventi, si ha \\[ \\begin{split} P(A \\cup B \\cup C) &amp;= P(A)+P(B)+P(C)-P(A\\cap B)-P(A\\cap C) - \\\\ &amp; \\qquad P(B\\cap C) + P(A\\cap B\\cap C). \\end{split} \\] La formula per il caso di \\(n\\) eventi si ricava per induzione. Per il caso di due soli eventi, se \\(A\\) e \\(B\\) sono indipendenti, la (7.4) si modifica nella relazione seguente: \\[\\begin{equation} P(A \\cup B) = P(A) + P(B) - P(A)P(B). \\end{equation}\\] Nel caso di due eventi \\(A\\) e \\(B\\) incompatibili, se cioè \\(P(A \\cap B) = \\varnothing\\), si ha che \\[ A\\cap B=\\varnothing \\Rightarrow P(A\\cup B)=P(A)+P(B). \\] Si può dimostrare per induzione che ciò vale anche per un insieme finito di eventi \\(A_{n}\\) a due a due incompatibili, ovvero che: \\[ A_i\\cap A_j=\\varnothing, i\\neq j \\Rightarrow P\\left(\\bigcup_{i=1}^n A_i\\right)=\\sum_{i=1}^nP(A_i). \\] 7.5 Il teorema della probabilità assoluta Il teorema della probabilità assoluta consente di calcolare la probabilità di un evento \\(E\\) di cui sono note le probabilità condizionate rispetto ad altri eventi \\((H_i)_{i\\geq 1}\\), a condizione che essi costituiscano una partizione dell’evento certo \\(\\Omega\\), ovvero \\(\\bigcup_{i=1}^\\infty H_i = \\Omega\\); \\(H_j \\cap H_j = \\emptyset, i\\neq j\\); \\(P(H_i) &gt; 0, i = 1, \\dots, \\infty\\). Nel caso di una partizione dello spazio campione in \\(n\\) sottoinsiemi abbiamo \\[\\begin{equation} P(E) = \\sum_{i=1}^n P(H_i\\cap E) = \\sum_{i=1}^n P(E \\mid H_i) P(H_i). \\end{equation}\\] Consideriamo, ad esempio, una partizione dell’evento certo in tre sottoinsiemi. FIGURA 7.3: Partizione dell’evento certo \\(\\Omega\\) in tre sottoinsiemi sui quali viene definito l’evento \\(E\\). In tali circostanze si ha che \\[\\begin{equation} P(E) = P(E \\cap H_1) + P(E \\cap H_2) + P(E \\cap H_3), \\notag \\tag{7.5} \\end{equation}\\] ovvero \\[\\begin{equation} P(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2) + P(E \\mid H_3) P(H_3). \\tag{7.6} \\end{equation}\\] In base al teorema della probabilità assoluta, dunque, se l’evento \\(E\\) è costituito da tutti gli eventi elementari in \\(E \\cap H_1\\), \\(E \\cap H_2\\) e \\(E \\cap H_3\\), allora la sua probabilità è data dalla somma delle probabilità condizionate \\(P(E \\mid H_i)\\), ciascuna delle quali pesata per la probabilità dell’evento condizionante \\(H_i\\). Esercizio 7.5 Si considerino tre urne, ciascuna delle quali contiene 100 palline: Urna 1: 75 palline rosse e 25 palline blu, Urna 2: 60 palline rosse e 40 palline blu, Urna 3: 45 palline rosse e 55 palline blu. Una pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso? Sia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che corrisponde alla scelta dell’\\(i\\)-esima urna. Sappiamo che \\[ P(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45. \\] Gli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilità assoluta, la probabilità di estrarre una pallina rossa è dunque \\[ \\begin{split} P(R) &amp;= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\ &amp;= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\ &amp;=0.60. \\end{split} \\] 7.6 Indipendenza condizionale Aggiungo qui delle considerazioni sul concetto di indipendenza condizionale a cui si farà riferimento nell’ultima parte della dispensa. L’indipendenza condizionale descrive situazioni in cui un’osservazione è irrilevante o ridondante quando si valuta la certezza di un’ipotesi. L’indipendenza condizionale è solitamente formulata nei termini della probabilità condizionata, come un caso speciale in cui la probabilità dell’ipotesi data un’osservazione non informativa è uguale alla probabilità senza tale osservazione non informativa. Se \\(A\\) è l’ipotesi e \\(B\\) e \\(C\\) sono osservazioni, l’indipendenza condizionale può essere espressa come l’uguaglianza: \\[ P(A \\mid B,C)=P(A \\mid C). \\] Dato che \\(P(A \\mid B,C)\\) è uguale a \\(P(A \\mid C)\\), questa uguaglianza corrisponde all’affermazione che \\(B\\) non fornisce alcun contributo alla certezza di \\(A\\). In questo caso si dice che \\(A\\) e \\(B\\) condizionalmente indipendenti dato \\(C\\), scritto simbolicamente come: \\((A \\perp\\!\\!\\!\\!\\perp B \\mid C)\\). In maniera equivalente, l’indipendenza condizionale \\((A \\perp\\!\\!\\!\\!\\perp B \\mid C)\\) si verifica se: \\[ P(A, B \\mid C) = P(A \\mid C) P(B \\mid C). \\] Un esempio è il seguente (da Wikipedia). Siano due eventi le probabilità che le persone \\(A\\) e \\(B\\) tornino a casa in tempo per la cena, e il terzo evento è il fatto che una tempesta di neve ha colpito la città. Mentre sia \\(A\\) che \\(B\\) hanno una probabilità più piccola di tornare a casa in tempo per la cena di quando non c’è la neve, tali probabilità sono indipendenti l’una dall’altra. Cioè, sapere che \\(A\\) è in ritardo non ci dice nulla sul fatto che \\(B\\) sia in ritardo o meno – \\(A\\) e \\(B\\) potrebbero vivere in quartieri diversi, percorrere distanze diverse e utilizzare mezzi di trasporto diversi. Tuttavia, se sapessimo che \\(A\\) e \\(B\\) vivono nello stesso quartiere, usano lo stesso mezzo di trasporto e lavorano nello stesso luogo, allora i due eventi non sarebbero condizionatamente indipendenti. Commenti e considerazioni finali La probabilità condizionata è importante perché ci fornisce uno strumento per precisare il concetto di indipendenza statistica. Una delle domande più importanti delle analisi statistiche è infatti quella che si chiede se due variabili siano associate tra loro oppure no. In questo Capitolo abbiamo discusso il concetto di indipendenza (come contrapposto al concetto di associazione). In seguito vedremo come sia possibile fare inferenza sull’associazione tra variabili. References "],["ch-theorem-bayes.html", "Capitolo 8 Il teorema di Bayes 8.1 Il teorema di Bayes Commenti e considerazioni finali", " Capitolo 8 Il teorema di Bayes Il teorema di Bayes assume un ruolo fondamentale nell’interpretazione soggettivista della probabilità perché descrive l’aggiornamento della fiducia che si aveva nel verificarsi di una determinata ipotesi \\(H\\) (identificata con la probabilità assegnata all’ipotesi stessa) in conseguenza del verificarsi dell’evidenza \\(E\\). 8.1 Il teorema di Bayes Teorema 8.1 Sia \\((H_i)_{i\\geq 1}\\) una partizione dell’evento certo \\(\\Omega\\) e sia \\(E \\subseteq \\Omega\\) un evento tale che \\(p(E) &gt; 0\\), allora, per \\(i = 1, \\dots, \\infty\\): \\[\\begin{equation} {\\mbox{P}}(H_i \\mid E) = \\frac{{\\mbox{P}}(E \\mid H_i){\\mbox{P}}(H_i)}{\\sum_{j=1}^{\\infty}{\\mbox{P}}(H_j)P(E \\mid H_j)}. \\tag{8.1} \\end{equation}\\] La formula di Bayes contiene tre concetti fondamentali. I primi due distinguono il grado di fiducia precedente al verificarsi dell’evidenza \\(E\\) da quello successivo al verificarsi dell’evidenza \\(E\\). Pertanto, dati gli eventi \\(H, E \\subseteq \\Omega\\) si definisce probabilità a priori la probabilità che viene attribuita al verificarsi dell’ipotesi \\(H\\) prima di sapere che si è verificato l’evento \\(E\\), tenendo conto delle caratteristiche cognitive del decisore (esperienza, modo di pensare, ecc.); si definisce probabilità a posteriori la probabilità assegnata ad \\(H\\) una volta che sia noto \\(E\\), ovvero l’aggiornamento della probabilità a priori alla luce della nuova evidenza \\(E\\). Il terzo concetto definisce la probabilità che ha l’evento \\(E\\) di verificarsi quando è vera l’ipotesi \\(H\\), ovvero la probabilità dell’evidenza in base all’ipotesi. Pertanto, dati gli eventi \\(H, E \\subseteq \\Omega\\) si definisce verosimiglianza di \\(H\\) dato \\(E\\) la probabilità condizionata che si verifichi \\(E\\), se è vera \\(H\\): \\(P (E \\mid H)\\). Si noti che, per il calcolo della quantità a denominatore, si ricorre al teorema della probabilità assoluta. Esercizio 8.1 Per fare un esempio, considerando una partizione dell’evento certo \\(\\Omega\\) in due soli eventi che chiamiamo ipotesi \\(H_1\\) e \\(H_2\\). Supponiamo conosciute le probabilità a priori \\(P(H_1)\\) e \\(P(H_2)\\). Consideriamo un terzo evento \\(E \\subseteq \\Omega\\) con probabilità non nulla di cui si conosce la verosimiglianza, ovvero si conoscono le probabilità condizionate \\({\\mbox{P}}(E \\mid H_1)\\) e \\(P(E \\mid H_2)\\). Supponendo che si sia verificato l’evento \\(E\\), vogliamo conoscere le probabilità a posteriori delle ipotesi, ovvero \\(P(H_1 \\mid E)\\) e \\(P(H_2 \\mid E)\\). Per trovare le probabilità cercate scriviamo: \\[ \\begin{split} P(H_1 \\mid E) &amp;= \\frac{P(E \\cap H_1)}{P(E)}\\notag\\\\ &amp;= \\frac{P(E \\mid H_1) P(H_1)}{P(E)}. \\end{split} \\] Sapendo che \\(E = (E \\cap H_1) \\cup (E \\cap H_2)\\) e che \\(H_1\\) e \\(H_2\\) sono eventi disgiunti, ovvero \\(H_1 \\cap H_2 = \\emptyset\\), ne segue che possiamo calcolare \\({\\mbox{P}}(E)\\) utilizzando il teorema della probabilità assoluta: \\[ \\begin{split} P(E) &amp;= P(E \\cap H_1) + P(E \\cap H_2)\\notag\\\\ &amp;= P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2). \\end{split} \\] Sostituendo tale risultato nella formula precedente otteniamo: \\[\\begin{equation} P(H_1 \\mid E) = \\frac{P(E \\mid H_1)P(H_1)}{P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2)}. \\tag{8.2} \\end{equation}\\] Un lettore attento si sarà reso conto che, in precedenza, abbiamo già applicato il teorema di Bayes quando abbiamo risolto l’esercizio riportato nella Sezione 7.1. In quel caso, le due ipotesi erano “malattia”, che possiamo denotare con \\(M\\), e “malattia assente”, \\(M^\\complement\\). L’evidenza \\(E\\) è costituita dal risultato positivo al test, ovvero \\(+\\). Con questa nuova notazione la (8.2) diventa: \\[\\begin{equation} P(M \\mid +) = \\frac{P(+ \\mid M) P(M)}{P(+ \\mid M) P(M) + P(+ \\mid M^\\complement) P(M^\\complement)}\\notag \\end{equation}\\] Inserendo i dati nella formula, otteniamo \\[\\begin{align} P(M \\mid +) &amp;= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\ &amp;= \\frac{9}{108} \\notag\\\\ &amp;\\approx 0.083.\\notag \\end{align}\\] Commenti e considerazioni finali Il teorema di Bayes rende esplicito il motivo per cui la probabilità non possa essere pensata come uno stato oggettivo, quanto piuttosto come un’inferenza soggettiva e condizionata. Il denominatore del membro di destra della (8.1) è un semplice fattore di normalizzazione. Nel numeratore compaiono invece due quantità: \\({\\mbox{P}}(H_i\\)) e \\({\\mbox{P}}(E \\mid H_i)\\). La probabilità \\({\\mbox{P}}(H_i\\)) è la probabilità probabilità a priori (prior) dell’ipotesi \\(H_i\\) e rappresenta l’informazione che l’agente bayesiano possiede a proposito dell’ipotesi \\(H_i\\). Diremo che \\({\\mbox{P}}(H_i)\\) codifica il grado di fiducia che l’agente ripone in \\(H_i\\) precedentemente al verificarsi dell’evidenza \\(E\\). Nell’interpretazione bayesiana, \\({\\mbox{P}}(H_i)\\) rappresenta un giudizio personale dell’agente e non esistono criteri esterni che possano determinare se tale giudizio sia coretto o meno. La probabilità condizionata \\({\\mbox{P}}(E \\mid H_i)\\) rappresenta invece la verosimiglianza di \\(H_i\\) dato \\(E\\) e descrive la plausibilità che si verifichi l’evento \\(E\\) se è vera l’ipotesi \\(H_i\\). Il teorema di Bayes descrive la regola che l’agente deve seguire per aggiornare il suo grado di fiducia nell’ipotesi \\(H_i\\) alla luce del verificarsi dell’evento \\(E\\). La \\({\\mbox{P}}(H_i \\mid E)\\) è chiamata probabilità a posteriori dato che rappresenta la nuova probabilità che l’agente assegna all’ipotesi \\(H_i\\) affinché rimanga consistente con le nuove informazioni fornitegli da \\(E\\). La probabilità a posteriori dipende sia dall’evidenza \\(E\\), sia dalla conoscenza a priori dell’agente \\({\\mbox{P}}(H_i)\\). È dunque chiaro come non abbia senso parlare di una probabilità oggettiva: per il teorema di Bayes la probabilità è definita condizionatamente alla probabilità a priori, la quale a sua volta, per definizione, è un’assegnazione soggettiva. Ne segue pertanto che ogni probabilità deve essere considerata come una rappresentazione del grado di fiducia soggettiva dell’agente. Dato che ogni assegnazione probabilistica rappresenta uno stato di conoscenza e che ciascun particolare stato di conoscenza è arbitrario, un accordo tra agenti diversi non è richiesto. Tuttavia, la teoria delle probabilità ci fornisce uno strumento che, alla luce di nuove evidenze, consente di aggiornare in un modo razionale il grado di fiducia che attribuiamo ad un’ipotesi, via via che nuove evidenze vengono raccolte, in modo tale da formulare un’ipotesi a posteriori la quale non è mai definitiva, ma può sempre essere aggiornata in base alle nuove evidenze disponibili. Questo processo si chiama aggiornamento bayesiano. Vedremo nel Capitolo ?? come estendere la (8.1) al caso continuo. "],["ch-prob-congiunta.html", "Capitolo 9 Probabilità congiunta 9.1 Funzione di probabilità congiunta 9.2 Marginalizzazione di variabili casuali continue Commenti e considerazioni finali", " Capitolo 9 Probabilità congiunta La probabilità congiunta è la probabilità che due o più eventi si verifichino contemporaneamente. In questo Capitolo verrà esaminato in dettaglio il caso discreto. 9.1 Funzione di probabilità congiunta Dopo aver trattato della distribuzione di probabilità di una variabile casuale, la quale associa ad ogni evento elementare dello spazio campione uno ed un solo numero reale, è naturale estendere questo concetto al caso di due o più variabili casuali. Iniziamo a descrivere il caso discreto con un esempio. Consideriamo l’esperimento casuale corrispondente al lancio di tre monete equilibrate. Lo spazio campione è \\[ \\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\}. \\] Dato che i tre lanci sono tra loro indipendenti, non c’è ragione di aspettarsi che uno degli otto risultati possibili dell’esperimento sia più probabile degli altri, dunque possiamo associare a ciascuno degli otto eventi elementari dello spazio campione la stessa probabilità, ovvero 1/8. Siano \\(X \\in \\{0, 1, 2, 3\\}\\) = “numero di realizzazioni con il risultato testa nei tre lanci” e \\(Y \\in \\{0, 1\\}\\) = “numero di realizzazioni con il risultato testa nel primo lancio” due variabili casuali definite sullo spazio campione \\(\\Omega\\). Indicando con T = ‘testa’ e C = ‘croce’, si ottiene la situazione riportata nella tabella 9.1. TABELLA 9.1: Spazio campione dell’esperimento consistente nel lancio di tre monete equilibrate su cui sono state definite le variabili aleatorie \\(X\\) = ‘numero di realizzazioni con il risultato testa nei tre lanci’ e \\(Y\\) = ‘numero di realizzazioni con il risultato testa nel primo lancio’. \\(\\omega\\) \\(X\\) \\(Y\\) \\(P(\\omega)\\) \\(\\omega_1\\) = TTT 3 1 1/8 \\(\\omega_2\\) = TTC 2 1 1/8 \\(\\omega_3\\) = TCT 2 1 1/8 \\(\\omega_4\\) = CTT 2 0 1/8 \\(\\omega_5\\) = CCT 1 0 1/8 \\(\\omega_6\\) = CTC 1 0 1/8 \\(\\omega_7\\) = TCC 1 1 1/8 \\(\\omega_8\\) = CCC 0 0 1/8 Ci poniamo il problema di associare un valore di probabilità ad ogni coppia \\((x, y)\\) definita su \\(\\Omega\\). La coppia \\((X = 0, Y = 0)\\) si realizza in corrispondenza di un solo evento elementare, ovvero CCC; avrà dunque una probabilità pari a \\(P(X=0, Y=0) = P(CCC) = 1/8\\). Nel caso della coppia \\((X = 1, Y = 0)\\) ci sono due eventi elementari che danno luogo al risultato considerato, ovvero, CCT e CTC. La probabilità dell’evento composto \\(P(X=1, Y=0)\\) è uguale alla somma delle probabilità dei due eventi elementari che lo costituiscono, cioé \\(P(X=1, Y=0) = P(\\mbox{CCT}) + P(\\mbox{CTC}) = 1/8 + 1/8 = 1/4\\). Sono riportati qui sotto i calcoli per tutti i possibili valori di \\(X, Y\\). \\[\\begin{align} P(X = 0, Y = 0) &amp;= P(\\omega_8 = CCC) = 1/8; \\notag\\\\ P(X = 1, Y = 0) &amp;= P(\\omega_5 = CCT) + P(\\omega_6 = CTC) = 2/8; \\notag\\\\ P(X = 1, Y = 1) &amp;= P(\\omega_7 = TCC) = 1/8; \\notag\\\\ P(X = 2, Y = 0) &amp;= P(\\omega_4 = CTT) = 1/8; \\notag\\\\ P(X = 2, Y = 1) &amp;= P(\\omega_3 = TCT) + P(\\omega_2 = TTC) = 2/8; \\notag\\\\ P(X = 3, Y = 1) &amp;= P(\\omega_1 = TTT) = 1/8; \\notag \\end{align}\\] Le probabilità così trovate sono riportate nella tabella 9.2 la quale descrive la distribuzione di probabilità congiunta delle variabili casuali \\(X\\) = “numero di realizzazioni con il risultato testa nei tre lanci” e \\(Y\\) = “numero di realizzazioni con il risultato testa nel primo lancio” per l’esperimento casuale consistente nel lancio di tre monete equilibrate. TABELLA 9.2: Distribuzione di probabilità congiunta per i risultati dell’esperimento consistente nel lancio di tre monete equilibrate. \\(x / y\\) 0 1 0 1/8 0 1 2/8 1/8 2 1/8 2/8 3 0 1/8 In generale, possiamo dire che, dato uno spazio campione discreto \\(\\Omega\\), è possibile associare ad ogni evento elementare \\(\\omega_i\\) dello spazio campione una coppia di numeri reali \\((x, y)\\), essendo \\(x = X(\\omega)\\) e \\(y = Y(\\omega)\\), il che ci conduce alla seguente definizione. Definizione 9.1 Siano \\(X\\) e \\(Y\\) due variabili casuali. La funzione che associa ad ogni coppia \\((x, y)\\) un valore di probabilità prende il nome di funzione di probabilità congiunta: \\[\\begin{equation} P(x, y) = P(X = x, Y = y). \\end{equation}\\] Il termine “congiunta” deriva dal fatto che questa probabilità è legata al verificarsi di una coppia di valori, il primo associato alla variabile casuale \\(X\\) ed il secondo alla variabile casuale \\(Y\\). Nel caso di due sole variabili casuali si parla di distribuzione bivariata, mentre nel caso di più variabili casuali si parla di distribuzione multivariata. 9.1.1 Proprietà Una distribuzione di massa di probabilità congiunta bivariata deve soddisfare due proprietà: \\(0 \\leq P(x_i, y_j) \\leq 1\\); la probabilità totale deve essere uguale a \\(1.0\\). Tale proprietà può essere espressa nel modo seguente \\[ \\sum_{i} \\sum_{j} P(x_i, y_j) = 1.0. \\] 9.1.2 Eventi Si noti che dalla probabilità congiunta possiamo calcolare la probabilità di qualsiasi evento definito in base alle variabili aleatorie \\(X\\) e \\(Y\\). Per capire come questo possa essere fatto, consideriamo nuovamente l’esperimento casuale discusso in precedenza. Esercizio 9.1 Per la distribuzione di massa di probabilità congiunta riportata nella tabella 9.2 si trovi la probabilità dell’evento \\(X+Y \\leq 1\\). Per trovare la probabilità richiesta dobbiamo sommare le probabilità associate a tutte le coppie \\((x,y)\\) che soddisfano la condizione \\(X+Y \\leq 1\\), ovvero \\[\\begin{equation} P_{XY}(X+Y \\leq 1) = P_{XY}(0, 0)+ P_{XY}(0, 1) + P_{XY}(1, 0) = 3/8.\\notag \\end{equation}\\] 9.1.3 Funzioni di probabilità marginali Nel caso di due variabili casuali discrete \\(X\\) e \\(Y\\) di cui conosciamo la distribuzione congiunta, la distribuzione marginale di \\(X\\) è calcolata sommando la distribuzione di probabilità congiunta sopra la variabile da “scartare”, in questo caso la \\(Y\\). La funzione di massa di probabilità marginale \\(P(X=x)\\) è \\[\\begin{equation} P(X = x) = \\sum_y P(X, Y = y) = \\sum_y P(X \\mid Y = y) P(Y = y), \\end{equation}\\] dove \\(P(X = x,Y = y)\\) è la distribuzione congiunta di \\(X, Y\\), mentre \\(P(X = x \\mid Y = y)\\) è la distribuzione condizionata di \\(X\\) dato \\(Y\\). Se esaminiamo \\(P(X=x)\\), diciamo che la variabile \\(Y\\) è stata marginalizzata. Le probabilità bivariate marginali e congiunte per variabili casuali discrete sono spesso mostrate come tabelle di contingenza. Si noti che \\(P(X = x)\\) e \\(P(Y = y)\\) sono normalizzate: \\[ \\sum_x P(X=x) = 1.0, \\quad \\sum_y P(Y=y) = 1.0. \\] Nel caso continuo si sostituisce l’integrazione alla somma – si veda la Sezione 9.2. Esercizio 9.2 Per l’esperimento casuale consistente nel lancio di tre monete equilibrate, si calcolino le probabilità marginali di \\(X\\) e \\(Y\\). Nell’ultima colonna a destra e nell’ultima riga in basso della tabella 9.3 sono riportate le distribuzioni di probabilità marginali di \\(X\\) e \\(Y\\). \\(P_X\\) si ottiene sommando su ciascuna riga fissata la colonna \\(j\\), \\(P_X(X = j) = \\sum_y p_{xy}(x = j, y)\\). \\(P_Y\\) si trova sommando su ciascuna colonna fissata la riga \\(i,\\) \\(P_Y (Y = i) = \\sum_x p_{xy}(x, y = i)\\). TABELLA 9.3: Distribuzione di probabilità congiunta \\(p(x,y)\\) per i risultati dell’esperimento consistente nel lancio di tre monete equilibrate e probabilità marginali \\(P(x)\\) e \\(P(y)\\). \\(x / y\\) 0 1 \\(P(x)\\) 0 1/8 0 1/8 1 2/8 1/8 3/8 2 1/8 2/8 3/8 3 0 1/8 1/8 \\(P(y)\\) 4/8 4/8 1.0 9.2 Marginalizzazione di variabili casuali continue Nella trattazione della statistca bayesiana useremo spesso il concetto di “marginalizzazione” e vedremo equazioni come la seguente: \\[\\begin{equation} p(y) = \\int_{\\theta} p(y, \\theta) = \\int_{\\theta} p(y \\mid \\theta) p(\\theta), \\tag{9.1} \\end{equation}\\] laddove \\(y\\) e \\(\\theta\\) sono due variabili casuali continue – nello specifico, con \\(y\\) denoteremo i dati e con \\(\\theta\\) i parametri di un modello statistico. Per ora, possiamo pensare a \\(y\\) e \\(\\theta\\) come a due variabili casuali qualsiasi. È possibiile pensare al caso continuo indicato nella (9.1) come all’estensione dell’esempio precedente ad un numero infinito di valori \\(\\theta\\). Commenti e considerazioni finali La funzione di probabilità congiunta tiene simultaneamente conto del comportamento di due variabili casuali \\(X\\) e \\(Y\\) e di come esse si influenzano reciprocamente. In particolare, si osserva che se le due variabili discrete \\(X\\) e \\(Y\\) non si influenzano, cioè se sono statisticamente indipendenti, allora la distribuzione di massa di probabilità congiunta si ottiene come prodotto delle funzioni di probabilità marginali di \\(X\\) e \\(Y\\): \\(P_{X, Y}(x, y) = P_X(x) P_Y(y)\\). "],["ch-intro-density-function.html", "Capitolo 10 La densità di probabilità 10.1 Spinner e variabili casuali continue uniformi 10.2 La funzione di ripartizione per una variabile casuale continua 10.3 La distribuzione uniforme 10.4 Dagli istogrammi alle densità 10.5 Funzione di densità di probabilità 10.6 La funzione di ripartizione 10.7 Media e mediana", " Capitolo 10 La densità di probabilità Finora abbiamo considerato solo variabili casuali discrete, cioè variabili che assumono solo valori interi. Ma cosa succede se vogliamo usare variabili casuali per rappresentare lunghezze, o volumi, o distanze, o una qualsiasi delle altre proprietà continue nel mondo fisico (o psicologico)? È necessario generalizzare l’approccio usato finora. Le variabili casuali continue assumono valori reali. L’insieme dei numeri reali è non numerabile perché è più grande dell’insieme degli interi.7 Le leggi della probabilità sono le stessa per le variabili casuali discrete e quelle continue. La nozione di funzione di massa di probabilità, invece, deve essere sostituita dal suo equivalente continuo, ovvero dalla funzione di densità di probabilità. Lo scopo di questo Capitolo è quello di chiarire il significato di questa nozione, usando un approccio basato sulle simulazioni. 10.1 Spinner e variabili casuali continue uniformi Consideriamo il seguente esperimento casuale. Facciamo ruotare ad alta velocità uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma (individuata dall’angolo acuto con segno tra il suo asse e l’asse orizzontale del goniometro). Chiamiamo \\(\\Theta\\) la variabile casuale “pendenza dello spinner”. Nella trattazione seguente useremo i gradi e, di conseguenza, \\(\\Theta \\in [0, 360]\\). FIGURA 10.1: Uno spinner che riposa a 36 gradi, o il dieci percento del percorso intorno al cerchio. La pendenza dello spinner può assumere qualunque valore tra 0 e 360 gradi. Cosa implica per \\(\\Theta\\) dire che lo spinner è simmetrico? Possiamo dire che, in ciascuna prova, la rotazione dello spinner produce un angolo qualunque da 0 a 360 gradi. In altri termini, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilità di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, poiché 36 gradi è un decimo del percorso intorno al cerchio, la probabilità di ottenere un qualsiasi intervallo di 36 gradi sarà sempre uguale al 10%. Ovvero \\(\\mbox{P}(0 \\leq \\Theta \\leq 36) \\ = \\ \\frac{1}{10}\\) e \\(\\mbox{P}(200 \\leq \\Theta \\leq 236) \\ = \\ \\frac{1}{10}\\). È importante notare che le probabilità precedenti non si riferiscono al fatto che \\(\\Theta\\) assume uno specifico valore, ma piuttosto all’evento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilità che la pendenza \\(\\Theta\\) dello spinner cada in intervallo è la frazione del cerchio rappresentata dall’intervallo, cioè, \\[ \\mbox{P}(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}, \\qquad 0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360. \\] La ragione di questo è che le variabili casuali continue non hanno una massa di probabilità. Invece, una massa di probabilità viene assegnata alla realizzazione della variabile casuale in un intervallo di valori. 10.1.1 Il paradosso delle variabili casuali continue Nel nostro esempio, la pendenza dello spinner è esattamente 36 gradi; ma avrebbe anche potuto essere 36.0376531 gradi, o qualunque altro valore in quell’intorno. Qual è la probabilità che la pendenza dello spinner sia esattamente 36? Paradossalmente, la risposta è zero: \\[ \\mbox{P}(\\Theta = 36) = 0. \\] Infatti, se la probabilità di un qualunque valore fosse maggiore di zero, ogni altro possibile valore dovrebbe avere la stessa probabilità, dato che abbiamo assunto che tutti i valori \\(\\Theta\\) siano egualmente probabili. Ma se poi andiamo a sommare tutte queste probabilità il totale diventerà maggiore di uno, il che non è possibile. Nel caso delle variabili casuali continue dobbiamo dunque rinunciare a qualcosa, e quel qualcosa è l’idea che, in una distribuzione continua, ciascun valore puntuale della variabile casuale possa avere una massa di probabilità maggiore di zero. Il paradosso sorge perché una realizzazione della variabile casuale continua produce sempre un qualche numero, ma ciscuno di tali numeri ha probabilità nulla. 10.2 La funzione di ripartizione per una variabile casuale continua Supponiamo che \\(\\Theta \\sim \\mathcal{U}(0, 360)\\) sia la pendenza dello spinner. La funzione di ripartizione (ovvero, la distribuzione cumulativa) è definita esattamente come nel caso delle variabili casuali discrete: \\[ F_{\\Theta}(\\theta) = \\mbox{P}(\\Theta \\leq \\theta). \\] Cioè, è la probabilità che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\). In questo caso, poiché si presume che lo spinner sia simmetrico, la funzione di distribuzione cumulativa è \\[ F_{\\Theta}(\\theta) = \\frac{\\theta}{360}. \\] Questa è una funzione lineare di \\(\\theta\\), cioè \\(\\frac{1}{360} \\cdot \\theta\\), come indicato dal grafico della figura 10.2. FIGURA 10.2: Funzione di distribuzione cumulativa per l’angolo \\(\\theta\\) (in gradi) risultante da una rotazione di uno spinner simmetrico. La linea tratteggiata mostra il valore a 180 gradi, che corrisponde ad una probabilità di 0.5, e la linea tratteggiata a 270 gradi, che corrisponde ad una probabilità di 0.75. Possiamo verificare questo risultato mediante simulazione. Per stimare la funzione di ripartizione, simuliamo \\(M\\) valori \\(\\theta^{(m)}\\) e poi li ordiniamo in ordine crescente. M &lt;- 1000 theta &lt;- runif(M, 0, 360) theta_asc &lt;- sort(theta) prob &lt;- (1:M) / M unif_cdf_df &lt;- data.frame( theta = theta_asc, prob = prob ) unif_cdf_plot &lt;- unif_cdf_df %&gt;% ggplot(aes(x = theta, y = prob)) + geom_line() + scale_x_continuous(breaks = c(0, 90, 180, 270, 360)) + scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1.0)) + xlab(expression(theta)) + ylab(expression(F(Theta)(theta))) unif_cdf_plot FIGURA 10.3: Grafico della funzione di ripartizione di una variabile casuale \\(\\Theta\\) che rappresenta il risultato di una rotazione di uno spinner simmetrico. Come previsto, tale funzione è una semplice funzione lineare perché la variabile sottostante \\(\\Theta\\) ha una distribuzione uniforme. Anche con M = 1000, tale grafico è praticamente indistinguibile da quello prodotto per via analitica. Come nel caso delle variabili casuali discrete, la funzione di ripartizione può essere utilizzata per calcolare la probabilità che la variabile casuale assuma valori in un certo intervallo. Ad esempio \\[\\begin{align} \\mbox{P}(180 &lt; \\Theta \\leq 270) &amp;= \\mbox{P}(\\Theta \\leq 270) \\ - \\ \\mbox{P}(\\Theta \\leq 180) \\notag\\\\ &amp;= F_{\\Theta}(270) - F_{\\Theta}(180)\\notag\\\\ &amp;= \\frac{3}{4} - \\frac{1}{2} \\notag\\\\ &amp;= \\frac{1}{4}.\\noindent \\end{align}\\] 10.3 La distribuzione uniforme Dopo avere visto come generare numeri casuali uniformi da 0 a 360, consideriamo ora una variabile casuale che assume valori nell’intervallo da 0 a 1. Chiamiamo tale variabile casuale \\(\\Theta\\) e assumiamo che abbia una distribuzione continua uniforme sull’intervallo [0, 1]: \\[ \\Theta \\sim \\mathcal{U}(0, 1). \\] Poiché le probabilità assumono valori nell’intervallo [0, 1], possiamo pensare a \\(\\Theta\\) come ad un valore di probabilità preso a caso in ciascuna realizzazione dell’esperimento casuale. La distribuzione uniforme è la più semplice delle distribuzioni di densità di probabilità. Per chiarire le proprietà di tale distribuzione, iniziamo con una simulazione e generiamo 10,000 valori casuali di \\(\\Theta\\). I primi 10 di tali valori sono stampati qui di seguito: set.seed(1234) M &lt;- 10000 theta &lt;- runif(M) theta[1:10] #&gt; [1] 0.113703411 0.622299405 0.609274733 0.623379442 0.860915384 0.640310605 #&gt; [7] 0.009495756 0.232550506 0.666083758 0.514251141 Creiamo ora un istogramma che descrive la distribuzione delle 10,000 realizzazioni \\(\\Theta\\) che abbiamo trovato: df_prob_unif &lt;- data.frame(theta = theta) unif_prob_plot &lt;- ggplot(df_prob_unif, aes(theta)) + geom_histogram( binwidth = 1 / 34, center = 1 / 68, color = &quot;black&quot;, size = 0.25 ) + scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) + scale_y_continuous(lim = c(0, 1000), breaks = c(500, 1000)) + xlab(expression(paste(Theta, &quot; ~ Uniform(0, 1)&quot;))) unif_prob_plot FIGURA 10.4: Istogramma di \\(10\\,000\\) realizzazioni \\(\\Theta \\sim \\mbox{Uniform}(0, 1)\\). È chiaro che, all’aumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell’istogramma tenderà a diventare una linea retta. Ciò significa che la funzione di densità di una variabile casuale uniforme continua è una costante. Cioè, se \\(\\Theta \\sim \\mathcal{U} (a, b)\\), allora \\(p_{\\Theta}(\\theta) = c\\), dove \\(c\\) è una costante. uniform_pdf_df &lt;- data.frame(y = c(0, 1), p_y = c(1, 1)) uniform_pdf_plot &lt;- ggplot(uniform_pdf_df, aes(x = y, y = p_y)) + geom_line(size = 0.5, color = &quot;#333333&quot;) + geom_point(size = 1.5, color = &quot;#333333&quot;) + scale_x_continuous(breaks = c(0, 1), labels = c(&quot;a&quot;, &quot;b&quot;)) + scale_y_continuous( lim = c(0, 1), breaks = c(0, 1), labels = c(&quot;0&quot;, &quot;c&quot;) ) + xlab(expression(theta)) + ylab(expression(paste(p[Theta], &quot;(&quot;, theta, &quot; | a, b)&quot;))) + geom_segment(aes(x = 0, y = 0, xend = 0, yend = 1), linetype = &quot;dotted&quot; ) + geom_segment(aes(x = 1, y = 0, xend = 1, yend = 1), linetype = &quot;dotted&quot; ) + geom_segment(aes(x = 0, y = 0, xend = 1, yend = 0), linetype = &quot;dotted&quot; ) + geom_segment(aes(x = -0.25, y = 0, xend = 0, yend = 0)) + geom_segment(aes(x = 1, y = 0, xend = 1.25, yend = 0)) + geom_point(aes(x = 0, y = 0), size = 1.5, shape = 21, fill = &quot;#ffffe6&quot; ) + geom_point(aes(x = 1, y = 0), size = 1.5, shape = 21, fill = &quot;#ffffe6&quot; ) uniform_pdf_plot Dal grafico vediamo che l’area sottesa alla funzione di densità è \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\), \\[ c = \\frac{\\displaystyle{1}}{\\displaystyle b - a}. \\] Ovvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora \\[ p_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b), \\] laddove \\[ \\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}. \\] In conclusione, la densità di una variabile casuale uniforme continua non dipende da \\(\\theta\\) — è costante e identica per ogni possibile valore \\(\\theta\\).8 Vedremo nel prossimo Paragrafo che, eseguendo una trasformazione su questa variabile casuale uniforme, possiamo creare altre variabili casuali di interesse. Esercizio 10.1 Si consideri una variabile casuale uniforme \\(X\\) definita sull’intervallo [0, 100]. Si trovi la probabilità \\(P(20 &lt; X &lt; 60)\\). Per trovare la soluzione è sufficiente calcolare l’area di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilità cercata è dunque \\(P(20 &lt; X &lt; 60) = 40 \\cdot 0.01 = 0.4\\). 10.4 Dagli istogrammi alle densità Non esiste l’equivalente di una funzione di massa di probabilità per le variabili casuali continue. Esiste invece una funzione di densità di probabilità la quale, nei termini di una simulazione, può essere concepita nel modo seguente: avendo a disposizione un numero enorme di casi, quando l’intervallo \\(\\Delta\\) di ciascuna classe \\(\\rightarrow\\) 0, il profilo dell’istogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) è detta funzione di densità di probabilità. Come si trasformano gli istogrammi all’aumentare del numero di osservazioni? Per fare un esempio, considereremo una funzione di una variabile casuale uniforme \\([0, 1]\\). Nello specifico, esamineremo la funzione logit: \\[ \\alpha = \\log \\left(\\frac{\\theta}{1-\\theta}\\right) \\] Alcuni valori \\(\\alpha\\) presi a caso sono i seguenti: set.seed(1234) M &lt;- 10000 logit &lt;- function(x) log(x / (1 - x)) theta &lt;- runif(M) alpha &lt;- logit(theta) for (m in 1:10) print(alpha[m]) #&gt; [1] -2.053458 #&gt; [1] 0.4993195 #&gt; [1] 0.4442646 #&gt; [1] 0.5039172 #&gt; [1] 1.822914 #&gt; [1] 0.5767125 #&gt; [1] -4.647369 #&gt; [1] -1.193965 #&gt; [1] 0.6905252 #&gt; [1] 0.05702001 Nei grafici seguenti, la numerosità cresce da \\(10\\) a \\(1\\,000\\,000\\). df_log_odds_growth &lt;- data.frame() for (log10M in 1:6) { M &lt;- 10^log10M alpha &lt;- logit(runif(M)) df_log_odds_growth &lt;- rbind( df_log_odds_growth, data.frame( alpha = alpha, M = rep(sprintf(&quot;M = %d&quot;, M), M) ) ) } log_odds_growth_plot &lt;- df_log_odds_growth %&gt;% ggplot(aes(alpha)) + geom_histogram(color = &quot;black&quot;, bins = 75) + facet_wrap(~M, scales = &quot;free&quot;) + scale_x_continuous( lim = c(-8.5, 8.5), breaks = c(-5, 0, 5) ) + xlab(expression(paste(Phi, &quot; = &quot;, logit(Theta)))) + ylab(&quot;proportion of draws&quot;) + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank(), panel.spacing.x = unit(2, &quot;lines&quot;), panel.spacing.y = unit(2, &quot;lines&quot;) ) log_odds_growth_plot FIGURA 10.5: Istogramma di \\(M\\) campioni casuali \\(\\Theta \\sim \\mbox{Uniform}(0, 1)\\) trasformati in valori \\(\\Phi = \\mbox{logit}(\\Theta).\\) Il profilo limite dell’istogramma è evidenziato nella figura in basso a destra che è stata costruita usando \\(1\\,000\\,000\\) di osservazioni. In un istogramma, l’area di ciascuna barra è proporzionale alla frequenza relativa delle osservazioni in quel’intervallo. Perché tutti gli intervalli hanno la stessa ampiezza, anche l’altezza di ciascuna barra sarà proporzionale alla frequenza relativa delle osservazioni in quel’intervallo. Nella simulazione, possiamo pensare all’area di ciascuna barra dell’istogramma come alla stima della probabilità che la variabile casuale assuma un valore compreso nell’intervallo considerato. All’aumentare del numero \\(M\\) di osservazioni, le probabilità stimate si avvicinano sempre di più ai veri valori della probabilità. All’aumentare del numero degli intervalli (quando l’ampiezza \\(\\Delta\\) dell’intervallo \\(\\rightarrow\\) 0), il profilo dell’istogramma tende a diventare una curva continua. Tale curva continua è la funzione di densità di probabilità della variabile casuale. Per l’esempio presente, con \\(M =1\\,000\\,000\\), otteniamo il grafico riportato nella figura 10.6. M &lt;- 1e6 alpha &lt;- logit(runif(M)) density_limit_df &lt;- data.frame(alpha = alpha) density_limit_plot &lt;- density_limit_df %&gt;% ggplot(aes(alpha)) + geom_histogram( stat = &quot;density&quot;, n = 75, color = &quot;black&quot;, size = 0.15 ) + stat_function( fun = dlogis, args = list(location = 0, scale = 1), col = &quot;black&quot;, size = 0.3 ) + scale_x_continuous( lim = c(-9, 9), breaks = c(-6, -4, -2, 0, 2, 4, 6) ) + xlab( expression(paste(Phi, &quot; = &quot;, logit(Theta))) ) + ylab(&quot;Frequenza relativa&quot;) + theme( axis.text.y = element_blank(), axis.ticks.y = element_blank() ) density_limit_plot FIGURA 10.6: Istogramma di \\(M = 1\\,000\\,000\\) campioni casuali \\(\\Theta \\sim \\mbox{Uniform}(0,1)\\) trasformati in valori \\(\\Phi = \\mbox{logit}(\\Theta)\\). La spezzata nera congiunge i punti centrali superiori delle barre dell’istogramma. Nel limite, quando il numero di osservazioni e di barre tende all’infinito, tale spezzata approssima la funzione di densità di probabilità della variabile casuale. Nella statistica descrittiva abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un metodo non parametrico per stimare la funzione di densità di probabilità di una variabile casuale. 10.5 Funzione di densità di probabilità Per descrivere le probabilità che possono essere associate ad una variabile casuale continua \\(X\\) è necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due proprietà: \\(p(x) \\geq 0, \\forall x\\), ovvero, l’ordinata della funzione di densità è 0 o positiva; \\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l’area sottesa dalla \\(p(x)\\) è unitaria9; \\(p(a &lt; x &lt; b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l’area sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilità che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi. Interpretazione. È possibile che \\(p(x) &gt; 1\\), quindi una densità di probabilità non può essere interpretata come una probabilità. Piuttosto, la densità \\(p(x)\\) può essere utilizzata per confrontare la fiducia relativa che può essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui è disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) &gt; p(x_l)\\), allora possiamo concludere che è più probabile, in termini relativi, osservare realizzazioni \\(X\\) nell’intorno di \\(x_k\\) piuttosto che nell’intorno di \\(x_l\\). 10.6 La funzione di ripartizione La funzione di ripartizione \\(F(X)\\) è quella funzione che associa a ogni valore di una variabile casuale \\(X\\) la probabilità che la variabile assuma valore minore o uguale a un prefissato valore \\(x_k\\). Come nel caso discreto, anche nel caso continuo la funzione di ripartizione è sempre non negativa, monotona non decrescente tra \\(0\\) e \\(1\\), tale che: \\[ \\lim_{x \\to -\\infty} F_x(X) = F_X(-\\infty) = 0, \\quad \\lim_{x \\to +\\infty} F_X(X) = F_X(+\\infty) = 1. \\] Se \\(X\\) è una variabile aleatoria continua, la funzione di ripartizione è: \\[ F(x_k) = P(X \\leq x_k) = \\int_{-\\infty}^{x_k} f(x) \\,\\operatorname {d}\\!x . \\] 10.7 Media e mediana Concludiamo questo capitolo con alcune considerazioni relative al contronto tra la media (valore atteso) e la mediana, nel caso di variabili casuali continue. Per distribuzioni simmetriche, sappiamo che la media e la mediana sono uguali. Chiediamoci ora cosa succede, nel caso di variabili casuali continue, nel caso di distribuzioni asimmetriche. La mediana indica il punto in cui la “massa totale” della distribuzione è suddivisa in due porzioni uguali. Nel caso della densità di probabilità, ciascuna di queste porzioni rappresenta un’area uguale, \\(A_1 = A_2 = 1/2\\) poiché l’area totale sottesa alla funzione di densità è 1 per definizione. FIGURA 10.7: Qual è la differenza tra mediana e media? La figura 10.7 mostra come differiscono i due concetti di mediana (indicata dalla linea verticale) e media (indicata dal “punto di equilibrio” triangolare). A sinistra, per una densità di probabilità simmetrica, la media e la mediana coincidono. A destra, una piccola porzione della distribuzione è stata spostata all’estremo destro. Questa modifica non ha influito sulla posizione della mediana, poiché le aree a destra e a sinistra della linea verticale sono ancora uguali. In altri termini, la mediana, \\(x_m\\), divide l’area sottesa alla funzione di densità in due porzioni uguali: \\[ \\int_{-\\infty}^{x_m} p(x) dx = \\int_{x_m}^{-\\infty} p(x) dx = \\frac{1}{2}. \\] Segue da tale definizione che la mediana è il valore \\(x\\) per il quale la distribuzione cumulativa soddisfa \\[ F(x_m) = \\frac{1}{2}. \\] Tuttavia, il fatto che una parte della massa sia stata allontanata verso destra porta a uno spostamento della media della distribuzione, per compensare tale cambiamento. In altre parole, la media contiene più informazioni sulla distribuzione “spaziale” delle osservazioni, rispetto alla mediana. Ciò deriva dal fatto che la media della distribuzione (il valore atteso) è una “somma” - cioè è un integrale - di termini cha hanno la forma \\(x p(x) \\Delta x\\). Quindi la posizione lungo l’asse \\(x\\), ovvero \\(x\\), e non solo la “massa”, \\(p(x) \\Delta x\\), influenza il contributo che le componenti della distribuzione hanno sulla media. Georg Cantor dimostrò che era impossibile mappare uno a uno i reali negli interi, dimostrando così che l’insieme dei reali è non numerabile.↩︎ Per comodità, possiamo assumere che i valori impossibili di \\(\\theta\\) abbiano una densità uguale a zero.↩︎ Per quel che riguarda la notazione dell’integrale, ovvero \\(\\int_x \\,\\operatorname {d}\\!x\\), rimando alla discussione di S.P. Thompson: https://calculusmadeeasy.org/1.html↩︎ "],["ch-expval-var-rv.html", "Capitolo 11 Valore atteso e varianza 11.1 Valore atteso 11.2 Varianza 11.3 Deviazione standard 11.4 Standardizzazione 11.5 Momenti di variabili casuali 11.6 Covarianza 11.7 Correlazione 11.8 Proprietà Conclusioni", " Capitolo 11 Valore atteso e varianza Spesso risulta utile fornire una rappresentazione sintetica della distribuzione di una variabile casuale attraverso degli indicatori caratteristici piuttosto che fare riferimento ad una sua rappresentazione completa mediante la funzione di ripartizione, o la funzione di massa o di densità di probabilità. Una descrizione più sintetica di una variabile casuale, tramite pochi valori, ci consente di cogliere le caratteristiche essenziali della distribuzione, quali: la posizione, cioè il baricentro della distribuzione di probabilità; la variabilità, cioè la dispersione della distribuzione di probabilità attorno ad un centro; la forma della distribuzione di probabilità, considerando la simmetria e la curtosi (pesantezza delle code). In questo Capitolo introdurremo quegli indici sintetici che descrivono il centro di una distribuzione di probabilità e la sua variabilità. 11.1 Valore atteso Quando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual è il suo “valore tipico”. La nozione di “valore tipico”, tuttavia, è ambigua. Infatti, essa può essere definita in almeno tre modi diversi: la media (somma dei valori divisa per il numero dei valori), la mediana (il valore centrale della distribuzione, quando la variabile è ordinata in senso crescente o decrescente), la moda (il valore che ricorre più spesso). Per esempio, la media di \\(\\{3, 1, 4, 1, 5\\}\\) è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è \\(3\\) e la moda è \\(1\\). Tuttavia, la teoria delle probabilità si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per “valore tipico” quando facciamo riferimento alle variabili casuali. Giungiamo così alla seguente definizione. Definizione 11.1 Sia \\(Y\\) è una variabile casuale discreta che assume i valori \\(y_1, \\dots, y_n\\) con distribuzione \\(p(y)\\), ossia \\[ P(Y = y_i) = p(y_i), \\] per definizione il valore atteso di \\(Y\\), \\(\\E(Y)\\), è \\[\\begin{equation} \\E(Y) = \\sum_{i=1}^n y_i \\cdot p(y_i). \\tag{11.1} \\end{equation}\\] A parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale è definito come la somma di tutti i valori che la variabile casuale può prendere, ciascuno pesato dalla probabilità con cui il valore è preso. Esercizio 11.1 Calcoliamo il valore atteso della variabile casuale \\(Y\\) corrispondente al lancio di una moneta equilibrata (testa: Y = 1; croce: Y = 0). \\[ \\E(Y) = \\sum_{i=1}^{2} y_i \\cdot P(y_i) = 0 \\cdot \\frac{1}{5} + 1 \\cdot \\frac{1}{5} = 0.5. \\] Esercizio 11.2 Supponiamo ora che Y sia il risultato del lancio di un dado equilibrato. Il valore atteso di Y diventa: \\[ \\E(Y) = \\sum_{i=1}^{6} y_i \\cdot P(y_i) = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + \\dots + 6 \\cdot \\frac{1}{6} = \\frac{21}{6} = 3.5. \\] 11.1.1 Interpretazione Che interpretazione può essere assegnata alla nozione di valore atteso? Bruno de Finetti adottò lo stesso termine di previsione (e lo stesso simbolo) tanto per la probabilità che per la speranza matematica. Si può pertanto dire che, dal punto di vista bayesiano, la speranza matematica è l’estensione naturale della nozione di probabilità soggettiva. 11.1.2 Proprietà del valore atteso La proprietà più importante del valore atteso è la linearità: il valore atteso di una somma di variabili casuali è uguale alla somma dei lori rispettivi valori attesi: \\[\\begin{equation} \\E(X + Y) = \\E(X) + \\E(Y). \\tag{11.2} \\end{equation}\\] La (11.2) sembra ragionevole quando \\(X\\) e \\(Y\\) sono indipendenti, ma è anche vera quando \\(X\\) e \\(Y\\) sono associati. Abbiamo anche che \\[\\begin{equation} \\E(cY) = c \\E(Y). \\tag{11.3} \\end{equation}\\] La (11.3) ci dice che possiamo estrarre una costante dall’operatore di valore atteso. Tale proprietà si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali \\(X\\) e \\(Y\\) sono indipendenti, abbiamo che \\[\\begin{equation} \\E(X Y) = \\E(X) \\E(Y). \\tag{11.4} \\end{equation}\\] Esercizio 11.3 Si considerino le seguenti variabili casuali: \\(Y\\), ovvero il numero che si ottiene dal lancio di un dado equilibrato, e \\(Y\\), il numero di teste prodotto dal lancio di una moneta equilibrata. Poniamoci il problema di trovare il valore atteso di \\(X+Y\\). Per risolvere il problema iniziamo a costruire lo spazio campionario dell’esperimento casuale consistente nel lancio di un dado e di una moneta. \\(x/ y\\) 1 2 3 4 5 6 0 (0, 1) (0, 2) (0, 3) (0, 4) (0, 5) (0, 6) 1 (1, 1) (1, 2) (1, 3) (1, 4) (1, 5) (1, 6) ovvero \\(x/ y\\) 1 2 3 4 5 6 0 1 2 3 4 5 6 1 2 3 4 5 6 7 Il risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campionario avrà la stessa probabilità di verificarsi, ovvero \\(Pr(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a: \\[ \\E(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0. \\] Lo stesso risultato si ottiene nel modo seguente: \\[ \\E(X+Y) = \\E(X) + E(Y) = 3.5 + 0.5 = 4.0. \\] Esercizio 11.4 Si considerino le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso del prodotto delle variabili casuali \\(X\\) e \\(Y\\). La distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente. \\(x/ y\\) 0 1 \\(p(Y)\\) 0 1/8 0 1/8 1 2/8 1/8 3/8 2 1/8 2/8 3/8 3 0 1/8 1/8 \\(p(y)\\) 4/8 4/8 1.0 Il calcolo del valore atteso di \\(XY\\) si riduce a \\[ \\E(XY) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0. \\] Si noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare la proprietà ??. Infatti, il valore atteso di \\(X\\) è \\[ \\E(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5 \\] e il valore atteso di \\(Y\\) è \\[ \\E(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5. \\] Dunque \\[ 1.5 \\cdot 0.5 \\neq 1.0. \\] 11.1.3 Variabili casuali continue Nel caso di una variabile casuale continua \\(Y\\) il valore atteso diventa: \\[\\begin{equation} \\E(Y) = \\int_{-\\infty}^{+\\infty} y p(y) \\,\\operatorname {d}\\!y \\tag{11.5} \\end{equation}\\] Anche in questo caso il valore atteso è una media ponderata della \\(y\\), nella quale ciascun possibile valore \\(y\\) è ponderato per il corrispondente valore della densità \\(p(y)\\). Possiamo leggere l’integrale pensando che \\(y\\) rappresenti l’ampiezza delle barre infinitamente strette di un istogramma, con la densità \\(p(y)\\) che corrisponde all’altezza di tali barre e la notazione \\(\\int_{-\\infty}^{+\\infty}\\) che corrisponde ad una somma. Un’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda della \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\): \\[\\begin{equation} \\Mo(Y) = \\argmax_y p(y). \\tag{11.6} \\end{equation}\\] 11.2 Varianza La seconda più importante proprietà di una variabile casuale, dopo che conosciamo il suo valore atteso, è la varianza. Definizione 11.2 Se \\(Y\\) è una variabile casuale discreta con distribuzione \\(p(y)\\), per definizione la varianza di \\(Y\\), \\(\\mathbb{V}(Y)\\), è \\[\\begin{equation} \\mathbb{V}(Y) = \\E\\Big[\\big(Y - \\E(Y)\\big)^2\\Big]. \\tag{11.7} \\end{equation}\\] A parole: la varianza è la deviazione media quadratica della variabile dalla sua media.10 Se denotiamo \\(\\E(Y) = \\mu\\), la varianza \\(\\mathbb{V}(Y)\\) diventa il valore atteso di \\((Y - \\mu)^2\\). Esercizio 11.5 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, poniamoci il problema di calcolare la varianza di \\(S\\). La variabile casuale \\(S\\) ha la seguente distribuzione di probabilità: \\(s\\) 2 3 4 5 6 7 8 9 10 11 12 \\(P(S = s)\\) \\(\\frac{1}{36}\\) \\(\\frac{2}{36}\\) \\(\\frac{3}{36}\\) \\(\\frac{4}{36}\\) \\(\\frac{5}{36}\\) \\(\\frac{6}{36}\\) \\(\\frac{5}{36}\\) \\(\\frac{4}{36}\\) \\(\\frac{3}{36}\\) \\(\\frac{2}{36}\\) \\(\\frac{1}{36}\\) Essendo \\(\\E(S) = 7\\), la varianza diventa \\[\\begin{align} \\mathbb{V}(S) &amp;= \\sum \\left(S- \\mathbb{E}(S)\\right)^2 \\cdot P(S) \\notag\\\\ &amp;= (2 - 7)^2 \\cdot 0.0278 + (3-7)^2 \\cdot 0.0556 + \\dots + (12 - 7)^2 \\cdot 0.0278 \\notag\\\\ &amp;= 5.8333.\\notag \\end{align}\\] 11.2.1 Formula alternativa per la varianza C’è un modo più semplice per calcolare la varianza: \\[\\begin{align} \\E\\Big[\\big(X - \\E(Y)\\big)^2\\Big] &amp;= \\E\\big(X^2 - 2X\\E(Y) + \\E(Y)^2\\big)\\notag\\\\ &amp;= \\E(Y^2) - 2\\E(Y)\\E(Y) + \\E(Y)^2,\\notag \\end{align}\\] dato che \\(\\E(Y)\\) è una costante; pertanto \\[\\begin{equation} \\mathbb{V}(Y) = \\E(Y^2) - \\big(\\E(Y) \\big)^2. \\tag{11.8} \\end{equation}\\] A parole: la varianza è la media dei quadrati meno il quadrato della media. Esercizio 11.6 Consideriamo la variabile casuale \\(Y\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Il valore atteso di \\(Y\\) è \\[ \\E(Y) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8. \\] Usando la formula tradizionale della varianza otteniamo: \\[ \\mathbb{V}(Y) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16. \\] Lo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(Y^2\\) è \\[ \\E(Y^2) = 0^2 \\cdot 0.2 + 1^2 * 0.8 = 0.8. \\] e la varianza diventa \\[ \\mathbb{V}(Y) = \\E(Y^2) - \\big(\\E(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16. \\] 11.2.2 Variabili casuali continue Nel caso di una variabile casuale continua \\(Y\\), la varianza diventa: \\[\\begin{equation} \\mathbb{V}(Y) = \\int_{-\\infty}^{+\\infty} \\large[y - \\E(Y)\\large]^2 p(y) \\,\\operatorname {d}\\!y \\tag{11.9} \\end{equation}\\] Come nel caso discreto, la varianza di una v.c. continua \\(y\\) misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori \\(y\\) dalla loro media. 11.3 Deviazione standard Quando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell’unità di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato deviazione standard e solitamente è denotato dalla lettera greca \\(\\sigma\\). Definizione 11.3 Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza: \\[\\begin{equation} \\sigma_Y = \\sqrt{\\mathbb{V}(Y)}. \\tag{11.10} \\end{equation}\\] Interpretiamo la deviazione standard di una variabile casuale come nella statistica descrittiva: misura approssimativamente la distanza tipica o prevista dei possibili valori \\(y\\) dalla loro media. Esercizio 11.7 Per i dadi equilibrati dell’esempio precedente, la deviazione standard della variabile casuale \\(S\\) è uguale a \\(\\sqrt{5.833} = 2.415\\). 11.4 Standardizzazione Definizione 11.4 Data una variabile casuale \\(Y\\), si dice variabile standardizzata di \\(Y\\) l’espressione \\[\\begin{equation} Z = \\frac{Y - \\E(Y)}{\\sigma_Y}. \\tag{11.11} \\end{equation}\\] Solitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\). 11.5 Momenti di variabili casuali Definizione 11.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità \\[\\begin{equation} \\E(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx. \\end{equation}\\] Se \\(X\\) è una v.c. discreta, i suoi momenti valgono: \\[\\begin{equation} \\E(X^q) = \\sum_i x_i^q p(x_i). \\end{equation}\\] I momenti sono importanti parametri indicatori di certe proprietà di \\(X\\). I più noti sono senza dubbio quelli per \\(q = 1\\) e \\(q = 2\\). Il momento del primo ordine corrisponde al valore atteso di \\(X\\). Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di \\(X\\), operando una traslazione \\(x_0 = x − \\E(X)\\) che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza. 11.6 Covarianza La covarianza quantifica la tendenza delle variabili aleatorie \\(X\\) e \\(Y\\) a ``variare assieme’’. Per esempio, l’altezza e il peso delle giraffe producono una covarianza positiva perché all’aumentare di una di queste due quantità tende ad aumentare anche l’altra. La covarianza misura la forza e la direzione del legame lineare tra due variabili aleatorie \\(X\\) ed \\(Y\\). Si utilizza la notazione \\(\\mbox{Cov}(X,Y)=\\sigma_{xy}\\). Definizione 11.6 Date due variabili aleatorie \\(X\\), \\(Y\\), chiamiamo covarianza tra \\(X\\) ed \\(Y\\) il numero \\[\\begin{equation} \\mbox{Cov}(X,Y) = \\mathbb{E}\\Bigl(\\bigl(X - \\mathbb{E}(X)\\bigr) \\bigl(Y - \\mathbb{E}(Y)\\bigr)\\Bigr), \\end{equation}\\] dove \\(\\mathbb{E}(X)\\) e \\(\\mathbb{E}(Y)\\) sono i valori attesi di \\(X\\) ed \\(Y\\). In maniera esplicita, \\[\\begin{equation} \\mbox{Cov}(X,Y) = \\sum_{(x,y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y). \\label{eq:cov_def} \\end{equation}\\] La definizione è analoga, algebricamente, a quella di varianza e risulta infatti \\[\\begin{equation} \\mathbb{V}(x) = cov(X, X) \\end{equation}\\] e \\[\\begin{equation} \\mbox{Cov}(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X). \\label{eq:cov_vc_alt} \\end{equation}\\] Dimostrazione. La proprietà precedente si dimostra nel modo seguente: \\[\\begin{align} \\mbox{Cov}(X,Y) &amp;= \\mathbb{E}\\Bigl(\\bigl(X-\\mathbb{E}(X)\\bigr) \\bigl(Y-\\mathbb{E}(Y)\\bigr)\\Bigr)\\notag\\\\ %&amp;= \\mathbb{E}(XY) - \\mathbb{E}(Y)X -\\mathbb{E}(X)Y + \\mathbb{E}(X)\\mathbb{E}(Y) )\\notag\\\\ &amp;= \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X) - \\mathbb{E}(X)\\mathbb{E}(Y) + \\mathbb{E}(X)\\mathbb{E}(Y)\\notag\\\\ &amp;= \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X)\\notag. \\end{align}\\] Esercizio 11.8 Consideriamo le variabili casuali definite nell’Esercizio 2.4. Si calcoli la covarianza di \\(X\\) e \\(Y\\). Abbiamo che \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). Ne segue che la covarianza di \\(X\\) e \\(Y\\) è: \\[\\begin{equation} \\begin{split} \\mbox{Cov}(X,Y) &amp;= \\sum_{(x,y) \\in\\ \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y)\\\\ &amp;= (0-1.5)(0-0.5)\\cdot \\frac{1}{8} + (0-1.5)(1-0.5) \\cdot 0 \\\\ &amp;\\hskip0.05\\textwidth\\relax + (1-1.5)(0-0.5)\\cdot \\frac{2}{8} + (1-1.5)(1-0.5) \\cdot \\frac{1}{8} \\\\ &amp;\\hskip0.05\\textwidth\\relax + (2-1.5)(0-0.5) \\cdot \\frac{1}{8} + (2-1.5)(1-0.5) \\cdot \\frac{2}{8} \\\\ &amp;\\hskip0.05\\textwidth\\relax + (3-1.5)(0-0.5) \\cdot 0 + (3-1.5)(1-0.5)\\cdot\\frac{1}{8} \\\\ &amp;= \\frac{1}{4}. \\notag \\end{split} \\end{equation}\\] Lo stesso risultato può essere trovato nel modo seguente. Iniziamo a calcolare il valore atteso del prodotto \\(XY\\): \\[ \\mathbb{E}(XY) = 0 \\cdot\\frac{4}{8} + 1 \\cdot\\frac{1}{8} + 2 \\cdot\\frac{2}{8} + 3 \\cdot\\frac{1}{8} = 1.0. \\] Dunque, la covarianza tra \\(X\\) e \\(Y\\) diventa \\[\\begin{align} \\mbox{Cov}(X,Y) &amp;= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\notag\\\\ &amp;= 1 - 1.5\\cdot 0.5 \\notag\\\\ &amp;= 0.25.\\notag \\end{align}\\] 11.7 Correlazione La covarianza dipende dall’unità di misura delle due variabili e quindi non consente di stabilire l’intensità della relazione. Una misura standardizzata della relazione che intercorre fra due variabili è invece rappresentata dalla correlazione. La correlazione si ottiene dividendo la covarianza per le deviazioni standard delle due variabili aleatorie. Il coefficiente di correlazione tra \\(X\\) ed \\(Y\\) è il numero definito da \\[\\begin{equation} \\rho(X,Y) =\\frac{\\mbox{Cov}(X,Y)}{\\sqrt{\\mathcal{V}(X)\\mathcal{V}(Y)}}. \\end{equation}\\] Si può anche scrivere \\(\\rho_{X,Y}\\) al posto di \\(\\rho(X,Y)\\). Il coefficiente di correlazione \\(\\rho_{xy}\\) è un numero puro, cioè non dipende dall’unità di misura delle variabili, e assume valori compresi tra -1 e +1. 11.8 Proprietà La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è nulla: \\[\\begin{equation} \\mbox{Cov}(c,X) = 0, \\end{equation}\\] la covarianza è simmetrica: \\[\\begin{equation} \\mbox{Cov}(X,Y) = \\mbox{Cov}(Y,X), \\end{equation}\\] vale \\[\\begin{equation} -1 \\leq \\rho(X,Y) \\leq 1, \\end{equation}\\] la correlazione non dipende dall’unità di misura: \\[\\begin{equation} \\rho(aX, bY) = \\rho(X,Y), \\qquad \\forall a, b &gt; 0, \\end{equation}\\] se \\(Y = a + bX\\) è una funzione lineare di \\(X\\) con costanti \\(a\\) e \\(b\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\), la covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, è uguale al prodotto delle costanti per la covarianza tra \\(X\\) e \\(Y\\): \\[\\begin{equation} \\mbox{Cov}(aX,bY) = ab \\;\\mbox{Cov}(X,Y), \\qquad \\forall a,b \\in \\Real, \\end{equation}\\] vale \\[\\begin{equation} \\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2 \\cdot \\mbox{Cov}(X,Y), \\end{equation}\\] vale \\[\\begin{equation} \\mbox{Cov}(X + Y, Z) = \\mbox{Cov}(X,Z) + \\mbox{Cov}(Y,Z), \\end{equation}\\] per una sequenza di variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\[\\begin{equation} \\mathbb{V}\\left( \\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i,j: i&lt;j}cov(X_i, X_j), \\end{equation}\\] vale \\[\\begin{equation} \\mbox{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_jY_j\\right) = \\sum_{i=1}^n \\sum_{j=1}^m a_j b_j\\mbox{Cov}(X_j, Y_j), \\end{equation}\\] se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\[\\begin{equation} \\mbox{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_jX_j\\right) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i). \\end{equation}\\] 11.8.1 Incorrelazione Si dice che \\(X\\) ed \\(Y\\) sono incorrelate, o linermente indipendenti, se la loro covarianza è nulla, \\[\\begin{equation} \\sigma_{XY} = \\mathbb{E} \\big[(X - \\mu_X) (y-\\mu_u) \\big] = 0, \\end{equation}\\] che si può anche scrivere come \\[\\begin{equation} \\rho_{XY} = 0, \\quad \\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y). \\end{equation}\\] Si introduce così un secondo tipo di indipendenza, più debole, dopo quello di indipendenza stocastica. Viceversa, però, se \\(\\mbox{Cov}(X, Y) = 0\\), non è detto che \\(X\\) ed \\(Y\\) siano indipendenti. Esercizio 11.9 Siano \\(X\\) e \\(Y\\) due variabili aleatorie discrete avente una distribuzione di massa di probabilità congiunta pari a \\[ f_{XY}(x,y) = \\frac{1}{4} \\quad (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\} \\] e zero altrimenti. Si calcoli la covarianza \\(\\rho_{XY}\\). Le due variabili aleatorie \\(X\\) e \\(Y\\) sono mutuamente indipendenti? La distribuzione marginale della \\(X\\) è \\[ \\begin{cases} X = 0, \\quad P_X = 1/4, \\\\ X = 1, \\quad P_X = 2/4, \\\\ X = 2, \\quad P_X = 1/4. \\end{cases} \\] \\[ \\mathbb{E}(X) = 0 \\frac{1}{4} + 1 \\frac{2}{4} + 2 \\frac{1}{4} = 1. \\] \\[ \\mathbb{E}(X^2) = 0^2 \\frac{1}{4} + 1^2 \\frac{2}{4} + 2^2 \\frac{1}{4} = \\frac{3}{2}. \\] \\[ \\mathbb{V}(X) = \\frac{3}{2} - 1^2 = \\frac{1}{2}. \\] La distribuzione marginale della \\(Y\\) è \\[ \\begin{cases} Y = -1, \\quad P_Y = 1/4, \\\\ Y = 0, \\quad P_Y = 2/4, \\\\ Y = 1, \\quad P_Y = 1/4. \\end{cases} \\] \\[ \\mathbb{E}(Y) = 0 \\frac{2}{4} + 1 \\frac{1}{4} + (-1) \\frac{1}{4} = 0. \\] \\[ \\mathbb{E}(Y^2) = 0^2 \\frac{2}{4} + 1^2 \\frac{1}{4} + (-1)^2 \\frac{1}{4} = \\frac{1}{2}. \\] \\[ \\mathbb{V}(X) = \\frac{1}{2} - 0^2 = \\frac{1}{2}. \\] Calcoliamo ora la covarianza tra \\(X\\) e \\(Y\\): \\[ \\mathbb{E}(XY) = \\sum_x\\sum_y xy f_{XY} (x,y) = (0\\cdot 0)\\frac{1}{4} + (1\\cdot 1)\\frac{1}{4} + (1\\cdot -1)\\frac{1}{4} + (2\\cdot 0)\\frac{1}{4} = 0. \\] \\[ \\mbox{Cov}(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y) = 0 - 1\\cdot0 = 0. \\] Quindi le due variabili aleatorie hanno covarianza pari a zero. Tuttavia, esse non sono indipendenti, in quanto non è vero che \\[ f_{XY} (x,y) = f_X(x) f_Y(y) \\] per tutti gli \\(x\\) e \\(y\\). In conclusione, anche se condizione di indipendenza implica una covarianza nulla, questo esempio mostra come l’inverso non sia necessariamente vero. La covarianza può essere zero anche quando le due variabili aleatorie non sono indipendenti. Conclusioni La densità di probabilità congiunta bivariata tiene simultaneamente conto del comportamento di due variabili aleatorie \\(X\\) e \\(Y\\) e di come esse si influenzino. Se \\(X\\) e \\(Y\\) sono legate linearmente, allora il coefficiente di correlazione \\[\\begin{equation} \\rho = \\frac{\\mbox{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\\notag \\end{equation}\\] fornisce l’indice maggiormente utilizzato per descrivere l’intensità e il segno dell’associazione lineare. Nel caso di un’associazione lineare perfetta, \\(Y = a + bX\\), avremo \\(\\rho = 1\\) con \\(b\\) positivo ed \\(\\rho = -1\\) con \\(b\\) negativo. Se il coefficiente di correlazione è pari a 0 le variabili si dicono incorrelate. Condizione sufficiente (ma non necessaria) affinché \\(\\rho = 0\\) è che le due variabili siano tra loro indipendenti. Data una variabile casuale \\(Y\\) con valore atteso \\(\\E(Y)\\), le “distanze” tra i valori di \\(Y\\) e il valore atteso \\(\\E(Y)\\) definiscono la variabile casuale \\(Y - \\E(Y)\\) chiamata scarto, oppure deviazione oppure variabile casuale centrata. La variabile \\(Y - \\E(Y)\\) equivale ad una traslazione di sistema di riferimento che porta il valore atteso nell’origine degli assi. Si può dimostrare facilmente che il valore atteso della variabile scarto \\(Y - \\E(Y)\\) vale zero, dunque la media di tale variabile non può essere usata per quantificare la “dispersione” dei valori di \\(Y\\) relativamente al suo valore medio. Occorre rendere sempre positivi i valori di \\(Y - \\E(Y)\\) e tale risultato viene ottenuto considerando la variabile casuale \\(\\left(Y - \\E(Y)\\right)^2\\).↩︎ "],["ch-distr-rv-discr.html", "Capitolo 12 Distribuzioni di v.c. discrete 12.1 Una prova Bernoulliana 12.2 Una sequenza di prove Bernoulliane 12.3 Distribuzione di Poisson 12.4 Distribuzione discreta uniforme 12.5 Distribuzione beta-binomiale Commenti e considerazioni finali", " Capitolo 12 Distribuzioni di v.c. discrete In questo Capitolo verranno esaminate le principali distribuzioni di probabilità delle variabili casuali discrete. Un esperimento casuale che può dare luogo a solo due possibili esiti (successo, insuccesso) è modellabile con una variabile casuale di Bernoulli. Una sequenza di prove di Bernoulli costituisce un processo Bernoulliano. Il numero di successi dopo \\(n\\) prove di Bernoulli corrisponde ad una variabile casuale che segue la legge binomiale. La distribuzione binomiale risulta da un insieme di prove di Bernoulli solo se il numero totale \\(n\\) è fisso per disegno. Se il numero di prove è esso stesso una variabile casuale, allora il numero di successi nella corrispondente sequenza di prove bernoulliane segue al distribuzione di Poisson. Concluderemo con la distribuzione discreta uniforme. 12.1 Una prova Bernoulliana Se un esperimento casuale ha solo due esiti possibili, allora le repliche indipendenti di questo esperimento sono chiamate “prove Bernoulliane” (il lancio di una moneta è il tipico esempio). Definizione 12.1 Viene detta variabile di Bernoulli una variabile casuale discreta \\(Y = \\{0, 1\\}\\) con la seguente distribuzione di probabilità: \\[ P(Y \\mid \\theta) = \\begin{cases} \\theta &amp; \\text{se $Y = 1$}, \\\\ 1 - \\theta &amp; \\text{se $Y = 0$}, \\end{cases} \\] con \\(0 \\leq \\theta \\leq 1\\). Convenzionalmente l’evento \\(\\{Y = 1\\}\\) con probabilità \\(\\theta\\) viene chiamato “successo” mentre l’evento \\(\\{Y = 0\\}\\) con probabilità \\(1-\\theta\\) viene chiamato “insuccesso”. Applicando l’operatore di valore atteso e di varianza, otteniamo \\[\\begin{align} \\mathbb{E}(Y) &amp;= 0 \\cdot P(Y=0) + 1 \\cdot P(Y=1) = \\theta, \\\\ \\mathbb{V}(Y) &amp;= (0 - \\theta)^2 \\cdot P(Y=0) + (1 - \\theta)^2 \\cdot P(Y=1) = \\theta(1-\\theta). \\tag{12.1} \\end{align}\\] Scriviamo \\(Y \\sim \\mbox{Bernoulli}(\\theta)\\) per indicare che la variabile casuale \\(Y\\) ha una distribuzione Bernoulliana di parametro \\(\\theta\\). Esercizio 12.1 Nel caso del lancio di una moneta equilibrata la variabile casuale di Bernoulli assume i valori \\(0\\) e \\(1\\). La distribuzione di massa di probabilità è pari a \\(\\frac{1}{2}\\) in corrispondenza di entrambi iv valori. La funzione di distribuzione vale \\(\\frac{1}{2}\\) per \\(Y = 0\\) e \\(1\\) per \\(Y = 1\\). 12.2 Una sequenza di prove Bernoulliane La distribuzione binomiale è rappresentata dall’elenco di tutti i possibili numeri di successi \\(Y = \\{0, 1, 2, \\dots n\\}\\) che possono essere osservati in \\(n\\) prove Bernoulliane indipendenti di probabilità \\(\\theta\\), a ciascuno dei quali è associata la relativa probabilità. Esempi di una distribuzione binomiale sono i risultati di una serie di lanci di una stessa moneta o di una serie di estrazioni da un’urna (con reintroduzione). La distribuzione binomiale di parametri \\(n\\) e \\(\\theta\\) è in realtà una famiglia di distribuzioni: al variare dei parametri \\(\\theta\\) e \\(n\\) variano le probabilità. Definizione 12.2 La probabilità di ottenere \\(y\\) successi e \\(n-y\\) insuccessi in \\(n\\) prove Bernoulliane è data dalla distribuzione binomiale: \\[\\begin{align} P(Y=y) &amp;= \\binom{n}{y} \\theta^{y} (1-\\theta)^{n-y} \\notag \\\\ &amp;= \\frac{n!}{y!(n-y)!} \\theta^{y} (1-\\theta)^{n-y}, \\tag{12.2} \\end{align}\\] dove \\(n\\) = numero di prove Bernoulliane, \\(\\theta\\) = probabilità di successo in ciascuna prova e \\(y\\) = numero di successi. Dimostrazione. La (12.2) può essere derivata nel modo seguente. Indichiamo con \\(S\\) il successo e con \\(I\\) l’insuccesso di ciascuna prova. Una sequenza di \\(n\\) prove Bernoulliane darà come esito una sequenza di \\(n\\) elementi \\(S\\) e \\(I\\). Ad esempio, una sequenza che contiene \\(y\\) successi è la seguente: \\[ \\overbrace{SS\\dots S}^\\text{$y$ volte} \\overbrace{II\\dots I}^\\text{$n-y$ volte} \\] Essendo \\(\\theta\\) la probabilità di \\(S\\) e \\(1-\\theta\\) la probabilità di \\(I\\), la probabilità di ottenere la specifica sequenza riportata sopra è \\[\\begin{equation} \\overbrace{\\theta \\theta\\dots \\theta}^\\text{$y$ volte} \\overbrace{(1-\\theta)(1-\\theta)\\dots (1-\\theta)}^\\text{$n-y$ volte} = \\theta^y \\cdot (1-\\theta)^{n-y}. \\tag{12.3} \\end{equation}\\] Non siamo però interessati alla probabilità di una specifica sequenza di \\(S\\) e \\(I\\) ma, bensì, alla probabilità di osservare una qualsiasi sequenza di \\(y\\) successi in \\(n\\) prove. In altre parole, vogliamo la probabilità dell’unione di tutti gli eventi corrispondenti a \\(y\\) successi in \\(n\\) prove. È immediato notare che una qualsiasi altra sequenza contenente esattamente \\(y\\) successi avrà sempre come probabilità \\(\\theta^y \\cdot (1-\\theta)^{n-y}\\): il prodotto infatti resta costante anche se cambia l’ordine dei fattori.11 Per trovare il risultato cercato dobbiamo moltiplicare la (12.3) per il numero di sequenze possibili di \\(y\\) successi in \\(n\\) prove. Il numero di sequenze che contengono esattamente \\(y\\) successi in \\(n\\) prove. La risposta è fornita dal coefficiente binomiale12: \\[\\begin{equation} \\binom{n}{y} = \\frac{n!}{y!(n-y)!}, \\tag{12.4} \\end{equation}\\] dove il simbolo \\(n!\\) si legge \\(n\\) fattoriale ed è uguale al prodotto di \\(n\\) numeri interi decrescenti a partire da \\(n\\). Per definizione \\(0! = 1\\). Essendo la probabilità dell’unione di \\(K\\) elementi incompatibili uguale alla somma delle loro rispettive probabilità, e dato che le sequenze di \\(y\\) successi in \\(n\\) prove hanno tutte la stessa probabilità, per trovare la formula della distributione binomiale (12.2) è sufficiente moltiplicare la (12.3) per la (12.4). La distribuzione di probabilità di alcune distribuzioni binomiali, per due valori di \\(n\\) e \\(\\theta\\), è fornita nella figura 12.1. FIGURA 12.1: Alcune distribuzioni binomiali. Nella figura, il parametro \\(\\theta\\) è indicato con \\(p\\). Esercizio 12.2 Usando la (12.2), si trovi la probabilità di \\(y = 2\\) successi in \\(n = 4\\) prove Bernoulliane indipendenti con \\(\\theta = 0.2\\) \\[ \\begin{aligned} P(Y=2) &amp;= \\frac{4!}{2!(4-2)!} 0.2^{2} (1-0.2)^{4-2} \\notag \\\\ &amp;= \\frac{4 \\cdot 3 \\cdot 2 \\cdot 1}{(2 \\cdot 1)(2 \\cdot 1)} 0.2^{2} 0.8^{2} = 0.1536. \\notag \\end{aligned} \\] Ripetendo i calcoli per i valori \\(y = 0, \\dots, 4\\) troviamo la distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\): y P(Y = y) 0 0.4096 1 0.4096 2 0.1536 3 0.0256 4 0.0016 sum 1.0 Lo stesso risultato si ottiene usando la sequente istruzione : dbinom(0:4, 4, 0.2) #&gt; [1] 0.4096 0.4096 0.1536 0.0256 0.0016 Esercizio 12.3 Lanciando \\(5\\) volte una moneta onesta, qual è la probabilità che esca testa almeno tre volte? In , la soluzione si trova con dbinom(3, 5, 0.5) + dbinom(4, 5, 0.5) + dbinom(5, 5, 0.5) #&gt; [1] 0.5 Alternativamente, possiamo trovare la probabilità dell’evento complementare a quello definito dalla funzione di ripartizione calcolata mediante pbinom(), ovvero 1 - pbinom(2, 5, 0.5) #&gt; [1] 0.5 12.2.1 Valore atteso e deviazione standard La media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale sono molto semplici: \\[\\begin{align} \\mu &amp;= n\\theta, \\notag \\\\ \\sigma &amp;= \\sqrt{n\\theta(1-\\theta)}. \\end{align}\\] Dimostrazione. Essendo \\(Y\\) la somma di \\(n\\) prove Bernoulliane indipendenti \\(Y_i\\), è facile vedere che \\[\\begin{align} \\E(Y) &amp;= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\E(Y_i) = n\\theta, \\\\ \\Var(Y) &amp;= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\Var(Y_i) = n \\theta (1-\\theta). \\end{align}\\] Esercizio 12.4 Si trovino il valore atteso e la varianza del lancio di quattro monete con probabilità di successo pari a \\(\\theta = 0.2\\). Il valore atteso è \\(\\mu = n \\theta = 4 \\cdot 0.2 = 0.8.\\) Ciò significa che, se l’esperimento casuale venisse ripetuto infinite volte, l’esito testa verrebbe osservato un numero medio di volte pari a 0.8. La varianza è \\(n \\theta (1-\\theta) = 4 \\cdot 0.2 \\cdot (1 - 0.2) = 0.64\\). 12.3 Distribuzione di Poisson La distribuzione di Poisson è una distribuzione di probabilità discreta che esprime le probabilità per il numero di eventi che si verificano successivamente ed indipendentemente in un dato intervallo di tempo, sapendo che mediamente se ne verifica un numero \\(\\lambda\\). La distribuzione di Poisson serve dunque per contare il numero di volte in cui un evento ha luogo in un determinato intervallo di tempo. La stessa distribuzione può essere estesa anche per contare gli eventi che hanno luogo in una determinata porzione di spazio. Definizione 12.3 La distribuzione di Poisson può essere intesa come limite della distribuzione binomiale, dove la probabilità di successo \\(\\theta\\) è pari a \\(\\frac{\\lambda}{n}\\) con \\(n\\) che tende a \\(\\infty\\): \\[\\begin{equation} \\lim_{y \\rightarrow \\infty} \\binom{n}{y} \\theta^y (1-\\theta)^{n-y} = \\frac{\\lambda^y}{y!}e^{-\\lambda}. \\end{equation}\\] Alcune distribuzioni di Poisson sono riportate nella figura 12.2. FIGURA 12.2: Alcune distribuzioni di Poisson. Esercizio 12.5 Supponiamo che un evento accada 300 volte all’ora e si vuole determinare la probabilità che in un minuto accadano esattamente 3 eventi. Il numero medio di eventi in un minuto è pari a lambda &lt;- 300 / 60 lambda #&gt; [1] 5 Quindi la probabilità che in un minuto si abbiano 3 eventi è pari a y &lt;- 3 (lambda^y / factorial(y)) * exp(-lambda) #&gt; [1] 0.1403739 Esercizio 12.6 Per i dati dell’esempio precedente, si trovi la probabilità che un evento accada almeno 8 volte in un minuto. La probabilità cercata è \\[ p(y \\geq 8) = 1 - p (y \\leq 7) = 1- \\sum_{i = 0}^7 \\frac{\\lambda^7}{7!}e^{-\\lambda}, \\] con \\(\\lambda = 5\\). Svolgendo i calcoli in otteniamo: 1 - ppois(q = 7, lambda = 5) #&gt; [1] 0.1333717 ppois(q = 7, lambda = 5, lower.tail = FALSE) #&gt; [1] 0.1333717 Esercizio 12.7 Sapendo che un evento avviene in media 6 volte al minuto, si calcoli (a) la probabilità di osservare un numero di eventi uguale o inferiore a 3 in un minuto, e (b) la probabilità di osservare esattamente 2 eventi in 30 secondi. In questo caso \\(\\lambda = 6\\) e la probabilità richiesta è ppois(q = 3, lambda = 6, lower.tail = TRUE) #&gt; [1] 0.1512039 In questo caso \\(\\lambda = 6 / 2\\) e la probabilità richiesta è dpois(x = 2, lambda = 3) #&gt; [1] 0.2240418 12.3.1 Alcune proprietà della variabile di Poisson Il valore atteso, la moda e la varianza della variabile di Poisson sono uguali a \\(\\lambda\\). La somma \\(Y_1 + \\dots + Y_n\\) di \\(n\\) variabili casuali indipendenti con distribuzioni di Poisson di parametri \\(\\lambda_{1},\\dots,\\lambda_{n}\\) segue una distribuzione di Poisson di parametro \\(\\lambda = \\lambda_{1}+\\dots+\\lambda_{n}\\). La differenze di due variabili di Poisson non è una variabile di Poisson. Basti infatti pensare che può assumere valori negativi. 12.4 Distribuzione discreta uniforme Una distribuzione discreta uniforme è una distribuzione di probabilità discreta che è uniforme su un insieme, ovvero che attribuisce ad ogni elemento dell’insieme discreto e finito \\(S\\) su cui è definita la stessa probabilità \\(p\\) di verificarsi. Consideriamo la variabile casuale \\(X\\) con supporto \\(1, 2, \\dots, m\\). Un esperimento casuale in cui si verifica questa distribuzione è la scelta casuale di un intero compreso tra 1 e \\(m\\) inclusi. Sia \\(X\\) il numero scelto. Allora \\[ P(X = x) = \\frac{1}{m}, \\quad x = 1, \\dots, m. \\] Il valore atteso è \\[ \\mathbb{E}(X) = \\sum_{x=1}^m x f_X(x) = \\sum_{x=1}^m x \\frac{1}{m} = \\frac{1}{m} (1 + 2 + \\dots + m) = \\frac{m+1}{2}, \\] dove abbiamo utilizzato l’identità \\(1+2+···+m = m(m+1)/2\\). Per trovare la varianza, prima calcoliamo \\[ \\mathbb{E}(X^2) = \\frac{1}{m} \\sum_{x=1}^m x^2, \\] e poi troviamo \\[ \\mathbb{V}(X) = \\mathbb{E}(X^2) - \\left[\\mathbb{E}(X)\\right]^2. \\] 12.4.1 Usiamo \\(\\textsf{R}\\) La sintassi generale per simulare una variabile casuale uniforme discreta è sample(x, size, replace = TRUE). L’argomento x identifica i numeri da cui campionare casualmente. Se x è un numero, il campionamento viene eseguito da 1 a x. L’argomento size indica quanto dovrebbe essere grande la dimensione del campione e replace indica se i numeri devono essere reintrodotti o meno nell’urna dopo essere stati estratti. L’opzione di default è replace = FALSE ma per le uniformi discrete i valori estratti devono essere sostituiti. Seguono alcuni esempi. Per lanciare un dado equilibrato 3000 volte: sample(6, size = 3000, replace = TRUE); per scegliere 27 numeri casuali da 30 a 70: sample(30:70, size = 27, replace = TRUE); per lanciare una moneta equa 1000 volte: sample(c(\"H\",\"T\"), size = 1000, replace = TRUE). 12.5 Distribuzione beta-binomiale La distribuzione beta-binomiale di parametri \\(N\\), \\(\\alpha\\) e \\(\\beta\\) è una distribuzione discreta con una funzione di massa di probabilità uguale a \\[\\begin{equation} \\mbox{BetaBinomial}(y \\mid N, \\alpha, \\beta) = \\binom{N}{y} \\frac{B(y + \\alpha, N-y+\\beta)}{B(\\alpha, \\beta)}, \\end{equation}\\] dove la funzione beta è \\(B(u, v) = \\frac{\\Gamma(u)\\Gamma(v)}{\\Gamma(u+v)}\\). Senza entrare nei dettagli, ci accontentiamo di sapere che tale distribuzione è implementata nella funzione dbbinom() del pacchetto extraDistr. Commenti e considerazioni finali La distribuzione binomiale è una distribuzione di probabilità discreta che descrive il numero di successi in un processo di Bernoulli, ovvero la variabile aleatoria \\(Y = Y_1 + \\dots + Y_n\\) che somma \\(n\\) variabili casuali indipendenti di uguale distribuzione di Bernoulli \\(\\mathcal{B}(\\theta)\\), ognuna delle quali può fornire due soli risultati: il successo con probabilità \\(\\theta\\) e il fallimento con probabilità \\(1 - \\theta\\). La distribuzione binomiale è molto importante per le sue molte applicazioni. Nelle presenti dispense, dedicate all’analisi bayesiana, è soprattutto importante perché costituisce il fondamento del caso più semplice del cosiddetto “aggiornamento bayesiano”, ovvero il caso Beta-Binomiale. Il modello Beta-Binomiale ci fornirà infatti un esempio paradigmatico dell’approccio bayesiano all’inferenza e sarà trattato in maniera analitica. È dunque importante che le proprietà della distribuzione binomiale risultino ben chiare. Viene detta scambiabilità la proprietà per cui l’ordine con cui compiamo le osservazioni è irrilevante per l’assegnazione delle probabilità.↩︎ La derivazione della formula del coefficiente binomiale è fornita nell’Appendice ??.↩︎ "],["ch-distr-rv-cont.html", "Capitolo 13 Distribuzioni di v.c. continue 13.1 Distribuzione Normale 13.2 La Normale prodotta con una simulazione 13.3 Teorema del limite centrale 13.4 Distribuzione Chi-quadrato 13.5 Distribuzione \\(t\\) di Student 13.6 Funzione beta 13.7 Distribuzione Beta 13.8 Distribuzione di Cauchy 13.9 Distribuzione log-normale 13.10 Distribuzione di Pareto Commenti e considerazioni finali", " Capitolo 13 Distribuzioni di v.c. continue Dopo avere introdotto con una simulazione il concetto di funzione di densità nel Capitolo ??, prendiamo ora in esame alcune delle densità di probabilità più note. La più importante di esse è sicuramente la distribuzione Normale. 13.1 Distribuzione Normale Non c’è un’unica distribuzione Normale, ma ce ne sono molte. Tali distribuzioni sono anche dette “gaussiane” in onore di Carl Friedrich Gauss (uno dei più grandi matematici della storia il quale, tra le altre cose, scoprì l’utilità di tale funzione di densità per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale densità alle misurazioni dell’uomo. Karl Pearson usò per primo il termine “distribuzione Normale” anche se ammise che questa espressione “ha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell’altro, non siano normali.” 13.1.1 Limite delle distribuzioni binomiali Iniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre notò che, aumentando il numero di prove in una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Con 10 prove e una probabilità di successo di 0.9 in ciascuna prova, la distribuzione è chiaramente asimmetrica. N &lt;- 10 x &lt;- 0:10 y &lt;- dbinom(x, N, 0.9) binomial_limit_plot &lt;- tibble(x = x, y = y) %&gt;% ggplot(aes(x = x, y = y)) + geom_bar( stat = &quot;identity&quot;, color = &quot;black&quot;, size = 0.2 ) + xlab(&quot;y&quot;) + scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10)) + ylab(&quot;Binomial(y | 10, 0.9)&quot;) binomial_limit_plot FIGURA 13.1: Probabilità del numero di successi in \\(N = 10\\) prove bernoulliane indipendenti, ciascuna con una probabilità di successo di 0.90. Il risultato è una distribuzione \\(\\Bin(y \\mid 10, 0.9)\\). Con solo dieci prove, la distribuzione è fortemente asimmetrica negativa. Ma se aumentiamo il numero di prove di un fattore di 100 a N = 1000, senza modificare la probabilità di successo di 0.9, la distribuzione assume una forma campanulare quasi simmetrica. Dunque, de Moivre scoprì che, quando N è grande, la funzione Normale (che introdurremo qui sotto), nonostante sia la densità di v.a. continue, fornisce una buona approssimazione alla funzione di massa di probabilità binomiale. N &lt;- 1000 x &lt;- 0:1000 y &lt;- dbinom(x, N, 0.9) binomial_limit_plot &lt;- tibble(x = x, y = y) %&gt;% ggplot(aes(x = x, y = y)) + geom_bar(stat = &quot;identity&quot;, color = &quot;black&quot;, size = 0.2) + xlab(&quot;y&quot;) + ylab(&quot;Binomial(y | 1000, 0.9)&quot;) + xlim(850, 950) binomial_limit_plot FIGURA 13.2: Probabilità del numero di successi in \\(N = 1000\\) prove bernoulliane indipendenti, ciascuna con una probabilità di successo di 0.90. Il risultato è una distribuzione \\(\\Bin(y \\mid 1000, 0.9)\\). Con mille prove, la distribuzione è quasi simmetrica a forma campanulare. La distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione. 13.2 La Normale prodotta con una simulazione McElreath (2020) presenta un esempio che illustra come sia possibile giungere alla distribuzione Normale mediante una simulazione. Supponiamo che vi siano mille persone tutte allineate su una linea di partenza. Quando viene dato un segnale, ciascuna persona lancia una moneta e fa un passo in avanti oppure all’indietro a seconda che sia uscita testa o croce. Supponiamo che la lunghezza di ciascun passo vari da 0 a 1 metro. Ciascuna persona lancia una moneta 16 volte e dunque compie 16 passi. Alla conclusione di queste passeggiate casuali (random walk) non possiamo sapere con esattezza dove si troverà ciascuna persona, ma possiamo conoscere con certezza le caratteristiche della distribuzione delle mille distanze dall’origine. Per esempio, possiamo predire in maniera accurata la proporzione di persone che si sono spostate in avanti oppure all’indietro. Oppure, possiamo predire accuratamente la proporzione di persone che si troveranno ad una certa distanza dalla linea di partenza (es., a 1.5 m dall’origine). Queste predizioni sono possibili perché tali distanze si distribuiscono secondo la legge Normale. È facile simulare questo processo usando . I risultati della simulazione sono riportati nella figura 13.3. pos &lt;- replicate(100, runif(16, -1, 1)) %&gt;% as_tibble() %&gt;% rbind(0, .) %&gt;% mutate(step = 0:16) %&gt;% gather(key, value, -step) %&gt;% mutate(person = rep(1:100, each = 17)) %&gt;% group_by(person) %&gt;% mutate(position = cumsum(value)) %&gt;% ungroup() ggplot( data = pos, aes(x = step, y = position, group = person) ) + geom_vline(xintercept = c(4, 8, 16), linetype = 2) + geom_line(aes(color = person &lt; 2, alpha = person &lt; 2)) + scale_color_manual(values = c(&quot;gray&quot;, &quot;black&quot;)) + scale_alpha_manual(values = c(1 / 5, 1)) + scale_x_continuous( &quot;Numero di passi&quot;, breaks = c(0, 4, 8, 12, 16) ) + labs(y = &quot;Posizione&quot;) + theme(legend.position = &quot;none&quot;) FIGURA 13.3: Passeggiata casuale di 4, 8 e 16 passi. La spezzata nera indica la media delle distanze dall’origine come funzione del numero di passi. Un kernel density plot delle distanze ottenute dopo 4, 8 e 16 passi è riportato nella figura 13.4. Nel pannello di destra, al kernel density plot è stata sovrapposta una densità Normale di opportuni parametri (linea tratteggiata). p1 &lt;- pos %&gt;% filter(step == 4) %&gt;% ggplot(aes(x = position)) + geom_line(stat = &quot;density&quot;, color = &quot;black&quot;) + labs(title = &quot;4 passi&quot;) p2 &lt;- pos %&gt;% filter(step == 8) %&gt;% ggplot(aes(x = position)) + geom_density(color = &quot;black&quot;, outline.type = &quot;full&quot;) + labs(title = &quot;8 passi&quot;) sd &lt;- pos %&gt;% filter(step == 16) %&gt;% summarise(sd = sd(position)) %&gt;% pull(sd) p3 &lt;- pos %&gt;% filter(step == 16) %&gt;% ggplot(aes(x = position)) + stat_function( fun = dnorm, args = list(mean = 0, sd = sd), linetype = 2 ) + geom_density(color = &quot;black&quot;, alpha = 1 / 2) + labs( title = &quot;16 passi&quot;, y = &quot;Densità&quot; ) (p1 | p2 | p3) &amp; coord_cartesian(xlim = c(-6, 6)) FIGURA 13.4: Kernel density plot dei risultati della passeggiata casuale riportata nella figura precente, dopo 4, 8 e 16 passi. Nel pannello di destra, una densità Normale di opportuni parametri è sovrapposta all’istogramma lisciato. Questa simulazione mostra che qualunque processo nel quale viene sommato un certo numero di valori casuali, tutti provenienti dalla medesima distribuzione, converge ad una distribuzione Normale. Non importa quale sia la forma della distribuzione di partenza: essa può essere uniforme, come nell’esempio presente, o di qualunque altro tipo. La forma della distribuzione da cui viene realizzato il campionamento determina la velocità della convergenza alla Normale. In alcuni casi la convergenza è lenta; in altri casi la convergenza è molto rapida (come nell’esempio presente). Da un punto di vista formale, diciamo che una variabile casuale continua \\(Y\\) ha una distribuzione Normale se la sua densità è \\[\\begin{equation} f(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2 \\sigma^2} \\right\\}, \\tag{13.1} \\end{equation}\\] dove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\) sono i parametri della distribuzione. La densità normale è unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densità in corrispondenza di \\(\\mu\\). Il significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nella (13.1) viene chiarito dalla dimostrazione che \\[\\begin{equation} \\mathbb{E}(X) = \\mu, \\qquad \\mathbb{V}(X) = \\sigma^2. \\end{equation}\\] La rappresentazione grafica di quattro densità Normali tutte con media 0 e con deviazioni standard 0.25, 0.5, 1 e 2 è fornita nella figura 13.5. FIGURA 13.5: Alcune distribuzioni Normali. 13.2.1 Concentrazione È istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media: \\[\\begin{align} P(\\mu - \\sigma &lt; X &lt; \\mu + \\sigma) &amp;= P (-1 &lt; Z &lt; 1) \\simeq 0.683, \\notag\\\\ P(\\mu - 2\\sigma &lt; X &lt; \\mu + 2\\sigma) &amp;= P (-2 &lt; Z &lt; 2) \\simeq 0.956, \\notag\\\\ P(\\mu - 3\\sigma &lt; X &lt; \\mu + 3\\sigma) &amp;= P (-3 &lt; Z &lt; 3) \\simeq 0.997. \\notag \\end{align}\\] Si noti come un dato la cui distanza dalla media è superiore a 3 volte la deviazione standard presenti un carattere di eccezionalità perché meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica. Per indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\). 13.2.2 Funzione di ripartizione Il valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) è l’area sottesa alla curva di densità \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione \\[\\begin{equation} F(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy, \\end{equation}\\] pertanto le probabilità \\(P(Y &lt; y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software. Esercizio 13.1 Usiamo per calcolare la funzione di ripartizione della Normale. La funzione pnorm(q, mean, sd) restituisce la funzione di ripartizione della Normale con media mean e deviazione standard sd, ovvero l’area sottesa alla funzione di densità di una Normale con media mean e deviazione standard sd nell’intervallo \\([-\\infty, q]\\). Per esempio, in precedenza abbiamo detto che il 68% circa dell’area sottesa ad una Normale è compresa nell’intervallo \\(\\mu \\pm \\sigma\\). Verifichiamo per la distribuzione del QI \\(\\sim \\mathcal{N}(\\mu = 100, \\sigma = 15)\\): pnorm(100+15, 100, 15) - pnorm(100-15, 100, 15) #&gt; [1] 0.6826895 Il 95% dell’area è compresa nell’intervallo \\(\\mu \\pm 1.96 \\cdot\\sigma\\): pnorm(100 + 1.96 * 15, 100, 15) - pnorm(100 - 1.96 * 15, 100, 15) #&gt; [1] 0.9500042 Quasi tutta la distribuzione è compresa nell’intervallo \\(\\mu \\pm 3 \\cdot\\sigma\\): pnorm(100 + 3 * 15, 100, 15) - pnorm(100 - 3 * 15, 100, 15) #&gt; [1] 0.9973002 13.2.3 Distribuzione Normale standard La distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale è l’insieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora \\[\\begin{equation} X = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y). \\end{equation}\\] L’area sottesa alla curva di densità di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) è uguale all’area sottesa alla densità Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) è il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l’area sottesa nella semiretta \\([1, \\infty)\\) è uguale all’area sottesa nella semiretta \\((-\\infty, 1]\\) e quest’ultima coincide con \\(F(-1)\\). Analogamente, l’area sottesa nell’intervallo \\([y_a, y_b]\\), con \\(y_a &lt; y_b\\), è pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\). Si ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema è quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z &lt; z) = p\\). Il valore \\(z\\) cercato è detto quantile di ordine \\(p\\) della Normale standard e può essere trovato mediante un software. Esercizio 13.2 Supponiamo che l’altezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un’altezza compresa tra \\(1.7\\) e \\(1.8\\) m. Il problema ci chiede di trovare l’area sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell’intervallo \\([1.7, 1.8]\\): df &lt;- tibble(x = seq(1.4, 2.0, length.out = 100)) %&gt;% mutate(y = dnorm(x, mean = 1.7, sd = 0.1)) ggplot(df, aes(x, y)) + geom_area(fill = &quot;sky blue&quot;) + gghighlight(x &lt; 1.8 &amp; x &gt; 1.7) + labs( x = &quot;Altezza&quot;, y = &quot;Densità&quot; ) La risposta si trova utilizzando la funzione di ripartizione \\(F(X)\\) della legge \\(\\mathcal{N}(1.7, 0.1)\\) in corrispondenza dei due valori forniti dal problema: \\(F(X = 1.8) - F(X = 1.7)\\). Utilizzando la seguente istruzione pnorm(1.8, 1.7, 0.1) - pnorm(1.7, 1.7, 0.1) #&gt; [1] 0.3413447 otteniamo il \\(31.43\\%\\). In maniera equivalente, possiamo standardizzare i valori che delimitano l’intervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell’intervallo sono \\[ z_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0, \\] quindi otteniamo pnorm(1.0, 0, 1) - pnorm(0, 0, 1) #&gt; [1] 0.3413447 Il modo più semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilità richiesta non è altro che la metà dell’area sottesa dalle distribuzioni Normali nell’intervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\). 13.2.3.1 Funzione di ripartizione della normale standard e funzione logistica Si noti che la funzione logistica (in blu), pur essendo del tutto diversa dalla Normale dal punto di vista formale, assomiglia molto alla Normale standard quando le due cdf hanno la stessa varianza. tibble(x = c(-3, 3)) %&gt;% ggplot(aes(x = x)) + stat_function(fun = pnorm) + stat_function( fun = plogis, args = list(scale = 0.56) ) 13.3 Teorema del limite centrale Laplace dimostrò il teorema del limite centrale (TLC) nel 1812. Il TLC ci dice che se prendiamo una sequenza di variabili casuali indipendenti e le sommiamo, tale somma tende a distribuirsi come una Normale. Il TLC specifica inoltre, sulla base dei valori attesi e delle varianze delle v.c. che vengono sommate, quali saranno i parametri della distribuzione Normale così ottenuta. Teorema 13.1 Si supponga che \\(Y = Y_1, Y_2, \\ldots, Y_N\\) sia una sequenza di v.a. i.i.d. con \\(\\mathbb{E}(Y_n) = \\mu\\) e \\(\\mbox{SD}(Y_n) = \\sigma\\). Si definisca una nuova v.c. come la media di \\(Y\\): \\[ Z = \\frac{1}{N} \\sum_{n=1}^N Y_n. \\] Con \\(N \\rightarrow \\infty\\), \\(Z\\) tenderà ad una Normale con lo stesso valore atteso di \\(Y_n\\) e una deviazione standard che sarà più piccola della deviazione standard originaria di un fattore pari a \\(\\sqrt{\\frac{1}{\\sqrt{N}}}\\): \\[\\begin{equation} p_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{1}{\\sqrt{N}} \\cdot \\sigma \\right). \\end{equation}\\] Il TLC può essere generalizzato a variabili che non hanno la stessa distribuzione purché siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l’altezza dell’uomo adulto di entrambi i sessi, sono il risultato di una serie di effetti additivi relativamente piccoli, la cui combinazione porta alla normalità, indipendentemente da come gli effetti additivi sono distribuiti. In pratica, questo è il motivo per cui la distribuzione normale ha senso come rappresentazione di molti fenomeni naturali. 13.4 Distribuzione Chi-quadrato Dalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà descrive la variabile casuale \\[ Z_1^2 + Z_2^2 + \\dots + Z_k^2, \\] dove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. con distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libertà. La densità di probabilità di \\(\\chi^2_{~\\nu}\\) è \\[ f(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x &gt; 0, \\] dove \\(C_{\\nu}\\) è una costante positiva. La figura 13.6 mostra alcune distribuzioni Chi-quadrato variando il parametro \\(\\nu\\). FIGURA 13.6: Alcune distribuzioni Chi-quadrato. 13.4.1 Proprietà La distribuzione di densità \\(\\chi^2_{~\\nu}\\) è asimmetrica. Il valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) è uguale a \\(\\nu\\). La varianza di una variabile \\(\\chi^2_{~\\nu}\\) è uguale a \\(2\\nu\\). Per \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\). Se \\(X\\) e \\(Y\\) sono due variabili casuali chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libertà, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende a qualunque numero finito di variabili casuali chi-quadrato indipendenti. Esercizio 13.3 Usiamo \\(\\mathsf{R}\\) per disegnare la densità chi-quadrato con 3 gradi di libertà dividendo l’area sottesa alla curva di densità in due parti uguali. df &lt;- tibble(x = seq(0, 15.0, length.out = 100)) %&gt;% mutate(y = dchisq(x, 3)) ggplot(df, aes(x, y)) + geom_area(fill = &quot;sky blue&quot;) + gghighlight(x &lt; 3) + labs( x = &quot;V.a. chi-quadrato con 3 gradi di libertà&quot;, y = &quot;Densità&quot; ) 13.5 Distribuzione \\(t\\) di Student Dalle distribuzioni Normale e Chi quadrato deriva un’altra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}\\) e \\(W \\sim \\chi^2_{~\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto \\[\\begin{equation} T = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}} \\end{equation}\\] definisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si usa scrivere \\(T \\sim t_{\\nu}\\). L’andamento della distribuzione \\(t\\) di Student è simile a quello della distribuzione Normale, ma ha una maggiore dispersione (ha le code più pesanti di una Normale, ovvero ha una varianza maggiore di 1). La figura 13.7 mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\). FIGURA 13.7: Alcune distribuzioni \\(t\\) di Student. 13.5.1 Proprietà La variabile casuale \\(t\\) di Student soddisfa le seguenti proprietà: Per \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard \\(\\mathcal{N}(0, 1)\\). La densità della \\(t_{\\nu}\\) è una funzione simmetrica con valore atteso nullo. Per \\(\\nu &gt; 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\); pertanto è sempre maggiore di 1 e tende a 1 per \\(\\nu \\rightarrow \\infty\\). 13.6 Funzione beta La funzione beta di Eulero è una funzione matematica, non una densità di probabilità. La menzioniamo qui perché viene utilizzata nella distribuzione Beta. La funzione beta si può scrivere in molti modi diversi; per i nostri scopi la scriveremo così: \\[\\begin{equation} B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,, \\end{equation}\\] dove \\(\\Gamma(x)\\) è la funzione Gamma, ovvero il fattoriale discendente, cioè \\[\\begin{equation} (x-1)(x-2)\\ldots (x-n+1)\\notag\\,. \\end{equation}\\] Per esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione beta assume il valore alpha &lt;- 3 beta &lt;- 9 beta(alpha, beta) #&gt; [1] 0.002020202 Per chiarire, lo stesso risultato si ottiene con ((2) * (8 * 7 * 6 * 5 * 4 * 3 * 2)) / (11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2) #&gt; [1] 0.002020202 ovvero gamma(alpha) * gamma(beta) / gamma(alpha + beta) #&gt; [1] 0.002020202 13.7 Distribuzione Beta Una distribuzione che viene usata per modellare percentuali e proporzioni è la distribuzione Beta in quanto è definita sull’intervallo \\((0; 1)\\) – ma non include i valori 0 o 1. Una definizione formale è la seguente. Definizione 13.1 Sia \\(\\pi\\) una variabile casuale che può assumere qualsiasi valore compreso tra 0 e 1, cioè \\(\\pi \\in [0, 1]\\). Diremo che \\(\\pi\\) segue la distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\), \\(\\pi \\sim \\text{Beta}(\\alpha, \\beta)\\), se la sua densità è \\[\\begin{align} \\text{Beta}(\\pi \\mid \\alpha, \\beta) &amp;= \\frac{1}{B(\\alpha, \\beta)}\\pi^{\\alpha-1} (1-\\pi)^{\\beta-1}\\notag\\\\ &amp;= \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\pi^{\\alpha-1} (1-\\pi)^{\\beta-1} \\quad \\text{per } \\pi \\in [0, 1]\\,, \\tag{13.2} \\end{align}\\] laddove \\(B(\\alpha, \\beta)\\) è la funzione beta. I termini \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione Beta e devono essere entrambi positivi. Tali parametri possono essere interpretati come l’espressione delle nostre credenze a priori relative ad una sequenza di prove Bernoulliane Il parametro \\(\\alpha\\) rappresenta il numero di “successi” e il parametro \\(\\beta\\) il numero di “insuccessi”: \\[\\begin{equation} \\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,. \\end{equation}\\] Il rapporto \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha+b)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) è una costante di normalizzazione: \\[\\begin{equation} \\int_0^1 \\pi^{\\alpha-1} (1-\\pi)^{\\beta-1} = \\frac{\\Gamma(\\alpha+b)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\,. \\end{equation}\\] Ad esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\) abbiamo a &lt;- 3 b &lt;- 9 integrand &lt;- function(p) {p^{a - 1}*(1 - p)^{b - 1}} integrate(integrand, lower = 0, upper = 1) #&gt; 0.002020202 with absolute error &lt; 2.2e-17 ovvero 1 / (gamma(a + b) / (gamma(a) * gamma(b))) #&gt; [1] 0.002020202 ovvero beta(alpha, beta) #&gt; [1] 0.002020202 Il valore atteso, la moda e la varianza di una distribuzione Beta sono dati dalle seguenti equazioni: \\[\\begin{equation} \\mathbb{E}(\\pi) = \\frac{\\alpha}{\\alpha+\\beta}\\,, \\tag{13.3} \\end{equation}\\] \\[\\begin{equation} \\mbox{Mo}(\\pi) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,, \\tag{13.4} \\end{equation}\\] \\[\\begin{equation} \\mathbb{V}(\\pi) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,. \\tag{13.5} \\end{equation}\\] Al variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un’illustrazione è fornita dalla seguente GIF animata. Si può ottenere una rappresentazione grafica della distribuzione \\(\\mbox{Beta}(\\pi \\mid \\alpha, \\beta)\\) con la funzione plot_beta() del pacchetto bayesrules. Per esempio: bayesrules::plot_beta(alpha = 3, beta = 9) La funzione bayesrules::summarize_beta() ci restituisce la media, moda e varianza della distribuzione Beta. Per esempio: bayesrules::summarize_beta(alpha = 3, beta = 9) #&gt; mean mode var sd #&gt; 1 0.25 0.2 0.01442308 0.1200961 Osservazione. Attenzione alle parole: in questo contesto, il termine “beta” viene utilizzato con tre significati diversi: la distribuzione di densità Beta, la funzione matematica beta, il parametro \\(\\beta\\). Esercizio 13.4 Nel disturbo depressivo la recidiva è definita come la comparsa di un nuovo episodio depressivo che si manifesta dopo un prolungato periodo di recupero (6-12 mesi) con stato di eutimia (umore relativamente normale). Supponiamo che una serie di studi mostri una comparsa di recidiva in una proporzione che va dal 20% al 60% dei casi, con una media del 40% (per una recente discussione, si veda Nuggerud-Galeas et al. 2020). Sulla base di queste ipotetiche informazioni, è possibile usare la distribuzione Beta per rappresentare le nostre credenze a priori relativamente alla probabilità di recidiva. Per fare questo dobbiamo trovare i parametri della distribuzione Beta tali per cui la massa della densità sia compresa tra 0.2 e 0.6, con la media in corrispondenza di 0.4. Procedendo per tentativi ed errori, ed usando la funzione bayesrules::plot_beta(), un risultato possibile è \\(\\Beta(16, 24)\\). La funzione find_pars() prende in input la media e \\(\\alpha + \\beta\\), ritorna i valori dei parametri: find_pars &lt;- function(ev, n) { a &lt;- ev * n b &lt;- n - a return(c(round(a), round(b))) } pars &lt;- find_pars(.4, 40) pars #&gt; [1] 16 24 bayesrules::plot_beta(pars[1], pars[2]) Verifichiamo il valore della media della distribuzione: 16 / (16 + 24) #&gt; [1] 0.4 La moda è (16 - 1) / (16 + 24 - 2) #&gt; [1] 0.3947368 La deviazione standard della distribuzione è uguale a circa 8 punti percentuali: sqrt((16 * 24) / ((16 + 24)^2 * (16 + 24 + 1))) #&gt; [1] 0.07650921 Gli stessi risultati si ottengono usando la funzione bayesrules::summarize_beta(): bayesrules::summarize_beta(alpha = 16, beta = 24) #&gt; mean mode var sd #&gt; 1 0.4 0.3947368 0.005853659 0.07650921 Possiamo concludere dicendo che, se utilizziamo la distribuzione \\(\\mbox{Beta}(16, 24)\\) per rappresentare le nostre credenze (a priori) rispetto la possibilità di recidiva, ciò significa che pensiamo che la nostra incertezza sia quantificabile nei termini di una deviazione standard di circa 8 punti percentuali rispetto a tutti i valori possibili di recidiva, per i quali il valore più verosimile (ovvero, la media della distribuzione) è 0.40. Esercizio 13.5 Poniamoci ora il problema di verificare la nostra comprensione delle funzioni \\(\\R\\) che possono essere usate per la funzione Beta. Continuiamo con l’esercizio precedente e utilizziamo i seguenti parametri per la distribuzione Beta: alpha &lt;- 16 beta &lt;- 24 La media di una \\(\\mbox{Beta}(16, 24)\\) è alpha / (alpha + beta) #&gt; [1] 0.4 In corrispondenza della media la densità della funzione è dbeta(pi, alpha, beta) #&gt; [1] 0 ovvero gamma(alpha + beta) / (gamma(alpha) * gamma(beta)) * pi^(alpha - 1) * (1 - pi)^(beta - 1) #&gt; [1] -6.99499e+26 Usando la funzione dbeta() possiamo costruire un grafico della funzione \\(\\mbox{Beta}(16, 24)\\) nel modo seguente: x &lt;- seq(0, 1, length.out = 1e4) tibble(x) %&gt;% ggplot(aes(x, dbeta(x, alpha, beta))) + geom_line() + labs( x = &quot;Probabilità di recidiva&quot;, y = &quot;Densità Beta(16, 24)&quot; ) 13.8 Distribuzione di Cauchy La distribuzione di Cauchy è un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libertà. È definita da una densità di probabilità che corrisponde alla funzione, dipendente da due parametri \\(\\theta\\) e \\(d\\) (con la condizione \\(d &gt; 0\\)), \\[\\begin{equation} f(x; \\theta, d) = \\frac{1}{\\pi d} \\frac{1}{1 + \\left(\\frac{x - \\theta}{d} \\right)^2}, \\end{equation}\\] dove \\(\\theta\\) è la mediana della distribuzione e \\(d\\) ne misura la larghezza a metà altezza. 13.9 Distribuzione log-normale Sia \\(y\\) una variabile casuale avente distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo poi una nuova variabile casuale \\(x\\) attraverso la relazione \\[ x = e^y \\quad \\Longleftrightarrow \\quad y = \\log x. \\] Il dominio di definizione della \\(x\\) è il semiasse \\(x &gt; 0\\) e la densità di probabilità \\(f(x)\\) è data da \\[\\begin{equation} f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\frac{1}{x} \\exp \\left\\{-\\frac{(\\log x - \\mu)^2}{2 \\sigma^2} \\right\\}. \\end{equation}\\] Questa funzione di densità si chiama log-normale. Il valore atteso e la varianza di una distribuzione log-normale sono dati dalle seguenti equazioni: \\[\\begin{equation} \\mathbb{E}(x) = \\exp \\left\\{\\mu + \\frac{\\sigma^2}{2} \\right\\}. \\end{equation}\\] \\[\\begin{equation} \\mathbb{V}(x) = \\exp \\left\\{2 \\mu + \\sigma^2 \\right\\} \\left(\\exp \\left\\{\\sigma^2 \\right\\} -1\\right). \\end{equation}\\] Si può dimostrare che il prodotto di variabili casuali log-normali ed indipendenti segue una distribuzione log-normale. 13.10 Distribuzione di Pareto La distribuzione paretiana (o distribuzione di Pareto) è una distribuzione di probabilità continua e così chiamata in onore di Vilfredo Pareto. La distribuzione di Pareto è una distribuzione di probabilità con legge di potenza utilizzata nella descrizione di fenomeni sociali e molti altri tipi di fenomeni osservabili. Originariamente applicata per descrivere la distribuzione del reddito in una società, adattandosi alla tendenza che una grande porzione di ricchezza è detenuta da una piccola frazione della popolazione, la distribuzione di Pareto è diventata colloquialmente nota e indicata come il principio di Pareto, o “regola 80-20”. Questa regola afferma che, ad esempio, l’80% della ricchezza di una società è detenuto dal 20% della sua popolazione. Viene spesso applicata nello studio della distribuzione del reddito, della dimensione dell’impresa, della dimensione di una popolazione e nelle fluttuazioni del prezzo delle azioni. La densità di una distribuzione di Pareto è \\[ f(x)=(x_m/x)^\\alpha, \\] dove \\(x_m\\) (parametro di scala) è il minimo (necessariamente positivo) valore possibile di \\(X\\) e \\(\\alpha\\) è un parametro di forma. La distribuzione di Pareto ha una asimmetria positiva. Il supporto della distribuzione di Pareto è la retta reale positiva. Tutti i valori devono essere maggiori del parametro di scala \\(x_m\\), che è in realtà un parametro di soglia. Commenti e considerazioni finali In questa dispensa le densità continue che useremo più spesso sono la distribuzione gaussiana e la distribuzione Beta. Faremo un uso limitato della distribuzione \\(t\\) di Student e della distribuzione di Cauchy. Le altre distribuzioni qui descritte sono stato presentate solo per completezza. References "],["ch-bayes-workflow.html", "Capitolo 14 Flusso di lavoro bayesiano 14.1 Modellizzazione bayesiana 14.2 Distribuzioni a priori 14.3 La funzione di verosimiglianza 14.4 La verosimiglianza marginale 14.5 Distribuzione a posteriori 14.6 Distribuzione predittiva a priori 14.7 Distribuzione predittiva a posteriori Commenti e considerazioni finali", " Capitolo 14 Flusso di lavoro bayesiano La moderna statistica bayesiana viene per lo più eseguita utilizzando un linguaggio di programmazione probabilistico implementato su computer. Ciò ha cambiato radicalmente il modo in cui venivano eseguite le statistiche bayesiane anche fin pochi decenni fa. La complessità dei modelli che possiamo costruire è aumentata e la barriera delle competenze matematiche e computazionali che sono richieste è diminuita. Inoltre, il processo di modellazione iterativa è diventato, sotto molti aspetti, molto più facile da eseguire. Anche se formulare modelli statistici complessi è diventato più facile che mai, la statistica è un campo pieno di sottigliezze che non scompaiono magicamente utilizzando potenti metodi computazionali. Pertanto, avere una buona preparazione sugli aspetti teorici, specialmente quelli rilevanti per la pratica, è estremamente utile per applicare efficacemente i metodi statistici. 14.1 Modellizzazione bayesiana Nell’approccio bayesiano all’inferenza statistica si prende in considerazione una variabile casuale \\(Y\\) di cui si conosce la distribuzione a meno di un parametro \\(\\theta\\). Secondo l’approccio bayesiano, è possibile modellare l’incertezza sul valore del parametro rappresentandolo con una variabile casuale continua \\(\\Theta\\) avente come supporto l’insieme dei valori ammissibili per il parametro cercato. La funzione di densità \\(p(\\theta)\\) prende il nome di distribuzione a priori e rappresenta la sintesi delle opinioni e delle informazioni che si hanno sul parametro prima dell’osservazione dei dati. L’aggiornamento dell’incertezza su \\(\\theta\\) è determinata dal verificarsi dell’evidenza \\(y\\), ovvero dall’osservazione dei risultati di un esperimento casuale. Le informazioni provenienti dal campione osservato \\(y = (y_1, \\dots, y_n)\\) sono contenute nella funzione \\(p(y \\mid \\theta)\\), che, osservata come funzione di \\(\\theta\\) per \\(y\\), prende il nome di funzione di verosimiglianza. L’aggiornamento delle conoscenze a priori incorporate nella distribuzione iniziale \\(p(\\theta)\\) in seguito al verificarsi di \\(Y = y\\) (evidenza empirica) avviene attraverso il teorema di Bayes in cui \\(p(\\theta \\mid y)\\) risulta proporzionale al prodotto della probabilità a priori e della verosimiglianza e prende il nome di distribuzione a posteriori: \\[\\begin{equation} p(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int_{\\Theta}p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\!\\theta} \\quad \\theta \\in \\Theta. \\tag{14.1} \\end{equation}\\] Si noti che l’integrale al denominatore della (14.1) è spesso di difficile risoluzione analitica per cui l’inferenza bayesiana solitamente procede attraverso metodi di ricampionamento e metodi iterativi, quali le Catene di Markov Monte Carlo (MCMC). Martin, Kumar, and Lao (2022) descrivono la modellazione bayesiana distinguendo tre passaggi. Dati alcuni dati e alcune ipotesi su come questi dati potrebbero essere stati generati, si progetta un modello statistico combinando e trasformando variabili casuali. Si usa il teorema di Bayes per condizionare il modello ai dati. Questo processo viene chiamato “inferenza” e come risultato si ottiene una distribuzione a posteriori. Si critica il modello utilizzando criteri diversi, inclusi i dati e la nostra conoscenza del dominio, per verificare se abbia senso. Poiché in generale siamo incerti sul modello, a volte si confrontano modelli diversi. Questi tre passaggi vengono eseguiti in modo iterativo e danno luogo a quello che è chiamato “flusso di lavoro bayesiano” (bayesian workflow). 14.1.1 Notazione Per fissare la notazione, nel seguito \\(y\\) rappresenterà i dati e \\(\\theta\\) rappresenterà i parametri incogniti di un modello statistico. Sia \\(y\\) che \\(\\theta\\) vengono concepiti come variabili casuali. Con \\(x\\) vengono invece denotate le quantità note, come ad esempio i predittori del modello lineare. Per rappresentare in un modo conciso i modelli probabilistici viene usata una notazione particolare. Ad esempio, invece di scrivere \\(p(\\theta) = \\mbox{Beta}(1, 1)\\) scriviamo \\(\\theta \\sim \\mbox{Beta}(1, 1)\\). Il simbolo “\\(\\sim\\)” viene spesso letto “è distribuito come”. Possiamo anche pensare che significhi che \\(\\theta\\) costituisce un campione casuale estratto dalla distribuzione Beta(1, 1). Allo stesso modo, ad esempio, la verosimiglianza del modello binomiale può essere scritta come \\(y \\sim \\text{Bin}(n, \\theta)\\). 14.2 Distribuzioni a priori Quando adottiamo un approccio bayesiano, i parametri della distribuzione di riferimento non venono considerati come delle costanti incognite ma bensì vengono trattati come variabili casuali; di conseguenza, i parametri assumono una particolare distribuzione che nelle statistica bayesiana viene definita “a priori”. I parametri \\(\\theta\\) possono assumere delle distribuzioni a priori differenti: a seconda delle informazioni disponibili bisogna selezionare una distribuzione di \\(\\theta\\) in modo tale che venga assegnata una probabilità maggiore a quei valori del parametro che si ritengono più plausibili. Idealmente, le credenze a priori che portano alla specificazione di una distribuzione a priori dovrebbero essere supportate da una qualche motivazione, come ad esempio i risultati di ricerche precedenti. 14.2.1 Tipologie di distribuzioni a priori Possiamo distinguere tra diverse distribuzioni a priori in base a quanto fortemente impegnano il ricercatore a ritenere come plausibile un particolare intervallo di valori dei parametri. Il caso più estremo è quello che rivela una totale assenza di conoscenze a priori, il che conduce alle distribuzioni a priori non informative, ovvero quelle che assegnano lo stesso livello di fiducia a tutti i valori dei parametri. Le distribuzioni a priori informative, d’altra parte, possono essere debolmente informative o fortemente informative, a seconda del modo in cui lo sperimentatore distribuisce la sua fiducia nello spazio del parametro. Il caso più estremo di credenza a priori è quello che assegna tutta la probabilità ad un singolo valore del parametro. La figura seguente mostra alcuni esempi di distribuzioni a priori per il modello Binomiale: distribuzione non informativa: \\(\\theta_c \\sim \\mbox{Beta}(1,1)\\); distribuzione debolmente informativa: \\(\\theta_c \\sim \\mbox{Beta}(5,2)\\); distribuzione fortemente informativa: \\(\\theta_c \\sim \\mbox{Beta}(50,20)\\); valore puntuale: \\(\\theta_c \\sim \\mbox{Beta}(\\alpha, \\beta)\\) con \\(\\alpha, \\beta \\rightarrow \\infty\\) e \\(\\frac{\\alpha}{\\beta} = \\frac{5}{2}\\). FIGURA 14.1: Esempi di distribuzioni a priori per il parametro \\(\\theta_c\\) nel Modello Binomiale. 14.2.2 Selezione della distribuzione a priori La selezione delle distribuzioni a priori è stata spesso vista come una delle scelte più importanti che un ricercatore fa quando implementa un modello bayesiano in quanto può avere un impatto sostanziale sui risultati finali. La soggettività delle distribuzioni a priori è evidenziata dai critici come un potenziale svantaggio dei metodi bayesiani. A questa critica, Schoot et al. (2021) rispondono dicendo che, al di là della scelta delle distribuzioni a priori, ci sono molti elementi del processo di inferenza statistica che sono soggettivi, ovvero la scelta del modello statistico e le ipotesi sulla distribuzione degli errori. In secondo luogo, Schoot et al. (2021) notano come le distribuzioni a priori svolgono due importanti ruoli statistici: quello della “regolarizzazione della stima”, ovvero, il processo che porta ad indebolire l’influenza indebita di osservazioni estreme, e quello del miglioramento dell’efficienza della stima, ovvero, la facilitazione dei processi di calcolo numerico di stima della distribuzione a posteriori. L’effetto della distribuzione a priori sulla distribuzione a posteriori verrà discusso in dettaglio nel Capitolo ??. 14.2.3 Un’applicazione empirica Per introdurre la modelizzazione bayesiana useremo qui i dati riportati da Zetsche, Bürkner, and Renneberg (2019) (si veda l’appendice E). Tali dati corrispondono a 23 “successi” in 30 prove e possono dunque essere considerati la manifestazione di una variabile casuale Bernoulliana. Se non abbiamo alcuna informazione a priori su \\(\\theta\\) (ovvero, la probabilità che l’aspettativa dell’umore futuro del partecipante sia distorta negativamente), potremmo pensare di usare una distribuzione a priori uniforme, ovvero una Beta di parametri \\(\\alpha=1\\) e \\(\\beta=1\\). Una tale scelta, tuttavia, è sconsigliata in quanto è più vantaggioso usare una distribuzione debolmente informativa, come ad esempio \\(\\mbox{Beta}(2, 2)\\), che ha come scopo la regolarizzazione, cioè quello di mantenere le inferenze in un intervallo ragionevole. Qui useremo una \\(\\mbox{Beta}(2, 10)\\). \\[ p(\\theta) = \\frac{\\Gamma(12)}{\\Gamma(2)\\Gamma(10)}\\theta^{2-1} (1-\\theta)^{10-1}. \\] bayesrules::plot_beta(alpha = 2, beta = 10, mean = TRUE, mode = TRUE) La \\(\\mbox{Beta}(2, 10)\\) esprime la credenza che \\(\\theta\\) assume valori \\(&lt; 0.5\\), con il valore più plausibile pari a circa 0.1. Questo è assolutamente implausibile per il caso dell’esempio in discussione: la \\(\\mbox{Beta}(2, 10)\\) verrà usata solo per scopi didattici, ovvero, per esplorare le conseguenze di tale scelta sulla distribuzione a posteriori. 14.3 La funzione di verosimiglianza Iniziamo con una definizione. Definizione 14.1 La funzione di verosimiglianza \\(\\mathcal{L}(\\theta \\mid y) = f(y \\mid \\theta), \\theta \\in \\Theta,\\) è la funzione di massa o di densità di probabilità dei dati \\(y\\) vista come una funzione del parametro sconosciuto (o dei parametri sconosciuti) \\(\\theta\\). Detto in altre parole, le funzioni di verosimiglianza e di (massa o densità di) probabilità sono formalmente identiche, ma è completamente diversa la loro interpretazione. Nel caso della funzione di massa o di densità di probabilità la distribuzione del vettore casuale delle osservazioni campionarie \\(y\\) dipende dai valori assunti dal parametro (o dai parametri) \\(\\theta\\); nel caso della la funzione di verosimiglianza la credibilità assegnata a ciascun possibile valore \\(\\theta\\) viene determinata avendo acquisita l’informazione campionaria \\(y\\) che rappresenta l’elemento condizionante. In altri termini, la funzione di verosimiglianza descrive in termini relativi il sostegno empirico che \\(\\theta \\in \\Theta\\) riceve da \\(y\\). Infatti, la funzione di verosimiglianza assume forme diverse al variare di \\(y\\). Possiamo dunque pensare alla funzione di verosimiglianza come alla risposta alla seguente domanda: avendo osservato i dati \\(y\\), quanto risultano (relativamente) credibili i diversi valori del parametro \\(\\theta\\)? In termini più formali possiamo dire: sulla base dei dati, \\(\\theta_1 \\in \\Theta\\) risulta più credibile di \\(\\theta_2 \\in \\Theta\\) quale indice del modello probabilistico generatore dei dati se \\(\\mathcal{L}(\\theta_1) &gt; \\mathcal{L}(\\theta_1)\\). Notiamo un punto importante: la funzione \\(\\mathcal{L}(\\theta \\mid y)\\) non è una funzione di densità. Infatti, essa non racchiude un’area unitaria. 14.3.1 Notazione Seguendo una pratica comune, in questa dispensa spesso useremo la notazione \\(p(\\cdot)\\) per rappresentare due quantità differenti, ovvero la funzione di verosimiglianza e la distribuzione a priori. Questo piccolo abuso di notazione riflette il seguente punto di vista: anche se la verosimiglianza non è una funzione di densità di probabilità, noi non vogliamo stressare questo aspetto, ma vogliamo piuttosto pensare alla verosimiglianza e alla distribuzione a priori come a due elementi che sono egualmente necessari per calcolare la distribuzione a posteriori. In altri termini, per così dire, questa notazione assegna lo stesso status epistemologico alle due diverse quantità che si trovano al numeratore della regola di Bayes. 14.3.2 La log-verosimiglianza Dal punto di vista pratico risulta più conveniente utilizzare, al posto della funzione di verosimiglianza, il suo logaritmo naturale, ovvero la funzione di log-verosimiglianza: \\[\\begin{equation} \\ell(\\theta) = \\log \\mathcal{L}(\\theta). \\end{equation}\\] Poiché il logaritmo è una funzione strettamente crescente (usualmente si considera il logaritmo naturale), allora \\(\\mathcal{L}(\\theta)\\) e \\(\\ell(\\theta)\\) assumono il massimo (o i punti di massimo) in corrispondenza degli stessi valori di \\(\\theta\\) (per un approfondimento, si veda l’Appendice ??): \\[ \\hat{\\theta} = \\argmax_{\\theta \\in \\Theta} \\ell(\\theta) = \\argmax_{\\theta \\in \\Theta} \\mathcal{L}(\\theta). \\] Per le proprietà del logaritmo, si ha \\[\\begin{equation} \\ell(\\theta) = \\log \\left( \\prod_{i = 1}^n f(y \\mid \\theta) \\right) = \\sum_{i = 1}^n \\log f(y \\mid \\theta). \\end{equation}\\] Si noti che non è necessario lavorare con i logaritmi, ma è fortemente consigliato. Il motivo è che i valori della verosimiglianza, in cui si moltiplicano valori di probabilità molto piccoli, possono diventare estremamente piccoli – qualcosa come \\(10^{-34}\\). In tali circostanze, non è sorprendente che i programmi dei computer mostrino problemi di arrotondamento numerico. Le trasformazioni logaritmiche risolvono questo problema. 14.3.3 Un’applicazione empirica Se i dati di Zetsche, Bürkner, and Renneberg (2019) possono essere riassunti da una proporzione allora è sensato adottare un modello probabilistico binomiale quale meccanismo generatore dei dati: \\[\\begin{equation} y \\sim \\mbox{Bin}(n, \\theta), \\tag{14.2} \\end{equation}\\] laddove \\(\\theta\\) è la probabiltà che una prova Bernoulliana assuma il valore 1 e \\(n\\) corrisponde al numero di prove Bernoulliane. Questo modello assume che le prove Bernoulliane \\(y_i\\) che costituiscono il campione \\(y\\) siano tra loro indipendenti e che ciascuna abbia la stessa probabilità \\(\\theta \\in [0, 1]\\) di essere un “successo” (valore 1). In altre parole, il modello generatore dei dati avrà una funzione di massa di probabilità \\[ p(y \\mid \\theta) \\ = \\ \\mbox{Bin}(y \\mid n, \\theta). \\] Nei capitoli precedenti è stato mostrato come, sulla base del modello binomiale, sia possibile assegnare una probabilità a ciascun possibile valore \\(y \\in \\{0, 1, \\dots, n\\}\\) assumendo noto il valore del parametro \\(\\theta\\). Ma ora abbiamo il problema inverso, ovvero quello di fare inferenza su \\(\\theta\\) alla luce dei dati campionari \\(y\\). In altre parole, riteniamo di conoscere il modello probabilistico che ha generato i dati, ma di tale modello non conosciamo i parametri: vogliamo dunque ottenere informazioni su \\(\\theta\\) avendo osservato i dati \\(y\\). Per i dati di Zetsche, Bürkner, and Renneberg (2019) la funzione di verosimiglianza corrisponde alla funzione binomiale di parametro \\(\\theta \\in [0, 1]\\) sconosciuto. Abbiamo osservato un “successo” 23 volte in 30 “prove”, dunque, \\(y = 23\\) e \\(n = 30\\). La funzione di verosimiglianza diventa \\[\\begin{equation} \\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} \\theta^{23} + (1-\\theta)^7. \\tag{14.3} \\end{equation}\\] Per costruire la funzione di verosimiglianza dobbiamo applicare la (14.3) tante volte, cambiando ogni volta il valore \\(\\theta\\) ma tenendo sempre costante il valore dei dati. Per esempio, se poniamo \\(\\theta = 0.1\\) \\[ \\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.1^{23} + (1-0.1)^7 \\] otteniamo dbinom(23, 30, 0.1) #&gt; [1] 9.737168e-18 Se poniamo \\(\\theta = 0.2\\) \\[ \\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.2^{23} + (1-0.2)^7 \\] otteniamo dbinom(23, 30, 0.2) #&gt; [1] 3.581417e-11 e così via. La figura 14.2 — costruita utilizzando 100 valori equispaziati \\(\\theta \\in [0, 1]\\) — fornisce una rappresentazione grafica della funzione di verosimiglianza. n &lt;- 30 y &lt;- 23 theta &lt;- seq(0, 1, length.out = 100) like &lt;- choose(n, y) * theta^y * (1 - theta)^(n - y) tibble(theta, like) %&gt;% ggplot(aes(x = theta, y = like)) + geom_line() + labs( y = expression(L(theta)), x = expression(&quot;Valori possibili di&quot; ~ theta) ) FIGURA 14.2: Funzione di verosimiglianza nel caso di 23 successi in 30 prove. Come possiamo interpretare la curva che abbiamo ottenuto? Per alcuni valori \\(\\theta\\) la funzione di verosimiglianza assume valori piccoli; per altri valori \\(\\theta\\) la funzione di verosimiglianza assume valori più grandi. Questi ultimi sono i valori di \\(\\theta\\) più credibili e il valore 23/30 (la moda della funzione di verosimiglianza) è il valore più credibile di tutti. 14.4 La verosimiglianza marginale Per il calcolo di \\(p(\\theta \\mid y)\\) è necessario dividere il prodotto tra la distribuzione a priori e la verosimiglianza per una costante di normalizzazione. Tale costante di normalizzazione, detta verosimiglianza marginale, ha lo scopo di fare in modo che \\(p(\\theta \\mid y)\\) abbia area unitaria. Si noti che, nel caso di variabili continue, la verosimiglianza marginale è espressa nei termini di un integrale. Tranne in pochi casi particolari, tale integrale non ha una soluzione analitica. Per questa ragione, l’inferenza bayesiana procede calcolando una approssimazione della distribuzione a posteriori mediante metodi numerici. 14.4.1 Un’applicazione empirica Consideriamo nuovamente i dati di Zetsche, Bürkner, and Renneberg (2019). Supponiamo che nel numeratore bayesiano la verosimiglianza sia moltiplicata per una distribuzione uniforme, ovvero \\(\\mbox{Beta}(1, 1)\\). In tali circostanze, il prodotto si riduce alla funzione di verosimiglianza. Per i dati di Zetsche, Bürkner, and Renneberg (2019), dunque, la costante di normalizzazione si ottiene marginalizzando la funzione di verosimiglianza \\(p(y = 23, n = 30 \\mid \\theta)\\) sopra \\(\\theta\\), ovvero risolvendo l’integrale: \\[\\begin{equation} p(y = 23, n = 30) = \\int_0^1 \\binom{30}{23} \\theta^{23} (1-\\theta)^{7} \\,\\operatorname {d}\\!\\theta. \\tag{14.4} \\end{equation}\\] Una soluzione numerica si trova facilmente usando \\(\\R\\): like_bin &lt;- function(theta) { choose(30, 23) * theta^23 * (1 - theta)^7 } integrate(like_bin, lower = 0, upper = 1)$value #&gt; [1] 0.03225806 La derivazione analitica è fornita nell’Appendice G. 14.5 Distribuzione a posteriori La distribuzione a postreriori si trova applicando il teorema di Bayes: \\[ \\text{probabilità a posteriori} = \\frac{\\text{probabilità a priori} \\cdot \\text{verosimiglianza}}{\\text{costante di normalizzazione}} \\] Una volta trovata la distribuzione a posteriori, possiamo usarla per derivare altre quantità di interesse. Questo viene generalmente ottenuto calcolando il seguente valore atteso: \\[ J = \\int f(\\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!y \\] Se \\(f(\\cdot)\\) è la funzione identità, ad esempio, \\(J\\) risulta essere la media di \\(\\theta\\): \\[ \\bar{\\theta} = \\int_{\\Theta} \\theta p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta . \\] Ripeto qui quanto detto sopra: le quantità di interesse della statistica bayesiana(costante di normalizzazione, valore atteso della distribuzione a posteriori, ecc.) contengono integrali che risultano, nella maggior parte dei casi, impossibili da risolvere analiticamente. Per questo motivo, si ricorre a metodi di stima numerici, in particolare a quei metodi Monte Carlo basati sulle proprietà delle catene di Markov (MCMC). Questo argomento verrà discusso nel Capitolo ??. 14.6 Distribuzione predittiva a priori La distribuzione a posteriori è l’oggetto centrale nella statistica bayesiana, ma non è l’unico. Oltre a fare inferenze sui valori dei parametri, potremmo voler fare inferenze sui dati. Questo può essere fatto calcolando la distribuzione predittiva a priori: \\[\\begin{equation} p(y^*) = \\int_\\Theta p(y^* \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\!\\theta . \\tag{14.5} \\end{equation}\\] La (14.5) descrive la distribuzione prevista dei dati in base al modello (che include la distribuzione a priori e la verosimiglianza), ovvero descrive i dati \\(y^*\\) che ci aspettiamo di osservare, dato il modello, prima di avere osservato i dati del campione. È possibile utilizzare campioni dalla distribuzione predittiva a priori per valutare e calibrare i modelli utilizzando le nostre conoscenze dominio-specifiche. Ad esempio, ci possiamo chiedere: “È sensato che un modello dell’altezza umana preveda che un essere umano sia alto -1.5 metri?”. Già prima di misurare una singola persona, possiamo renderci conto dell’assurdità di questa domanda. Se la distribuzione prevista dei dati consente domande di questo tipo (ovvero, prevede di osservare dati che risultano insensati alla luce delle nostre conoscenze dominio-specifiche), è chiaro che il modello deve essere riformulato. 14.7 Distribuzione predittiva a posteriori Un’altra quantità utile da calcolare è la distribuzione predittiva a posteriori: \\[\\begin{equation} p(\\tilde{y} \\mid y) = \\int_\\Theta p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta . \\tag{14.6} \\end{equation}\\] Questa è la distribuzione dei dati attesi futuri \\(\\tilde{y}\\) alla luce della distribuzione a posteriori \\(p(\\theta \\mid y)\\), che a sua volta è una conseguenza del modello adottato (distribuzione a priori e verosimiglianza) e dei dati osservati. In altre parole, questi sono i dati che il modello si aspetta dopo aver osservato i dati de campione. Dalla (14.6) possiamo vedere che le previsioni sui dati attesi futuri sono calcolate integrando (o marginalizzando) sulla distribuzione a posteriori dei parametri. Di conseguenza, le previsioni calcolate in questo modo incorporano l’incertezza relativa alla stima dei parametri del modello. Commenti e considerazioni finali Questo Capitolo ha brevemente passato in rassegna i concetti di base dell’inferenza statistica bayesiana. In base all’approccio bayesiano, invece di dire che il parametro di interesse di un modello statistico ha un valore vero ma sconosciuto, diciamo che, prima di eseguire l’esperimento, è possibile assegnare una distribuzione di probabilità, che chiamano stato di credenza, a quello che è il vero valore del parametro. Questa distribuzione a priori può essere nota (per esempio, sappiamo che la distribuzione dei punteggi del QI è normale con media 100 e deviazione standard 15) o può essere del tutto arbitraria. L’inferenza bayesiana procede poi nel modo seguente: si raccolgono alcuni dati e si calcola la probabilità dei possibili valori del parametro alla luce dei dati osservati e delle credenze a priori. Questa nuova distribuzione di probabilità è chiamata “distribuzione a posteriori” e riassume l’incertezza dell’inferenza. References "],["ch-subj-think-prop.html", "Capitolo 15 Pensare ad una proporzione in termini soggettivi 15.1 Inferenza bayesiana con una distribuzione a priori discreta 15.2 Inferenza bayesiana con una distribuzione a priori continua Commenti e considerazioni finali", " Capitolo 15 Pensare ad una proporzione in termini soggettivi Obiettivo di questo Capitolo è introdurre l’inferenza bayesiana considerando il caso della verosimiglianza binomiale. Esamineremo prima il caso di una distribuzione a priori è discreta; poi considereremo una distribuzione a priori continua. Il materiale qui presentato segue molto da vicino il capitolo 7 del testo di Albert and Hu (2019). 15.1 Inferenza bayesiana con una distribuzione a priori discreta Nei problemi tradizionali di teoria delle probabilità ci sono molti esempi che riguardano l’estrazione di palline colorate da un’urna. In questi esempi, ci viene fornito il numero di palline di vari colori presenti nell’urna e ci viene chiesto di calcolare le probabilità di vari eventi. Ad esempio, in un’urna ci sono 40 palline bianche e 20 rosse. Se estrai due palline a caso, qual è la probabilità che entrambe siano bianche? L’approccio bayesiano considera uno scenario diverso, ovvero quello in cui non conosciamo le proporzioni delle palline colorate presenti nell’urna. Cioè, nell’esempio precedente, sappiamo solo che nell’urna ci sono due tipi di palline colorate, ma non sappiamo che 40 sono bianche (proporzione di bianco = \\(2/3\\)) e 20 sono rosse (proporzione di rosso = \\(1/3\\)). Ci poniamo la seguente domanda: è possibile inferire le proporzioni di palline nell’urna estraendo un campione di palline dall’urna e osservando i colori delle palline nel campione? Espresso in questo modo, questo diventa un problema di inferenza statistica, perché stiamo cercando di inferire la proporzione \\(\\theta\\) della popolazione sulla base di un campione casuale. Per continuare con l’esempio precedente, quello che vogliamo fare è inferire \\(\\theta\\), la proporzione di palline rosse nell’urna, in base al numero di palline rosse e bianche che osserviamo nel campione. Le proporzioni assomigliano alle probabilità. Ricordiamo che sono state proposte tre diverse interpretazioni del concetto di una probabilità. Il punto di vista classico: è necessario enumerare tutti gli eventi elementari dello spazio campionario in cui ogni risultato è ugualmente probabile. Il punto di vista frequentista: è necessario ripetere l’esperimento esperimento casuale (cioè l’estrazione del campione) molte volte in condizioni identiche. La visione soggettiva: è necessario esprimere la propria opinione sulla probabilità di un evento unico e irripetibile. La visione classica non sembra potere funzionare qui, perché sappiamo solo che ci sono due tipi di palline colorate e il numero totale di palline è 60. Anche se estraiamo un campione di 10 palline, possiamo solo osservare la proporzione di palline rosse palline nel campione. Non c’è modo per stabilire quali sono le proprietà dello spazio campionario in cui ogni risultato è ugualmente probabile. La visione frequentista potrebbe funzionare nel caso presente. Possiamo considerare il processo del campionamento (cioè l’estrazione di un campione casuale di 10 palline dall’urna) come un esperimento casuale che produce una proporzione campionaria \\(p\\). Potremmo quindi pensare di ripetere l’esperimento molte volte nelle stesse condizioni, ottenere molte proporzioni campionarie \\(p\\) e riassumere poi in qualche modo questa distribuzione di statistiche campionarie. Ripetendo l’esperimento casuale tante volte è possibile ottenere una stima abbastanza accurata della proporzione \\(\\theta\\) di palline rosse nell’urna. Questo processo è fattibile, ma è però noioso, dispendioso in termini di tempo e soggetto ad errori. La visione soggettivista concepisce invece la probabilità sconosciuta \\(\\theta\\) come un’opinione soggettiva di cui possiamo essere più o meno sicuri. Abbiamo visto in precedenza come questa opinione soggettiva dipenda da due tipi di evidenze: le nostre credenze iniziali e le nuove informazioni fornite dai dati che abbiamo osservato. Vedremo in questo capitolo come sia possibile combinare le credenze iniziali rispetto al possibile valore \\(\\theta\\) con le evidenza fornite dai dati per giungere ad una credenza a posteriori su \\(\\theta\\). In particolare, vedremo come si possa pensare in termini soggetti a delle quantità sconosciute (in questo caso, \\(\\theta\\)) usando le distribuzioni di probabilità. Sappiamo che, essendo una proporzione, \\(\\theta\\) può assumere valori compresi tra 0 e 1. Potremmo pensare che \\(\\theta\\) sia uguale, ad esempio, a 0.5. Ciò significa assegnare all’evento \\(\\theta = 1\\) la probabilità 1 – in altri termini, significa dire che siamo assolutamente certi che la quantità sconosciuta \\(\\theta\\) ha il valore di 0.5. Questa posizione, però, è troppo estrema: non possiamo essere assolutamente certi che una quantità sconosciuta abbia uno specifico valore; altrimenti non sarebbe una quantità sconosciuta. Invece, sembra più sensato pensare che \\(\\theta\\) può, in linea di principio, assumere valori diversi e, a questi valori, vengono attribuiti diversi livelli di certezza soggettiva. Consideriamo, ad esempio, 10 possibili valori per \\(\\theta\\): theta = seq(0.1, 1, length.out = 10) theta #&gt; [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Se non abbiamo alcun motivo di pensare diversamente, potremmo pensare di assegnare a ciascuno di questi valori lo stesso livello di plausibilità: p1 &lt;- rep(0.1, 10) p1 #&gt; [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 tibble(theta, p1) %&gt;% ggplot(aes(theta, p1)) + geom_segment( aes(xend = theta, yend = 0), size = 10, lineend = &quot;butt&quot; ) Oppure, per qualche ragione, potremmo pensare che i valori centrali della distribuzione di \\(\\theta\\) siamo più plausibili dei valori estremi. Tale opinione soggettiva potrebbe corrispondere alla seguente distribuzione di massa di probabilità: p2 &lt;- c( 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05 ) p2 #&gt; [1] 0.050 0.050 0.050 0.175 0.175 0.175 0.175 0.050 0.050 0.050 tibble(theta, p2) %&gt;% ggplot(aes(theta, p2)) + geom_segment( aes(xend = theta, yend = 0), size = 10, lineend = &quot;butt&quot; ) La prima distribuzione di probabilità è chiamata distribuzione discreta uniforme perché attribuisce la stessa probabilità (ovvero, 1/10) ad ogni elemento dell’insieme discreto su cui è definita (ovvero, \\(0.1, 0.2, \\dots, 1.0\\)). Anche la seconda distribuzione è discreta, ma non è uniforme: viene ritenuto più plausibile che \\(\\theta\\) assuma un valore nell’insieme \\(\\{0.4, 0.5, 0.6, 0.7\\}\\) piuttosto che nell’insieme \\(\\{0.1, 0.2, 0.3, 0.8, 0.9, 1.0\\}\\). Le credenze relative alla plausibilità dei possibili valori che \\(\\theta\\) possono assumere forme diverse e corrispondono a quella che viene chiamata la distribuzione a priori, ovvero descrivono le credenze che possediamo relativamente alla quantità sconosciuta di interesse. La procedura di inferenza bayesiana non fa altro che “aggiornare” tali credenze a priori utilizzando le informazioni fornite da un campione di dati. Usando il teorema di Bayes, le informazioni dei dati vengono combinate con le nostre precedenti credenze relative alla quantità sconosciuta \\(\\theta\\) per giungere ad una credenza detta “a posteriori”. Supponendo che i dati corrispondano all’osservazione di 12 palline rosse in 20 estrazioni con rimessa dall’urna, usiamo ora la seconda delle distribuzioni a priori descritte in precedenza per ottenere la distribuzione a posteriori. Il teorema di Bayes specifica la distribuzione a posteriori come il prodotto della verosimiglianza e la distribuzione a priori, diviso per una costante di normalizzazione: \\[ p(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)}. \\] Per definire la funzione di verosimiglianza, \\(p(y \\mid \\theta)\\), è necessario pensare a come abbiamo ottenuto i dati. Abbiamo estratto 20 palline dall’una, con rimessa. Dunque, se l’estrazione è stata casuale con reinserimento, allora i dati (12 successi in 20 prove) possono essere intesi come il risultato di un esperimento casuale binomiale. Usando \\(\\textsf{R}\\), la funzione di verosimiglianza è dunque data da: like &lt;- dbinom(12, 20, theta) like #&gt; [1] 5.422595e-08 8.656592e-05 3.859282e-03 3.549744e-02 1.201344e-01 #&gt; [6] 1.797058e-01 1.143967e-01 2.216088e-02 3.557765e-04 0.000000e+00 tibble(theta, like) %&gt;% ggplot(aes(theta, like)) + geom_segment( aes(xend = theta, yend = 0), size = 10, lineend = &quot;butt&quot; ) Per calcolare la distribuzione a posteriori dobbiamo dunque fare il prodotto (elemento per elemento) del vettore che contiene i valori della distribuzione a priori per il vettore che contiene i valori di verosimiglianza. Tale prodotto andrà poi diviso per una costante di normalizzazione, \\(p(y)\\). Per la legge della probabilità totale, il denominatore corrisponde alla probabilità marginale dei dati \\(y\\) ed è uguale alla somma dei prodotti tra la distribuzione a priori e la verosimiglianza calcolata in corrispondenza di ciascun valore possibile di \\(\\theta\\). Nel nostro caso discreto, la probabilità marginale dei dati ci calcola utilizzando la distribuzione a priori p2 #&gt; [1] 0.050 0.050 0.050 0.175 0.175 0.175 0.175 0.050 0.050 0.050 e la verosimiglianza like #&gt; [1] 5.422595e-08 8.656592e-05 3.859282e-03 3.549744e-02 1.201344e-01 #&gt; [6] 1.797058e-01 1.143967e-01 2.216088e-02 3.557765e-04 0.000000e+00 Dopo avere fatto il prodotto p2 * like #&gt; [1] 2.711298e-09 4.328296e-06 1.929641e-04 6.212052e-03 2.102351e-02 #&gt; [6] 3.144851e-02 2.001943e-02 1.108044e-03 1.778882e-05 0.000000e+00 dobbiamo sommare: sum(p2 * like) #&gt; [1] 0.08002663 Una volta calcolata la verosimiglianza marginale dei dati, possiamo trovare la distribuzione a posteriori di \\(\\theta\\): post &lt;- (p2 * like) / sum(p2 * like) post #&gt; [1] 3.387994e-08 5.408570e-05 2.411248e-03 7.762481e-02 2.627064e-01 #&gt; [6] 3.929756e-01 2.501596e-01 1.384594e-02 2.222863e-04 0.000000e+00 tibble(theta, post) %&gt;% ggplot(aes(theta, post)) + geom_segment( aes(xend = theta, yend = 0), size = 10, lineend = &quot;butt&quot; ) Conoscendo la distribuzione a posteriori di \\(\\theta\\) diventa possibile calcolare altre quantità di interesse. Per esempio, la moda a posteriori di \\(\\theta\\) si ricava direttamente dal grafico precedente, e corrisponde a 0.6. La media a posteriori è data da: sum(pi * post) #&gt; [1] 3.141593 La varianza della distribuzione a posteriori è sum(theta^2 * post) - (sum(theta * post))^2 #&gt; [1] 0.008817409 Il calcolo della distribuzione a posteriori, nel caso di una distribuzione a priori discreta, è implementata nella funzione bayesian_crank() del pacchetto ProbBayes. Dato che ProbBayes non è su CRAN, può essere installato nel modo seguente: library(&quot;devtools&quot;) install_github(&quot;bayesball/ProbBayes&quot;) Una volta installato, il pacchetto può essere caricato come facciamo normalmente: library(&quot;ProbBayes&quot;) Per usare bayesian_crank() procediamo come indicato di seguito: df &lt;- tibble(p = theta, Prior = p2) y &lt;- 12 n &lt;- 20 df$Likelihood &lt;- dbinom(y, prob = df$p, size = n) df &lt;- bayesian_crank(df) df #&gt; # A tibble: 10 × 5 #&gt; p Prior Likelihood Product Posterior #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.1 0.05 0.0000000542 0.00000000271 0.0000000339 #&gt; 2 0.2 0.05 0.0000866 0.00000433 0.0000541 #&gt; 3 0.3 0.05 0.00386 0.000193 0.00241 #&gt; 4 0.4 0.175 0.0355 0.00621 0.0776 #&gt; 5 0.5 0.175 0.120 0.0210 0.263 #&gt; 6 0.6 0.175 0.180 0.0314 0.393 #&gt; 7 0.7 0.175 0.114 0.0200 0.250 #&gt; 8 0.8 0.05 0.0222 0.00111 0.0138 #&gt; # … with 2 more rows Verifichiamo il risultato trovato calcolando, ad esempio, la media a posteriori (come abbiamo fatto sopra): sum(pi * df$Posterior) #&gt; [1] 3.141593 In questo modo possiamo dunque trovare la distribuzione a posteriori per \\(\\theta\\), nel caso di qualunque distribuzione a priori discreta. 15.2 Inferenza bayesiana con una distribuzione a priori continua Il caso di una distribuzione a priori discreta è stato discusso solo per scopi didattici. In generale, però, l’uso di una distribuzione a priori discreta non è una buona scelta per rappresentare le nostre credenze a priori sul parametro sconosciuto. Infatti, per definizione, una distribuzione a priori discreta può rappresentare solo alcuni dei possibili valori del parametro – nel caso dell’esempio precedente, non abbiamo considerato il valore 0.55, per esempio. Sembra molto più sensato descrivere le nostre credenze a priori sul parametro utilizzando una distribuzione continua. Cerchiamo una funzione di densità con supporto in \\([0, 1]\\). Il candidato naturale è ovviamente fornito dalla funzione Beta (si veda il Capitolo ??). Come per le altre funzioni di densità, abbiamo a disposizione quattro funzioni \\(\\textsf{r}\\) che ci consentono di manipolare facilmente questa densità. Ad esempio, possiao valutare la funzione di densità \\(\\mbox{Beta}(1, 1)\\) in corrispondenza dei valori \\(p = 0.5\\) e \\(p = 0.8\\), che dovrebbe essere entrambi uguali a 1, e in corrispondenza di \\(p = 1.2\\), che dovrebbe essere ugualea 0 poiché questo valore è al di fuori dell’intervallo \\([ 0, 1]\\). dbeta(c(0.5, 0.8, 1.2), 1, 1) #&gt; [1] 1 1 0 Oppure possiamo valutare la funzione distribuzione \\(\\mbox{Beta}(1, 1)\\) in corrispondenza dei punti 0.5 e 0.8: pbeta(c(0.5, 0.8), 1, 1) #&gt; [1] 0.5 0.8 Oppure possiamo calcolare la probabilità \\(P(0.5 &lt; p &lt; 0.8)\\) pbeta(0.8, 1, 1) - pbeta(0.5, 1, 1) #&gt; [1] 0.3 Possiamo trovare i quntili della distribuzione \\(\\mbox{Beta}(1, 1)\\) di ordine 0.5 e 0.8: qbeta(c(0.5, 0.8), 1, 1) #&gt; [1] 0.5 0.8 Infine, è possibile simulare dei valori casuali dalla distribuzione \\(\\mbox{Beta}(1, 1)\\). Se vogliamo 5 valori, scriviamo: rbeta(5, 1, 1) #&gt; [1] 0.2523117 0.5492791 0.2174402 0.4063601 0.2128675 Se vogliamo 5 valori da una \\(\\mbox{Beta}(2, 10)\\), scriviamo: rbeta(5, 2, 10) #&gt; [1] 0.17364773 0.21332530 0.24430864 0.15817644 0.04897118 Il pacchetto ProbBayes offre la funzione beta_area() per visualizzare la probabilità di una distribuzione Beta in un certo intrvallo di valori. Per esempio, se vogliamo la probabilità dell’evento per cui la variabile casuale \\(p\\) è contenuta nell’intervallo \\([0.1, 0.3]\\) nel caso di una \\(\\mbox{Beta}(2, 10)\\), scriviamo: beta_area(0.1, 0.3, c(2, 10)) 15.2.1 Quali parametri per la distribuzione Beta? Se usiamo una distribuzione Beta per rappresentare le nostre credenze a priori sul parametro \\(\\theta\\) (probabilità di successo), allora dobbiamo porci il problema di scegliere i parametri che definiscono la distribuzione Beta che meglio rappresenta le nostre opinioni a priori. Il modo più ovvio per ottenere questo risultato è per prove ed errori. Oppure, possiamo individuare i parametri \\(\\alpha\\) e \\(\\beta\\) della distribuzione interpretando \\(\\alpha\\) come la nostra stima a priori del numero di “successi”, \\(\\beta\\) come a nostra stima a priori del numero di “insuccessi” e \\(\\alpha + \\beta\\) come il numero di prove del campione. Quindi, per esempio, se pensiamo che, su 30 prove, verranno osservati 10 successi, otteniamo una \\(\\mbox{Beta}(10, 20)\\): bayesrules::plot_beta(10, 20, mean = TRUE, mode = TRUE) In alternativa, potremmo specificare la distribuzione a priori definendo la mediana e un quantile della distribuzione. Per esempio, le nostre opinioni a priori sul parametro potrebbero essere tali per cui pensiamo che la mediana della distribuzione sia 0.25 e il quantile della distribuzione di ordine 0.9 sia 0.5. Usando la Shiny App ProbBayes::ChooseBeta() troviamo i parametri \\(\\alpha = 1.84\\) e \\(\\beta = 4.89\\). Commenti e considerazioni finali Abbiamo qui introdotto la procedura dell’aggiornamento bayesiano nel caso in cui la distribuzione a priori sia discreta. Abbiamo anche fornito alcune informazioni che sono utili per affrontare il problema nel caso in cui viene utilizzata una distribuzione a priori continua. Se viene utilizzata una distribuzione a priori continua, al denominatore del rapporto di Bayes troviamo un integrale che, in generale, non si può risolvere per via analitica. Il caso dell’inferenza di una proporzione, in cui la distribuzione a priori è una distribuzione Beta e la verosimiglianza è binoniale, rappresenta però un’eccezione, ovvero consente di derivare le proprietà della distribuzione a posteriori per via analitica. Il prossimo capitolo ha lo scopo di mostrare come questo possa essere fatto. References "],["ch-distr-coniugate.html", "Capitolo 16 Distribuzioni coniugate 16.1 Lo schema beta-binomiale 16.2 Inferenza bayesiana con distribuzioni a priori continue 16.3 Principali distribuzioni coniugate Commenti e considerazioni finali", " Capitolo 16 Distribuzioni coniugate Obiettivo di questo Capitolo è fornire un esempio di derivazione della distribuzione a posteriori scegliendo quale distribuzione a priori una distribuzione coniugata. Esamineremo qui il lo schema beta-binomiale. 16.1 Lo schema beta-binomiale Esiste una particolare classe di distribuzioni a priori, dette distribuzioni a priori coniugate al modello, che godono di un’importante proprietà: se la distribuzione iniziale appartiene a tale classe, anche la distribuzione finale vi appartiene, cioé ha la stessa forma funzionale, e l’aggiornamento della fiducia si riduce alla modifica dei parametri della distribuzione a priori. Ad esempio, se la distribuzione a priori è una Beta e la verosimiglianza è binomiale, allora la distribuzione a posteriori sarà anch’essa una distribuzione Beta. Da un punto di vista matematico, le distribuzioni a priori coniugate sono la scelta più conveniente in quanto consentono di calcolare analiticamente la distribuzione a posteriori con “carta e penna”, senza la necessità di ricorrere a calcoli complessi. Da una prospettiva computazionale moderna, però, le distribuzioni a priori coniugate generalmente non sono migliori delle alternative, dato che i moderni metodi computazionali consentono di eseguire l’inferenza praticamente con qualsiasi scelta delle distribuzioni a priori, e non solo con le distribuzioni a priori che risultano matematicamente convenienti. Tuttavia, le famiglie coniugate offronto un utile ausilio didattico nello studio dell’inferenza bayesiana. Questo è il motivo per cui le esamineremo qui. Nello specifico, esamineremo quello che viene chiamato lo schema beta-binomiale. Per fare un esempio concreto, consideriamo nuovamente i dati di Zetsche, Bürkner, and Renneberg (2019): nel campione di 30 partecipanti clinici le aspettative future di 23 partecipanti risultano negativamente distorte mentre quelle di 7 partecipanti risultano positivamente distorte. Nel seguito, indicheremo con \\(\\theta\\) la probabilità che le aspettative di un paziente clinico siano distorte negativamente. Ci poniamo il problema di ottenere una stima a posteriori di \\(\\theta\\) avendo osservato 23 “successi” in 30 prove. I dati osservati (\\(y = 23\\)) possono essere considerati la manifestazione di una variabile casuale Bernoulliana, dunque la verosimiglianza è binomiale. In tali circostanze, se viene scelta una distribuzione a priori Beta, allora anche la distribuzione a posteriori sarà una Beta. 16.1.1 La specificazione della distribuzione a priori È possibile esprimere diverse credenze iniziali rispetto a \\(\\theta\\) mediante la distribuzione Beta. Ad esempio, la scelta di una \\(\\mbox{Beta}(\\alpha = 4, \\beta = 4)\\) quale distribuzione a priori per il parametro \\(\\theta\\) corrisponde alla credenza a priori che associa all’evento “presenza di una aspettativa futura distorta negativamente” una grande incertezza: il valore 0.5 è il valore di \\(\\theta\\) più plausibile, ma anche gli altri valori del parametro (tranne gli estremi) sono ritenuti piuttosto plausibili. Questa distribuzione a priori esprime la credenza che sia egualmente probabile per un’aspettativa futura essere distorta negativamente o positivamente. library(&quot;bayesrules&quot;) plot_beta(alpha = 4, beta = 4, mean = TRUE, mode = TRUE) Possiamo quantificare la nostra incertezza calcolando, con un grado di fiducia del 95%, la regione nella quale, in base a tale credenza a priori, si trova il valore del parametro. Per ottenere tale intervallo di credibilità a priori, usiamo la funzione qbeta() di \\(\\R\\). In qbeta() i parametri \\(\\alpha\\) e \\(\\beta\\) sono chiamati shape1 e shape2: qbeta(c(0.025, 0.975), shape1 = 4, shape2 = 4) #&gt; [1] 0.1840516 0.8159484 Se poniamo \\(\\alpha=10\\) e \\(\\beta=10\\), questo corrisponde ad una credenza a priori che sia egualmente probabile per un’aspettativa futura essere distorta negativamente o positivamente, plot_beta(alpha = 10, beta = 10, mean = TRUE, mode = TRUE) ma ora la nostra certezza a priori sul valore del parametro è maggiore, come indicato dall’intervallo al 95%: qbeta(c(0.025, 0.975), shape1 = 10, shape2 = 10) #&gt; [1] 0.2886432 0.7113568 Quale distribuzione a priori dobbiamo scegliere? In un problema concreto di analisi dei dati, la scelta della distribuzione a priori dipende dalle credenze a priori che vogliamo includere nell’analisi dei dati. Se non abbiamo alcuna informazione a priori, potremmo usare \\(\\alpha=1\\) e \\(\\beta=1\\), che produce una distribuzione a priori uniforme. Ma l’uso di distribuzioni a priori uniformi è sconsigliato per vari motivi, inclusa l’instabilità numerica della stima dei parametri. È meglio invece usare una distribuzione a priori debolmente informativa, come \\(\\mbox{Beta}(2, 2)\\). Nella discussione presente, solo per fare un esempio, useremo quale distribuzione a priori una \\(\\mbox{Beta}(2, 10)\\), ovvero: \\[ p(\\theta) = \\frac{\\Gamma(12)}{\\Gamma(2)\\Gamma(10)}\\theta^{2-1} (1-\\theta)^{10-1}. \\] plot_beta(alpha = 2, beta = 10, mean = TRUE, mode = TRUE) La \\(\\mbox{Beta}(2, 10)\\) esprime la credenza che \\(\\theta &lt; 0.5\\), con il valore più plausibile pari a cicrca 0.1. 16.1.2 La specificazione della distribuzione a posteriori Una volta scelta una distribuzione a priori di tipo Beta, i cui parametri rispecchiano le nostre credenze iniziali su \\(\\theta\\), la distribuzione a posteriori viene specificata dalla formula di Bayes: \\[ \\text{distribuzione a posteriori} = \\frac{\\text{verosimiglianza}\\cdot\\text{distribuzione a priori}}{\\text{verosimiglianza marginale}}. \\] Nel caso presente abbiamo \\[ p(\\theta \\mid n=30, y=23) = \\frac{\\Big[\\binom{30}{23}\\theta^{23}(1-\\theta)^{30-23}\\Big]\\Big[\\frac{\\Gamma(12)}{\\Gamma(2)\\Gamma(10)}\\theta^{2-1} (1-\\theta)^{10-1}\\Big]}{p(y = 23)}, \\] laddove \\(p(y = 23)\\), ovvero la verosimiglianza marginale, è una costante di normalizzazione. Riscriviamo l’equazione precedente in termini più generali: \\[ p(\\theta \\mid n, y) = \\frac{\\Big[\\binom{n}{y}\\theta^{y}(1-\\theta)^{n-y}\\Big]\\Big[\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\theta^{a-1} (1-\\theta)^{b-1}\\Big]}{p(y)} \\] Raccogliendo tutte le costanti otteniamo: \\[ p(\\theta \\mid n, y) =\\left[\\frac{\\binom{n}{y}\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}}{p(y)}\\right] \\theta^{y}(1-\\theta)^{n-y}\\theta^{a-1} (1-\\theta)^{b-1}. \\] Se ignoriamo il termine costante all’interno della parentesi quadra \\[\\begin{align} p(\\theta \\mid n, y) &amp;\\propto \\theta^{y}(1-\\theta)^{n-y}\\theta^{a-1} (1-\\theta)^{b-1},\\notag\\\\ &amp;\\propto \\theta^{a+y-1}(1-\\theta)^{b+n-y-1},\\notag \\end{align}\\] il termine di destra dell’equazione precedente identifica il kernel della distribuzione a posteriori e corrisponde ad una Beta non normalizzata di parametri \\(a + y\\) e \\(b + n - y\\). Per ottenere una distribuzione di densità, dobbiamo aggiungere una costante di normalizzazione al kernel della distribuzione a posteriori. In base alla definizione della distribuzione Beta, ed essendo \\(a&#39; = a+y\\) e \\(b&#39; = b+n-y\\), tale costante di normalizzazione sarà uguale a \\[ \\frac{\\Gamma(a&#39;+b&#39;)}{\\Gamma(a&#39;)\\Gamma(b&#39;)} = \\frac{\\Gamma(a+b+n)}{\\Gamma(a+y)\\Gamma(b+n-y)}. \\] In altri termini, nel caso dello schema beta-binomiale, la distribuzione a posteriori è una \\(\\mbox{Beta}(a+y, b+n-y)\\): \\[ \\mbox{Beta}(a+y, b+n-y) = \\frac{\\Gamma(a+b+n)}{\\Gamma(a+y)\\Gamma(b+n-y)} \\theta^{a+y-1}(1-\\theta)^{b+n-y-1}. \\] In sintesi, moltiplicando verosimiglianza \\(\\mbox{Bin}(n = 30, y = 23 \\mid \\theta)\\) per la la distribuzione a priori \\(\\theta \\sim \\mbox{Beta}(2, 10)\\) e dividendo per la costante di normalizzazione, abbiamo ottenuto la distribuzione a posteriori \\(p(\\theta \\mid n, y) \\sim \\mbox{Beta}(25, 17)\\). Questo è un esempio di analisi coniugata. La presente combinazione di verosimiglianza e distribuzione a priori è chiamata caso coniugato beta-binomiale ed è descritta dal seguente teorema. Teorema 16.1 Sia data la funzione di verosimiglianza \\(\\mbox{Bin}(n, y \\mid \\theta)\\) e sia \\(\\mbox{Beta}(\\alpha, \\beta)\\) una distribuzione a priori. In tali circostanze, la distribuzione a posteriori del parametro \\(\\theta\\) sarà una distribuzione \\(\\mbox{Beta}(\\alpha + y, \\beta + n - y)\\). È facile calcolare il valore atteso a posteriori di \\(\\theta\\). Essendo \\(\\E[\\mbox{Beta}(\\alpha, \\beta)] = \\frac{\\alpha}{\\alpha + \\beta}\\), il risultato cercato diventa \\[\\begin{equation} \\E_{\\text{post}} [\\mathrm{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta +n}. \\tag{16.1} \\end{equation}\\] Esercizio 16.1 Si rappresenti in maniera grafica e si descriva in forma numerica l’aggiornamento bayesiano beta-binomiale per i dati di Zetsche, Bürkner, and Renneberg (2019). Si assuma una distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). Per i dati in questione, l’aggiornamento bayesiano può essere rappresentato in forma grafica usando la funzione plot_beta_binomial() del pacchetto bayesrules: bayesrules::plot_beta_binomial( alpha = 2, beta = 10, y = 23, n = 30 ) Oppure, possiamo scrivere noi stessi una funzione, come ad esempio la funzione plot_beta_binom() riportata in Appendice F. Mediante tale la funzione otteniamo plot_beta_bin(2, 10, 23, 30) Un sommario delle distribuzioni a priori e a posteriori può essere ottenuto, ad esempio, usando la funzione summarize_beta_binomial() del pacchetto bayesrules: bayesrules:::summarize_beta_binomial( alpha = 2, beta = 10, y = 23, n = 30 ) #&gt; model alpha beta mean mode var sd #&gt; 1 prior 2 10 0.1666667 0.1 0.010683761 0.1033623 #&gt; 2 posterior 25 17 0.5952381 0.6 0.005603016 0.0748533 Esercizio 16.2 Per i dati di Zetsche, Bürkner, and Renneberg (2019), si trovino la media, la moda, la deviazione standard della distribuzione a posteriori di \\(\\theta\\). Si trovi inoltre l’intervallo di credibilità a posteriori del 95% per il parametro \\(\\theta\\). Usando il Teorema 16.1, l’intervallo di credibilità a posteriori del 95% per il parametro \\(\\theta\\) è: qbeta(c(0.025, 0.975), shape1 = 25, shape2 = 17) #&gt; [1] 0.4450478 0.7368320 Usando la (16.1), la media della distribuzione a posteriori è 25 / (25 + 17) #&gt; [1] 0.5952381 Per le proprietà della distribuzione Beta, la moda della distribuzione a posteriori è (25 - 1) / (25 + 17 - 2) #&gt; [1] 0.6 e la deviazione standard della distribuzione a priori è sqrt((25 * 17) / ((25 + 17)^2 * (25 + 17 + 1))) #&gt; [1] 0.0748533 Esercizio 16.3 Si trovino i parametri e le proprietà della distribuzione a posteriori del parametro \\(\\theta\\) per i dati dell’esempio relativo alla ricerca di Stanley Milgram discussa da Johnson, Ott, and Dogucu (2022). Nel 1963, Stanley Milgram presentò una ricerca sulla propensione delle persone a obbedire agli ordini di figure di autorità, anche quando tali ordini possono danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come “consist[ing] of ordering a naive subject to administer electric shock to a victim. A simulated shock generator is used, with 30 clearly marked voltage levels that range from IS to 450 volts. The instrument bears verbal designations that range from Slight Shock to Danger: Severe Shock. The responses of the victim, who is a trained confederate of the experimenter, are standardized. The orders to administer shocks are given to the naive subject in the context of a `learning experiment’ ostensibly set up to study the effects of punishment on memory. As the experiment proceeds the naive subject is commanded to administer increasingly more intense shocks to the victim, even to the point of reaching the level marked Danger: Severe Shock.” All’insaputa del partecipante, gli shock elettrici erano falsi e l’attore stava solo fingendo di provare il dolore dello shock. Johnson, Ott, and Dogucu (2022) fanno inferenza sui risultati dello studio di Milgram mediante il modello Beta-Binomiale. Il parametro di interesse è \\(\\theta\\), la probabiltà che una persona obbedisca all’autorità (in questo caso, somministrando lo shock più severo), anche se ciò significa recare danno ad altri. Johnson, Ott, and Dogucu (2022) ipotizzano che, prima di raccogliere dati, le credenze di Milgram relative a \\(\\theta\\) possano essere rappresentate mediante una \\(\\mbox{Beta}(1, 10)\\). Sia \\(y = 26\\) il numero di soggetti che, sui 40 partecipanti allo studio, aveva accettato di infliggere lo shock più severo. Assumendo che ogni partecipante si comporti indipendentemente dagli altri, possiamo modellare la dipendenza di \\(y\\) da \\(\\theta\\) usando la distribuzione binomiale. Giungiamo dunque al seguente modello bayesiano Beta-Binomiale: \\[\\begin{align} y \\mid \\theta &amp; \\sim \\mbox{Bin}(n = 40, \\theta) \\notag\\\\ \\theta &amp; \\sim \\text{Beta}(1, 10) \\; . \\notag \\end{align}\\] Usando le funzioni di bayesrules possiamo facilmente calcolare i parametri e le proprietà della distribuzione a posteriori: bayesrules:::summarize_beta_binomial( alpha = 1, beta = 10, y = 26, n = 40 ) #&gt; model alpha beta mean mode var sd #&gt; 1 prior 1 10 0.09090909 0.0000000 0.006887052 0.08298827 #&gt; 2 posterior 27 24 0.52941176 0.5306122 0.004791057 0.06921746 Il processo di aggiornamento bayesiano è descritto dalla figura seguente: plot_beta_bin(1, 10, 26, 40) 16.2 Inferenza bayesiana con distribuzioni a priori continue L’inferenza bayesiane sulla proporzione \\(\\theta\\) si basa su vari riepiloghi della distribuzione a posteriori Beta. Il riepilogo che si calcola dalla distribuzione a posteriori dipende dal tipo di inferenza. Consideriamo qui su due tipi di inferenza: (1) problemi in cui si è interessati a valutare la plausibilità che il parametro assuma valori contenuti in un dato intervallo di valori, (2) stime dell’intervallo che contiene il parametro ad un dato livello di probabilità soggettiva. 16.2.1 Approccio bayesiano alla verifica di ipotesi Nell’esempio precedente sui dati di Zetsche, Bürkner, and Renneberg (2019), la nostra credenza a posteriori relativa a \\(\\theta\\) (ovvero, la probabilità che l’aspettativa dell’umore futuro sia distorta negativamente) è descritta da una distribuzione Beta(25,17). Una volta definita la distribuzione a posteriori, ci possiamo porre altre domande. Per esempio: qual è la probabilità che \\(\\theta\\) sia maggiore di 0.5? Una risposta a questa domanda si trova con 1 - pbeta(0.5, 25, 17) #&gt; [1] 0.8944882 oppure, in maniera equivalente, con ProbBayes::beta_area(lo = 0.5, hi = 1.0, shape_par = c(25, 17)) Questo calcolo può essere svolto mediante simulazione. Dato che conosciamo la distribuzione target, è possibile ricavare un campione casuale di osservazioni da una tale distribuzione e poi riassumere il campione in modo da calcolare \\(\\theta &gt; 0.5\\). nsim &lt;- 1e6 theta_samples &lt;- rbeta(nsim, 25, 17) sum(theta_samples &gt; 0.5) / nsim #&gt; [1] 0.894317 Il risultato della simulazione è molto simile a quello ottenuto in precedenza. 16.2.2 Intervalli di credibilità Un secondo tipo di inferenza bayesiana è quella che ci porta a formulare gli intervalli di credibilità. Un intervallo di credibilità di ordine \\(a \\in [0, 1]\\) è l’intervallo di valori che contiene una proporzione della distribuzione a posteriori pari ad \\(a\\). La funzione ProbBayes::beta_interval() consente di calcolare l’intervallo di credibilità che lascia la stessa probabilità nelle due code. Per esempio, l’intervallo di credibilità all’89% per la distribuzione a posteriori dell’esempio relativo ai dati di Zetsche, Bürkner, and Renneberg (2019) è ProbBayes::beta_interval(0.89, c(25, 17)) Per i dati di Zetsche, Bürkner, and Renneberg (2019), l’intervallo di credibilità all’50% per la distribuzione a posteriori è ProbBayes::beta_interval(0.5, c(25, 17)) 16.3 Principali distribuzioni coniugate Esistono molte altre combinazioni simili di verosimiglianza e distribuzione a priori le quali producono una distribuzione a posteriori che ha la stessa densità della distribuzione a priori. Sono elencate qui sotto le più note coniugazioni tra modelli statistici e distribuzioni a priori. Per il modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribizione iniziale è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione finale è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\). Per il modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribizione iniziale è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione finale è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\). Per il modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribizione iniziale è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione finale è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\). Per il modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribizione iniziale è \\(\\mbox{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione finale è \\(\\mbox{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\). Commenti e considerazioni finali Lo scopo di questa discussione è mostrare come sia possibile combinare le nostre conoscenze a priori (espresse nei termini di una densità di probabilità) con le evidenze fornite dai dati (espresse nei termini della funzione di verosimiglianza), così da determinare, mediante il teorema di Bayes, una distribuzione a posteriori, la quale condensa l’incertezza che abbiamo sul parametro \\(\\theta\\). Per illustrare tale problema, abbiamo considerato una situazione nella quale \\(\\theta\\) corrisponde alla probabilità di successo in una sequenza di prove Bernoulliane. In tali circostanze è ragionevole esprimere le nostre credenze a priori mediante la densità Beta, con opportuni parametri. L’inferenza rispetto a \\(\\theta\\) può essere svolta utilizzando una distribuzione a priori Beta e una verosimiglianza binomiale. Così facendo, la distribuzione a posteriori diventa essa stessa una distribuzione Beta – questo è il cosiddetto schema beta-binomiale. Dato che utilizza una distribuzione a priori coniugata, lo schema beta-binomiale rende possibile la determinazione analitica dei parametri della distribuzione a posteriori. References "],["ch-prior-influence.html", "Capitolo 17 L’influenza della distribuzione a priori 17.1 Il test di Benchdel 17.2 Stessi dati ma diverse distribuzioni a priori 17.3 Dati diversi ma la stessa distribuzione a priori 17.4 Dati diversi e diverse distribuzioni a priori 17.5 Collegare le intuizioni alla teoria Commenti e considerazioni finali", " Capitolo 17 L’influenza della distribuzione a priori La notazione \\(p(\\theta \\mid y) \\propto p(\\theta) \\ p(y \\mid \\theta)\\) rende particolarmente chiaro che la distribuzione a posteriori è un “miscuglio” della distribuzione a priori e della verosimiglianza. Prima di preoccuparci di come calcolare la distribuzione a posteriori, cerchiamo di capire meglio cosa significa “mescolare” la distribuzione a priori e la verosimiglianza. Considereremo qui un esempio discusso da Johnson, Ott, and Dogucu (2022). 17.1 Il test di Benchdel Nel fumetto di Alison Bechdel The Rule, un personaggio afferma di guardare un film solo se soddisfa le seguenti tre regole (Bechdel 1986): almeno due caratteri nel film devono essere donne; queste due donne si parlano; parlano di qualcosa altro oltre a parlare di qualche uomo. Questi criteri costituiscono il test di Bechdel per la rappresentazione delle donne nei film. Johnson, Ott, and Dogucu (2022) pongono la seguente domanda “Quale percentuale dei film che avete visto supera il test di Bechdel?”. Sia \\(\\pi \\in [0, 1]\\) una variabile casuale che indica la proporzione sconosciuta di film che superano il test di Bechdel. Tre amiche — la femminista, l’ignara e l’ottimista — hanno opionioni diverse su \\(\\pi\\). Riflettendo sui film che ha visto, la femminista capisce che nella maggioranza dei film mancano personaggi femminili forti. L’ignara non ricorda bene i film che ha visto, quindi non sa quanti film superano il test di Bechdel. Infine, l’ottimista pensa che, in generale, le donne sono ben rappresentate all’interno dei film: secondo lei quasi tutti i film superano il test di Bechdel. Le tre amiche hanno dunque tre modelli a priori diversi di \\(\\pi\\). Abbiamo visto in precedenza come sia possibile usare la distribuzione Beta per rappresentare le credenze a priori. Ponendo la gran parte della massa della probabilità a priori su valori \\(\\pi &lt; 0.5\\), la distribuzione a priori \\(\\text{Beta}(5, 11)\\) riflette il punto di vista femminista secondo il quale la maggioranza dei film non supera il test di Bechdel. Al contrario, la \\(\\text{Beta}(14,1)\\) pone la gran parte della massa della distribuzione a priori su valori \\(\\pi\\) prossimi a 1, e corrisponde quindi alle credenze a priori dell’amica ottimista. Infine, una \\(\\text{Beta}(1 ,1)\\) o \\(Unif(0, 1)\\), assegna lo stesso livello di plausibilità a tutti i valori \\(\\pi \\in [0, 1]\\), e corrisponde all’incertezza a priori dell’ignara. Nell’esempio di Johnson, Ott, and Dogucu (2022), le tre amiche decidono di rivedere un campione di \\(n\\) film e di registrare \\(y\\), ovvero il numero di film che superano il test di Bechdel. Se \\(y\\) corrisponde al numero di “successi” in un numero fisso di \\(n\\) prove Bernoulliane i.i.d., allora la dipendenza di \\(y\\) da \\(\\pi\\) viene specificata nei termini di un modello binomiale. Quindi, per ciascuna delle tre amiche è possibile scrivere un modello beta-binomiale \\[\\begin{align} Y \\mid \\pi &amp; \\sim \\mbox{Bin}(n, \\pi) \\notag\\\\ \\pi &amp; \\sim \\mbox{Beta}(\\alpha, \\beta) \\notag \\end{align}\\] che utilizza diversi parametri \\(\\alpha\\) e \\(\\beta\\) per la distribuzione a priori e che conduce a tre diverse distribuzioni a posteriori per il parametro sconosciuto \\(\\pi\\): \\[\\begin{equation} \\pi \\mid (Y = y) \\sim \\mbox{Beta}(\\alpha + y, \\beta + n - y). \\end{equation}\\] Johnson, Ott, and Dogucu (2022) si chiedono come le credenze a priori delle tre amiche influenzano le conclusioni a posteriori a cui esse giungono, dopo avere osservato i dati. Si chiedono inoltre in che modo la dimensione del campione moduli l’influenza della distribuzione a priori sulla distribuzione a posteriori. Per rispondere a queste domande, Johnson, Ott, and Dogucu (2022) consideriamo tre diversi scenari: gli stessi dati osservati, ma distribuzioni a priori diverse; dati diversi, ma la stessa distribuzione a priori; dati diversi e distribuzioni a priori diverse. 17.2 Stessi dati ma diverse distribuzioni a priori Iniziamo con lo scenario che descrive il caso in cui abbiamo gli stessi dati ma diverse distribuzioni a priori. Supponiamo che le tre amiche decidano di guardare insieme 20 film selezionati a caso: data(bechdel, package = &quot;bayesrules&quot;) set.seed(84735) bechdel_20 &lt;- bechdel %&gt;% sample_n(20) bechdel_20 %&gt;% head(3) #&gt; # A tibble: 3 × 3 #&gt; year title binary #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 2005 King Kong FAIL #&gt; 2 1983 Flashdance PASS #&gt; 3 2013 The Purge FAIL Di questi 20 film, solo il 45% (\\(y\\) = 9) passa il test di Bechdel: bechdel_20 %&gt;% janitor::tabyl(binary) %&gt;% janitor::adorn_totals(&quot;row&quot;) #&gt; binary n percent #&gt; FAIL 11 0.55 #&gt; PASS 9 0.45 #&gt; Total 20 1.00 Esaminiamo ora le tre distribuzioni a posteriori. Per la femminista abbiamo: bayesrules:::plot_beta_binomial( alpha = 5, beta = 11, y = 9, n = 20 ) bayesrules:::summarize_beta_binomial( alpha = 5, beta = 11, y = 9, n = 20 ) #&gt; model alpha beta mean mode var sd #&gt; 1 prior 5 11 0.3125000 0.2857143 0.01263787 0.11241827 #&gt; 2 posterior 14 22 0.3888889 0.3823529 0.00642309 0.08014418 Per l’ottimista abbiamo: bayesrules:::plot_beta_binomial( alpha = 14, beta = 1, y = 9, n = 20 ) bayesrules:::summarize_beta_binomial( alpha = 14, beta = 1, y = 9, n = 20 ) #&gt; model alpha beta mean mode var sd #&gt; 1 prior 14 1 0.9333333 1.0000000 0.003888889 0.06236096 #&gt; 2 posterior 23 12 0.6571429 0.6666667 0.006258503 0.07911070 Infine, per l’ignara troviamo bayesrules:::plot_beta_binomial( alpha = 1, beta = 1, y = 9, n = 20 ) bayesrules:::summarize_beta_binomial( alpha = 1, beta = 1, y = 9, n = 20 ) #&gt; model alpha beta mean mode var sd #&gt; 1 prior 1 1 0.5000000 NaN 0.08333333 0.2886751 #&gt; 2 posterior 10 12 0.4545455 0.45 0.01077973 0.1038255 Per calcolare la distribuzione a posteriori, ho qui usato le funzioni del pacchetto bayesrules. Ma per lo schema beta-binomiale è facile trovare i parametri della distribuzione a posteriori. Per esempio, nel caso dell’amica femminista, la distribuzione a posteriori è una Beta di parametri \\[ \\alpha_{post} = \\alpha_{prior} + y = 5+9 = 14 \\] e \\[ \\beta_{post} = \\beta_{prior} + n - y = 11 + 20 - 9 = 22. \\] L’aggiornamento bayesiano indica che le tre amiche ottengono valori per la media (o la moda) a posteriori per \\(\\pi\\) molto diversi. Dunque, anche dopo avere visto 20 film, le tre amiche non si trovano d’accordo su quale sia la proporzione di film che passano il test di Bechdel. Questo non dovrebbe sorprenderci. L’amica ottimista aveva opinioni molto forti sul valore di \\(\\pi\\) e i pochi nuovi dati che le sono stati forniti non sono riusciti a convincerla a cambiare idea: crede ancora che i valori \\(\\pi &gt; 0.5\\) siano i più plausibili. Lo stesso si può dire, all’estremo opposto, dell’amica femminista: anche lei continua a credere che i valori \\(\\pi &lt; =.5\\) siano i più plausibili. Infine, l’ignara non aveva nessuna opinione a priori su \\(\\pi\\) e, anche dopo avere visto 20 film, continua a credere che il valore \\(\\pi\\) più plausibile sia quello intermedio, nell’intorno di 0.5. 17.3 Dati diversi ma la stessa distribuzione a priori Supponiamo ora che l’amica ottimista abbia tre amiche, Maria, Anna e Sara, tutte ottimiste come lei. L’ottimista chiede a Maria, Anna e Sara di fare loro stesse l’esperimento descritto in precedenza. Maria guarda 13 film; di questi 6 passano il test di Bechdel. Anna guarda 63 film; di questi 29 passano il test di Bechdel. Sara guarda 99 film; di questi 46 passano il test di Bechdel. Supponiamo che Maria, Anna e Sara condividano la stessa credenza a priori su \\(\\pi\\): ovvero, Beta(14, 1). In tali circostanze e, alla luce dei dati osservati, cosa possiamo dire delle tre distribuzioni a posteriori? p1 &lt;- bayesrules:::plot_beta_binomial( alpha = 14, beta = 1, y = 6, n = 13 ) + theme(legend.position = &quot;none&quot;) p2 &lt;- bayesrules:::plot_beta_binomial( alpha = 14, beta = 1, y = 29, n = 63 ) + theme(legend.position = &quot;none&quot;) p3 &lt;- bayesrules:::plot_beta_binomial( alpha = 14, beta = 1, y = 46, n = 99 ) + theme(legend.position = &quot;none&quot;) p1 + p2 + p3 FIGURA 17.1: Aggiornamento bayesiano per le credenze di Maria, Anna e Sara. Notiamo due cose. All’aumentare delle informazioni disponibili (ovvero, all’aumentare dell’ampiezza del campione), la distribuzione a posteriori si allontana sempre di più dalla distribuzione a priori, e si avvicina sempre di più alla verosimiglianza. In secondo luogo, all’aumentare dell’ampiezza del campione la varianza della distribuzione a posteriori diminuisce sempre di più — ovvero, diminuisce l’incertezza su quelli che sono i valori \\(\\pi\\) più plausibili. 17.4 Dati diversi e diverse distribuzioni a priori Nella figura successiva esaminiamo le distribuzioni a posteriori che si ottengono incrociando tre diversi set di dati (\\(y\\) = 6, \\(n\\) = 13;, \\(y\\) = 29, \\(n\\) = 63; \\(y\\) = 66, \\(n\\) = 99) con tre diverse distribuzioni a priori [Beta(14, 1), Beta(5, 11), Beta(1, 1)]. p1 &lt;- bayesrules:::plot_beta_binomial( alpha = 14, beta = 1, y = 6, n = 13 ) + theme(legend.position = &quot;none&quot;) p2 &lt;- bayesrules:::plot_beta_binomial( alpha = 14, beta = 1, y = 29, n = 63 ) + theme(legend.position = &quot;none&quot;) p3 &lt;- bayesrules:::plot_beta_binomial( alpha = 14, beta = 1, y = 46, n = 99 ) + theme(legend.position = &quot;none&quot;) p4 &lt;- bayesrules:::plot_beta_binomial( alpha = 5, beta = 11, y = 6, n = 13 ) + theme(legend.position = &quot;none&quot;) p5 &lt;- bayesrules:::plot_beta_binomial( alpha = 5, beta = 11, y = 29, n = 63 ) + theme(legend.position = &quot;none&quot;) p6 &lt;- bayesrules:::plot_beta_binomial( alpha = 5, beta = 11, y = 46, n = 99 ) + theme(legend.position = &quot;none&quot;) p7 &lt;- bayesrules:::plot_beta_binomial( alpha = 1, beta = 1, y = 6, n = 13 ) + theme(legend.position = &quot;none&quot;) p8 &lt;- bayesrules:::plot_beta_binomial( alpha = 1, beta = 1, y = 29, n = 63 ) + theme(legend.position = &quot;none&quot;) p9 &lt;- bayesrules:::plot_beta_binomial( alpha = 1, beta = 1, y = 46, n = 99 ) + theme(legend.position = &quot;none&quot;) (p1 + p2 + p3) / (p4 + p5 + p6) / (p7 + p8 + p9) FIGURA 17.2: Sulle colonne (a partire da sinistra) i dati utilizzati sono, rispettivamente, (y = 6, n = 13), (y = 29, n = 63) e (y = 66, n = 99). Sulle righe (a partire dall’alto), le distribuzioni a priori usate sono: Beta(14, 1), Beta(5, 11) e Beta(1, 1). La figura indica che, se il campione è grande, una distribuzione a priori debolmente informativa ha uno scarso effetto sulla distribuzione a posteriori. Invece, se il campione è piccolo, anche una distribuzione a priori debolmente informativa ha un grande effetto sulla distribuzione a posteriori. 17.5 Collegare le intuizioni alla teoria Il compromesso che abbiamo osservato nell’esempio precedente, che combina la distribuzione a priori con le evidenze fornite dai dati, è molto vicino alle nostre intuizioni. Ma è anche il frutto di una necessità matematica. È infatti possibile riscrivere la (16.1) nel modo seguente \\[\\begin{align} \\E_{\\text{post}} &amp;[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta +n}\\notag\\\\ &amp;= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}. \\tag{17.1} \\end{align}\\] Ciò indica che il valore atteso a posteriori è una media pesata fra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la frequenze di successi osservata \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Quindi, quando \\(n\\) è grande rispetto ad \\(\\alpha + \\beta\\), conta molto quanto abbiamo osservato e conta poco la credenza a priori. Viceversa, quando \\(n\\) è piccolo rispetto a \\(\\alpha + \\beta\\), le osservazioni contano poco rispetto alla credenza a priori. Queste osservazioni ci fanno capire come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se vogliamo assumere una totale ignoranza rispetto al fenomeno in esame, la scelta coerente è \\(\\alpha = \\beta = 1\\) (ogni valore di \\(\\theta\\) è ugualmente probabile); se invece abbiamo delle credenze a priori, allora possiamo scegliere \\(\\alpha\\) così che sia uguale al valore atteso a priori, mentre \\(\\alpha + \\beta\\) esprime l’importanza che diamo all’informazione a priori: maggiore è il valore di \\(\\alpha + \\beta\\), tanti più dati serviranno per allontanare la distribuzione a posteriori dalla distribuzione a priori. Se \\(n\\) è grande, infine, la distribuzione a posteriori sarà scarsamente influenzata dalla distribuzione a priori, a meno di scelte estreme. Commenti e considerazioni finali La conclusione che possiamo trarre dall’esempio di Johnson, Ott, and Dogucu (2022) è molto chiara: l’aggiornamento bayesiano può essere paragonato ai processi di ragionamento del senso comune. Quando le nuove evidenze (i dati) sono deboli, non c’è ragione di cambiare idea (le nostre credenze “a posteriori” sono molto simili a ciò che pensavamo prima di avere osservato i dati). Quando le nuove evidenze sono irrefutabili, invece, è necessario modificare le nostre credenze sulla base di ciò che ci dicono i dati, quali che siano le nostre credenze pregresse — non farlo significherebbe vivere in un mondo di fantasia e avere scarse possibilità di sopravvivere nel mondo empirico. L’aggiornamento bayesiano esprime in maniera quantitativa e precisa ciò che ci dicono le nostre intuizioni. Incredibilmente, però, l’approccio frequentista nega questa logica. I test frequentisti non tengono conto delle conoscenze pregresse. Dunque, se un test frequentista, calcolato su un piccolo campione (ovvero, quando i dati sono molto deboli), suggerisce che dovremmo farci un’opinione di un certo tipo sul fenomeno in esame, l’indicazione è di prendere seriamente il risultato del test quali siano le evidenze precedenti — le quali, possibilmente, mostrano che il risultato del test non ha alcun senso. È sorprendente che un tale modo di pensare possa essere preso sul serio nella comunità scientifica, ma vi sono alcuni ricercatori che continuano a seguire questo modo di (s)ragionare. Dato che in questo Capitolo paliamo di fumetti, concluderei dicendo che la presente discussione è catturata nella maniera più chiara possibile in questa famosa striscia. References "],["ch-post-approx.html", "Capitolo 18 Approssimazione della distribuzione a posteriori 18.1 Metodo basato su griglia 18.2 Metodo Monte Carlo Commenti e considerazioni finali", " Capitolo 18 Approssimazione della distribuzione a posteriori In generale, in un problema bayesiano i dati \\(y\\) provengono da una densità \\(p(y \\mid \\theta)\\) e al parametro \\(\\theta\\) viene assegnata una densità a priori \\(p(\\theta)\\). Dopo avere osservato i dati \\(Y = y\\), la funzione di verosimiglianza è uguale a \\(\\mathcal{L}(\\theta) = p(y \\mid \\theta)\\) e la densità a posteriori diventa \\[\\begin{equation} p(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\! \\theta}. \\notag \\end{equation}\\] Se vogliamo trovare la distribuzione a posteriori con metodi analitici è necessario ricorrere all’impiego di distribuzioni a priori coniugate, come nello schema beta-binomiale. Per quanto “semplice” in termini formali, la scelta di distribuzioni a priori coniugate limita di molto le possibili scelte del ricercatore. Inoltre, non è sempre sensato, dal punto di vista teorico, utilizzare tali distribuzioni per la stima dei parametri di interesse. Il mancato ricorso all’impiego delle distribuzioni a priori coniugate richiede necessariamente il computo dell’espressione a denominatore della formula di Bayes che solo in rare occasioni può essere ottenuta per via analitica. In altre parole, è possibile ottenere analiticamenre la distribuzione a posteriori solo per alcune specifiche combinazioni di distribuzioni a priori e verosimiglianza, il che limita considerevolmente la flessibilità della modellizzazione. Inoltre, i sommari della distribuzione a posteriori sono espressi come rapporto di integrali. Ad esempio, la media a posteriori di \\(\\theta\\) è data da \\[\\begin{equation} \\mathbb{E}(\\theta \\mid y) = \\frac{\\int \\theta p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\! \\theta}{\\int p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\! \\theta}.\\notag \\end{equation}\\] Il calcolo del valore atteso a posteriori richiede dunque il computo di due integrali, quello a denominatore e quello a numeratore dell’espressione, ciascuno dei quali non esprimibile in forma chiusa. Per questa ragione, la strada principale che viene seguita nella modellistica bayesiana è quella che porta a determinare la distribuzione a posteriori non per via analitica, ma bensì mediante metodi numerici. La simulazione fornisce dunque la strategia generale del calcolo bayesiano. A questo fine vengono principalmente usati i metodi di campionamento Monte Carlo basati su Catena di Markov (MCMC). Tali metodi costituiscono una potente e praticabile alternativa per la costruzione della distribuzione a posteriori per modelli complessi e consentono di decidere quali distribuzioni a priori e quali distribuzioni di verosimiglianza usare sulla base di considerazioni teoriche soltanto, senza dovere preoccuparsi di altri vincoli. Dato che è basata su metodi computazionalmente intensivi, la stima numerica della funzione a posteriori può essere svolta soltanto mediante software. In anni recenti i metodi Bayesiani di analisi dei dati sono diventati sempre più popolari proprio perché la potenza di calcolo necessaria per svolgere tali calcoli è ora alla portata di tutti. Questo non era vero solo pochi decenni fa. In questo Capitolo verranno presentati due metodi di simulazione iterativa13 che consentono di generare dalle distribuzioni a posteriori campioni dei parametri del modello: metodi basati su griglia: dove, sebbene non sia disponibile alcuna formula algebrica in forma chiusa, le proprietà della distribuzione a posteriori possono essere calcolate con una precisione arbitraria; metodi Monte Carlo: dove, utilizzando appropriate funzioni di numeri casuali, viene generato un ampio campione di casi della variabile casuale per poi stimare empiricamente la proprietà di interesse in base al campione così otttenuto. 18.1 Metodo basato su griglia Il metodo basato su griglia (grid-based) è un metodo numerico esatto basato su una griglia di punti uniformemente spaziati. Anche se la maggior parte dei parametri è continua (ovvero, in linea di principio ciascun parametro può assumere un numero infinito di valori), possiamo ottenere un’eccellente approssimazione della distribuzione a posteriori considerando solo una griglia finita di valori dei parametri. In un tale metodo, la densità di probabilità a posteriori può dunque essere approssimata tramite le densità di probabilità calcolate in ciascuna cella della griglia. Il metodo basato su griglia si sviluppa in quattro fasi: fissare una griglia discreta di possibili valori \\(\\theta\\); valutare la distribuzione a priori \\(p(\\theta)\\) e la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) in corrispondenza di ciascun valore \\(\\theta\\) della griglia; ottenere un’approssimazione discreta della densità a posteriori: per ciascun valore \\(\\theta\\) della griglia, calcolare il prodotto \\(p(\\theta) p(y \\mid \\theta)\\); normalizzare i prodotti così ottenuti in modo tale che la loro somma sia 1; selezionare \\(N\\) valori casuali della griglia in modo tale da ottenere un campione casuale delle densità a posteriori normalizzate. Possiamo migliorare l’approssimazione aumentando il numero di punti della griglia. Infatti utilizzando un numero infinito di punti si otterrebbe la descrizione esatta della distribuzione a posteriori, dovendo però pagare il costo dell’utilizzo di infinite risorse di calcolo. Il limite maggiore dell’approccio basato su griglia è che, al crescere della dimensionalità \\(N\\) dello spazio dei parametri, i punti della griglia necessari per avere una buona stima crescerebbero esponenzialmente con \\(N\\), rendendo questo metodo inattuabile. 18.1.1 Modello Beta-Binomiale Per fare un esempio, consideriamo lo schema beta-binomiale di cui conosciamo la soluzione esatta. Utilizziamo nuovamente i dati di Zetsche, Bürkner, and Renneberg (2019): 23 “successi” in 30 prove Bernoulliane indipendenti.14 Imponiamo alla distribuzione a priori su \\(\\theta\\) (probabilità di successo in una singola prova, laddove per “successo” si intende una aspettativa distorta negativamente dell’umore futuro) una \\(\\mbox{Beta}(2, 10)\\) per descrivere la nostra incertezza sul parametro prima di avere osservato i dati. Dunque, il modello diventa: \\[\\begin{align} Y \\mid \\theta &amp; \\sim \\mbox{Bin}(n = 30, \\theta), \\notag\\\\ \\theta &amp; \\sim \\mbox{Beta}(2, 10).\\notag \\end{align}\\] In queste circostanze, l’aggiornamento bayesiano produce una distribuzione a posteriori Beta di parametri 25 (\\(y + \\alpha\\) = 23 + 2) e 17 (\\(n - y + \\beta\\) = 30 - 23 + 10): \\[\\begin{equation} \\theta \\mid (y = 23) \\sim \\mbox{Beta}(25, 17).\\notag \\end{equation}\\] Per approssimare la distribuzione a posteriori, fissiamo una griglia di \\(n = 11\\) valori equispaziati: \\(\\theta \\in \\{0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1\\}\\): grid_data &lt;- tibble( theta_grid = seq(from = 0, to = 1, length.out = 11) ) grid_data #&gt; # A tibble: 11 × 1 #&gt; theta_grid #&gt; &lt;dbl&gt; #&gt; 1 0 #&gt; 2 0.1 #&gt; 3 0.2 #&gt; 4 0.3 #&gt; 5 0.4 #&gt; 6 0.5 #&gt; 7 0.6 #&gt; 8 0.7 #&gt; # … with 3 more rows In corrispondenza di ciascun valore della griglia, valutiamo la distribuzione a priori \\(\\mbox{Beta}(2, 10)\\) e la verosimiglianza \\(\\mbox{Bin}(y = 23, n = 30)\\). grid_data &lt;- grid_data %&gt;% mutate( prior = dbeta(theta_grid, 2, 10), likelihood = dbinom(23, 30, theta_grid) ) In ciascuna cella della griglia calcoliamo poi il prodotto della verosimiglianza e della distribuzione a priori. Troviamo così un’approssimazione discreta e non normalizzata della distribuzione a posteriori (unnormalized). Normalizziamo questa approssimazione dividendo ciascun valore unnormalized per la somma di tutti i valori del vettore: grid_data &lt;- grid_data %&gt;% mutate( unnormalized = likelihood * prior, posterior = unnormalized / sum(unnormalized) ) Verifichiamo: grid_data %&gt;% summarize( sum(unnormalized), sum(posterior) ) #&gt; # A tibble: 1 × 2 #&gt; `sum(unnormalized)` `sum(posterior)` #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.000869 1 Abbiamo dunque ottenuto la seguente distribuzione a posteriori discretizzata \\(p(\\theta \\mid y)\\): round(grid_data, 2) #&gt; # A tibble: 11 × 5 #&gt; theta_grid prior likelihood unnormalized posterior #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 0 0 0 0 #&gt; 2 0.1 4.26 0 0 0 #&gt; 3 0.2 2.95 0 0 0 #&gt; 4 0.3 1.33 0 0 0 #&gt; 5 0.4 0.44 0 0 0.02 #&gt; 6 0.5 0.11 0 0 0.23 #&gt; 7 0.6 0.02 0.03 0 0.52 #&gt; 8 0.7 0 0.12 0 0.21 #&gt; # … with 3 more rows La figura 18.1 mostra un grafico della distribuzione a posteriori discretizzata così ottenuta: grid_data %&gt;% ggplot( aes(x = theta_grid, y = posterior) ) + geom_point() + geom_segment( aes( x = theta_grid, xend = theta_grid, y = 0, yend = posterior) ) FIGURA 18.1: Distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi in 30 prove Bernoulliane, con distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). È stata utilizzata una griglia di solo \\(n\\) = 11 punti. L’ultimo passo della simulazione è il campionamento dalla distribuzione a posteriori discretizzata: set.seed(84735) post_sample &lt;- sample_n( grid_data, size = 1e5, weight = posterior, replace = TRUE ) La figura 18.2 mostra che, con una griglia così sparsa abbiamo ottenuto una versione approssimata della vera distribuzione a posteriori (all’istogramma è stata sovrapposta l’esatta distribuzione a posteriori \\(\\mbox{Beta}(25, 17)\\)). ggplot(post_sample, aes(x = theta_grid)) + geom_histogram(aes(y = ..density..), color = &quot;white&quot;) + stat_function(fun = dbeta, args = list(25, 17)) + lims(x = c(0, 1)) FIGURA 18.2: Campionamento dalla distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi in 30 prove Bernoulliane, con distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). È stata utilizzata una griglia di solo \\(n\\) = 11 punti. Possiamo ottenere un risultato migliore con una griglia più fine, come indicato nella figura 18.3: grid_data &lt;- tibble( theta_grid = seq(from = 0, to = 1, length.out = 100) ) grid_data &lt;- grid_data %&gt;% mutate( prior = dbeta(theta_grid, 2, 10), likelihood = dbinom(23, 30, theta_grid) ) grid_data &lt;- grid_data %&gt;% mutate( unnormalized = likelihood * prior, posterior = unnormalized / sum(unnormalized) ) grid_data %&gt;% ggplot( aes(x = theta_grid, y = posterior) ) + geom_point() + geom_segment( aes( x = theta_grid, xend = theta_grid, y = 0, yend = posterior ) ) FIGURA 18.3: Distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi in 30 prove Bernoulliane, con distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). È stata utilizzata una griglia di \\(n\\) = 100 punti. Campioniamo ora 10000 punti: # Set the seed set.seed(84735) post_sample &lt;- sample_n( grid_data, size = 1e4, weight = posterior, replace = TRUE ) Con il campionamento dalla distribuzione a posteriori discretizzata costruita mediante una griglia più densa (\\(n = 100\\)) otteniamo un risultato soddisfacente (figura 18.4): ora la distribuzione dei valori prodotti dalla simulazione approssima molto bene la corretta distribuzione a posteriori \\(p(\\theta \\mid y) = \\mbox{Beta}(25, 17)\\). post_sample %&gt;% ggplot(aes(x = theta_grid)) + geom_histogram( aes(y = ..density..), color = &quot;white&quot;, bins=50 ) + stat_function(fun = dbeta, args = list(25, 17)) + lims(x = c(0, 1)) FIGURA 18.4: Campionamento dalla distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi in 30 prove Bernoulliane, con distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). È stata utilizzata una griglia di \\(n\\) = 100 punti. All’istogramma è stata sovrapposta la corretta distribuzione a posteriori, ovvero la densità \\(\\mbox{Beta}(25, 17)\\). In conclusione, il metodo basato su griglia è molto intuitivo e non richiede particolari competenze di programmazione per essere implementato. Inoltre, fornisce un risultato che, per tutti gli scopi pratici, può essere considerato come un campione casuale estratto da \\(p(\\theta \\mid y)\\). Tuttavia, anche se tale metodo fornisce risultati accuratissimi, esso ha un uso limitato. A causa della maledizione della dimensionalità15, tale metodo può solo essere solo nel caso di semplici modelli statistici, con non più di due parametri. Nella pratica concreta tale metodo viene dunque sostituito da altre tecniche più efficienti in quanto, anche nei più comuni modelli utilizzati in psicologia, vengono solitamente stimati centinaia se non migliaia di parametri. 18.2 Metodo Monte Carlo I metodi più ampiamente adottati nell’analisi bayesiana per la costruzione della distribuzione a posteriori per modelli complessi sono i metodi di campionamento MCMC. Tali metodi consentono al ricercatore di decidere quali distribuzioni a priori e quali distribuzioni di verosimiglianza usare sulla base di considerazioni teoriche soltanto, senza doversi preoccupare di altri vincoli. Dato che è basata su metodi computazionalmente intensivi, la stima numerica MCMC della funzione a posteriori può essere svolta soltanto mediante software. In anni recenti i metodi Bayesiani di analisi dei dati sono diventati sempre più popolari proprio perché la potenza di calcolo necessaria per svolgere tali calcoli è ora alla portata di tutti. Questo non era vero solo pochi decenni fa. 18.2.1 Integrazione di Monte Carlo Il termine Monte Carlo si riferisce al fatto che la computazione fa ricorso ad un ripetuto campionamento casuale attraverso la generazione di sequenze di numeri casuali. Una delle sue applicazioni più potenti è il calcolo degli integrali mediante simulazione numerica. Supponiamo di essere in grado di estrarre campioni casuali dalla distribuzione continua \\(p(\\theta \\mid y)\\) di media \\(\\mu\\). Se possiamo ottenere una sequenza di realizzazioni indipendenti \\[ \\theta^{(1)}, \\theta^{(2)},\\dots, \\theta^{(T)} \\overset{\\text{iid}}{\\sim} p(\\theta \\mid y) \\] allora diventa possibile calcolare \\[ \\mathbb{E}(\\theta \\mid y) = \\int \\theta p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta \\approx \\frac{1}{T} \\sum_{i=1}^T \\theta^{(t)}. \\] In altre parole, l’aspettazione teorica di \\(\\theta\\) può essere approssimata dalla media campionaria di un insieme di realizzazioni indipendenti ricavate da \\(p(\\theta \\mid y)\\). Per la Legge Forte dei Grandi Numeri, l’approssimazione diventa arbitrariamente esatta per \\(T \\rightarrow \\infty\\).16 Quello che è stato detto sopra non è altro che un modo sofisticato per dire che, se vogliamo calcolare un’approssimazione del valore atteso di una variabile casuale, non dobbiamo fare altro che la media aritmetica di un grande numero di realizzazioni indipendenti della variabile casuale. Come è facile intuire, l’approssimazione migliora al crescere del numero di dati che abbiamo a disposizione. Un’altra importante funzione di \\(\\theta\\) è la funzione indicatore, \\(I(l &lt; \\theta &lt; u)\\), che assume valore 1 se \\(\\theta\\) giace nell’intervallo \\((l, u)\\) e 0 altrimenti. Il valore di aspettazione di \\(I(l &lt; \\theta &lt; u)\\) rispetto a \\(p(\\theta)\\) dà la probabilità che \\(\\theta\\) rientri nell’intervallo specificato, \\(Pr(l &lt; \\theta &lt; u)\\), e può essere approssimato usando l’integrazione Monte Carlo, ovvero prendendo la media campionaria del valore della funzione indicatore per ogni realizzazione \\(\\theta^{(t)}\\). È semplice vedere come \\[ Pr(l &lt; \\theta &lt; u) \\approx \\frac{\\text{numero di realizzazioni } \\theta^{(t)} \\in (l, u)}{T}. \\] Presentiamo qui l’integrazione di Monte Carlo perché, nell’analisi bayesiana, il metodo Monte Carlo viene usato per ottenere un’approssimazione della distribuzione a posteriori, quando tale distribuzione non può essere calcolata con metodi analitici. In altre parole, il metodo Monte Carlo consente di ottenere un gran numero di valori \\(\\theta\\) che, nelle circostanze ideali, avrà una distribuzione identica alla distribuzione a posteriori \\(p(\\theta \\mid y)\\). 18.2.2 Descrizione intuitiva Se la funzione di densità \\(p(\\theta \\mid y)\\) è conosciuta, è facile ottenere una sequenza di realizzazioni iid della variabile casuale, per esempio, usando \\(\\textsf{R}\\). Ma ora supponiamo di non conoscere \\(p(\\theta \\mid y)\\). Quello che vogliamo fare è ottenere comunque una sequenza di valori \\(\\theta\\). Anche se tali valori non saranno iid, per qualunque coppia di valori \\(\\theta_a\\) e \\(\\theta_b\\) nella sequenza vogliamo che sia soddisfatto il seguente vincolo: \\[ \\frac{\\#\\theta&#39;\\text{ nella sequenza} = \\theta_a}{\\#\\theta&#39;\\text{ nella sequenza} = \\theta_b} \\approx \\frac{p(\\theta_a \\mid y)}{p(\\theta_b \\mid y)}. \\] L’algoritmo di Metropolis ci consente di ottenere una tale sequenza di valori, la cui distribuzione sarà dunque uguale a \\(p(\\theta \\mid y)\\). In forma intuitiva, l’algoritmo di Metropolis può essere descritto come indicato di seguito. Data una sequenza di valori \\(\\{\\theta^{(1)}, \\theta^{(2)},\\dots, \\theta^{(t)}\\}\\), ci poniamo il problema di aggiungere un nuovo valore \\(\\theta^{t+1}\\) alla sequenza. Consideriamo un valore \\(\\theta^*\\) simile a \\(\\theta^{(t)}\\); ci chiediamo se dobbiamo inserire un tale valore nella sequenza oppure no. Se \\(p(\\theta^* \\mid y) &gt; p(\\theta^{(t)} \\mid y)\\), allora sicuramente lo dobbiamo aggiungere alla sequenza perché, nella sequenza, il numero di valori \\(\\theta^*\\) deve essere maggiore del numero dei valori \\(\\theta^{(t)}\\). Se invece \\(p(\\theta^* \\mid y) &lt; p(\\theta^{(t)} \\mid y)\\), allora non dobbiamo necessariamente aggiungere \\(\\theta^*\\) alla sequenza. La decisione di aggiungere o no \\(\\theta^*\\) alla sequenza dipenderà dal confronto tra \\(p(\\theta^* \\mid y)\\) e \\(p(\\theta^{(t)} \\mid y)\\). Calcoliamo il rapporto \\[ r = \\frac{p(\\theta^* \\mid y)}{p(\\theta^{(t)} \\mid y)} = \\frac{p(y \\mid \\theta^*) p(\\theta^*)}{p(y \\mid p(\\theta^{(t)}) p(p(\\theta^{(t)})}. \\] Se \\(r &gt; 1\\), accettiamo \\(\\theta^*\\) e lo aggiungiamo alla sequenza: \\(\\theta^{(t+1)} = \\theta^*\\), in quanto \\(\\theta^{(t)}\\) è già presente nella sequenza e \\(\\theta^*\\) ha una probabilità maggiore di \\(\\theta^{(t)}\\). Se \\(r &lt; 1\\), per ciasuna istanza di \\(\\theta^{(t)}\\), accettiamo \\(\\theta^*\\) solo una frazione di volte uguale a \\[ \\frac{p(\\theta^* \\mid y)}{p(\\theta^{(t)} \\mid y)} \\] in quanto la frequenza relativa dei valori \\(\\theta^{(t)}\\) e \\(\\theta^*\\) nella sequenza deve essere uguale al rapporto precedente. Per ottenere questo risultato, poniamo \\(\\theta^{(t+1)}\\) uguale a \\(\\theta^*\\) o \\(\\theta^{(t)}\\) con probabilità rispettivamente uguali a \\(r\\) o \\(1 - r\\). Questa è l’intuizione che sta alla base dell’algoritmo di Metropolis et al. (1953). 18.2.3 Un’applicazione empirica Poniamoci ora il problema di usare l’algoritmo di Metropolis per calcolare la distribuzione a posteriori di una proporzione \\(\\theta\\). Usiamo nuovamente i dati di Zetsche, Bürkner, and Renneberg (2019) (ovvero, 23 “successi” in 30 prove Bernoulliane) e, per rendere il problema più interessante, assumiamo per \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). Sappiamo che, in tali circostanze, la distribuzione a posteriori può essere ottenuta analiticamente tramite lo schema beta-binomiale ed è una \\(\\mbox{Beta}(25, 17)\\). Se vogliamo il valore della media a posteriori di \\(\\theta\\), il risultato esatto è dunque \\[ \\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 17} \\approx 0.5952. \\] È anche possibile ottenere il valore della media a posteriori per via numerica. Sapendo che la distribuzione a posteriori è una \\(\\mbox{Beta}(25, 17)\\), possiamo estrarre un campione di osservazioni da una tale distribuzione e calcolare la media. Con poche osservazioni (diciamo 10) otteniamo un risultato molto approssimato set.seed(84735) print(mean(rbeta(1e2, shape1 = 25, shape2 = 17)), 6) #&gt; [1] 0.584251 ma, per la legge dei grandi numeri, l’approssimazione migliora all’aumentare del numero di osservazioni: print(mean(rbeta(1e4, shape1 = 25, shape2 = 17)), 6) #&gt; [1] 0.595492 print(mean(rbeta(1e6, shape1 = 25, shape2 = 17)), 6) #&gt; [1] 0.595192 Lo stesso si può dire delle altre statistiche descrittive: moda, varianza, eccetera. Nel presente esempio, la simulazione Monte Carlo produce il risultato desiderato perché sappiamo che la distribuzione a posteriori è una \\(\\mbox{Beta}(25, 17)\\), è possibile usare le funzioni \\(\\textsf{R}\\) per estrarre campioni casuali da una tale distribuzione. Tuttavia, capita raramente di usare una distribuzione a priori coniugata alla verosimiglianza. Quindi, in generale, le due condizioni descritte sopra non si applicano. Ad esempio, nel caso di una verosimiglianza binomiale e di una distribuzione a priori gaussiana, la distribuzione a posteriori di \\(\\theta\\) è \\[ p(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}. \\] Una tale distribuzione non è implementata in \\(\\textsf{R}\\) e dunque non possiamo ottenere dei campioni casuali da una tale distribuzione. In tali circostanze, però, è ancora possibile ottenere ottenere un campione causale dalla distribuzione a posteriori in un altro modo. Questo risultato si ottiene utilizzando i metodi Monte Carlo basati su Catena di Markov (MCMC). I metodi MCMC, di cui l’algoritmo di Metropolis è un caso particolare e ne rappresenta il primo esempio, sono una classe di algoritmi che consentono di ottenere campioni casuali da una distribuzione a posteriori senza dovere conoscere la rappresentazione analitica di una tale distribuzione.17 Le tecniche MCMC sono il metodo computazionale maggiormente usato per risolvere i problemi dell’inferenza bayesiana. 18.2.4 Una passeggiata casuale sui numeri naturali Prima di applicare l’algoritmo di Metropolis ai dati di Zetsche, Bürkner, and Renneberg (2019), consideriamo un caso più semplice. In questo esempio preliminare useremo l’algoritmo di Metropolis per ottenere un campione casuale da una distribuzione di massa di probabilità; esamineremo il caso continuo in seguito.18 Definiamo la distribuzione di probabilità discreta della variabile casuale \\(X\\) che assume valori nell’insieme dei numeri naturali \\(1, 2, \\dots, K\\). Scriviamo in \\(\\textsf{R}\\) la funzione pd() che assegna a \\(X = \\{1, 2, \\dots, 8\\}\\) valori di probabilità proporzionali agli interi 5, 10, 4, 4, 20, 20, 12 e 5: pd &lt;- function(x){ values &lt;- c(5, 10, 4, 4, 20, 20, 12, 5) ifelse( x %in% 1:length(values), values[x] / sum(values), 0 ) } prob_dist &lt;- tibble( x = 1:8, prob = pd(1:8) ) La figura 18.5 illustra la distribuzione di massa di probabilità che è stata generata in questo modo. x &lt;- 1:8 prob_dist %&gt;% ggplot(aes(x = x, y = prob)) + geom_bar(stat = &quot;identity&quot;, width = 0.06) + scale_x_continuous(&quot;x&quot;, labels = as.character(x), breaks = x) + labs( y = &quot;Probabilità&quot;, x = &quot;X&quot; ) FIGURA 18.5: Distribuzione di massa di probabilità della variabile casuale discreta \\(X\\) avente supporto \\(\\{1, 2, ..., 8\\}\\). Per i dati di questo esempio, l’algoritmo di Metropolis corrisponde alla seguente passeggiata aleatoria.19 L’algoritmo inizia con un valore iniziale qualsiasi da 1 a \\(K=8\\) della variabile casuale. Per simulare il valore successivo della sequenza, lanciamo una moneta equilibrata. Se esce testa, consideriamo come valore candidato il valore immediatamente precedente al valore corrente nella sequenza; se esce croce, il candidato è il valore nella sequenza immediatamente successivo a quello corrente. Si calcola il rapporto \\(r\\) tra la probabilità del valore candidato e la probabilità del valore corrente: \\[ r = \\frac{pd(\\text{valore candidato})}{pd(\\text{valore corrente})}. \\] Si estrae un numero a caso \\(\\in [0, 1]\\). Se tale valore è minore di \\(r\\) si accetta il valore candidato come valore successivo della catena markoviana; altrimenti il valore successivo della catena rimane il valore corrente. In termini tecnici (si veda l’Appendice H), i passi da 1 a 4 definiscono una catena di Markov irriducibile e aperiodica sui valori di stato \\(\\{1, 2,\\dots, 8\\}\\), dove il passo 1 fornisce il valore iniziale della catena e i passi da 2 a 4 definiscono la matrice di transizione \\(P\\). Il campionamento dalla distribuzione di massa pd corrisponde ad una passeggiata aleatoria che inizia da una posizione qualsiasi e che ripete le fasi 2, 3 e 4 dell’algoritmo di Metropolis. Dopo un gran numero di passi, la distribuzione dei valori della catena markoviana approssimerà la distribuzione di probabilità pd. La funzione random_walk() implementa l’algoritmo di Metropolis. Tale funzione prende in input la distribuzione di probabilità pd, la posizione di partenza start e il numero di passi dell’algoritmo num_steps. random_walk &lt;- function(pd, start, num_steps){ y &lt;- rep(0, num_steps) current &lt;- start for (j in 1:num_steps){ candidate &lt;- current + sample(c(-1, 1), 1) prob &lt;- pd(candidate) / pd(current) if (runif(1) &lt; prob) current &lt;- candidate y[j] &lt;- current } return(y) } Implementiamo ora l’algoritmo di Metropolis utilizzando, quale valore iniziale, \\(X=4\\). Ripetiamo la simulazione 10,000 volte. out &lt;- random_walk(pd, 4, 1e4) S &lt;- tibble(out) %&gt;% group_by(out) %&gt;% summarize( N = n(), Prob = N / 10000 ) prob_dist2 &lt;- rbind( prob_dist, tibble( x = S$out, prob = S$Prob ) ) prob_dist2$Type &lt;- rep( c(&quot;Prob. corrette&quot;, &quot;Prob. simulate&quot;), each = 8 ) x &lt;- 1:8 prob_dist2 %&gt;% ggplot(aes(x = x, y = prob, fill = Type)) + geom_bar( stat = &quot;identity&quot;, width = 0.1, position = position_dodge(0.3) ) + scale_x_continuous( &quot;x&quot;, labels = as.character(x), breaks = x ) + scale_fill_manual(values = c(&quot;black&quot;, &quot;gray80&quot;)) + theme(legend.title = element_blank()) + labs( y = &quot;Probabilità&quot;, x = &quot;X&quot; ) FIGURA 18.6: L’istogramma confronta i valori prodotti dall’algoritmo di Metropolis con i valori corretti della distribuzione di massa di probabilità. La figura 18.6 confronta l’istogramma dei valori simulati dalla passeggiata aleatoria con l’effettiva distribuzione di probabilità pd. Si noti che le due distribuzioni sono molto simili. 18.2.5 L’algoritmo di Metropolis Dopo avere introdotto l’algoritmo di Metropolis con l’esempio proposto da Albert and Hu (2019), consideriamo ora l’algoritmo nella sua forma più generale.20 Nelle iterazioni dell’algoritmo di Metropolis possiamo distinguere le seguenti fasi. Si inizia con un punto arbitrario \\(\\theta^{(1)}\\); quindi il primo valore della catena di Markov \\(\\theta^{(1)}\\) può corrispondere semplicemente ad un valore a caso tra i valori possibili del parametro. Per ogni passo successivo della catena, \\(m + 1\\), si estrae un valore candidato \\(\\theta&#39;\\) da una distribuzione proposta: \\(\\theta&#39; \\sim \\Pi(\\theta)\\). La distribuzione proposta può essere qualunque distribuzione, anche se, idealmente, è meglio che sia simile alla distribuzione a posteriori. In pratica, però, la distribuzione a posteriori è sconosciuta e quindi il valore \\(\\theta&#39;\\) viene estratto a caso da una qualche distribuzione simmetrica centrata sul valore corrente \\(\\theta^{(m)}\\) del parametro. Nell’esempio presente useremo la gaussiana quale distribuzione proposta. La distribuzione proposta (gaussiana) sarà centrata sul valore corrente della catena e avrà una deviazione standard appropriata: \\(\\theta&#39; \\sim \\mathcal{N}(\\theta^{(m)}, \\sigma)\\). In pratica, questo significa che, se \\(\\sigma\\) è piccola, il valore candidato \\(\\theta&#39;\\) sarà simile al valore corrente \\(\\theta^{(m)}\\). Si calcola il rapporto \\(r\\) tra la densità della distribuzione a posteriori non normalizzata calcolata nel punto \\(\\theta&#39;\\) e la densità nel punto \\(\\theta^{(m)}\\): \\[\\begin{equation} r = \\frac{p(y \\mid \\theta&#39;) p(\\theta&#39;)}{p(y \\mid \\theta^{(m)}) p(\\theta^{(m)})}. \\tag{18.1} \\end{equation}\\] Il numeratore della (18.1) contiene il prodotto tra la verosimiglianza \\(p(y \\mid \\theta&#39;)\\) e la densità a priori di \\(\\theta\\), entrambe calcolate nel punto \\(\\theta&#39;\\). Il denominatore contiene il prodotto tra la verosimiglianza \\(p(y \\mid \\theta^{(m)})\\) e la densità a priori di \\(\\theta\\), entrambe calcolate nel punto \\(\\theta^{(m)}\\). Si noti che, essendo un rapporto, la (18.1) cancella la costante di normalizzazione. Si decide se accettare il candidato \\(\\theta&#39;\\) oppure se rigettarlo e estrarre un nuovo valore dalla distribuzione proposta. Possiamo pensare al rapporto \\(r\\) come alla risposta alla seguente domanda: alla luce dei dati, quale stima di \\(\\theta\\) è più plausibile il valore candidato o il valore corrente? Se \\(r\\) è maggiore di 1, ciò significa che il candidato è più plausibile del valore corrente; dunque il candidato viene sempre accettato. Altrimenti, si decide di accettare il candidato con una probabilità minore di 1, ovvero non sempre, ma soltanto con una probabilità uguale ad \\(r\\). Se \\(r\\) è uguale a 0.10, ad esempio, questo significa che la credibilità a posteriori del valore candidato è 10 volte più piccola della credibilità a posteriori del valore corrente. Dunque, il valore candidato verrà accettato solo nel 10% dei casi. Come conseguenza di questa strategia di scelta, l’algoritmo di Metropolis ottiene un campione casuale dalla distribuzione a posteriori, dato che la probabilità di accettare il valore candidato è proporzionale alla densità del candidato nella distribuzione a posteriori. Dal punto di vista algoritmico, la procedura descritta sopra viene implementata confrontando il rapporto \\(r\\) con un valore estratto a caso da una distribuzione uniforme \\(\\mbox{Unif}(0, 1)\\). Se \\(r &gt; u \\sim \\mbox{Unif}(0, 1)\\), allora il candidato \\(\\theta&#39;\\) viene accettato e la catena si muove in quella nuova posizione, ovvero \\(\\theta^{(m+1)} = \\theta&#39;\\). Altrimenti \\(\\theta^{(m+1)} = \\theta^{(m)}\\) e si estrae un nuovo candidato dalla distribuzione proposta. Il passaggio finale dell’algoritmo calcola l’accettanza in una specifica esecuzione dell’algoritmo, ovvero la proporzione di candidati \\(\\theta&#39;\\) che sono stati accettati quali valori successivi della catena. L’algoritmo di Metropolis prende come input il numero \\(T\\) di passi da simulare, la deviazione standard \\(\\sigma\\) della distribuzione proposta e la densità a priori, e ritorna come output la sequenza \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\). La chiave del successo dell’algoritmo di Metropolis è il numero di passi fino a che la catena approssima la stazionarietà. Tipicamente i primi da 1000 a 5000 elementi sono scartati. Dopo un certo periodo \\(k\\) (detto di burn-in), la catena di Markov converge ad una variabile casuale che è distribuita secondo la distribuzione a posteriori. In altre parole, i campioni del vettore \\(\\left(\\theta^{(k+1)}, \\theta^{(k+2)}, \\dots, \\theta^{(T)}\\right)\\) diventano campioni di \\(p(\\theta \\mid y)\\). 18.2.6 Un’applicazione empirica Possiamo ora utilizzare l’algoritmo di Metropolis per trovare, nel caso dei pazienti clinici depressi di Zetsche, Bürkner, and Renneberg (2019), la distribuzione a posteriori di \\(\\theta\\), ovvero la probabilità che l’umore futuro atteso sia negativo. I dati di Zetsche, Bürkner, and Renneberg (2019) ci dicono che, nel caso dei 30 pazienti che sono stati esaminati, 23 hanno manifestato aspettative distorte negativamente circa il loro stato d’animo futuro. A priori, abbiamo deciso di imporre su \\(\\theta\\) una \\(\\mbox{Beta}(2, 10)\\).21 18.2.6.1 Funzioni Definiamo la funzione likelihood(), considerati come fissi i dati di Zetsche, Bürkner, and Renneberg (2019), ritorna l’ordinata della verosimiglianza binomiale per ciascun valore param in input: likelihood &lt;- function(param, x = 23, N = 30) { dbinom(x, N, param) } La funzione prior() ritorna l’ordinata della distribuzione a priori \\(\\mbox{Beta}(2, 10)\\) per ciascun valore param in input: prior &lt;- function(param, alpha = 2, beta = 10) { dbeta(param, alpha, beta) } La funzione posterior() ritorna, per ciascun valore param in input, il prodotto della densità a priori e della verosimiglianza: posterior &lt;- function(param) { likelihood(param) * prior(param) } 18.2.6.2 Implementazione Per implementare l’algoritmo di Metropolis utilizzeremo una distribuzione proposta gaussiana. Il valore candidato sarà dunque un valore selezionato a caso da una gaussiana di parametri \\(\\mu\\) uguale al valore corrente nella catena e \\(\\sigma = 0.9\\). In questo esempio, la deviazione standard \\(\\sigma\\) è stata scelta empiricamente in modo tale da ottenere una accettanza adeguata. L’accettanza ottimale èpari a circa 0.20/0.30 — se l’accettanza è troppo grande, l’algoritmo esplora uno spazio troppo ristretto della distribuzione a posteriori.22 proposal_distribution &lt;- function(param) { while(1) { res = rnorm(1, mean = param, sd = 0.9) if (res &gt; 0 &amp; res &lt; 1) break } res } Ho inserito un controllo che impone al valore candidato di essere incluso nell’intervallo [0, 1], com’è necessario per il valore di una proporzione.23 L’algoritmo di Metropolis viene implementato nella seguente funzione: metropolis &lt;- function(startvalue, iterations) { chain &lt;- vector(length = iterations + 1) chain[1] &lt;- startvalue for (i in 1:iterations) { proposal &lt;- proposal_distribution(chain[i]) r &lt;- posterior(proposal) / posterior(chain[i]) if (runif(1) &lt; r) { chain[i + 1] &lt;- proposal } else { chain[i + 1] &lt;- chain[i] } } chain } Mediante la funzione precedente, generiamo una catena di valori \\(\\theta\\): set.seed(84735) startvalue &lt;- runif(1, 0, 1) niter &lt;- 1e4 chain &lt;- metropolis(startvalue, niter) In questo modo, abbiamo ottenuto una catena di Markov costituita da 10,001 valori. Escludiamo i primi 5,000 valori considerati come burn-in. Consideriamo i restanti 5,001 valori come un campione casuale estratto dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). L’accettanza è pari a burnin &lt;- niter / 2 acceptance &lt;- 1 - mean(duplicated(chain[-(1:burnin)])) acceptance #&gt; [1] 0.2585483 il che conferma la bontà della deviazione standard (\\(\\sigma\\) = 0.9) scelta per la distribuzione proposta. Mediante i valori della catena così ottenuta è facile trovare una stima a posteriori del parametro \\(\\theta\\). Per esempio, la stima della media a posteriori è: mean(chain[-(1:burnin)]) #&gt; [1] 0.5956983 Una figura che mostra l’approssimazione di \\(p(\\theta \\mid y)\\) ottenuta con l’algoritmo di Metropolis, insieme ad un trace plot dei valori della catena di Markov, è prodotta nel modo seguente: p1 &lt;- tibble( x = chain[-(1:burnin)] ) %&gt;% ggplot(aes(x)) + geom_histogram(fill = &quot;darkgray&quot;) + labs( x = expression(theta), y = &quot;Frequenza&quot;, title = &quot;Distribuzione a posteriori&quot; ) + geom_vline( xintercept = mean(chain[-(1:burnin)]) ) + xlim(c(0.3, 0.85)) + coord_flip() p2 &lt;- tibble( x = 1:length(chain[-(1:burnin)]), y = chain[-(1:burnin)] ) %&gt;% ggplot(aes(x, y)) + geom_line(color = &quot;darkgray&quot;) + labs( x = &quot;Numero di passi&quot;, y = expression(theta), title = &quot;Valori della catena&quot; ) + geom_hline( yintercept = mean(chain[-(1:burnin)]), colour = &quot;black&quot; ) + ylim(c(0.3, 0.85)) p1 + p2 FIGURA 18.7: Sinistra. Stima della distribuzione a posteriori della probabilità di una aspettativa futura distorta negativamente per i dati di Zetsche et al. (2019). Destra. Trace plot dei valori della catena di Markov escludendo il periodo di burn-in. 18.2.6.3 Funzione metropolis() I calcoli precedenti possono essere svolti anche mediante la funzione metropolis() del pacchetto ProbBayes. Per fare un esempio, consideriamo i dati corrispondenti a 23 successi in 30 prove, con una distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). Le istruzioni sono le seguenti: set.seed(123) lpost &lt;- function(theta, s){ dbeta(theta, 2, 10,log = TRUE) + dbinom(23, 30, theta, log = TRUE) } post &lt;- ProbBayes::metropolis(lpost, 0.5, 0.2, 8000) tibble( x = post$S[4001:8000] ) %&gt;% ggplot(aes(x)) + geom_histogram(fill = &quot;darkgray&quot;) + labs( x = expression(theta), y = &quot;Frequenza&quot;, title = &quot;Distribuzione a posteriori&quot; ) Utilizzando un burn-in piuttosto lungo, la stima a posteriori di \\(\\theta\\) diventa: mean(post$S[4001:8000]) #&gt; [1] 0.594834 L’accettanza però non è ottimale: post$accept_rate #&gt; [1] 0.546375 18.2.7 Gibb’s sampling Il campionamento di Gibbs è un algoritmo MCMC per ottenere una sequenza di campioni casuali da una distribuzione di probabilità congiunta di due o più variabili casuali quando il campionamento diretto si dimostra difficoltoso. Questa sequenza può essere usata per approssimare la distribuzione congiunta. Consideriamo, quale esempio, la seguente distribuzione di probabilità congiunta \\(p(x, y)\\) delle due variabili casuali \\(X\\) e \\(Y\\) (lo script \\(\\textsf{R}\\) è ricavato da Albert and Hu 2019): p &lt;- matrix(c( 4, 3, 2, 1, 3, 4, 3, 2, 2, 3, 4, 3, 1, 2, 3, 4 ) / 40, 4, 4, byrow = TRUE) dimnames(p)[[1]] &lt;- 1:4 dimnames(p)[[2]] &lt;- 1:4 p #&gt; 1 2 3 4 #&gt; 1 0.100 0.075 0.050 0.025 #&gt; 2 0.075 0.100 0.075 0.050 #&gt; 3 0.050 0.075 0.100 0.075 #&gt; 4 0.025 0.050 0.075 0.100 Supponiamo che sia difficile campionare direttamente da \\(p(x, y)\\); supponiamo, tuttavia, di poter facilmente campionare dalle distribuzioni condizionate \\(p(x \\mid y)\\) e \\(p(y \\mid x)\\). Poniamo che l’algoritmo inizi con il valore \\(X = 1\\). Passo 1. Si simula \\(Y\\) dalla distribuzione condizionata \\(f(y \\mid X = 1)\\). Questa distribuzione condizionata è contenuta nella prima colonna della matrice \\(p(x, y)\\), ovvero p[, 1] #&gt; 1 2 3 4 #&gt; 0.100 0.075 0.050 0.025 Supponiamo di avere ottenuto il valore \\(Y = 2\\). Passo 2. Ora estraiamo un valore a caso \\(X\\) dalla distribuzione condizionata \\(f(x \\mid Y = 2)\\). Questa distribuzione condizionata è contenuta nella seconda riga della matrice \\(p(x, y)\\), ovvero p[2, ] #&gt; 1 2 3 4 #&gt; 0.075 0.100 0.075 0.050 Supponiamo di avere ottenuto il valore \\(X = 3\\). Implementando i passi 1 e 2, si ottiene un’iterazione del campionamento di Gibbs, ovvero la coppia simulata \\((X, Y) = (3, 2)\\). Il campionamento di Gibbs si realizza ripetendo i passaggi 1 e 2 molte volte, laddove in ogni passo condizioniamo i valori simulati ai valori \\(X\\) o \\(Y\\) più recenti. Le seguenti istruzioni generano 100,000 iterazioni dell’algorimo di Gibbs per l’esempio in considerazione: n_iter &lt;- 1e5 gibbs_discrete &lt;- function(p, i = 1, iter = n_iter){ x &lt;- matrix(0, iter, 2) n_x &lt;- dim(p)[1] n_y &lt;- dim(p)[2] for(k in 1:n_iter){ j &lt;- sample(1:n_y, 1, prob = p[i, ]) i &lt;- sample(1:n_x, 1, prob = p[, j]) x[k, ] &lt;- c(i, j) } x } Esaminando i risultati ottenuti, notiamo che il campionamento di Gibbs produce una buona approssimazione della distribuzione di probabilità congiunta di partenza: sp &lt;- data.frame(gibbs_discrete(p)) names(sp) &lt;- c(&quot;X&quot;, &quot;Y&quot;) round(table(sp) / n_iter, 3) #&gt; Y #&gt; X 1 2 3 4 #&gt; 1 0.090 0.068 0.046 0.023 #&gt; 2 0.067 0.090 0.068 0.046 #&gt; 3 0.045 0.069 0.091 0.069 #&gt; 4 0.023 0.045 0.068 0.093 18.2.7.1 Campionamento beta-binomiale L’esempio precedente ha dimostrato il campionamento di Gibbs per una distribuzione discreta a due parametri, ma il campionamento di Gibbs funziona per qualsiasi distribuzione a due parametri. Per illustrare questo, consideriamo nuovamente lo schema beta-binomiale. \\[ \\begin{split} Y \\mid p &amp;\\sim \\mbox{Binom}(n, p),\\\\ p &amp;\\sim \\mbox{Beta}(a, b). \\end{split} \\] Per implementare il campionamento Gibbs per questa situazione, è necessario identificare le due distribuzioni condizionate \\(Y \\mid P\\) e \\(p \\mid Y\\). A questo fine, calcoliamo prima la distribuzione congiunta \\(f(Y, p)\\): \\[ \\begin{split} f(Y, p) &amp;= f(p) f(y \\mid p)\\\\ &amp;= \\left[ \\frac{1}{B(a, b)}p^{a-1} (1-p)^{b-1} \\right] \\left[ \\binom{n}{y}p^y (1-p)^{n-y}\\right]. \\end{split} \\] Per trovare le distribuzioni marginali, sopprimiamo la dipendenza di \\(f(Y, p)\\) dalle costanti irrilevanti. Se teniamo fisso \\(p\\), l’unica variabile casuale è \\(y\\). Dunque, tutto il contenuto della prima parentesi quadra diventa una costante che può essere ignorata. Per cui \\(f(y \\mid p)\\) è \\(\\mbox{Binom}(n, p)\\). D’altra parte, se teniamo fisso \\(y\\), ignorando le costanti, la densità congiunta risulta proporzionale a \\[ p^{y+a-1} (1-p)^{n-y+b-1} \\] che è il kernel della distribuzione Beta con parametri di forma \\(y+a\\) e \\(n-y+b\\). Quindi abbiamo \\(f(p \\mid y) = \\mbox{Beta}(y+a, n-y+b)\\). Una volta trovate le due distribuzioni condizionate è facile modificare l’algoritmo di Gibbs visto sopra per adattarlo alla situazione presente: gibbs_betabin &lt;- function(n, a, b, p = 0.5, iter = n_iter){ x &lt;- matrix(0, iter, 2) for(k in 1:iter){ y &lt;- rbinom(1, size = n, prob = p) p &lt;- rbeta(1, y + a, n - y + b) x[k, ] &lt;- c(y, p) } x } Di seguito eseguiamo il campionamento Gibbs per questo modello Beta-Binomiale con \\(n=20\\), \\(a = 5\\) e \\(b=5\\). Dopo aver eseguito 100,000 iterazioni, possiamo considerare la matrice \\(sp\\) come un campione casuale tratto dalla distribuzione congiunta \\(f(Y, p)\\). Se dalla sequenza di coppie \\((Y, p)\\) generate dall’algoritmo di Gibbs consideriamo solo i valori \\(Y\\), possiamo ottenere un’approssimazione della distribuzione marginale \\(f(y)\\) di \\(Y\\). set.seed(123) sp &lt;- data.frame(gibbs_betabin(20, 5, 5)) ggplot(data.frame(Y = sp$X1), aes(Y)) + geom_bar(width = 0.5, fill = &quot;darkgray&quot;) + ylab(&quot;Frequency&quot;) La figura seguente mostra invece l’approssimazione della distribuzione congiunta \\(f(Y, p)\\) che è stata ottenuta: ggplot(sp, aes(X1, X2)) + geom_point(size = 0.5, color = &quot;black&quot;, alpha = 0.05) + xlab(&quot;Y&quot;) + ylab(&quot;p&quot;) 18.2.8 Input Negli esempi discussi in questo Capitolo abbiamo illustrato l’esecuzione di una singola catena in cui si parte un unico valore iniziale e si raccolgono i valori simulati da molte iterazioni. È possibile però che i valori di una catena siano influenzati dalla scelta del valore iniziale. Quindi una raccomandazione generale è di eseguire l’algoritmo di Metropolis più volte utilizzando diversi valori di partenza. In questo caso, si avranno più catene di Markov. Confrontando le proprietà delle diverse catene si esplora la sensibilità dell’inferenza alla scelta del valore di partenza. I software MCMC consentono sempre all’utente di specificare diversi valori di partenza e di generare molteplici catene di Markov. 18.2.9 Stazionarietà Un punto importante da verificare è se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta “mixing”. 18.2.9.1 Autocorrelazione Informazioni sul “mixing” della catena di Markov sono fornite dall’autocorrelazione. L’autocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore \\(m\\)-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantità \\(k\\) (dove \\(k\\) è l’entità del ritardo) per verificare quanto si correli al variare di \\(k\\). L’autocorrelazione di ordine 1 (lag 1) misura la correlazione tra valori successivi della catena di Markow (cioè, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-1)}\\)); l’autocorrelazione di ordine 2 (lag 2) misura la correlazione tra valori della catena di Markow separati da due “passi” (cioè, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-2)}\\)); e così via. L’autocorrelazione di ordine \\(k\\) è data da \\(\\rho_k\\) e può essere stimata come: \\[\\begin{align} \\rho_k &amp;= \\frac{\\mbox{Cov}(\\theta_m, \\theta_{m+k})}{\\mbox{Var}(\\theta_m)}\\notag\\\\ &amp;= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m. \\tag{18.2} \\end{align}\\] Per fare un esempio pratico, simuliamo dei dati autocorrelati con la funzione \\(\\textsf{R}\\) colorednoise::colored_noise(): suppressPackageStartupMessages(library(&quot;colorednoise&quot;)) set.seed(34783859) rednoise &lt;- colored_noise( timesteps = 30, mean = 0.5, sd = 0.05, phi = 0.3 ) L’autocorrelazione di ordine 1 è semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza. Nell’esempio, il vettore rednoise è una sequenza temporale di 30 elementi. Il vettore rednoise[-length(rednoise)] include gli elementi con gli indici da 1 a 29 nella sequenza originaria, mentre il vettore rednoise[-1] include gli elementi 2:30. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici \\((1, 2), (2, 3), \\dots (29, 30)\\) degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori rednoise[-length(rednoise)] e rednoise[-1] corrisponde all’autocorrelazione di ordine 1 della serie temporale. cor(rednoise[-length(rednoise)], rednoise[-1]) #&gt; [1] 0.3967366 Il Correlogramma è uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall’autocorrelazione \\(\\rho_k\\) di una catena di Markov in funzione del ritardo (lag) \\(k\\) con cui l’autocorrelazione è calcolata: nel grafico ogni barretta verticale riporta il valore dell’autocorrelazione (sull’asse delle ordinate) in funzione del ritardo (sull’asse delle ascisse). In \\(\\textsf{R}\\), il correlogramma può essere prodotto con una chiamata a acf(): acf(rednoise) Nel correlogramma precedente vediamo che l’autocorrelazione di ordine 1 è circa pari a 0.4 e diminuisce per lag maggiori; per lag di 4, l’autocorrelazione diventa negativa e aumenta progressivamente fino ad un lag di 8; eccetera. In situazioni ottimali l’autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per piccoli lag. Ciò indica che i valori della catena di Markov che si trovano a più di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del “mixing” della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l’autocorrelazione è quella di assottigliare l’output immagazzinando solo ogni \\(m\\)-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di thinning. 18.2.10 Test di convergenza Un test di convergenza può essere svolto in maniera grafica mediante le tracce delle serie temporali (trace plot), cioè il grafico dei valori simulati rispetto al numero di iterazioni. Se la catena è in uno stato stazionario le tracce mostrano assenza di periodicità nel tempo e ampiezza costante, senza tendenze visibili o andamenti degni di nota. Un esempio di trace plot è fornito nella figura 18.7 (destra). Ci sono inoltre alcuni test che permettono di verificare la stazionarietà del campionatore dopo un dato punto. Uno è il test di Geweke che suddivide il campione, dopo aver rimosso un periodo di burn in, in due parti. Se la catena è in uno stato stazionario, le medie dei due campioni dovrebbero essere uguali. Un test modificato, chiamato Geweke z-score, utilizza un test \\(z\\) per confrontare i due subcampioni ed il risultante test statistico, se ad esempio è più alto di 2, indica che la media della serie sta ancora muovendosi da un punto ad un altro e quindi è necessario un periodo di burn-in più lungo. Commenti e considerazioni finali In generale, la distribuzione a posteriori dei parametri di un modello statistico non può essere determinata per via analitica. Tale problema viene invece affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilità che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre più semplice l’uso dei metodi MCMC, insieme all’incremento della potenza di calcolo dei computer, ha contribuito a rendere sempre più popolare il metodo dell’inferenza bayesiana che, in questo modo, può essere estesa a problemi di qualunque grado di complessità. References "],["ch-stan-beta-binom.html", "Capitolo 19 Il modello beta-binomiale in linguaggio Stan 19.1 Il presidente Trump e l’idrossiclorochina 19.2 Una proporzione 19.3 Interfaccia cmdstanr 19.4 La critica di Hulme et al. (2020) 19.5 Due proporzioni Commenti e considerazioni finali", " Capitolo 19 Il modello beta-binomiale in linguaggio Stan In questo Capitolo introdurremo un linguaggio di programmazione probabilistica chiamato Stan (Carpenter et al. 2017). Stan consente di generare campioni da distribuzioni di probabilità basati sulla costruzione di una catena di Markov avente come distribuzione di equilibrio (o stazionaria) la distribuzione desiderata. Prende il nome da uno dei creatori del metodo Monte Carlo, Stanislaw Ulam (Eckhardt 1987). Un’introduzione al linguaggio Stan è fornita nell’Appendice ??. In questo Capitolo useremo Stan per fare inferenza su una proporzione. 19.1 Il presidente Trump e l’idrossiclorochina Per fare un esempio concreto, consideriamo un set di dati reali. Cito dal Washington Post del 7 aprile 2020: “One of the most bizarre and disturbing aspects of President Trump’s nightly press briefings on the coronavirus pandemic is when he turns into a drug salesman. Like a cable TV pitchman hawking ‘male enhancement’ pills, Trump regularly extols the virtues of taking hydroxychloroquine, a drug used to treat malaria and lupus, as a potential ‘game changer’ that just might cure Covid-19.” Tralasciamo qui il fatto che il Donald Trump non sia un esperto in questo campo. Esaminiamo invece le evidenze iniziali a supporto dell’ipotesi che l’idrossiclorochina possa essere utile per la cura del Covid-19, ovvero le evidenze che erano disponibili nel momento in cui il Donald Trump ha fatto le affermazioni riportate sopra (in seguito, quest’idea è stata screditata). Tali evidenze sono state fornite da uno studio di Gautret et al. (2020). Il disegno sperimentale di Gautret et al. (2020) comprende, tra le altre cose, il confronto tra una condizione sperimentale e una condizione di controllo. Il confronto importante è tra la proporzione di paziente positivi al virus SARS-CoV-2 nel gruppo sperimentale (a cui è stata somministrata l’idrossiclorochina; 6 su 14) e la proporzione di paziente positivi nel gruppo di controllo (a cui non è stata somministrata l’idrossiclorochina; ovvero 14 su 16). Obiettivo di questo Capitolo è mostrare come si possa fare inferenza sui dati di Gautret et al. (2020) usando il linguaggio Stan. Per semplicità, iniziamo considerando solo il gruppo di controllo. 19.2 Una proporzione Sulla base di ciò che è stato detto nel Capitolo ??, sappiamo che, quando i dati sono rappresentati da una proporzione \\(\\theta\\), e quando utilizziamo una distribuzione a priori Beta per \\(\\theta\\), la distribuzione a posteriori di \\(\\theta\\) è specificata dallo schema beta-binomiale. Se scegliamo, ad esempio, una \\(\\mbox{Beta}(2, 2)\\) quale distribuzione a priori per \\(\\theta\\), il modello diventa: \\[\\begin{align} y &amp;\\sim \\mbox{Bin}(n, \\theta) \\notag\\\\ \\theta &amp;\\sim \\mbox{Beta}(2, 2) \\tag{19.1} \\end{align}\\] dove la prima riga definisce la funzione di verosimiglianza e la seconda riga definisce la distribuzione a priori. Vediamo ora come specificare il modello beta-binomiale in linguaggio Stan. 19.3 Interfaccia cmdstanr I modelli presentati in questo capitolo sono discussi da Gelman et al. (1995) mentre il codice è stato ricavato dalla seguente pagina web. In questo e nei successivi capitoli useremo Stan mediante l’interfaccia cmdstanr di CmdStan. Iniziamo con il caricare i pacchetti necessari: library(&quot;cmdstanr&quot;) library(&quot;posterior&quot;) availableCores() SEED &lt;- 84735 # set random seed for reproducibility Per svolgere l’analisi mediante cmdstanr è necessario prima specificare la struttura del modello bayesiano nella notazione Stan e, poi, eseguire il campionamento dalla distribuzione a posteriori. Esaminiamo questi due passaggi per il caso dell’esempio presente. 19.3.1 Fase 1 Nella prima fase dell’analisi dobbiamo definire i dati, i parametri e il modello. I dati devono essere contenuti in un oggetto di classe list. Per l’esempio presente abbiamo: data1_list &lt;- list( N = 16, y = c(rep(1, 14), rep(0, 2)) ) Il modello è \\(\\mbox{Bin}(n, \\theta)\\). Oppure, dato che abbiamo specificato in input ciascuna singola osservazione, \\(\\mbox{Bernoulli}(\\theta)\\). In linguaggio Stan, la verosimiglianza si specifica nel modo seguente. y ~ bernoulli(theta); La verosimiglianza dipende dal parametro theta. In Stan, è necessario specificare che theta è un numero reale compreso tra 0 e 1. Inoltre, è necessario imporre su \\(\\theta\\) una distribuzione a priori. Nel caso presente abbiamo scelto una \\(\\mbox{Beta}(2, 2)\\) e, in linguaggio Stan, scriviamo la distribuzione a priori per \\(\\theta\\) ne modo seguente. theta ~ beta(2, 2); Memorizziamo il modello beta-binomiale che abbiamo specificato in linguaggio Stan come stringa di caratteri. modelString = &quot; data { int&lt;lower=0&gt; N; array[N] int&lt;lower=0, upper=1&gt; y; } parameters { real&lt;lower=0, upper=1&gt; theta; } model { theta ~ beta(2, 2); y ~ bernoulli(theta); } &quot; Utilizzando il seguente link si può ottenere una formattazione automatica del codice e anche, in qualche misura, una correzione della sintassi. Salviamo modelString in un file a cui assegniamo il nome oneprop.stan (si noti l’estensione .stan). Sul mio computer ho creato una cartella chiamata code dove salvo i file .stan. Se non vogliamo definire una sotto-cartella chiamata code, è sufficiente scrivere writeLines(modelString, con = \"oneprop.stan\"). writeLines(modelString, con = &quot;code/oneprop.stan&quot;) 19.3.2 Fase 2 Per utilizzare il modello che abbiamo specificato, prima leggiamo l’indirizzo del file che contiene il codice Stan file &lt;- file.path(&quot;code&quot;, &quot;oneprop.stan&quot;) poi compiliamo il codice Stan. Questo crea un file eseguibile che, nel caso presente, abbiamo chiamato mod. mod &lt;- cmdstan_model(file) Possiamo ora eseguire il campionamento MCMC con la seguente chiamata. fit1 &lt;- mod$sample( data = data1_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = 84735, chains = 4L, refresh = 0 ) Si noti che $sample() è un “metodo” che viene applicato al file eseguibile che abbiamo compilato, al quale è stato assegnato il nome mod. Il metodo $sample() richiede una serie di argomenti. data, ovvero i dati in input in formato lista (nel caso presente, data1_list). chains specifica quante catene di Markov parallele eseguire. Eseguiamo qui quattro catene, quindi otterremo quattro campioni distinti di valori \\(\\pi\\). iter specifica il numero desiderato di iterazioni o la lunghezza di ciascuna catena di Markov. Per impostazione predefinita, la prima metà di queste iterazioni è costituita da campioni “burn-in” o “warm-up” che verranno ignorati. La seconda metà è conservata e costituisce un campione della distribuzione a posteriori. iter_warmup specifica il numero di campioni “warm-up” che vogliamo vengano ignorati. seed imposta il numero casuale che viene usato per generare il punto di partenza di ciascuna catena di Markov. Avendo assunto una distribuzione a priori per il parametro \\(\\theta\\), l’algoritmo procede in maniera ciclica, correggendo la distribuzione a priori di \\(\\theta\\) condizionandola ai valori già generati. Dopo un certo numero di cicli, necessari per portare l’algoritmo a convergenza, i valori estratti possono essere assunti come campionati dalla distribuzione a posteriori di \\(\\theta\\). Al crescere del numero di passi della catena, la distribuzione di target viene sempre meglio approssimata. All’inizio del campionamento, però, la distribuzione può essere significativamente lontana da quella stazionaria, e ci vuole un certo tempo prima di raggiungere la distribuzione stazionaria di equilibrio, detto, appunto, periodo di burn-in. I campioni provenienti da tale parte iniziale della catena vanno tipicamente scartati perché possono non rappresentare accuratamente la distribuzione a posteriori. 19.3.3 Fase 3 Possiamo ora fare inferenza usando i risultati ottenuti. Un sommario della distribuzione a posteriori si ottiene con: fit1$summary(c(&quot;theta&quot;)) #&gt; # A tibble: 1 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 theta 0.798 0.808 0.0876 0.0872 0.638 0.924 1.00 5769. 6359. Creiamo un oggetto di classe stanfit stanfit1 &lt;- rstan::read_stan_csv(fit1$output_files()) di dimensioni dim(as.matrix(stanfit1, pars = &quot;theta&quot;)) #&gt; [1] 16000 1 I primi 10 valori sono presentati qui di seguito as.matrix(stanfit1, pars = &quot;theta&quot;) %&gt;% head(10) #&gt; parameters #&gt; iterations theta #&gt; [1,] 0.852111 #&gt; [2,] 0.784496 #&gt; [3,] 0.784496 #&gt; [4,] 0.755076 #&gt; [5,] 0.725578 #&gt; [6,] 0.774385 #&gt; [7,] 0.774385 #&gt; [8,] 0.806225 #&gt; [9,] 0.826550 #&gt; [10,] 0.849894 La matrice precedente include i valori assunti dalla catena di Markov, ovvero un insieme di valori plausibili \\(\\theta\\) estratti dalla distribuzione a posteriori. Un tracciato della catena di Markov illustra questa esplorazione rappresentando il valore \\(\\theta\\) sulle ordinate e l’indice progressivo di in ogni iterazione sull’ascissa. Usiamo la funzione mcmc_trace() del pacchetto bayesplot per costruire il grafico che include tutte e quattro le catene di Markov: stanfit1 %&gt;% mcmc_trace(pars = c(&quot;theta&quot;), size = 0.1) FIGURA 19.1: Trace-plot per il parametro \\(\\theta\\) nel modello Beta-Binomiale. La figura 19.1 mostra che le catene esplorano uno spazio compreso approssimativamenre tra 0.5 e 0.95; questa figura descrive il comportamento longitudinale delle catene di Markov. Possiamo anche esaminare la distribuzione degli stati della catena di Markov, ovvero, dei valori che queste catene visitano lungo il loro percorso, ignorando l’ordine di queste visite. L’istogramma della figura 19.2 fornisce una rappresentazione grafica di questa distribuzione per i 16000 valori complessivi delle quattro catene, ovvero per 4000 valori provienienti da ciascuna catena. mcmc_hist(stanfit1, pars = &quot;theta&quot;) + yaxis_text(TRUE) + ylab(&quot;count&quot;) FIGURA 19.2: Istogramma che illustra l’approssimazione della distribuzione a posteriori per il parametro \\(\\theta\\) nel modello Beta-Binomiale. Nello schema beta-binomiale in cui la verosimiglianza è binomiale con 14 successi su 16 prove e in cui assumiamo una distribuzione a priori \\(\\mbox{Beta}(2, 2)\\) sul parametro \\(\\theta\\), la distribuzione a posteriori è una distribuzione Beta di parametri \\(\\alpha\\) = 2 + 14 e \\(\\beta\\) = 2 + 16 - 14. La figura 19.3 riporta un kernel density plot per i valori delle quattro catene di Markov con sovrapposta in nero la densità \\(\\mbox{Beta}(16, 4)\\). Si noti come la distribuzione dei valori delle catene di Markov produca un’eccellente approssimazione alla distribuzione bersaglio.24 mcmc_dens(stanfit1, pars = &quot;theta&quot;) + yaxis_text(TRUE) + ylab(&quot;density&quot;) + stat_function(fun = dbeta, args = list(shape1 = 16, shape2=4)) FIGURA 19.3: Istogramma che illustra l’approssimazione della distribuzione a posteriori per il parametro \\(\\theta\\) nel modello Beta-Binomiale. La curva nera rappresenta la corretta distribuzione a posteriori Beta(16, 4). Un intervallo di credibilità al 95% per \\(\\theta\\) si ottiene con la seguente chiamata: posterior1 &lt;- extract(stanfit1) rstantools::posterior_interval(as.matrix(stanfit1), prob = 0.95) #&gt; 2.5% 97.5% #&gt; theta 0.5990419 0.9376123 #&gt; lp__ -12.5817650 -10.0086000 Svolgendo un’analisi bayesiana simile a questa, Gautret et al. (2020) hanno trovato che gli intervalli di credibilità del gruppo di controllo e del gruppo sperimentale non si sovrappongono. Questo fatto viene interpretato dicendo che il parametro \\(\\theta\\) è diverso nei due gruppi. Sulla base di queste evidenza, Gautret et al. (2020) hanno concluso, con un grado di certezza soggettiva del 95%, che nel gruppo sperimentale vi è una probabilità più bassa di risultare positivi al SARS-CoV-2 rispetto al gruppo di controllo. In altri termini, l’analisi statistica condotta da Gautret et al. (2020) suggerisce che l’idrossiclorochina è una terapia efficace per il Covid-19. 19.4 La critica di Hulme et al. (2020) Un articolo pubblicato da Hulme et al. (2020) si è posto il problema di rianalizzare i dati di Gautret et al. (2020).25 Tra gli autori di questo articolo figura anche Eric-Jan Wagenmakers, uno psicologo molto conosciuto per i suoi contributi metodologici. Hulme et al. (2020) osservano che, nelle loro analisi statistiche, Gautret et al. (2020) hanno escluso alcuni dati. Nel gruppo sperimentale, infatti, vi erano alcuni pazienti i quali, anziché migliorare, sono in realtà peggiorati. L’analisi statistica di Gautret et al. (2020) ha escluso i dati di questi pazienti. Se consideriamo tutti i pazienti — non solo quelli selezionati da Gautret et al. (2020) — la situazione diventa la seguente: gruppo sperimentale: 10 positivi su 18; gruppo di controllo: 14 positivi su 16. L’analisi dei dati proposta da Hulme et al. (2020) richiede l’uso di alcuni strumenti statistici che, in queste dispense, non verranno discussi. Ma possiamo giungere alle stesse conclusioni raggiunte da questi ricercatori anche usando le procedure statistiche descritte nel Paragrafo successivo. 19.5 Due proporzioni Svolgiamo ora l’analisi statistica considerando tutti i dati, come suggerito da Hulme et al. (2020). Per fare questo verrà creato un modello bayesiano per fare inferenza sulla differenza tra due proporzioni. Dopo avere generato le distribuzioni a posteriori per le proporzioni di “successi” nei due gruppi, calcoleremo la quantità \\[ \\omega = \\frac{\\theta_2 / (1-\\theta_2)}{\\theta_1 / (1-\\theta_1)}, \\] ovvero il rapporto tra gli Odds di positività tra i pazienti del gruppo di controllo e gli Odds di positività tra i pazienti del gruppo sperimentale. Se il valore dell’OR è uguale a 1, significa che l’Odds di positività nel gruppo di controllo è uguale all’Odds di positività nel gruppo sperimentale, cioè il fattore in esame (somministrazione dell’idrossiclorochina) è ininfluente sulla comparsa della malattia. L’inferenza statistica sull’efficacia dell’idrossiclorochina come terapia per il Covid-19 può dunque essere effettuata esaminando l’intervallo di credibilità al 95% per l’OR: se tale intervallo include il valore 1, allora non c’è evidenza che l’idrossiclorochina sia efficace come terapia per il Covid-19. Nell’implementazione di questo modello, la quantità di interesse è l’odds ratio; tale quantità viene calcolata nel blocco generated quantities. Per i parametri \\(\\theta_1\\) e \\(\\theta_2\\) useremo delle distribuzioni a priori debolmente informative il cui scopo è la regolarizzazione dei dati. data_list &lt;- list( N1 = 18, y1 = 10, N2 = 16, y2 = 14 ) modelString &lt;- &quot; // Comparison of two groups with Binomial data { int&lt;lower=0&gt; N1; // number of experiments in group 1 int&lt;lower=0&gt; y1; // number of deaths in group 1 int&lt;lower=0&gt; N2; // number of experiments in group 2 int&lt;lower=0&gt; y2; // number of deaths in group 2 } parameters { real&lt;lower=0, upper=1&gt; theta1; // probability of death in group 1 real&lt;lower=0, upper=1&gt; theta2; // probability of death in group 2 } model { theta1 ~ beta(2, 2); // prior theta2 ~ beta(2, 2); // prior y1 ~ binomial(N1, theta1); // likelihood y2 ~ binomial(N2, theta2); // likelihood } generated quantities { real oddsratio = (theta2 / (1 - theta2)) / (theta1 / (1 - theta1)); } &quot; writeLines(modelString, con = &quot;code/twoprop1.stan&quot;) file &lt;- file.path(&quot;code&quot;, &quot;twoprop1.stan&quot;) mod &lt;- cmdstan_model(file) fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) stanfit &lt;- rstan::read_stan_csv(fit$output_files()) print( stanfit, pars = c(&quot;theta1&quot;, &quot;theta2&quot;, &quot;oddsratio&quot;), digits_summary = 3L ) #&gt; Inference for Stan model: twoprop1-202204281129-1-5c36f6. #&gt; 4 chains, each with iter=6000; warmup=2000; thin=1; #&gt; post-warmup draws per chain=4000, total post-warmup draws=16000. #&gt; #&gt; mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat #&gt; theta1 0.546 0.001 0.103 0.344 0.475 0.546 0.620 0.740 12795 1 #&gt; theta2 0.798 0.001 0.087 0.601 0.744 0.808 0.862 0.937 14193 1 #&gt; oddsratio 4.721 0.043 4.411 0.906 2.166 3.514 5.698 15.558 10400 1 #&gt; #&gt; Samples were drawn using NUTS(diag_e) at Gio Apr 28 11:29:57 2022. #&gt; For each parameter, n_eff is a crude measure of effective sample size, #&gt; and Rhat is the potential scale reduction factor on split chains (at #&gt; convergence, Rhat=1). L’intervallo di credibilità del 95% per l’OR include il valore di 1.0 (ovvero, il valore che indica che gli Odds di positività sono uguali nei due gruppi). In base agli standard correnti, un risultato di questo tipo non viene considerato come evidenza sufficiente per potere concludere che il parametro \\(\\theta\\) assume un valore diverso nei due gruppi. In conclusione, se consideriamo tutti i dati, e non solo quelli selezionati da Gautret et al. (2020), non vi sono evidenze sull’efficacia dell’idrossiclorochina come terapia per i casi di Covid-19. Commenti e considerazioni finali Ciò che è stato presentato in questo capitolo è un esercizio didattico: la ricerca di Gautret et al. (2020) include altre informazioni e altre analisi statistiche che non sono state qui considerate. Tuttavia, notiamo che la semplice analisi statistica che abbiamo qui descritto è stata in grado di replicare le conclusioni a cui sono giunti (per altra via) Hulme et al. (2020). References "],["ch-diagn-markov-chains.html", "Capitolo 20 Diagnostica delle catene markoviane 20.1 Esame dei trace plot 20.2 Confronto delle catene parallele 20.3 Numerosità campionaria effettiva 20.4 Autocorrelazione 20.5 Statistica \\(\\hat{R}\\) 20.6 Diagnostica di convergenza di Geweke", " Capitolo 20 Diagnostica delle catene markoviane Come discusso nel Paragrafo 19.3, le catene di Markov forniscono un’approssimazione che tende a convergere alla distribuzione a posteriori. “Approssimazione” e “convergenza” sono le parole chiave qui: il punto è che il campionamento MCMC non è perfetto. Questo solleva le seguenti domande: A cosa corrisponde, dal punto di vista grafico, una “buona” catena di Markov? Come possiamo sapere se il campione prodotto dalla catena di Markov costituisce un’approssimazione adeguata della distribuzione a posteriori? Quanto deve essere grande la dimensione del campione casuale prodotto dalla catena Markov? Rispondere a queste ed altre domande di questo tipo fa parte di quell’insieme di pratiche che vano sotto il nome di diagnostica delle catene Markoviane. La diagnostica delle catene Markoviane non è “una scienza esatta”. Ovvero, non sono disponibili procedure che risultano valide in tutti i casi possibili e non sempre siamo in grado di rispondere a tutte le domande precedenti. È piuttosto l’esperienza del ricercatore che consente di riconoscere una “buona” catena di Markov e a suggerire cosa si può fare per riparare una “cattiva” catena di Markov. In questo Capitolo ci concentreremo su alcuni strumenti diagnostici grafici e numerici che possono essere utilizzati per la diagnostica delle catene markoviane. L’utilizzo di questi strumenti diagnostici deve essere eseguito in modo olistico. Nessuna singola diagnostica visiva o numerica è sufficiente: un quadro completo della qualità della catena di Markov si può solo ottenere considerando tutti gli strumenti descritti di seguito. 20.1 Esame dei trace plot La convergenza e il “mixing” possono essere controllate mediante il trace plot che mostra l’andamento delle simulazioni e ci dice se stiamo effettivamente utilizzando una distribuzione limite. Consideriamo nuovamente il trace plot del simulazione Beta-Binomiale della figura 20.1: FIGURA 20.1: Trace plot per il modello Beta-Binomiale dei dati di Gautret et al.(2020). La figura 20.1 fornisce un esempio perfetto di come dovrebbero apparire i trace plot. Quando le catene markoviane raggiungono uno stato stazionario e sono stabili ciò significa che hanno raggiunto la distribuzione stazionaria e il trace plot rivela un’assenza di struttura e diventa simile alla rappresentazione del rumore bianco, come nella figura 20.1. Una mancanza di convergenza è invece indicata dalla figura 20.226. FIGURA 20.2: Trace plots (a sinistra) e corrispondenti grafici di densità (a destra) di due ipotetiche catene di Markov. Queste figure forniscono due esempi di come potrebbero apparire delle catene di Markov non stazionarie. Le linee nere sovrapposte alle densità empiriche (a destra) rappresentano una ipotetica distribuzione target Beta(11,3). Nel trace-plot della figura 20.2, la tendenza verso il basso indica che la catena A non è stazionaria, ovvero non si mantiene costante all’evolversi nel tempo. La tendenza verso il basso suggerisce inoltre la presenza di una forte correlazione tra i valori della catena: il trace-plot non fornisce una rappresentazione di rumore indipendente. Tutto questo significa che la catena A “si sta mescolando lentamente”. Sebbene le catene di Markov siano intrinsecamente dipendenti, più si comportano come se fossero dei campioni casuali (rumorosi), minore è l’errore dell’approssimazione alla distribuzione a posteriori. La catena B presenta un problema diverso. Come evidenziato dalle due linee completamente piatte nel tracciato, essa tende a bloccarsi quando visita valori bassi di \\(\\theta\\). Gli istogrammi lisciati della figura 20.2 (a destra) confermano che entrambe queste catene sono problematiche: infatti producono approssimazioni scadenti della distribuzione a posteriori che, nell’esempio di Johnson, Ott, and Dogucu (2022), è una \\(\\mbox{Beta}(11, 3)\\) (la curva nera nella figura). Consideriamo la catena A. Dal momento che si sta mescolando lentamente, nelle iterazioni eseguite ha esplorato unicamente i valori \\(\\theta\\) nell’intervallo da 0.6 a 0.9. Di conseguenza, la sua approssimazione della distribuzione a posteriori sopravvaluta la plausibilità dei valori \\(\\theta\\) in questo intervallo e, nel contempo, sottovaluta la plausibilità dei valori \\(\\theta\\) esterni a questo intervallo. Consideriamo ora la catena B. Rimanendo bloccata, la catena B campiona in maniera eccessiva alcuni valori nella coda sinistra della distribuzione a posteriori di \\(\\theta\\). Questo fenomeno produce i picchi che sono presenti nell’approssimazione alla distribuzione a posteriori. In pratica, al di là dei presenti esempi “scolastici” (in cui disponiamo di una formulazione analitica della distribuzione a posteriori), non abbiamo mai il privilegio di poter confrontare i risultati del campionamento MCMC con la corretta distribuzione a posteriori. Ecco perché la diagnostica delle catene di Markov è così importante: se vediamo trace-plots come quelli della figura 20.2, sappiamo che non abbiamo ottenuto una adeguata approssimazione della distribuzione a posteriori. In tali circostanze possiamo ricorrere ad alcuni rimedi. Controllare il modello. Siamo sicuri che le distribuzioni a priori e la verosimiglianza siano appropriate per i dati osservati? Utilizzare un numero maggiore di iterazioni. Alcune tendenze indesiderate a breve termine della catena possono appianarsi nel lungo termine. 20.2 Confronto delle catene parallele Nella simulazione cmdstanr() per il modello beta-binomiale dei dati di Gautret et al. (2020) abbiamo utilizzato quattro catene di Markov parallele. Non solo è necessario che ogni singola catena sia stazionaria (come discusso sopra), ma è anche necessario che le quattro catene siano coerenti tra loro. Sebbene le catene esplorino percorsi diversi nello spazio dei parametri, quando convergono ad uno stato di equilibrio dovrebbero presentare caratteristiche simili e dovrebbero produrre approssimazioni simili alla distribuzione a posteriori. Per il caso beta-binomiale dei dati di Gautret et al. (2020), gli istogrammi lisciati della figura seguente indicano che le quattro catene producono approssimazioni della distribuzione a posteriori quasi indistinguibili tra loro. Ciò prova che la simulazione è stabile e contiene un nunero sufficiente di valori: l’esecuzione delle catene per un numero maggiore di iterazioni non porterebbe ad un miglioramento della stima della distribuzione a posteriori. mcmc_dens_overlay(stanfit1, pars = &quot;theta&quot;) + ylab(&quot;density&quot;) Per fare un confronto, per lo stesso modello, consideriamo la simulazione di una catena di Markov più corta. La chiamata seguente richiede quattro catene parallele per sole 100 iterazioni ciascuna: bb_short &lt;- mod$sample( data = data1_list, iter_sampling = 50*2L, seed = 84735, chains = 4L, parallel_chains = 4L, refresh = 0, thin = 1 ) FALSE Running MCMC with 4 parallel chains... FALSE FALSE Chain 1 finished in 0.0 seconds. FALSE Chain 2 finished in 0.0 seconds. FALSE Chain 3 finished in 0.0 seconds. FALSE Chain 4 finished in 0.0 seconds. FALSE FALSE All 4 chains finished successfully. FALSE Mean chain execution time: 0.0 seconds. FALSE Total execution time: 0.2 seconds. stanfit_bb_short &lt;- rstan::read_stan_csv(bb_short$output_files()) Di seguito sono riportati i trace-plot e i corrispondenti istogrammi lisciati. mcmc_trace(stanfit_bb_short, pars = &quot;theta&quot;) mcmc_dens_overlay(stanfit_bb_short, pars = &quot;theta&quot;) Anche se i trace plot sembrano tutti mostrare un andamento casuale, gli istogrammi lisciati sono piuttosto diversi tra loro e producono approssimazioni diverse della distribuzione a posteriori. Di fronte a tale instabilità è chiaro che sarebbe un errore interrompere la simulazione dopo solo 100 iterazioni. 20.3 Numerosità campionaria effettiva Nella simulazione del modello beta-binomiale per i dati di Gautret et al. (2020) abbiamo utilizzato quattro catene di Markov parallele che producono un totale di \\(N\\) = 16000 campioni dipendenti di \\(\\theta\\). Sapendo che l’errore dell’approssimazione alla distribuzione a posteriori è probabilmente più grande di quello che si otterrebbe usando 16000 campioni indipendenti, ci possiamo porre la seguente domanda: quanti campioni indipendenti sarebbero necessari per produrre un’approssimazione della distribuzione a posteriori equivalentemente a quella che abbiamo ottenuto? La numerosità campionaria effettiva (effective sample size, \\(N_{eff}\\)) fornisce una risposta a questa domanda. Tipicamente, \\(N_{eff} &lt; N\\), per cui il rapporto campionario effettivo (effective sample size ratio) \\(\\frac{N_{eff}}{N}\\) è minore di 1. Come regola euristica, viene considerato problematico un rapporto campionario effettivo minore del 10% del numero totale di campioni ottenuti nella simulazione (più basso è il rapporto campionario effettivo peggiore è il “mixing” della catena). La funzione bayesplot::neff_ratio() consente di calcolare il rapporto campionario effettivo. Per il modello Beta-Binomiale dei dati di Gautret et al. (2020), questo rapporto è di circa 0.34: bayesplot::neff_ratio(stanfit1, pars = c(&quot;theta&quot;)) #&gt; [1] 0.3629411 Ciò indica che l’accuratezza dell’approssimazione della distribuzione a posteriori di \\(\\theta\\) ottenuta mediante 16000 campioni dipendenti è approssimativamente simile a quella che si potrebbe ottenere con bayesplot::neff_ratio( stanfit1, pars = c(&quot;theta&quot;) ) * 16000 #&gt; [1] 5807.058 campioni indipendenti. In questo esempio, il rapporto campionario effettivo è maggiore di 0.1; dunque non ci sono problemi. 20.4 Autocorrelazione Normalmente un algoritmo MCMC genera catene di Markov di campioni, ognuno dei quali è autocorrelato a quelli generati immediatamente prima e dopo di lui. Conseguentemente campioni successivi non sono indipendenti ma formano una catena di Markov con un certo grado di correlazione. Il valore \\(\\theta^{(i)}\\) tende ad essere più simile al valore \\(\\theta^{(i-1)}\\) che al valore \\(\\theta^{(i-2)}\\), o al valore \\(\\theta^{(i-3)}\\), eccetera. Una misura di ciò è fornita dall’autocorrelazione tra i valori consecutivi della catena. Il correlogramma per ciascuna delle quattro catene dell’esempio si produce con la seguente chiamata: bayesplot::mcmc_acf(stanfit1, pars = &quot;theta&quot;) Il correlogramma mostra l’autocorrelazione in funzione di ritardi da 0 a 20. L’autocorrelazione di lag 0 è naturalmente 1 – misura la correlazione tra un valore della catena di Markov e se stesso. L’autocorrelazione di lag 1 è di circa 0.5, indicando una correlazione moderata tra i valori della catena che distano di solo 1 passo l’uno dall’altro. Successivamente, l’autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per un lag di 5. Questo risultato fornisce una conferma del fatto che la catena di Markov costituisce una buona approssimazione di un campione casuale di \\(p(\\theta \\mid y)\\). Al contrario, nella figura 20.3 (a destra) (riprodotta da Johnson, Ott, and Dogucu 2022) vediamo un esempio nel quale il trace plot rivela una forte tendenza tra i valori di una catena di Markov e, dunque, una forte autocorrelazione. FIGURA 20.3: Trace plot (a sinistra) e correlogramma (a destra) di una catena di Markow in cui il mixing è lento – figura riprodotta da Johnson, Ott, and Dogucu (2022). Questa osservazione è confermata nell’correlogramma (a destra). La lenta diminuzione della curva di autocorrelazione indica che la dipendenza tra i valori della catena non svanisce rapidamente. Con un lag di 20 la correlazione è addirittura pari a 0.9. Poiché i valori della catena sono fortemente associati tra loro, il “mixing” è lento: la simulazione richiede un numero molto grande di iterazioni per esplorare adeguatamente l’intera gamma di valori della distribuzione a posteriori.27 In presenza di catene di Markov non rapidly mixing sono possibili due rimedi. Aumentare il numero di iterazioni. Anche una catena non rapidly mixing può produrre eventualmente una buona approssimazione della distribuzione a posteriori se il numero di iterazioni è sufficientemente grande. Thinning. Per esempio, se la catena di Markov è costituita da 16000 valori di \\(\\theta\\), potremmo decidere di conservare solo ogni secondo valore e ignorare gli altri valori: \\(\\{\\theta^{(2)}, \\theta^{(4)}, \\theta^{(6)}, \\dots, \\theta^{(16000)}\\}\\). Oppure, potremmo decidere di conservare ogni decimo valore: \\(\\{\\theta^{(10)}, \\theta^{(20)}, \\theta^{(30)}, \\dots, \\theta^{(16000)}\\}\\). Scartando i campioni intermedi, è possibile rimuovere le forti correlazioni che sono presenti nel caso di lag più piccoli. Vediamo ora come sia possibile estrarre i valodi di una catena dall’oggetto stanfit1. # valori delle 4 catene S &lt;- ggmcmc::ggs(stanfit1) head(S) #&gt; # A tibble: 6 × 4 #&gt; Iteration Chain Parameter value #&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 1 1 theta 0.628 #&gt; 2 2 1 theta 0.758 #&gt; 3 3 1 theta 0.719 #&gt; 4 4 1 theta 0.715 #&gt; 5 5 1 theta 0.856 #&gt; 6 6 1 theta 0.870 La prima catena può essere isolata nel modo seguente: S1 &lt;- S %&gt;% dplyr::filter( Chain == 1, Parameter == &quot;theta&quot; ) Una serie temporale della catena si ottiene con la funzione ggmcmc::ggs_running: ggmcmc::ggs_running(S1) Il grafico precedente mostra che, per il modello bayesiano che stiamo discutendo, una condizione di equilibrio della catena di Markov richiederebbe un numero maggiore di iterazioni di quelle che sono state effettivamente simulate. L’autocorrelazione di ordine 1 si ottiene nel modo seguente (si veda il Paragrafo 18.2.9.1): cor(S1$value[-length(S1$value)], S1$value[-1]) #&gt; [1] 0.3819515 Questo valore corrisponde a ciò che è riportato nel correlogramma mostrato sopra. 20.5 Statistica \\(\\hat{R}\\) In precedenza abbiamo detto che non solo è necessario che ogni singola catena sia stazionaria, è anche necessario che le diverse catene siano coerenti tra loro. La statistica \\(\\hat{R}\\) affronta questo problema calcolando il rapporto tra la varianza tra le catene markoviane e la varianza entro le catene. In una situazione ottimale \\(\\hat{R} = 1\\); se \\(\\hat{R}\\) è lontano da 1 questo vuol dire che non è ancora stata raggiunta la convergenza. È possibile calcolare \\(\\hat{R}\\) mediante la chiamata alla funzione bayesplot::rhat(). Per il modello Beta-Binomiale applicato ai dati di Gautret et al. (2020) abbiamo: bayesplot::rhat(stanfit1, pars = &quot;theta&quot;) #&gt; [1] 1.00039 il che indica che il valore \\(\\hat{R}\\) ottenuto è molto simile al valore ottimale. In maniera euristica, si può affermare che se \\(\\hat{R}\\) supera la soglia di 1.05 questo viene interpretato come evidenza che le diverse catene parallele non producono approssimazioni coerenti della distribuzione a posteriori, quindi la simulazione è instabile. Una rappresentazione grafica dei valori \\(\\hat{R}\\) per tutti i parametri del modello si ottiene con la seguente chiamata: ggmcmc::ggs_Rhat(S) + xlab(&quot;R_hat&quot;) + xlim(0.95, 1.05) 20.6 Diagnostica di convergenza di Geweke La statistica diagnostica di convergenza di Geweke è basata su un test per l’uguaglianza delle medie della prima e dell’ultima parte di una catena di Markov (di default il primo 10% e l’ultimo 50% della catena). Se i due campioni sono estratti dalla distribuzione stazionaria della catena, le due medie sono statisticamente uguali e la statistica di Geweke ha una distribuzione asintotica Normale standardizzata. Utilizzando l’oggetto stanfit1, possiamo recuperare la statistica di Geweke nel modo seguente: fit_mcmc &lt;- As.mcmc.list( stanfit1, pars = c(&quot;theta&quot;) ) coda::geweke.diag(fit_mcmc, frac1 = .1, frac2 = .5) #&gt; [[1]] #&gt; #&gt; Fraction in 1st window = 0.1 #&gt; Fraction in 2nd window = 0.5 #&gt; #&gt; theta #&gt; -0.017 #&gt; #&gt; #&gt; [[2]] #&gt; #&gt; Fraction in 1st window = 0.1 #&gt; Fraction in 2nd window = 0.5 #&gt; #&gt; theta #&gt; 0.6504 #&gt; #&gt; #&gt; [[3]] #&gt; #&gt; Fraction in 1st window = 0.1 #&gt; Fraction in 2nd window = 0.5 #&gt; #&gt; theta #&gt; -0.04024 #&gt; #&gt; #&gt; [[4]] #&gt; #&gt; Fraction in 1st window = 0.1 #&gt; Fraction in 2nd window = 0.5 #&gt; #&gt; theta #&gt; 1.315 Per interpretare questi valori ricordiamo che la statistica di Geweke è uguale a zero quando le medie delle due porzioni della catena di Markov sono uguali. Valori maggiori di \\(\\mid 2 \\mid\\) suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria. References "],["ch-sintesi-distr-post.html", "Capitolo 21 Sintesi a posteriori 21.1 Stima puntuale 21.2 Intervallo di credibilità 21.3 Un esempio concreto 21.4 La funzione di perdita attesa Commenti e considerazioni finali", " Capitolo 21 Sintesi a posteriori La distribuzione a posteriori è un modo per descrivere il nostro grado di incertezza rispetto al parametro incognito (o rispetto ai parametri incogniti) oggetto dell’inferenza. La distribuzione a posteriori contiene tutte le informazioni disponibili sui possibili valori del parametro. Se il parametro esaminato è monodimensionale (o bidimensionale) è possibile fornire un grafico di tutta la distribuzione a posteriori \\(p(\\theta \\mid y)\\). Tuttavia, spesso vogliamo anche giungere ad una sintesi numerica della distribuzione a posteriori, soprattutto se il vettore dei parametri ha più di due dimensioni. A a questo proposito è possibile utilizzare le consuete statistiche descrittive, come media, mediana, moda, varianza, deviazione standard e i quantili. In alcuni casi, queste statistiche descrittive sono più facili da presentare e interpretare rispetto alla rappresentazione grafica della distribuzione a posteriori. La stima puntuale della tendenza centrale della distribuzione a posteriori fornisce informazioni su quello che può essere considerato come il “valore più plausibile” del parametro. L’intervallo di credibilità fornisce invece un’indicazione dell’ampiezza dell’intervallo che contiene una determinata quota della massa della distribuzione a posteriori del parametro. 21.1 Stima puntuale Per sintetizzare la distribuzione a posteriori in modo da giungere ad una stima puntuale di \\(\\theta\\) si è soliti scegliere tra moda, mediana o media a seconda del tipo di distribuzione con cui si ha a che fare e della sua forma. Ogni stima puntuale ha una sua interpretazione. La media è il valore atteso a posteriori del parametro. La moda può essere interpretata come il singolo valore più credibile (“più plausibile”) del parametro, alla luce dei dati, ovvero il valore per il parametro \\(\\theta\\) che massimizza la distribuzione a posteriori. Per questa ragione la moda viene detta massimo a posteriori, MAP. Il limite della moda quale statistica riassuntiva della distribuzione a posteriori è che, talvolta, tale distribuzione è multimodale e il MAP non è necessariamente il valore “più credibile”. La mediana è il valore del parametro tale per cui, su entrambi i lati di essa, giace il 50% della massa di probabilità a posteriori. La misura di variabilità del parametro è la varianza a posteriori la quale, nel caso di una distribuzione a posteriori ottenuta per via numerica, si calcola con la formula della varianza che conosciamo rispetto alla tendenza centrale data dalla media a posteriori. La radice quadrata della varianza a posteriori è la deviazione standard a posteriori che descrive l’incertezza a posteriori circa il parametro di interesse nella stessa unità di misura dei dati. Le procedure bayesiane basate sui metodi MCMC utilizzano un numero finito di campioni dalla distribuzione stazionaria, e una tale caratteristica della simulazione introduce un ulteriore livello di incertezza nella stima del parametro. L’errore standard della stima (in inglese Monte Carlo standard error, MCSE) misura l’accuratezza della simulazione. La deviazione standard a posteriori e l’errore standard della stima sono due concetti completamente diversi. La deviazione standard a posteriori descrive l’incertezza circa il parametro (l’ampiezza della distribuzione a posteriori) ed è una funzione della dimensione del campione; il MCSE descrive invece l’incertezza nella stima del parametro dovuta alla simulazione MCMC ed è una funzione del numero di iterazioni nella simulazione. 21.2 Intervallo di credibilità Molto spesso la stima puntuale è accompagnata da una stima intervallare (abbiamo già incontrato questo aspetto nel Capitolo 16 discutendo lo schema beta-binomiale). Nella statistica bayesiana, se il parametro \\(\\theta \\in \\Theta\\) è monodimensionale, si dice intervallo di credibilità un intervallo di valori \\(I_{\\alpha}\\) che contiene la proporzione \\(1 - \\alpha\\) della massa di probabilità della funzione a posteriori: \\[\\begin{equation} p(\\Theta \\in I_{\\alpha} \\mid y) = 1 - \\alpha. \\tag{21.1} \\end{equation}\\] L’intervallo di credibilità ha lo scopo di esprimere il nostro grado di incertezza riguardo la stima del parametro. Se il parametro \\(\\theta\\) è multidimensionale, si parla invece di “regione di credibilità”. La condizione (21.1) non determina un unico intervallo di credibilità al \\((1 - \\alpha) \\cdot 100\\%\\). In realtà esiste un numero infinito di tali intervalli. Ciò significa che dobbiamo definire alcune condizioni aggiuntive per la scelta dell’intervallo di credibilità. Esaminiamo due delle condizioni aggiuntive più comuni. 21.2.1 Intervallo di credibilità a code uguali Un intervallo di credibilità a code uguali a livello \\(\\alpha\\) è un intervallo \\[ I_{\\alpha} = [q_{\\alpha/2}, 1 - q_{\\alpha/2}], \\] dove \\(q_z\\) è un quantile \\(z\\) della distribuzione a posteriori. Per esempio, l’intervallo di credibilità a code uguali al 95% è un intervallo \\[ I_{0.05} = [q_{0.025}, q_{0.975}] \\] che lascia il 2.5% della massa di densità a posteriori in ciascuna coda. 21.2.2 Intervallo di credibilità a densità a posteriori più alta Nell’intervallo di credibilità a code uguali alcuni valori del parametro che sono inclusi nell’intervallo possono avere una credibilità a posteriori più bassa rispetto a quelli esterni all’intervallo. L’intrevallo di credibilità a densità a posteriori più alta (in inglese High Posterior Density Interval, HPD) è invece costruito in modo tale da assicurare di includere nell’intervallo tutti i valori \\(\\theta\\) che sono a posteriori maggiormente credibili. Graficamente questo intervallo può essere ricavato tracciando una linea orizzontale sulla rappresentazione della distribuzione a posteriori e regolando l’altezza della linea in modo tale che l’area sottesa alla curva sia pari a \\(1 - \\alpha\\). Questo tipo di intervallo è il più stretto possibile, tra tutti i possibili intervalli di credibilità allo stesso livello di fiducia. Se la distribuzione a posteriori è simmetrica unimodale, l’intervallo di credibilità a densità a posteriori più alta corrisponde all’intervallo di credibilità a code uguali. 21.2.3 Interpretazione L’interpretazione dell’intervallo di credibilità è molto intuitiva: l’intervallo di credibilità è un intervallo di valori all’interno del quale cade il valore del parametro incognito con un particolare livello di probabilità soggettiva. Possiamo dire che, dopo aver visto i dati crediamo, con un determinato livello di probabilità soggettiva, che il valore del parametro (ad esempio, la dimensione dell’effetto di un trattamento) abbia un valore compreso all’interno dell’intervallo che è stato calcolato, laddove per probabilità soggettiva intendiamo “il grado di fiducia che lo sperimentatore ripone nel verificarsi di un evento”. Gli intervalli di credibilità si calcolano con un software. 21.3 Un esempio concreto Per fare un esempio pratico, consideriamo nuovamente i valori del BDI-II dei 30 soggetti clinici di Zetsche, Bürkner, and Renneberg (2019): suppressPackageStartupMessages(library(&quot;bayesrules&quot;)) df &lt;- tibble( y = c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22) ) Un valore BDI-II \\(\\geq 30\\) indica la presenza di un livello “grave” di depressione. Nel campione clinico di Zetsche, Bürkner, and Renneberg (2019), sum(df$y &gt; 29) #&gt; [1] 17 17 pazienti su 30 manifestano un livello grave di depressione. Supponiamo di volere stimare la distribuzione a posteriori della probabilità \\(\\theta\\) di depressione “grave” nei pazienti clinici, così come viene misurata dal test BDI-II, imponendo su \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(8, 2)\\). Sappiamo che il modello Beta-Binomiale può essere espresso nella forma seguente: \\[\\begin{align} Y | \\theta &amp; \\sim \\mbox{Bin}(30, \\theta) \\notag\\\\ \\theta &amp; \\sim \\mbox{Beta}(8, 2) \\notag \\end{align}\\] con una corrispondente distribuzione a posteriori \\(\\mbox{Beta}(25, 15)\\): \\[\\begin{equation} f(\\theta | y = 17) = \\frac{\\Gamma(25 + 15)}{\\Gamma(25)\\Gamma(15)}\\theta^{25-1} (1-\\theta)^{15-1} \\;\\; \\text{ for } \\theta \\in [0,1] \\; . \\tag{21.2} \\end{equation}\\] plot_beta_binomial(alpha = 8, beta = 2, y = 17, n = 30) 21.3.1 Stime puntuali della distribuzione a posteriori Una volta trovata l’intera distribuzione a posteriori, quale valore di sintesi è necessario riportare? Questa sembra una domanda innocente, ma in realtà è una domanda a cui è difficile rispondere. La stima bayesiana dei parametri è fornita dall’intera distribuzione a posteriori, che non è un singolo numero, ma una funzione che mappa ciascun valore del parametro ad un valore di plausibilità. Quindi non è necessario scegliere una stima puntuale. In linea di principio, una stima puntuale non è quasi mai necessaria ed è spesso dannosa in quanto comporta una perdita di informazioni. Tuttavia talvolta una tale sintesi è richiesta. Diverse risposte sono allora possibili. La media della distribuzione a posteriori per \\(\\theta\\) è \\[ \\mathbb{E}(\\pi \\mid y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25+15} = 0.625. \\] Una stima del massimo della probabilità a posteriori, o brevemente massimo a posteriori, MAP (da maximum a posteriori probability), è la moda della distribuzione a posteriori. Nel caso presente, una stima del MAP può essere ottenuta nel modo seguente: \\[ \\mbox{Mo}(\\pi \\mid y = 17) = \\frac{\\alpha-1}{\\alpha + \\beta-2} = \\frac{25-1}{25+15-2} = 0.6316. \\] Gli stessi risultati si ottiengono usando la chiamata a bayesrules::summarize_beta_binomial(): summarize_beta_binomial(alpha = 8, beta = 2, y = 17, n = 30) #&gt; model alpha beta mean mode var sd #&gt; 1 prior 8 2 0.800 0.8750000 0.014545455 0.1206045 #&gt; 2 posterior 25 15 0.625 0.6315789 0.005716463 0.0756073 La mediana si ottiene con qbeta(.5, shape1 = 25, shape2 = 15) #&gt; [1] 0.6271031 21.3.2 Intervallo di credibilità È più comune sintetizzare la distribuzione a posteriori mediante l’intervallo di credibilità. Per esempio, l’intervallo di credibilità a code uguali al 95% plot_beta_ci(alpha = 25, beta = 15, ci_level = 0.95) è dato dalla chiamata qbeta(c(0.025, 0.975), 25, 15) #&gt; [1] 0.4717951 0.7663607 Il calcolo precedente evidenzia l’interpretazione intuitiva dell’intervallo di credibilità. Tale intervallo, infatti, può essere interpretato come la probabilità che \\(\\theta\\) assuma valori compresi tra 0.472 e 0.766: \\[ P(\\theta \\in (0.472, 0.766) | Y = 17) = \\int_{0.472}^{0.766} f(\\theta \\mid y=17) d\\theta = 0.95, \\] ovvero postFun &lt;- function(theta) { gamma(25 + 15) / (gamma(25) * gamma(15)) * theta^24 * (1 - theta)^14 } integrate( postFun, lower = 0.4717951, upper = 0.7663607 )$value #&gt; [1] 0.95 Possiamo costruire diversi intervalli di credibilità a code equivalenti. Ad esempio, l’intervallo di credibilità compreso tra il 25-esimo e il 75-esimo percentile è qbeta(c(0.25, 0.75), 25, 15) #&gt; [1] 0.5743878 0.6778673 ovvero, abbiamo una certezza a posteriori del 50% che la probabilità di depressione grave tra i pazienti clinici sia un valore compreso tra 0.57 e 0.68. Non esiste un livello credibile “corretto”. I ricercatori, utilizzano vari livelli, ad esempio 50%, 80% o 95%, a seconda del contesto dell’analisi. Ciascuno di questi intervalli fornisce un’immagine diversa della nostra comprensione della distribuzione a posteriori del parametro di interesse. Non è inoltre necessario riportare l’intervallo di credibilità a code uguali. Se la distribuzione a posteriori è fortemente asimmetrica è più sensato riportare l’intervallo di credibilità a densità a posteriori più alta. L’intervallo HPD risulta più semplice da determinare quando la distribuzione a posteriori viene approssimata con il metodo MCMC. 21.3.3 Probabilità della distribuzione a posteriori Il test di ipotesi è un compito comune dell’analisi della distribuzione a posteriori (si veda anche il Capitolo 16). Supponiamo che si voglia conoscere la probabilità a posteriori che \\(\\theta\\) sia superiore a 0.5. Per sapere quanto credibile sia l’evento \\(\\theta &gt; 0.5\\) possiamo calcolare il seguente integrale: \\[ P(\\theta &gt; 0.5 \\; \\mid \\; y = 17) = \\int_{0.5}^{1}f(\\theta \\mid y=17)d\\theta \\;, \\] dove \\(f(\\cdot)\\) è la distribuzione \\(\\mbox{Beta}(25, 15)\\): pbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = FALSE) #&gt; [1] 0.9459355 il che è equivalente a: postFun &lt;- function(theta) { gamma(25 + 15) / (gamma(25) * gamma(15)) * theta^24 * (1 - theta)^14 } integrate( postFun, lower = 0.5, upper = 1 )$value #&gt; [1] 0.9459355 21.3.3.1 Fattore di Bayes È anche possibile formulare un test di ipotesi contrastando due ipotesi contrapposte. Per esempio, \\(H_1: \\theta \\geq 0.5\\) e \\(H_2: \\theta &lt; 0.5\\). Ciò consente di calcolare l’odds a posteriori di \\(\\theta &gt; 0.5\\): \\[\\begin{equation} \\text{poterior odds} = \\frac{H_1 \\mid y = 17}{H_2 \\mid y = 17} \\end{equation}\\] ovvero posterior_odds &lt;- pbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = FALSE) / pbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = TRUE) posterior_odds #&gt; [1] 17.49642 L’odds a posteriori rappresenta l’aggiornamento delle nostre credenze dopo avere osservato \\(y = 17\\) in \\(n = 30\\). L’odds a priori di \\(\\theta &gt; 0.5\\) era: prior_odds &lt;- pbeta(0.5, shape1 = 8, shape2 = 2, lower.tail = FALSE) / pbeta(0.5, shape1 = 8, shape2 = 2, lower.tail = TRUE) prior_odds #&gt; [1] 50.2 Il fattore di Bayes (Bayes Factor; BF) confronta gli odds a posteriori con gli odds a priori e quindi fornisce informazioni su quanto sia mutata la nostra comprensione relativa a \\(\\theta\\) dopo avere osservato i nostri dati del campione: \\[ \\text{BF} = \\frac{\\text{odds a posteriori}}{\\text{odds a priori}}. \\] Nel caso presente abbiamo BF &lt;- posterior_odds / prior_odds BF #&gt; [1] 0.3485343 Quindi, dopo avere osservato i dati, gli odds a posteriori della nostra ipotesi a proposito di \\(\\theta\\) sono pari a solo il 34% degli odds a priori. Per fare un altro esempio, consideriamo il caso in cui le credenze a priori rivelano una credenza diametralmente opposta rispetto a \\(\\theta\\) rispetto al caso considerato in precedenza (in precedenza avevamo \\(\\mbox{Beta}(8, 2)\\) mentre ora imponiamo su \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(2, 8)\\)). Con una tale scelta della distribuzione a priori, la distribuzione a posteriori diventa una \\(\\mbox{Beta}(19, 21)\\). summarize_beta_binomial(alpha = 2, beta = 8, y = 17, n = 30) #&gt; model alpha beta mean mode var sd #&gt; 1 prior 2 8 0.200 0.1250000 0.014545455 0.12060454 #&gt; 2 posterior 19 21 0.475 0.4736842 0.006082317 0.07798921 Con questa diversa distribuzione a priori, il BF è uguale a posterior_odds &lt;- pbeta(0.5, shape1 = 19, shape2 = 21, lower.tail = FALSE) / pbeta(0.5, shape1 = 19, shape2 = 21, lower.tail = TRUE) prior_odds &lt;- pbeta(0.5, shape1 = 2, shape2 = 8, lower.tail = FALSE) / pbeta(0.5, shape1 = 2, shape2 = 8, lower.tail = TRUE) BF &lt;- posterior_odds / prior_odds BF #&gt; [1] 30.07239 In alre parole, in questo secondo esempio gli odds a posteriori della nostra ipotesi a proposito di \\(\\theta\\) sono aumentati di 30 volte rispetto agli odds a priori. In generale, in un test di ipotesi che contrappone un’ipotesi sostantiva \\(H_a\\) ad un’ipotesi nulla \\(H_0\\) il BF è un rapporto di odds per l’ipotesi sostantiva: \\[ \\text{Bayes Factor} = \\frac{\\text{posterior odds}}{\\text{prior odds}} = \\frac{P(H_a \\mid Y) / P(H_0 \\mid Y)}{P(H_a) / P(H_0)} \\; . \\] 21.3.3.2 Interpretazione del fattore di Bayes Essendo un rapporto, il BF deve essere valutato rispetto al valore di 1. Ci sono tre possibilità: BF = 1: La credibilità di \\(H_a\\) non è cambiata dopo avere osservato i dati. BF &gt; 1: La credibilità di \\(H_a\\) è aumentata dopo avere osservato i dati. Quindi maggiore è BF, più convincente risulta l’evidenza per \\(H_a\\). BF &lt; 1: La credibilità di \\(H_a\\) è diminuita dopo avere osservato i dati. Non ci sono delle soglie universalmente riconosciute per interpretare il BF, ma uno schema popolare, proposto da Lee and Wagenmakers (2014), è il seguente: BF Interpretation &gt; 100 Extreme evidence for \\(H_a\\) 30 - 100 Very strong evidence for \\(H_a\\) 10 - 30 Strong evidence for \\(H_a\\) 3 - 10 Moderate evidence for \\(H_a\\) 1 - 3 Anecdotal evidence for \\(H_a\\) 1 No evidence 1/3 - 1 Anecdotal evidence for \\(H_0\\) 1/10 - 1/3 Moderate evidence for \\(H_0\\) 1/30 - 1/10 Strong evidence for \\(H_0\\) 1/100 - 1/30 Very strong evidence for \\(H_0\\) &lt; 1/100 Extreme evidence for \\(H_0\\) 21.3.3.3 Limiti del fattore di Bayes È importante notare che l’opinione maggiormente diffusa nella comunità scientifica incoraggia a non trarre conclusioni rigide dai dati utilizzando dei criteri fissati una volta per tutte. È stato ripetuto molte volte che l’esame di tutta la distribuzione a posteriori fornisce una misura olistica del nostro livello di incertezza riguardo all’affermazione (il parametro, ovvero l’ipotesi) che viene valutata e, dunque, è molto più informativo di una decisione binaria. Non è dunque possibile stabilire una soglia univoca per il BF che consenta di classificare le ipotesi dei ricercatori in una delle due categorie “vero” o “falso”. Invece, è più utile adottare una pratica interpretativa più flessibile in grado di tenere in considerazione il contesto e le potenziali implicazioni di ogni singolo test di ipotesi. La discussione precedente mette inoltre in evidenza come il BF dipenda fortemente dalle caratteristiche della distribuzione a priori. Dato che la la distribuzione a priori è una scelta arbitraria del ricercatore, da ciò consegue che il BF contiene una componente intrinseca di arbitrarietà. Questo aspetto, tuttavia, è incompatibile con l’idea di un confronto con delle soglie “assolute”. 21.4 La funzione di perdita attesa Il modo più razionale per giungere ad una decisione statistica utilizzando l’intera distribuzione a posteriori è quello di usare la funzione di perdita (loss function). La funzione di perdita è un concetto nella teoria delle decisioni statistiche e consente di quantificare il costo che deriva dalla decisione di scegliere il valore \\(\\theta_0\\) quale stima del parametro, quando in realtà il parametro ha il valore \\(\\theta\\). Per chiarire che cosa si intende per funzione di perdita, esaminiamo qui un semplice esempio nel quale vengono considerati due soli valori di probabilità per l’evento target, anziché l’intera distribuzione a posteriori (il codice è ricavato da Schmettow 2021). Si consideri la scelta di prendere o meno l’ombrello nell’uscire di casa. Le previsioni del tempo sono le seguenti: Risultato &lt;- tibble( risultato = c(&quot;piove&quot;, &quot;non piove&quot;), prob = c(0.6, 0.4) ) Risultato #&gt; # A tibble: 2 × 2 #&gt; risultato prob #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 piove 0.6 #&gt; 2 non piove 0.4 Le azioni possibili sono: prendo / non prendo l’ombrello: Azione &lt;- tibble(azione = c(&quot;prendo l&#39;ombrello&quot;, &quot;non prendo l&#39;ombrello&quot;)) Azione #&gt; # A tibble: 2 × 1 #&gt; azione #&gt; &lt;chr&gt; #&gt; 1 prendo l&#39;ombrello #&gt; 2 non prendo l&#39;ombrello Assegniamo un costo massimo (4) alla conseguenza peggiore (“non prendo l’ombrello e piove”) e uno minimo (0) alla conseguenza migliore (“non prendo l’ombrello e non piove”): Costi &lt;- expand.grid( azione = Azione$azione, risultato = Risultato$risultato ) %&gt;% inner_join(Risultato) %&gt;% mutate(costo = c(2, 4, 2, 0)) Costi #&gt; azione risultato prob costo #&gt; 1 prendo l&#39;ombrello piove 0.6 2 #&gt; 2 non prendo l&#39;ombrello piove 0.6 4 #&gt; 3 prendo l&#39;ombrello non piove 0.4 2 #&gt; 4 non prendo l&#39;ombrello non piove 0.4 0 Calcoliamo ora il costo atteso delle due azioni tenuto conto delle probabilità che si verifichi l’uno o l’altro stato del mondo (ricordiamo che piove/non piove hanno una probabilità rispettivamente del 40% e del 60%). In altre parole ponderiamo il costo di ogni azione con la probabilità che si verifichi l’evento corrispondente: Util &lt;- Costi %&gt;% mutate(costo_condizionato = prob * costo) %&gt;% group_by(azione) %&gt;% summarise(costo_atteso = sum(costo_condizionato)) Util #&gt; # A tibble: 2 × 2 #&gt; azione costo_atteso #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 prendo l&#39;ombrello 2 #&gt; 2 non prendo l&#39;ombrello 2.4 La regola della minimizzazione dei costi ci porta a scegliere l’alternativa che comporta il costo minore: nel nostro esempio, questo corrisponde all’azione “prendere l’ombrello”. La stessa logica dell’esempio qui discusso può essere usata anche quando, anziché avere solo due valori per la probabilità dello stato del mondo (per esempio, pioverà / non pioverà), utilizziamo l’intera distribuzione a posteriori (per esempio, quella relativa alla previsione di pioggia). Concludiamo questi brevi accenni relativi alla funzione di perdita con una considerazione di McElreath (2020) il quale nota che, anche se gli statistici e i teorici dei giochi sono da tempo interessati alle funzioni di perdita e alle relazioni che intercorrono tra esse e l’inferenza bayesiana, i ricercatori non le usano quasi mai in modo esplicito. Commenti e considerazioni finali Questo capitolo introduce le procedure di base per la manipolazione della distribuzione a posteriori. Lo strumento fondamentale che è stato utilizzato è quello fornito dai campioni di valori del parametro che vengono estratti dalla distribuzione a posteriori. Lavorare con campioni di valori del parametro estratti dalla distribuzione a posteriori trasforma un problema di calcolo integrale in un problema di riepilogo dei dati. Abbiamo visto le procedure maggiormente usate che consentono di utilizzare i campioni a posteriori per produrre indici di sintesi della distribuzione a posteriori: gli intervalli di credibilità e le stime puntuali. References "],["ch-prediction.html", "Capitolo 22 La predizione bayesiana 22.1 La distribuzione predittiva a posteriori 22.2 Soluzione analitica 22.3 La distribuzione predittiva a posteriori mediante simulazione 22.4 La distribuzione predittiva a posteriori mediante MCMC 22.5 I metodi per la valutazione del modello 22.6 Distribuzione predittiva a priori Commenti e considerazioni finali", " Capitolo 22 La predizione bayesiana Oltre ad una sintesi della distribuzione a posteriori attraverso il computo di indici caratteristici e alla verifica di ipotesi, un altro compito dell’analisi bayesiana è la predizione di nuovi dati futuri. Dopo aver osservato i dati di un campione e dopo avere ricavato le distribuzioni a posteriori dei parametri, è infatti possibile ottenere delle indicazioni sulle proprietà di dati futuri. L’uso più immediato della stima della distribuzione dei possibili valori futuri della variabile di esito è la verifica del modello in esame. Infatti, il modo più diretto per testare un modello è quello di utilizzare il modello corrente per fare previsioni sui possibili dati futuri per poi confrontare i dati predetti con i dati che sono stati effettivamente osservati nel campione corrente. Questa pratica va sotto il nome di controllo predittivo a posteriori. In questo capitolo ci focalizzeremo sul problema della predizione bayesiana esaminando il caso più semplice, ovvero lo schema beta-binomiale. In seguito estenderemo questa discussione al caso generale. 22.1 La distribuzione predittiva a posteriori Una volta costruita la distribuzione a posteriori del parametro o dei parametri sconosciuti, potremmo essere interessati a utilizzare il modello bayesiano allo scopo di prevedere la probabilità di risultati futuri basandoci sui dati già osservati. Questo tipo di analisi inferenziale va sotto il nome di analisi predittiva. L’esempio che considereremo qui nei dettagli riguarda il caso beta-binomiale, nel quale la distribuzione a priori per il parametro ignoto \\(\\theta\\) (ovvero, la probabilità di successo) è una distribuzione Beta, la verosimiglianza è binomiale e i dati sono costituiti dal numero \\(y\\) di successi in \\(n\\) prove Bernoulliane indipendenti. Nell’esempio che discuteremo useremo un’altra volta i dati del campione di pazienti clinici depressi di Zetsche, Bürkner, and Renneberg (2019). Supponendo di volere esaminare in futuro altri \\(m\\) pazienti clinici, ci chiediamo: quanti di essi manifesteranno una depressione grave? Siamo dunque interessati a predire i risultati che si potrebbero osservare in nuovi campioni di \\(m = 30\\) osservazioni. Denotiamo con \\(\\tilde{y}\\) la manifestazione della variabile casuale \\(\\tilde{Y}\\). In un nuovo campione di \\(m\\) osservazioni, \\(\\tilde{y}\\) assumerà il valore \\(\\tilde{y}_1\\) (ad es., 12), in un altro campione assumerà il valore \\(\\tilde{y}_2\\) (ad es., 23), e così via. Siamo interessati a descrivere la probabilità che \\(\\tilde{y}\\) assuma i valori \\(0, 1, 2, \\dots, 29, 30\\). Tale distribuzione (in questo caso) di massa di probabilità si chiama distribuzione predittiva a posteriori \\(p(\\tilde{Y} = \\tilde{y} \\mid Y = y)\\) e corrisponde alla probabilità assegnata a ciascuno dei possibili valori \\(\\tilde{y}\\) (\\(0, 1, 2, \\dots, 29, 30\\)) nei possibili campioni futuri di \\(m\\) osservazioni. In questo Capitolo ci porremo il problema di trovare la distribuzione predittiva a posteriori nel caso beta-binomiale. Useremo tre metodi diversi: la soluzione analitica, i risultati di una simulazione, il campionamento MCMC. I tre metodi producono risultati equivalenti. In seguito useremo il metodo MCMC perché ci consente di trovare facilmente la risposta cercata, anche quando una soluzione analitica non è disponibile. 22.2 Soluzione analitica Nel caso dell’esempio in discussione, la distribuzione di \\(\\tilde{Y}\\) dipende da \\(\\theta\\) e ciò che sappiamo di \\(\\theta\\) è sintetizzato nella distribuzione a posteriori \\(p(\\theta \\mid y)\\). Usando la regola della catena, possiamo scrivere la distribuzione congiunta di \\(\\tilde{y}\\) e \\(\\theta\\) nel modo seguente \\[\\begin{equation} p(\\tilde{y}, \\theta \\mid y) = p(\\tilde{y} \\mid \\theta, y) p(\\theta \\mid y). \\end{equation}\\] Assumendo che le osservazioni future \\(\\tilde{y}\\) e passate \\(y\\) siano condizionalmente indipendenti dato \\(\\theta\\), l’espressione precedente può essere scritta come \\[\\begin{equation} p(\\tilde{y}, \\theta \\mid y) = p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y). \\end{equation}\\] La distribuzione predittiva a posteriori viene ottenuta dalla distribuzione congiunta di \\(\\tilde{y}\\) e \\(\\theta\\) integrando rispetto a \\(\\theta\\): \\[\\begin{equation} p(\\tilde{y} \\mid y) = \\int_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta. \\tag{14.6} \\end{equation}\\] Nel caso dello schema beta-binomiale, la funzione \\(p(\\tilde{y} \\mid \\theta)\\) è binomiale di parametri \\(m\\) e \\(\\theta\\), e la distribuzione a posteriori \\(p(\\theta \\mid y)\\) è una \\(\\mbox{Beta}(\\alpha + y, \\beta + n - y)\\). Risolvendo l’integrale otteniamo: \\[\\begin{align} p(\\tilde{y} \\mid y) &amp;= \\int_0^1 p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y)\\,\\operatorname {d}\\!\\theta \\notag\\\\ &amp;= \\int_0^1 \\begin{pmatrix}m\\\\\\tilde{y}\\end{pmatrix} \\theta^{\\tilde{y}} (1-\\theta)^{m-\\tilde{y}} \\, \\mbox{Beta}(a+y,b+n-y) \\, d\\theta \\notag\\\\ &amp;= \\begin{pmatrix}{m}\\\\\\tilde{y}\\end{pmatrix} \\int_0^1 \\theta^{\\tilde{y}} (1-\\theta)^{m-\\tilde{y}} \\frac{1}{B(a+y, b+n-y)}\\theta^{a+y-1}(1-\\theta)^{b+n-y-1}\\notag\\\\ &amp;= \\begin{pmatrix}{ m }\\\\\\tilde{y}\\end{pmatrix} \\frac{1}{B(a+y, b+n-y)}\\int_0^1 \\theta^{\\tilde{y}+a+y-1}(1-\\theta)^{m-\\tilde{y}+b+n-y-1}\\notag\\\\ &amp;= \\begin{pmatrix}{ m }\\\\\\tilde{y}\\end{pmatrix} \\frac{B(\\tilde{y}+a+y,b+n-y+m-\\tilde{y})}{B(a+y, b+n-y)} \\; . \\tag{22.1} \\end{align}\\] In conclusione, per lo schema beta-binomiale, la distribuzione predittiva a posteriori è \\[\\begin{equation} f(\\tilde{y} \\mid y) = \\binom{m}{\\tilde{y}} \\frac{B(a+ y + \\tilde{y}, b + n - y + m - \\tilde{y})}{B(a+y, b+n-y)}, \\tag{22.2} \\end{equation}\\] ovvero, corrisponde ad una distribuzione di probabilità discreta chiamata distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha+y\\) e \\(\\beta+n-y\\). Nell’esempio relativo allo studio di Zetsche, Bürkner, and Renneberg (2019), la verosimiglianza è binomiale, i dati sono costituiti da 23 successi su 30 prove e la distribuzione a priori su \\(\\theta\\) è \\(\\mbox{Beta}(2, 10)\\). Di conseguenza, la distribuzione a posteriori è \\(\\mbox{Beta}(25, 17)\\). Vogliamo calcolare la distribuzione predittiva a posteriori per un nuovo campione, poniamo, di \\(m = 30\\) osservazioni (ma, in generale, \\(m\\) può essere diverso da \\(n\\)). In base alla (22.2) sappiamo che la distribuzione predittiva a posteriori è una distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha+y\\) e \\(\\beta+n-y\\), dove \\(m\\) è il numero di prove nel nuovo campione, \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione a priori, e \\(y\\) e \\(n\\) sono le proprietà del campione corrente. Nel caso dell’esempio in discussione, \\(m = 30\\), \\(\\alpha = 2 + 23 = 25\\), \\(\\beta = 10 + 30 - 23 = 17\\). Possiamo svolgere i calcoli necessario usando le funzioni del pacchetto extraDistr. Per i parametri specificati sopra, un grafico della distribuzione predittiva a posteriori si ottiene nel modo seguente: prob &lt;- extraDistr::dbbinom(0:30, 30, 25, 17) tibble(Y=0:30, Probability = prob) %&gt;% ProbBayes::prob_plot(Color = &quot;black&quot;) La distribuzione predittiva a posteriori illustrata nella figura precedente ci dice qual è la plausibilità relativa di osservare \\(0, 1, \\dots, 30\\) successi su \\(m = 30\\) prove in un futuro campione di osservazioni, alla luce dei dati che abbiamo osservato nel campione corrente (23 successi in 30 prove) e tenuto conto delle nostre opinioni a priori sulla plausibilità dei possibili valori \\(\\theta\\) (ovvero, \\(\\mbox{Beta}(2, 10)\\)). Esaminando la distribuzione predittiva notiamo che, nei possibili campioni futuri di 30 osservazioni, il valore \\(\\tilde{y}\\) più plausibile è 18. Tuttavia, \\(\\tilde{y}\\) può assumere anche altri valori e la distribuzione predittiva ci informa sulla plausibilità relativa di ciascuno dei possibili valori futuri \\(\\tilde{y}\\) – nel presente esempio, \\(\\tilde{y}\\) corrisponde al numero di pazienti clinici (su 30) che manifesteranno una depressione grave. È desiderabile costruire un intervallo che contiene le realizzazioni \\(\\tilde{y}\\) ad un livello specificato di probabilità. Supponiamo che il livello di probabilità richiesto sia 0.89. L’intervallo si costruisce aggiungendo valori \\(\\tilde{y}\\) all’intervallo (partendo da quello con la probabilità maggiore) fino a che il contenuto di probabilità dell’insieme eccede la soglia richiesta, nel caso present di 0.89. La procedura è implementata nella funzione discint() del pacchetto LearnBayes. Per i dati dell’esempio otteniamo LearnBayes::discint(cbind(0:30, prob), 0.89) #&gt; $prob #&gt; [1] 0.9152885 #&gt; #&gt; $set #&gt; [1] 12 13 14 15 16 17 18 19 20 21 22 23 Sulla base delle informazioni disponibili, possiamo dunque prevedere, con un livello di certezza soggettiva che eccede la soglia di 0.91, che in un futuro campione di 30 soggetti clinici depressi, il numero di pazienti con depressione grave sarà compreso tra 12 e 23. \\[ P(12 \\leq \\tilde{y} \\leq 23) = 0.9145. \\] In conclusione, per il caso beta-binomiale, possiamo dire che la predizione bayesiana di una nuova osservazione futura è la realizzazione di una distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha + y\\), e \\(\\beta + n - y\\), dove \\(m\\) è il numero di prove nel nuovo campione, \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione a priori, e \\(y\\) e \\(n\\) sono le caratteristiche del campione. 22.3 La distribuzione predittiva a posteriori mediante simulazione In situazioni dove è difficile derivare l’esatta distribuzione predittiva a posteriori è possibile ottenere un campione casuale di valori della distribuzione predittiva posteriori mediante simulazione. Facciamo un esempio riferito al caso che stiamo discutendo. È possibile svolgere la simulazione richiesta in due fasi. Supponiamo di volere ottenere un campione casuale di \\(n\\) osservazioni dalla distribuzione predittiva a posteriori. A tal fine dobbiamo (1) estrarre \\(n\\) valori a caso del parametro \\(\\theta\\) dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\): (2) con tali valori del parametro \\(\\theta\\) generiamo \\(n\\) valori casuali \\(\\tilde{y}\\); a tal fine usiamo il modello binomiale di parametri \\(m\\) e \\(\\theta_i\\) (con \\(i = 1, \\dots, n\\)). Otteniamo così \\(n\\) realizzazioni casuali di \\(n\\) distribuzioni binomiali aventi i parametri specificati sopra. Vediamo come si fa in pratica con \\(\\mathsf{R}\\). Per l’esempio che stiamo discutendo, la distribuzione a posteriori è una \\(\\mbox{Beta}(25, 17)\\). Estraiamo 100,000 valori a caso da tale distribuzione: set.seed(12345) nrep &lt;- 1e5 a &lt;- 2 b &lt;- 10 n &lt;- 30 y &lt;- 23 pred_p_sim &lt;- rbeta(nrep, a + y, b + n - y) I primi 10 valori così ottenuti sono pred_p_sim[1:10] #&gt; [1] 0.5435206 0.5319551 0.6045577 0.6337146 0.7552324 0.5393935 0.6187069 #&gt; [8] 0.6193819 0.6736216 0.6051480 Per ciascuno di tali valori \\(\\theta_i\\), con \\(i = 1, \\dots, 100,000\\), estraiamo a caso un valore dalla distribuzione binomiale di parametri \\(n = 30\\) e \\(\\theta_i\\). pred_y_sim &lt;- rep(NA, nrep) for (i in 1:nrep) { pred_y_sim[i] &lt;- rbinom(1, 30, pred_p_sim[i]) } # In maniera equivalente posso fare: # pred_y_sim &lt;- rbinom(1e5, n, pred_p_sim) Calcolo la proporzione di volte in cui sono stati osservai i valori \\(\\tilde{y} = 0, 1, \\dots, 30\\). ppd &lt;- table(pred_y_sim) / nrep ppd #&gt; pred_y_sim #&gt; 3 4 5 6 7 8 9 10 11 12 #&gt; 0.00002 0.00004 0.00011 0.00036 0.00096 0.00241 0.00533 0.01000 0.01753 0.02882 #&gt; 13 14 15 16 17 18 19 20 21 22 #&gt; 0.04290 0.06110 0.07812 0.09476 0.10763 0.11311 0.10821 0.09765 0.07982 0.06185 #&gt; 23 24 25 26 27 28 29 30 #&gt; 0.04156 0.02536 0.01299 0.00630 0.00224 0.00064 0.00016 0.00002 Calcolo l’intervallo di valori \\(\\tilde{y}\\) a cui è associata una probabilità di 0.89 (per fare un confronto con il risultato ottenuto in precedenza). LearnBayes::discint(cbind(3:30, ppd), 0.89) #&gt; $prob #&gt; 12 #&gt; 0.91553 #&gt; #&gt; $set #&gt; 12 13 14 15 16 17 18 19 20 21 22 23 #&gt; 12 13 14 15 16 17 18 19 20 21 22 23 # i risultati minori di 3 non sono stati calcolati Confronto i risultati della simulazione con i valori esatti della distribuzione predittiva a posteriori. Di seguito riporto i risultati esatti. prob30 &lt;- extraDistr::dbbinom(0:30, 30, 25, 17) LearnBayes::discint(cbind(0:30, prob30), 0.89) #&gt; $prob #&gt; [1] 0.9152885 #&gt; #&gt; $set #&gt; [1] 12 13 14 15 16 17 18 19 20 21 22 23 Un grafico con la distribuzione predittiva a posteriori esatta è fornito nella figura seguente. tibble(Y=0:30, Probability = prob30) %&gt;% ProbBayes::prob_plot(Color = &quot;black&quot;) Una rappresentazione della distribuzione a posteriori ottenuta mediante simulazione è il seguente. tibble(Y=0:30, Probability = c(0, 0, 0, ppd)) %&gt;% ProbBayes::prob_plot(Color = &quot;black&quot;) Si noti che i risultati della simulazione sono indistinguibili dalla soluzione esatta. 22.4 La distribuzione predittiva a posteriori mediante MCMC Il metodo basato su simulazione che abbiamo discusso sopra è proprio il metodo che viene utilizzato dai metodi MCMC per ottenere un’approssimazione della distribuzione predittiva a posteriori. Le stime delle possibili osservazioni future \\(p(\\tilde{y} \\mid y)\\), chiamate \\(p(y^{rep} \\mid y)\\), si ottengono nel modo seguente: campionare \\(\\theta_i \\sim p(\\theta \\mid y)\\), ovvero campionare un valore del parametro dalla distribuzione a posteriori; campionare \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\), ovvero campionare il valore di un’osservazione dalla funzione di verosimiglianza condizionata al valore del parametro definito nel passo precedente. Se i due passaggi descritti sopra vengono ripetuti un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva a posteriori che, in teoria (ma in pratica non sempre) potrebbe essere ottenuta per via analitica. Esercizio 22.1 Riportiamo qui sotto il codice Stan per generare \\(p(y^{rep} \\mid y)\\) nel caso dell’inferenza su una proporzione. modelString = &quot; data { int&lt;lower=0&gt; N; array[N] int&lt;lower=0, upper=1&gt; y; } parameters { real&lt;lower=0, upper=1&gt; theta; } model { theta ~ beta(2, 10); y ~ bernoulli(theta); } generated quantities { array[N] int y_rep; for (n in 1 : N) { y_rep[n] = bernoulli_rng(theta); } } &quot; writeLines(modelString, con = &quot;code/betabin23-30-2-10.stan&quot;) Si noti che nel nel blocco generated quantities sono state aggiunte le istruzioni necessarie per simulare \\(y^{rep}\\), ovvero, y_rep[n] = bernoulli_rng(theta). Una tale istruzione ci dice di generare un valore casuale di una variabile Bernoulliana di parametro \\(\\theta\\). Il valore \\(\\theta\\) è preso a caso dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). Il ciclo for specifica che tale operazione va ripetuta 30 volte. Tutto questo verrà ripetuto un numero di volte uguale al numero di iterazioni richieste. I dati dell’esempio sono: data_list &lt;- list( N = 30, y = c(rep(1, 23), rep(0, 7)) ) Compiliamo il codice Stan file &lt;- file.path(&quot;code&quot;, &quot;betabin23-30-2-10.stan&quot;) mod &lt;- cmdstan_model(file) ed eseguiamo il campionamento MCMC: fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Per comodità, trasformiamo l’oggetto fit in un oggetto di classe stanfit: stanfit &lt;- rstan::read_stan_csv(fit$output_files()) Il contenuto dell’oggetto stanfit può essere esaminato nel modo seguente: list_of_draws &lt;- extract(stanfit) print(names(list_of_draws)) #&gt; [1] &quot;theta&quot; &quot;y_rep&quot; &quot;lp__&quot; Dall’oggetto list_of_draws recuperiamo y_rep: y_bern &lt;- list_of_draws$y_rep dim(y_bern) #&gt; [1] 16000 30 head(y_bern) #&gt; #&gt; iterations [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #&gt; [1,] 1 1 1 1 0 1 1 1 1 1 1 1 1 #&gt; [2,] 0 1 0 1 1 1 0 0 1 0 0 0 0 #&gt; [3,] 0 1 0 1 1 1 0 0 1 1 1 0 1 #&gt; [4,] 1 0 0 1 1 0 0 1 0 1 1 1 0 #&gt; [5,] 0 0 0 1 1 0 1 1 0 1 0 0 1 #&gt; [6,] 1 1 1 1 1 1 0 1 0 1 1 1 0 #&gt; #&gt; iterations [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] #&gt; [1,] 0 1 1 1 1 1 0 0 1 0 1 #&gt; [2,] 1 0 0 1 0 1 1 1 0 0 0 #&gt; [3,] 0 0 1 0 1 1 0 1 0 0 1 #&gt; [4,] 0 1 0 1 0 1 0 0 1 0 1 #&gt; [5,] 0 0 1 1 1 1 1 0 1 0 1 #&gt; [6,] 1 1 0 1 0 1 1 0 0 1 0 #&gt; #&gt; iterations [,25] [,26] [,27] [,28] [,29] [,30] #&gt; [1,] 1 1 1 1 1 1 #&gt; [2,] 0 1 1 0 1 1 #&gt; [3,] 1 1 1 1 1 0 #&gt; [4,] 0 1 1 0 0 1 #&gt; [5,] 0 0 0 0 1 0 #&gt; [6,] 0 0 1 0 1 1 Dato che il codice Stan definisce un modello per i dati grezzi (ovvero, per ciascuna singola prova Bernoulliana del campione), ogni riga della matrice y_bern ha 30 colonne, ciascuna delle quali corrisponde ad un campione (\\(n\\) = 16,000 in questa simulazione) di possibili valori futuri \\(y_i \\in \\{0, 1\\}\\). In altre parole, abbiamo generato 16,000 campioni casuali di 30 osservazioni possibili future Per ottenere una stima p(y_rep) della distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\), ovvero, per ottenere una stima della probabilità associata a ciascuno dei possibili numeri di “successi” \\(\\tilde{y}\\) in \\(m = 30\\) nuove prove future, è sufficiente calcolare la proporzione di valori 1 in ciascuna riga: tibble(y_rep = rowSums(y_bern)) %&gt;% ggplot(aes(x = y_rep, after_stat(density))) + geom_histogram(binwidth = 1) Si noti che questo istogramma è equivalente a quello ottenuto nella simulazione precedente. 22.5 I metodi per la valutazione del modello 22.5.1 Posterior predictive checks La distribuzione predittiva a posteriori viene utilizzata per eseguire i cosiddetti controlli predittivi a posteriori (Posterior Predictive Checks, PPC). Nella distribuzione predittiva a posteriori, viene generato un campione di dati possibili futuri utilizzando le proprietà del modello adattato. È ovvio che tali dati possibili futuri devono almento essere coerenti con i dati del campione presente. I PPC eseguono un confronto grafico tra \\(p(y^{rep} \\mid y)\\) e i dati osservati \\(y\\): confrontando visivamente gli aspetti chiave dei dati previsti futuri \\(y^{rep}\\) e dei dati osservati \\(y\\) è possibile determinare se il modello è adeguato. Oltre al confronto visivo tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\) è anche possibile un confronto tra la distribuzione di varie statistiche descrittive, i cui valori sono calcolati su diversi campioni \\(y^{rep}\\), e le corrispondenti statistiche calcolate sui dati osservati. Vengono solitamente considerate statistiche descrittive quali la media, la varianza, la deviazione standard, il minimo o il massimo, ma sono possibili confronti di questo tipo per qualunque altra statistica. Esercizio 22.2 Esaminiamo ora un set di dati che non seguono la distribuzione normale (Gelman, Hill, and Vehtari 2020). I dati corrispondono ad una serie di misurazioni prese da Simon Newcomb nel 1882 come parte di un esperimento per stimare la velocità della luce. A questi dati verrà (inappropriatamente) adattata una distribuzione normale. L’obiettivo dell’esempio è quello di mostrare come i PPC possono rivelare la mancanza di adattamento di un modello ai dati. I PPC mostrano che il modo più semplice per verificare l’adattamento del modello è quello di visualizzare \\(y^{rep}\\) insieme ai dati effettivi. Iniziamo a caricare i dati: library(&quot;MASS&quot;) data(&quot;newcomb&quot;) Visualizziamo la distribuzione dei dati con un istogramma: tibble(newcomb) %&gt;% ggplot(aes(x = newcomb, after_stat(density))) + geom_histogram(binwidth = 1) Creiamo un oggetto di tipo list dove inserire i dati: data_list &lt;- list( y = newcomb, N = length(newcomb) ) Il codice Stan per il modello normale è il seguente: modelString &lt;- &quot; data { int&lt;lower=0&gt; N; vector[N] y; } parameters { real mu; real&lt;lower=0&gt; sigma; } model { mu ~ normal(25, 10); sigma ~ cauchy(0, 10); y ~ normal(mu, sigma); } generated quantities { vector[N] y_rep; for (n in 1 : N) { y_rep[n] = normal_rng(mu, sigma); } } &quot; writeLines(modelString, con = &quot;code/newcomb.stan&quot;) Adattando il modello ai dati file &lt;- file.path(&quot;code&quot;, &quot;newcomb.stan&quot;) mod &lt;- cmdstan_model(file) fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) otteniamo le seguenti stime dei parametri \\(\\mu\\) e \\(\\sigma\\): fit$summary(c(&quot;mu&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 2 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 mu 26.2 26.2 1.33 1.30 24.0 28.4 1.00 13305. 11189. #&gt; 2 sigma 10.9 10.8 0.958 0.943 9.40 12.5 1.00 12614. 10352. Trasformiamo fit in un oggetto stanfit: stanfit &lt;- rstan::read_stan_csv(fit$output_files()) La distribuzione a posteriori di \\(\\mu\\) è mu_draws &lt;- as.matrix(stanfit, pars = &quot;mu&quot;) mcmc_areas(mu_draws, prob = 0.95) # color 95% interval Confrontiamo \\(\\mu\\) con la media di \\(y\\): mean(newcomb) #&gt; [1] 26.21212 Anche se trova la media giusta, il modello non è comunque adeguato a prevedere le altre proprietà della \\(y\\). Estraiamo \\(y^{rep}\\) dall’oggetto stanfit: y_rep &lt;- as.matrix(stanfit, pars = &quot;y_rep&quot;) dim(y_rep) #&gt; [1] 16000 66 I valori y_rep sono i dati della distribuzione predittiva a posteriori che sono stati simulati usando gli stessi valori \\(X\\) dei predittori utilizzati per adattare il modello. Il confronto tra l’istogramma della \\(y\\) e gli istogrammi di diversi campioni \\(y^{rep}\\) mostra una scarsa corrispondenza tra i due: ppc_hist(data_list$y, y_rep[1:8, ], binwidth = 1) Alla stessa conclusione si giunge tramite un confronto tra la funzione di densità empirica della \\(y\\) e quella di diversi campioni \\(y^{rep}\\): ppc_dens_overlay(data_list$y, y_rep[1:50, ]) Generiamo ora i PPC per la media e il minimo della distribuzione: ppc_stat_2d(data_list$y, y_rep, stat = c(&quot;mean&quot;, &quot;min&quot;)) Mentre la media viene riprodotta accuratamente dal modello (come abbiamo visto sopra), ciò non è vero per il minimo dela distribuzione. L’origine di questa mancanza di adattamento è il fatto che la distribuzione delle misurazioni della velocità della luce è asimmetrica negativa. Dato che ci sono poche osservazioni nella coda negativa della distribuzione, solo per fare un esempio, utilizzeremo ora un secondo modello che ipotizza una distribuzione \\(t\\) di Student: modelString = &quot; data { int&lt;lower=0&gt; N; vector[N] y; } parameters { real mu; real&lt;lower=0&gt; sigma; real&lt;lower=0&gt; nu; } model { mu ~ normal(25, 10); sigma ~ cauchy(0, 10); nu ~ cauchy(0, 10); y ~ student_t(nu, mu, sigma); } generated quantities { vector[N] y_rep; for (n in 1 : N) { y_rep[n] = student_t_rng(nu, mu, sigma); } } &quot; writeLines(modelString, con = &quot;code/newcomb2.stan&quot;) Adattiamo questo secondo modello ai dati. file &lt;- file.path(&quot;code&quot;, &quot;newcomb2.stan&quot;) mod &lt;- cmdstan_model(file) fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) #&gt; Running MCMC with 4 sequential chains... #&gt; #&gt; Chain 1 finished in 0.3 seconds. #&gt; Chain 2 finished in 0.3 seconds. #&gt; Chain 3 finished in 0.2 seconds. #&gt; Chain 4 finished in 0.3 seconds. #&gt; #&gt; All 4 chains finished successfully. #&gt; Mean chain execution time: 0.3 seconds. #&gt; Total execution time: 1.4 seconds. Per questo secondo modello il confronto tra la funzione di densità empirica della \\(y\\) e quella di diversi campioni \\(y^{rep}\\) risulta adeguato: stanfit &lt;- rstan::read_stan_csv(fit$output_files()) y_rep &lt;- as.matrix(stanfit, pars = &quot;y_rep&quot;) ppc_dens_overlay(data_list$y, y_rep[1:50, ]) Inoltre, anche la statistica “minimo della distribuzione” viene ben predetta dal modello. ppc_stat_2d(data_list$y, y_rep, stat = c(&quot;mean&quot;, &quot;min&quot;)) In conclusione, per le misurazioni della velocità della luce di Newcomb l’accuratezza predittiva del modello basato sulla distribuzione \\(t\\) di Student è chiaramente migliore di quella del modello normale. 22.6 Distribuzione predittiva a priori Nella sezione precedente abbiamo visto come la distribuzione predittiva è stata usata per generare nuovi dati previsti futuri. Più precisamente, mediante la (14.6) \\[\\begin{equation} p(\\tilde{y} \\mid y) = \\int_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta\\notag \\end{equation}\\] abbiamo descritto la nostra incertezza sulla distribuzione di future osservazioni di dati, data la distribuzione a posteriori di \\(\\theta\\), ovvero tenendo conto della scelta del modello e della stima dei parametri mediante i dati osservati. Si noti che, nella (14.6), \\(\\tilde{y}\\) è condizionato da \\(y\\) ma non da ciò che è incognito, ovvero \\(\\theta\\). La distribuzione predittiva a posteriori è ottenuta mediante marginalizzazione sopra i parametri incogniti \\(\\theta\\). In un modello bayesiano dove \\(\\theta\\) ha una distribuzione a priori \\(p(\\theta)\\) e per \\(y\\) possiamo definire la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) possiamo scrivere la distribuzione congiunta \\(p(y, \\theta)\\) come il prodotto della verosimiglianza e della distribuzione a priori: \\[ p(y, \\theta) = p(y \\mid \\theta)p(\\theta). \\] Una rappresentazione alternativa della distribuzione congiunta \\(p(y, \\theta)\\) è \\[ p(y, \\theta) = p(\\theta \\mid y)p(y) \\] Il primo termine in questo prodotto, la densità \\(p(\\theta \\mid y)\\), è la densità a posteriori di \\(\\theta\\) date le osservazioni \\(y\\). Il secondo termine in questo prodotto, \\(p(y)\\), è la distribuzione predittiva a priori che rappresenta la distribuzione dei dati futuri previsti dal modello prima di avere osservato il campione \\(y\\). Se risulta che i dati \\(y\\) non sono coerenti con distribuzione predittiva a priori, questa è evidenza che il modello bayesiano non è specificato correttamente. In altre parole, questo ci dice che, in base al modello bayesiano così come è stato formulato, è improbabile che si verifichino i dati che sono stati effettivamente osservati. Ovviamente, questo vuol dire che, per i dati del campione, il modello è inadeguato. In seguito vedremo come la distribuzione predittiva a priori possa essere facilmente ricavata se l’inferenza bayesiana viene svolta mediante i metodi MCMC. Qui consideriamo un esempio relativo ai dati di Zetsche, Bürkner, and Renneberg (2019) senza approfondire i dettagli computazionali. Lo scopo è solo quello di interpretare il risultato ottenuto. Nel campione di Albert and Hu (2019) abbiamo osservato 23 successi in 30 prove. Nella discussione precedente abbiamo svolto l’aggiornamento bayesiano imponendo su \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). Ci poniamo il problema di costruire la distribuzione predittiva a priori per questo modello. Nel caso di una verosimiglianza binomiale e di una distribuzione a priori Beta, la distribuzione predittiva a priori può essere costruita mediante la funzione LearnBayes::pbetap(). Con i dati dell’esempio, otteniamo df &lt;- tibble( y = 0:30, Probability = LearnBayes::pbetap(c(2, 10), 30, 0:30) ) df %&gt;% ProbBayes::prob_plot(Color = &quot;gray&quot;, Size = 3) + geom_point(data = tibble(y = 23, Probability = 0), size = 3) La distribuzione predittiva a priori assegna livelli diversi di plausibilità a ciascuno dei possibili risultati del nostro esperimento casuale, ovvero all’osservazione di \\(0, 1, \\dots, 30\\) successi in 30 prove Bernoulliane. Nella distribuzione predittiva a priori assegna ho evidenziato il punto \\(y = 23\\), ovvero il numero di successi che sono stati effettivamente osservati nel campione. Il grafico mostra che la distribuzione predittiva a priori assegna una plausibilità quasi nulla all’evento \\(y = 23\\), ovvero ai dati che sono stati effettivamente osservati. Questo indica chiaramente che la distribuzione a priori \\(\\mbox{Beta}(2, 10)\\) non è adeguata per i dati che stiamo analizzando. Se viene invece utilizzata una distribuzione a priori debolmente informativa, come \\(\\mbox{Beta}(2, 2)\\), la distribuzione predittiva a priori diventa: df &lt;- tibble( y = 0:30, Probability = LearnBayes::pbetap(c(2, 2), 30, 0:30) ) df %&gt;% ProbBayes::prob_plot(Color = &quot;gray&quot;, Size = 3) + geom_point(data = tibble(y = 23, Probability = 0), size = 3) In questo secondo caso al valore \\(y\\) osservato nel campione viene assegnata una plausibilità piuttosto alta. Ciò significa che una \\(\\mbox{Beta}(2, 2)\\) è adeguata quale distribuzione a priori. Ricordo che, nell’analisi dei dati di Zetsche, Bürkner, and Renneberg (2019), la \\(\\mbox{Beta}(2, 10)\\) è stata utilizzata quale distribuzione a priori solo per scopi didattici, ovvero per evidenziare le proprietà dell’aggiornamento bayesiano (la differenza tra la distribuzione a priori e la distribuzione a posteriori). La discussione presente mette però chiaramente in evidenza il fatto che la \\(\\mbox{Beta}(2, 10)\\) non è una buona scelta per la distribuzione a priori: sarebbe invece più opportuno usare una \\(\\mbox{Beta}(2, 2)\\). Commenti e considerazioni finali Questo capitolo discute la predizione bayesiana e ne mostra un’applicazione nel caso dei controlli predittivi a posteriori. A questo proposito è necessario notare un punto importante: un buona corrispondenza tra \\(y\\) e \\(y^{rep}\\) costituisce una condizione necessaria ma non sufficiente per la validità del modello. Infatti, i PPC non sono in grado di garantire la generalizzabilità del modello a nuovi campioni di dati. D’altra parte, invece, se i PPC mostrano un cattivo adattamento del modello ai dati previsti futuri, questo ci dice chiaramente che il modello è specificato in manera errata. References "],["ch-normal-normal-mod-stan.html", "Capitolo 23 Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale) 23.1 Caso Normale-Normale con varianza nota 23.2 Derivazione analitica della distribuzione a posteriori \\(p(\\mu \\mid y)\\) 23.3 Il modello Normale con Stan Commenti e considerazioni finali", " Capitolo 23 Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale) Estendiamo ora la discussione precedente considerano un altro caso comune: quello in cui disponiamo di un campione di dati a livello di scala a intervalli o rapporti e vogliamo fare inferenza sulla media della popolazione da cui il campione è stato estratto. 23.1 Caso Normale-Normale con varianza nota Supponiamo che i dati \\(y\\) siano un campione casuale estratto da una popolazione che segue la legge Normale. Ciò significa che le osservazioni possono essere considerate come una sequenza di variabili casuali indipendenti e identicamente distribuite. Supponiamo che ciascuna v.c. segua la distribuzione Normale. Abbiamo dunque \\[ Y_1, \\dots, Y_n \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma). \\] In precedenza abbiamo visto come, in tali circostanze, la verosimiglianza \\(p(y \\mid \\mu, \\sigma)\\) sia Normale. Per fare inferenza sul parametro \\(\\mu\\), facciamo due assunzioni: consideriamo \\(\\sigma\\) nota e imponiamo su \\(\\mu\\) una distribuzione a priori Normale. Questa situazione definisce lo schema coniugato Normale-Normale. Il caso Normale-Normale consente una derivazione analitica della distribuzione a posteriori \\(p(\\mu \\mid y)\\) (così come nel caso beta-binomiale era possibile una derivazione analitica della distribuzione a posteriori \\(p(\\theta \\mid y)\\)). La trattazione matematica di una tale derivazione è piuttosto complessa e qui verrà solo accennata. Nel seguito, impareremo invece ad applicare la soluzione che viene ottenuta in tali circostanze; mostreremo inoltre come fare inferenza su \\(\\mu\\) mediante i metodi MCMC. 23.2 Derivazione analitica della distribuzione a posteriori \\(p(\\mu \\mid y)\\) Per \\(\\sigma^2\\) nota, la famiglia della distribuzione Normale è coniugata a sé stessa: se la funzione di verosimiglianza è Normale, la scelta di una distribuzione a priori Normale per \\(\\mu\\) assicura che anche la distribuzione a posteriori \\(p(\\mu \\mid y)\\) sia Normale. Poniamoci dunque il problema di trovare \\(p(\\mu \\mid y)\\) nel caso di un campione casuale \\(Y_1, \\dots, Y_n \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma)\\), supponendo \\(\\sigma\\) perfettamente nota e imponendo su \\(\\mu\\) una distribuzione a priori Normale. Ricordiamo che la densità gaussiana è \\[ p(y_i \\mid \\mu, \\sigma) = \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_i - \\mu)^2}{2\\sigma^2}}\\right\\}. \\] Essendo le variabili i.i.d., possiamo scrivere la densità congiunta come il prodotto delle singole densità e quindi si ottiene \\[ p(y \\mid \\mu) = \\, \\prod_{i=1}^n p(y_i \\mid \\mu). \\] Una volta osservati i dati \\(y\\), la verosimiglianza diventa \\[\\begin{align} p(y \\mid \\mu) =&amp; \\, \\prod_{i=1}^n p(y_i \\mid \\mu) = \\notag\\\\ &amp; \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_1 - \\mu)^2}{2\\sigma^2}}\\right\\} \\times \\notag\\\\ &amp; \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_2 - \\mu)^2}{2\\sigma^2}}\\right\\} \\times \\notag\\\\ &amp; \\vdots \\notag\\\\ &amp; \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_n - \\mu)^2}{2\\sigma^2}}\\right\\}. \\end{align}\\] Se la densità a priori \\(p(\\mu)\\) è gaussiana, allora anche la densità a posteriori \\(p(\\mu \\mid y)\\) sarà gaussiana. Poniamo \\[\\begin{equation} p(\\mu) = \\frac{1}{{\\tau_0 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(\\mu - \\mu_0)^2}{2\\tau_0^2}}\\right\\}, \\tag{23.1} \\end{equation}\\] ovvero imponiamo a \\(\\mu\\) una distribuzione a priori gaussiana con media \\(\\mu_0\\) e varianza \\(\\tau_0^2\\). Ciò significa dire che, a priori, \\(\\mu_0\\) rappresenta il valore più verosimile per \\(\\mu\\), mentre \\(\\tau_0^2\\) quantifica il grado della nostra incertezza rispetto a tale valore. Svolgendo una serie di passaggi algebrici, si arriva alla distribuzione a posteriori \\[\\begin{equation} p(\\mu \\mid y) = \\frac{1}{{\\tau_p \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(\\mu - \\mu_p)^2}{2\\tau_p^2}}\\right\\}, \\tag{23.2} \\end{equation}\\] dove \\[\\begin{equation} \\mu_p = \\frac{\\frac{1}{\\tau_0^2}\\mu_0+ \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\tau_0^2} + \\frac{n}{\\sigma^2}} \\tag{23.3} \\end{equation}\\] e \\[\\begin{equation} \\tau_p^2 = \\frac{1}{\\frac {1}{\\tau_0^2}+ \\frac{n}{\\sigma^2}}. \\tag{23.4} \\end{equation}\\] Ciò significa che, se la distribuzione a priori \\(p(\\mu)\\) è gaussiana, allora anche la distribuzione a posteriori \\(p(\\mu \\mid y)\\) sarà gaussiana con valore atteso \\(\\mu_p\\) e varianza \\(\\tau_p^2\\) date dalle espressioni precedenti. In conclusione, il risultato trovato indica che: il valore atteso a posteriori è una media pesata fra il valore atteso a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\); il peso della media campionaria è tanto maggiore tanto più è grande \\(n\\) (il numero di osservazioni) e \\(\\tau_0^2\\) (l’incertezza iniziale); l’incertezza (varianza) a posteriori \\(\\tau_p^2\\) è sempre più piccola dell’incertezza a priori \\(\\tau_0^2\\) e diminuisce al crescere di \\(n\\). Esercizio 23.1 Per esaminare un esempio pratico, consideriamo i 30 valori BDI-II dei soggetti clinici di Zetsche, Bürkner, and Renneberg (2019): df &lt;- data.frame( y = c( 26.0, 35.0, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22 ) ) Supponiamo che la varianza \\(\\sigma^2\\) della popolazione sia identica alla varianza del campione: sigma &lt;- sd(df$y) sigma #&gt; [1] 6.606858 Per fare un esempio, imponiamo su \\(\\mu\\) una distribuzione a priori \\(\\mathcal{N}(25, 2)\\). In tali circostanze, la distribuzione a posteriori del parametro \\(\\mu\\) può essere determinata per via analitica e corrisponde ad una Normale di media e varianza definite dalle equazioni (23.3) e (23.4). È possibile visualizzare tale distribuzione a posteriori usando la funzione plot_normal_normal() del pacchetto bayesrules. bayesrules::plot_normal_normal( mean = 25, # media della distribuzione a priori per mu sd = 2, # sd della distribuzione a priori per mu sigma = sd(df$y), # sd del campione y_bar = mean(df$y), # media del campione n = length(df$y) # ampiezza campionaria ) La funzione bayesrules::summarize_normal_normal() fornisce una sintesi numerica della distribuzione a posteriori \\(p(\\mu \\mid y, \\sigma)\\). bayesrules::summarize_normal_normal( mean = 25, # media della distribuzione a priori per mu sd = 2, # sd della distribuzione a priori per mu sigma= sd(df$y), # sd del campione y_bar = mean(df$y), # media del campione n = length(df$y) # ampiezza campionaria ) #&gt; model mean mode var sd #&gt; 1 prior 25.00000 25.00000 4.000000 2.000000 #&gt; 2 posterior 29.35073 29.35073 1.066921 1.032919 Verifichiamo i risultati forniti da bayesrules::summarize_normal_normal() applicando le formule (23.3) e (23.4). La media della distribuzione a posteriori di \\(\\mu\\) è mu_post &lt;- function(tau_0, mu_0, sigma, ybar, n) { (1/tau_0^2 * mu_0 + n/sigma^2 * ybar) / (1/tau_0^2 + n/sigma^2) } mu_0 &lt;- 25 # media della distribuzione a priori per mu tau_0 &lt;- 2 # sd della distribuzione a priori per mu sigma &lt;- sd(df$y) # sd del campione (assunta essere sigma) ybar &lt;- mean(df$y) # media del campione n &lt;- length(df$y) mu_post(tau_0, mu_0, sigma, ybar, n) #&gt; [1] 29.35073 La deviazione standard della distribuzione a posteriori di \\(\\mu\\) è tau_post &lt;- function(tau_0, sigma, n) { sqrt(1 / (1/tau_0^2 + n/sigma^2)) } tau_0 &lt;- 2 # sd della distribuzione a priori per mu sigma &lt;- sd(df$y) # sd del campione (assunta essere sigma) n &lt;- length(df$y) tau_post(tau_0, sigma, n) #&gt; [1] 1.032919 I risultati trovati riproducono quelli forniti da bayesrules::summarize_normal_normal(). 23.3 Il modello Normale con Stan I priori coniugati Normali di una Normale non richiedono una approssimazione numerica ottenuta mediante metodi MCMC. Tuttavia, per fare un esercizio e per verificare che i risultati ottenuti mediante MCMC siano simili a quelli trovati per via analitica, ripetiamo l’esercizio precedente usando Stan. 23.3.1 Versione 1 (\\(\\sigma\\) nota) Come in precedenza, impongo su \\(\\mu\\) una distribuzione a priori \\(\\mathcal{N}(25, 2)\\) e considero noto il parametro \\(\\sigma = 6.606858\\). Il modello dunque diventa il seguente. \\[\\begin{align} Y_i &amp;\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\ \\mu &amp;\\sim \\mathcal{N}(25, 2) \\notag\\\\ \\sigma &amp;= 6.606858 \\notag \\end{align}\\] In base al modello definito sopra, la variabile casuale \\(Y\\) segue la distribuzione Normale di parametri \\(\\mu\\) e \\(\\sigma\\). Il parametro \\(\\mu\\) è sconosciuto e abbiamo deciso di descrivere la nostra incertezza relativa ad esso mediante una distribuzione a priori Normale di media 25 e deviazione standard 2. Il parametro \\(\\sigma\\) è invece assunto essere noto e uguale a 6.606858. Usando il linguaggio Stan specifico il modello come segue. modelString = &quot; data { int&lt;lower=0&gt; N; real&lt;lower=0&gt; sigma; vector[N] y; } parameters { real mu; } model { mu ~ normal(25, 2); y ~ normal(mu, sigma); } &quot; writeLines(modelString, con = &quot;code/normal_normal_1.stan&quot;) Sistemo i dati nel formato appropriato per Stan. dlist &lt;- list( N = length(df$y), sigma = sd(df$y), y = df$y ) Leggo il file in cui ho salvato il codice Stan. file &lt;- file.path(&quot;code&quot;, &quot;normal_normal_1.stan&quot;) Compilo il modello. mod &lt;- cmdstan_model(file) Eseguo il campionamento MCMC. fit &lt;- mod$sample( data = dlist, iter_sampling = 100000L, iter_warmup = 2000L, chains = 4L, refresh = 0 ) Una sintesi della distribuzione a posteriori dei parametri si ottiene nel modo seguente. fit$summary(c(&quot;mu&quot;)) #&gt; # A tibble: 1 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 mu 29.4 29.4 1.04 1.04 27.6 31.1 1.00 153786. 188314. Si noti che le stime ottenute sono molto vicine ai valori teorici attesi, ovvero \\(\\mu_p\\) = 29.57 contro un valore teorico di 29.35 e \\(\\tau_p\\) = 0.96 contro un valore teorico di 1.03. Qui sotto è fornita una rappresentazione grafica dell’intera distribuzione a posteriori del parametro \\(\\mu\\). stanfit &lt;- rstan::read_stan_csv(fit$output_files()) mu_draws &lt;- as.matrix(stanfit,pars =&quot;mu&quot;) mcmc_areas(mu_draws,prob = 0.95) Trovo l’intervallo di credibilità al 95%. post &lt;- fit$draws() post_parms &lt;- subset_draws(post, c(&quot;mu&quot;)) posterior::summarise_draws( post_parms, ~ quantile(.x, probs = c(0.025, 0.975)) ) #&gt; # A tibble: 1 × 3 #&gt; variable `2.5%` `97.5%` #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 mu 27.3 31.4 Le stime così trovate sono molto simili ai quantili di ordine 0.025 e 0.975 della vera distribuzione a posteriori di \\(\\mu\\): qnorm(c(0.025, 0.975), 29.35073, 1.032919) #&gt; [1] 27.32625 31.37521 23.3.2 Versione 2 (\\(\\sigma\\) incognita) È facile estendere il caso precedente alla situazione in cui il parametro \\(\\sigma\\) è incognito. Se non conosciamo \\(\\sigma\\), è necessario imporre su tale parametro una distribuzione a priori. Supponiamo di ipotizzare per \\(\\sigma\\) una distribuzione a priori \\(\\mbox{Cauchy}(0, 15)\\). Mediante una \\(\\mbox{Cauchy}(0, 15)\\) descrivo il grado di plausibilità soggettiva che attribuisco ai possibili valori (&gt; 0) del parametro \\(\\sigma\\). Ai valori prossimi allo 0 attribuisco la plausibilità maggiore; la plausibilità dei possibili valori \\(\\sigma\\) diminuisce progressivamente quando ci si allontana dallo 0, come indicato dalla curva della figura seguente. Ritengo poco plausibili valori \\(\\sigma\\) maggiori di 40, anche se non escludo completamente che \\(\\sigma\\) possa assumere un valore di questo tipo. curve( dcauchy(x, location = 0, scale = 15), from = 0, to = 50, col = &#39;gray&#39;, lwd = 3, ylab = &quot;Densità&quot;, xlab = &quot;sigma&quot; ) In questo secondo caso, più realistico, il modello diventa il seguente. \\[\\begin{align} Y_i &amp;\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\ \\mu &amp;\\sim \\mathcal{N}(25, 2) \\notag\\\\ \\sigma &amp;\\sim \\mbox{Cauchy}(0, 15) \\notag \\end{align}\\] Il modello precedente è simile a quello esaminato in precedenza, eccetto che abbiamo quantificato la nostra incertezza relativa a \\(\\sigma\\) (che è ignota) mediante una distribuzione a priori \\(\\mbox{Cauchy}(0, 15)\\). La procedura MCMC utilizzata da Stan è basata su un campionamento Monte Carlo Hamiltoniano che non richiede l’uso di distribuzioni a priori coniugate. Pertanto è possibile scegliere per i parametri una qualunque distribuzione a priori. Nel caso presente, appunto, per \\(\\sigma\\) ho scelto una \\(\\mbox{Cauchy}(0, 15)\\). Per un tale caso non è possibile ottenere la derivazione analitica della distribuzione a posteriori di \\(\\mu\\). È dunque necessario procedere con il campionamento MCMC. Scrivo il modello in linguaggio in Stan. model_string_2 = &quot; data { int&lt;lower=0&gt; N; vector[N] y; } parameters { real mu; real&lt;lower=0&gt; sigma; } model { mu ~ normal(25, 2); sigma ~ cauchy(0, 15); y ~ normal(mu, sigma); } &quot; writeLines(model_string_2, con = &quot;code/normal_mod_2.stan&quot;) Creo l’oggetto di classe list che contiene i dati. dlist2 &lt;- list( N = length(df$y), y = df$y ) Leggo il file con il codice Stan del modello. file2 &lt;- file.path(&quot;code&quot;, &quot;normal_mod_2.stan&quot;) Compilo il modello. mod2 &lt;- cmdstan_model(file2) Eseguo il campionamento MCMC. fit2 &lt;- mod2$sample( data = dlist2, iter_sampling = 50000L, iter_warmup = 2000L, chains = 4L, refresh = 0 ) In questo modo ottengo le seguenti stime a posteriori dei parametri. fit2$summary(c(&quot;mu&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 2 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 mu 29.2 29.2 1.14 1.12 27.3 31.0 1.00 129256. 114237. #&gt; 2 sigma 7.06 6.95 1.01 0.954 5.63 8.88 1.00 121123. 115765. Dopo avere trasformato l’oggetto fit2 nel formato stanfit, trovo l’intervallo di credibilità al 95%. stanfit &lt;- rstan::read_stan_csv(fit2$output_files()) out &lt;- rstantools::posterior_interval( as.matrix(stanfit), prob = 0.95 ) out #&gt; 2.5% 97.5% #&gt; mu 26.851295 31.331500 #&gt; sigma 5.418299 9.360616 #&gt; lp__ -76.415107 -72.666800 Come in precedenza, uso la funzione mcmc_areas() per creare una rappresentazione grafica della distribuzione a posteriori di \\(\\mu\\). mu_draws &lt;- as.matrix(stanfit, pars =&quot;mu&quot;) mcmc_areas(mu_draws, prob = 0.95) Considerati i dati osservati e le mie ipotesi a priori sui parametri, posso dunque concludere, con un grado di certezza soggettiva del 95%, che la media della popolazione dei punteggi BDI-II dei pazienti clinici depressi è compresa nell’intervallo [26.85, 31.33]. Commenti e considerazioni finali In questo capitolo abbiamo visto come calcolare l’intervallo di credibilità per la media di una v.c. Normale. La domanda più ovvia di analisi dei dati, dopo avere visto come trovare l’intervallo di credibilità per la media di un solo gruppo, riguarda il confronto tra le medie di due gruppi. Il confronto tra le medie di due gruppi può essere considerato come un caso particolare di un metodo più generale di analisi dei dati, chiamato analisi di regressione lineare. Prima di discutere il problema del confronto tra le medie di due gruppi è dunque necessario esaminare il modello statistico della regressione lineare. References "],["ch-regr-intro.html", "Capitolo 24 Introduzione 24.1 La funzione lineare 24.2 Una media per ciascuna osservazione 24.3 Relazione lineare tra la media \\(y \\mid x\\) e il predittore 24.4 Il modello lineare Commenti e considerazioni finali", " Capitolo 24 Introduzione Lo scopo della ricerca è trovare le associazioni tra le variabili e fare confronti fra le condizioni sperimentali. Nel caso della psicologia, il ricercatore vuole scoprire le leggi generali che descrivono le relazioni tra i costrutti psicologici e le relazioni che intercorrono tra i fenomeni psicologici e quelli non psicologici (sociali, economici, storici, …). Abbiamo già visto come la correlazione di Pearson sia uno strumento adatto a questo scopo. Infatti, essa ci informa sulla direzione e sull’intensità della relazione lineare tra due variabili. Tuttavia, la correlazione non è sufficiente, in quanto il ricercatore ha a disposizione solo i dati di un campione, mentre vorrebbe descrivere la relazione tra le variabili nella popolazione. A causa della variabilità campionaria, le proprietà dei campioni sono necessariamente diverse da quelle della popolazione: ciò che si può osservare nella popolazione potrebbe non emergere nel campione e, al contrario, il campione manifesta caratteristiche che non sono necessariamente presenti nella popolazione. È dunque necessario chiarire, dal punto di vista statistico, il legame che intercorre tra le proprietà del campione e le proprietà della popolazione da cui esso è stato estratto. Il modello lineare utilizza la funzione matematica più semplice per descrivere la relazione fra due variabili, ovvero la funzione lineare. In questo Capitolo vedremo come si possa fare inferenza sulla relazione tra due variabili mediante il modello lineare bayesiano. Inizieremo a descrivere le proprietà geometriche della funzione lineare per poi utilizzare questa semplice funzione per costruire un modello statistico secondo un approccio bayesiano. 24.1 La funzione lineare Iniziamo con un ripasso sulla funzione di lineare. Si chiama funzione lineare una funzione del tipo \\[\\begin{equation} f(x) = a + b x, \\end{equation}\\] dove \\(a\\) e \\(b\\) sono delle costanti. Il grafico di tale funzione è una retta di cui il parametro \\(b\\) è detto coefficiente angolare e il parametro \\(a\\) è detto intercetta con l’asse delle \\(y\\) [infatti, la retta interseca l’asse \\(y\\) nel punto \\((0,a)\\), se \\(b \\neq 0\\)]. Per assegnare un’interpretazione geometrica alle costanti \\(a\\) e \\(b\\) si consideri la funzione \\[\\begin{equation} y = b x. \\end{equation}\\] Tale funzione rappresenta un caso particolare, ovvero quello della proporzionalità diretta tra \\(x\\) e \\(y\\). Il caso generale della linearità \\[\\begin{equation} y = a + b x \\end{equation}\\] non fa altro che sommare una costante \\(a\\) a ciascuno dei valori \\(y = b x\\). Nella funzione lineare \\(y = a + b x\\), se \\(b\\) è positivo allora \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) è negativo allora \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\) la retta è orizzontale, ovvero \\(y\\) non muta al variare di \\(x\\). Consideriamo ora il coefficiente \\(b\\). Si consideri un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\) come indicato nella figura 24.1. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono detti incrementi di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) è uguale al rapporto \\[\\begin{equation} b = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}, \\end{equation}\\] indipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Il modo più semplice per assegnare un’interpretazione geometrica al coefficiente angolare (o pendenza) della retta è dunque quello di porre \\(\\Delta x = 1\\). In tali circostanze infatti \\(b = \\Delta y\\). FIGURA 24.1: La funzione lineare \\(y = a + bx\\). 24.2 Una media per ciascuna osservazione In precedenza abbiamo visto come sia possibile stimare i parametri di un modello bayesiano nel quale le osservazioni sono indipendenti e identicamente distribuite secondo una densità gaussiana, \\[\\begin{equation} Y_i \\stackrel{i.i.d.}{\\sim} \\mathcal{N}(\\mu, \\sigma), \\quad i = 1, \\dots, n. \\tag{24.1} \\end{equation}\\] Il modello (24.1) assume che ogni \\(Y_i\\) sia la realizzazione di una v.c. descritta da una \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Da un punto di vista bayesiano,questo modello può essere implementato assegnando le distribuzioni a priori ai parametri \\(\\mu\\) e \\(\\sigma\\) e generando la verosimiglianza in base ai dati osservati. Con queste informazioni, possono poi essere definite le distribuzioni a posteriori dei parametri (Gelman, Hill, and Vehtari 2020): \\[\\begin{align} Y_i \\mid \\mu, \\sigma &amp; \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\notag\\\\ \\mu &amp; \\sim \\mathcal{N}(\\mu_0, \\tau^2) \\notag\\\\ \\sigma &amp; \\sim \\mbox{Cauchy}(x_0, \\gamma) \\notag \\end{align}\\] 24.3 Relazione lineare tra la media \\(y \\mid x\\) e il predittore È però comune che vengano registrate altre variabili che possono essere associate alla risposta di interesse \\(y_i\\). Chiamiamo \\(x\\) una di tali variabili. La variabile \\(x\\) viene chiamata predittore (o variabile indipendente) in quanto il ricercatore è tipicamente interessato a predire \\(y_i\\) a partire dal valore assunto da \\(x_i\\). Come si può estende il modello (24.1) descritto in precedenza per lo studio della relazione tra \\(y_i\\) e \\(x_i\\)? Il modello (24.1) assume una media \\(\\mu\\) comune per ciascuna osservazione \\(Y_i\\). Dal momento che desideriamo introdurre una nuova variabile \\(x_i\\) che assume un diverso valore per ciascuna osservazione \\(y_i\\), il modello (24.1) può essere modificato in modo che la media comune \\(\\mu\\) venga sostituita da una media \\(\\mu_i\\) specifica a ciascuna osservazione \\(i\\)-esima: \\[\\begin{equation} Y_i \\mid \\mu_i, \\sigma \\stackrel{ind}{\\sim} \\mathcal{N}(\\mu_i, \\sigma), \\quad i = 1, \\dots, n. \\tag{24.2} \\end{equation}\\] Si noti che le osservazioni \\(Y_1, \\dots, Y_n\\) non sono più identicamente distribuite poiché hanno medie diverse, ma sono ancora indipendenti come indicato dalla notazione ind posta sopra il simbolo \\(\\sim\\) nella (24.2). L’approccio che consente di mettere in relazione un predittore \\(x_i\\) con la risposta \\(Y_i\\) è quello di assumere che la media di ciascuna \\(Y_i\\), ovvero \\(\\mu_i\\), sia una funzione lineare del predittore \\(x_i\\). Una tale relazione lineare è scritta come \\[\\begin{equation} \\mu_i = \\beta_0 + \\beta_ 1 x_i, \\quad i = 1, \\dots, n. \\tag{24.3} \\end{equation}\\] Nella (24.3), ciascuna \\(x_i\\) è una costante nota (ecco perché viene usata una lettera minuscola per la \\(x\\)) e \\(\\beta_0\\) e \\(\\beta_ 1\\) sono parametri incogniti. Questi parametri rappresentano l’intercetta e la pendenza della retta di regressione e sono delle variabili casuali.28 L’inferenza bayesiana procede assegnando una distribuzione a priori a \\(\\beta_0\\) e a \\(\\beta_ 1\\) e si esegue l’inferenza riassumendo la distribuzione a posteriori di questi parametri. Nel modello (24.3), la funzione lineare \\(\\beta_0 + \\beta_ 1 x_i\\) è interpretata come il valore atteso della \\(Y_i\\) per ciascun valore \\(x_i\\), mentre l’intercetta \\(\\beta_0\\) rappresenta il valore atteso della \\(Y_i\\) quando \\(x_i = 0\\). Il parametro \\(\\beta_ 1\\) (pendenza) rappresenta invece l’aumento medio della \\(Y_i\\) quando \\(x_i\\) aumenta di un’unità. È importante notare che la relazione lineare (24.2) di parametri \\(\\beta_0\\) e \\(\\beta_ 1\\) descrive l’associazione tra la media \\(\\mu_i\\) e il predittore \\(x_i\\). In altri termini, tale relazione lineare ci fornisce una predizione sul valore medio \\(\\mu_i\\), non sul valore effettivo \\(Y_i\\). 24.4 Il modello lineare Sostituendo la (24.3) nella (24.2) otteniamo il modello lineare: \\[\\begin{equation} Y_i \\mid \\beta_0, \\beta_ 1, \\sigma \\stackrel{ind}{\\sim} \\mathcal{N}(\\beta_0 + \\beta_ 1 x_i, \\sigma), \\quad i = 1, \\dots, n. \\tag{24.4} \\end{equation}\\] Questo è dunque un caso speciale del modello di campionamento Normale, dove le \\(Y_i\\) seguono indipendentemente una densità Normale con una media (\\(\\beta_0 + \\beta_ 1 x_i\\)) specifica per ciascuna osservazione e con una deviazione standard (\\(\\sigma\\)) comune a tutte le osservazioni. Poiché include un solo predittore (\\(x\\)), questo modello è chiamato modello di regressione lineare bivariata. Il modello statistico di regressione lineare bivariata può essere rappresentato in forma geometrica come indicato di seguito. La figura illustra che, in tale modello statistico, la variabile \\(X\\) è fissa per disegno – in altre parole, i valori \\(x\\) restano immutati tra campioni diversi. Potendo ipotizzare infiniti campioni tutti con gli stessi valori \\(x\\), in corrispondenza di ciascun valore \\(x_i\\) vi sarà una distribuzione di valori \\(y\\). La figura illustra il caso di tre valori \\(x\\). A ciascun valore \\(x_i\\), con \\(i = 1, 2, 3\\) per l’esempio della figura, corrisponde una distribuzione di valori \\(y\\) condizionati a \\(x_i\\), \\(p(y \\mid x_i)\\). Il modello statistico di regressione lineare assume che le distribuzioni condizionate \\(p(y \\mid x_i)\\) siano \\[ y_i \\sim \\mathcal{N}(\\mu_i, \\sigma), \\] (assunzione di normalità), laddove \\[ \\mu_i = \\mathbb{E}(y \\mid x_i) = \\alpha + \\beta x_i. \\] L’equazione precedente descrive l’assunzione di linearità. Si noti che il parametro \\(\\sigma\\) non ha un pedice: questo significa che il modello ipotizza una dispersione costante delle distribuzioni \\(p(y \\mid x_i), \\forall i\\). Tale assunzione va sotto il nome di omoschedasticità. Se questa è la struttura della popolazione, possiamo pensare ad un campione casuale di ampiezza \\(n\\) come ad una serie di coppie \\(x_i, y_i\\), con \\(i = 1, \\dots, n\\), nelle quali i valori \\(x\\) sono fissi per disegno e ciascun valore \\(y_i\\) è una realizzazione della variabile casuale \\(Y = y_i \\mid X = x_i\\). Questa è l’ultima assunzione del modello statistico lineare: l’indipendenza. In maniera equivalente possiamo dire che gli errori \\(\\varepsilon_i = y_i - \\hat{y}_i = y_i - (\\beta_0 + \\beta_1 x_i)\\) sono variabili casuali distribuite secondo la legge Normale di parametri \\(\\mathcal{N}(0, \\sigma)\\). Commenti e considerazioni finali Il modello lineare semplice viene usato per descrivere la relazione tra due variabili e per determinare il segno e l’intensità di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base al valore assunto dalla variabile indipendente. References "],["ch-regr-model-lm.html", "Capitolo 25 Metodo dei minimi quadrati 25.1 Stima dei coefficienti di regressione 25.2 Indice di determinazione Commenti e considerazioni finali", " Capitolo 25 Metodo dei minimi quadrati In questo capitolo mi pongo il problema di applicare il modello di regressione bivariata ad un campione di dati. Userò il campione di dati kidiq. Riporto qui di seguito la descrizione delle variabili. Data from a survey of adult American women and their children (a subsample from the National Longitudinal Survey of Youth). Source: Gelman and Hill (2007) 434 obs. of 4 variables kid_score Child’s IQ score mom_hs Indicator for whether the mother has a high school degree mom_iq Mother’s IQ score mom_age Mother’s age Leggo i dati in \\(\\mathsf{R}\\). kidiq &lt;- rio::import(here::here( &quot;data&quot;, &quot;kidiq.dta&quot; )) glimpse(kidiq) #&gt; Rows: 434 #&gt; Columns: 5 #&gt; $ kid_score &lt;dbl&gt; 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78, 1… #&gt; $ mom_hs &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, … #&gt; $ mom_iq &lt;dbl&gt; 121.11753, 89.36188, 115.44316, 99.44964, 92.74571, 107.9018… #&gt; $ mom_work &lt;dbl&gt; 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, 3, … #&gt; $ mom_age &lt;dbl&gt; 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 24, … In questo esercizio considererò la relazione tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq). kidiq %&gt;% ggplot(aes(x = mom_iq, y = kid_score)) + geom_point() I dati rappresentati nel diagramma a dispersione suggeriscono che, in questo campione, sembra esserci un’associazione positiva tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq). Mi pongo il problema di descrivere questa associazione mediante una relazione lineare. kidiq %&gt;% ggplot(aes(x = mom_iq, y = kid_score)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) Ci sono infinite rette che, in linea di principio, possono essere usate per “approssimare” la nube di punti nel diagramma a dispersione. È dunque necessario introdurre dei vincoli per selezionare una di queste rette. Vediamo qui di seguito come tale problema viene risolto dall’approccio frequentista mediante il metodo dei minimi quadrati. Un vincolo che viene introdotto dall’approccio frequentista è quello di costringere la retta di regressione a passare per il punto \\((\\bar{x}, \\bar{y})\\). kidiq %&gt;% ggplot(aes(x = mom_iq, y = kid_score)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + geom_point( aes(x=mean(mom_iq), y=mean(kid_score)), colour=&quot;red&quot;, size = 4 ) Una retta che passa per il punto \\((\\bar{x}, \\bar{y})\\) ha delle desideraibili proprietà statistiche che verranno descritte di seguito. Il campione è costituito da \\(n\\) coppie (\\(x, y\\)). Per ciascuna coppia \\(i\\)-esima di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione: \\[ y_i = a + b x_i + e_i \\] Le osservazioni \\(y_i\\) corrispondono, nell’esempio presente, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti: kidiq$kid_score[1:10] #&gt; [1] 65 98 85 83 115 98 69 106 102 95 Per fare riferimento a ciascuna osservazione usiamo l’indice \\(i\\). Quindi, ad esempio, \\(y_3\\) è uguale a kidiq$kid_score[3] #&gt; [1] 85 La variabile \\(x\\), nel caso presente, è mom_iq. I primi 10 valori di \\(x\\) sono kidiq$mom_iq[1:10] #&gt; [1] 121.11753 89.36188 115.44316 99.44964 92.74571 107.90184 138.89311 #&gt; [8] 125.14512 81.61953 95.07307 In maniera corrispondente alla \\(y\\), uso un indice per fare riferimento ai singoli valori della variabile. Ad esempio, \\(x_3\\) è kidiq$mom_iq[3] #&gt; [1] 115.4432 L’equazione precedente ci dice che ciascun valore \\(y\\) è dato dalla somma di due componenti: una componente deterministica e una componente aleatoria. Consideriamo il primo valore \\(y\\) del campione. Per esso, il modello di regressione afferma quanto segue: \\[ y_1 = a + b x_1 + e_1, \\] laddove \\(a + b x_1\\) è la componente deterministica, detta \\(\\hat{y}\\), e \\(e_1\\) è la componente aleatoria. La componente deterministica è la componente di ciascun valore \\(y_i\\) che è possibile prevedere (in maniera deterministica) conoscendo il corrispondente valore \\(x_i\\). Tuttavia, non è possibile prevedere perfettamente i valori \\(y\\) – ciò si verificherebbe soltanto se tutti punti del diagramma a dispersione fossero disposti su una retta. Ma non lo sono mai nella pratica concreta: la retta è solo un’approssimazione della relazione (lineare) tra \\(x\\) e \\(y\\). Pertanto, conoscendo \\(x_i\\) possiamo solo prevedere una “componente” del corrispondente valore \\(y_i\\). Cosa significa che possiamo prevedere una componente di ciascuna osservazione \\(y_i\\)? Significa che il valore \\(y_i\\) osservato sarà diverso dal valore previsto dal modello. Il che è equivalente a dire che ciascun \\(y_i\\) è dato dalla seguente somma: \\(y_i = \\hat{y}_i + e_i\\). L’affermazione precedente pone due domande: come possiamo trovare i coefficienti \\(a\\) e \\(b\\) che consentono di predire in maniera deterministica una componente della \\(y\\) a partire dalla conoscenda della \\(x\\)? quant’è grande la porzione della \\(y\\) che può essere predetta conoscendo la \\(x\\)? In altre parole, quant’è accurata la predizione della \\(y\\) che può essere fornita dalla conoscenza della \\(x\\)? Rispondere a tali due domanda definisce i primi due obiettivi del modello statistico della regressione lineare. Il terzo obiettivo è quello dell’inferenza, ovvero quello di capire che relazioni ci sono tra la relazione tra \\(x\\) e \\(y\\) osservata nel campione e la la relazione tra \\(x\\) e \\(y\\) nella popolazione. 25.1 Stima dei coefficienti di regressione Iniziamo con il primo obiettivo, ovvero quello di trovare i coefficienti \\(a\\) e \\(b\\) che consentono di predire una frazione di ciascuna osservazione \\(y\\) conoscendo \\(x\\). Quindi, nel caso presente, ci chiediamo quanto segue. Il primo bambino del campione ha un QI uguale a 65. Sua madre ha un QI di 121.12. Qual è la stima migliore del punteggio QI del bambino che può essere fornita conoscendo il QI di sua madre? È chiaro, guardando i numeri, che non c’è una corrispondenza perfetta tra QI della madre e QI del bambino, tutt’altro! Infatti, se guardiamo il diagramma di dispersione ci rendiamo conto che i punti sono piuttosto lontani dalla retta che abbiamo usato per descrivere la relazione tra \\(x\\) e \\(y\\). Tuttavia, il diagramma di dispersione suggerisce che, comunque, al di là del rumore, c’è una relazione tra le due variabili. Il nostro obiettivo è di trovare un metodo quantitativo che consenta di descrivere una tale relazione. Abbiamo detto che, di ciascuna osservazione \\(y_i\\), è possibile prevedere una componente, conoscendo \\(x_i.\\) La componente \\(y_i\\) predicibile da \\(x_i\\) viene denotata da \\(\\hat{y}_i\\). Il modello di regressione lineare ci dice che \\[ \\hat{y}_i = a_i + bx_i. \\] L’equazione precedente è un’equazione lineare e, dal punto di vista geometrico, corrisponde ad una retta. Ci sono infinite equazioni che, in linea di principio, potremmo pensare di usare per descrivere la relazione tra \\(x\\) e \\(y\\). Abbiamo scelto questa perché è la più semplice. Se guardiamo il diagramma di dispersione, infatti, non ci sono ragioni per descrivere la relazione tra \\(x\\) e \\(y\\) con qualche curva, anziché con una retta. In altri campioni, una curva può essere più sensata di una retta, quale descrizione della relazione media tra \\(x\\) e \\(y\\), ma non nel caso presente. Ricordiamo il principio del rasoio di Occam (ovvero, il principio che sta alla base del pensiero scientifico moderno): se un modello semplice funziona, non c’è ragione di usare un modello più complesso. Dunque, abbiamo capito che vogliamo descrivere la relazione media tra \\(x\\) e \\(y\\) con una retta, ovvero, con l’equazione lineare \\[ \\hat{y}_i = a + b x_i. \\] L’equazione precedente indica che il modello lineare \\(a + b x_i\\) non è in grado di prevedere il valore di ciascuna osservazione \\(y_i\\). Questo, in generale, non è mai possibile (ovvero, è possibile solo in un caso specifico che, nella realtà empirica, non si verifica mai). L’equazione precedente ci dice che possiamo prevedere solo una frazione di ciascuna osservazione \\(y_i\\), ovvero quella frazione che abbiamo denotato con \\(\\hat{y}_i\\). La componente che non possiamo prevedere con l’equazione \\(a + b x_i\\) viene detta residuo e si denota con \\(e_i\\): \\[ e_i = y_i - \\hat{y}_i = y_i - (a + bx_i). \\] Dal punto di vista geometrico, la componente erratica del modello, \\(e_i\\), corrisponde alla distanza verticale tra ciascun punto e la retta di regressione \\(a + bx\\). Diciamo che scomponiamo il valore di ciascuna osservazione \\(y_i\\) in due componenti nel senso che \\[ y_i = \\hat{y}_i + e_i = (a + bx_i) + e_i. \\] Il primo obiettivo del modello di regressione è quello di trovare i coefficienti dell’equazione \\[ a + b x_i \\] che consente di trovare \\(\\hat{y}_i\\) conoscendo \\(x_i\\). Questi due coefficienti sono detti coefficienti di regressione. Per trovare i coefficienti di regressione dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo di tali vincoli è stato introdotto in precedenza: vogliamo che la retta \\(\\hat{y}_i = a + b x_i\\) passi per il punto \\((\\bar{x}, \\bar{y})\\). Il punto \\((\\bar{x}, \\bar{y})\\) corrisponde al baricentro del diagramma a dispersione. Ci sono però infinite rette che passano per i punto \\((\\bar{x}, \\bar{y})\\). Tutte queste rette soddisfano la seguente proprietà: \\[ \\sum_{i=1}^n e_i = 0, \\] ovvero, fanno in modo che la somma dei residui (positivi, per i punti che si trovano al di sopra della retta di regressione, negativi, per punti che si trovano al di sotto della retta di regressione) sia uguale a zero. Questo significa che non possiamo selezionare una tra le infinite rette che passano per il punto \\((\\bar{x}, \\bar{y})\\) usando il criterio che ci porta a scegliere la retta che rende la più piccola possibile (ovvero, minimizza) la somma dei residui. Infatti, tutte le rette passanti per il punto \\((\\bar{x}, \\bar{y})\\) soddisfano questo requisito (rendono uguale a zero la somma dei residui). Dunque, dobbiamo trovare qualche altri criterio per scegliere una tra le infinite rette che passano per il punto \\((\\bar{x}, \\bar{y})\\). Il criterio che viene normalmente scelto è quello di minimizzare la somma dei quadrati dei residui \\((y_i - \\hat{y}_i)^2\\). In altri termini, vogliamo trovare i coefficienti \\(a\\) e \\(b\\) tali per cui la quantità \\[ \\sum_{i=1}^{n}{(y_i - (a + b x_i))^2} \\] assume il suo valore minimo. I coefficienti \\(a\\) e \\(b\\) che soddisfano questa proprietà si chiamano coefficienti dei minimi quadrati. Questo problema ha una soluzione analitica. La soluzione analitica si trova riconoscendo il fatto che l’equazione precedente definisce una superficie e il problema diventa quello di trovare il punto di minimo di questa superficie. Per trovare la soluzione ci si deve rendere conto che il punto cercato è quello per cui il piano tangente alla superficie (nelle due direzioni \\(a\\) e \\(b\\)) è piatto (le tangenti nelle due direzioni sono uguali a zero). Rendere uguale a zero la tangente ad una curva significa porre uguali a zero la derivata della curva. Nel caso presente, abbiamo una superficie, dunque due tangenti ortogonali e quindi abbiamo il problema di rendere uguali a zero le derivate parziali rispetto ad \\(a\\) e \\(b\\). Così facendo si definisce un sistema di equazioni lineari con due incognite, \\(a\\) e \\(b\\). La soluzione di tali equazioni, che si chiamano equazioni normali, è la seguente: \\[ a = \\bar{y} - b \\bar{x}, \\] \\[ b = \\frac{\\mbox{Cov}(x, y)}{\\mbox{Var}(x)}. \\] Le due precedenti equazioni corrispondono alla stima dei minimi quadrati dei coefficienti di regressione della retta che minimizza la somma dei quadrati dei residui. Nel caso dell’esempio presente, tali coefficienti sono uguali a: b &lt;- cov(kidiq$kid_score, kidiq$mom_iq) / var(kidiq$mom_iq) b #&gt; [1] 0.6099746 a &lt;- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq) a #&gt; [1] 25.79978 In \\(\\mathsf{R}\\) li possiamo facilmente trovare con la seguente funzione: fm &lt;- lm(kid_score ~ mom_iq, data = kidiq) coef(fm) #&gt; (Intercept) mom_iq #&gt; 25.7997778 0.6099746 In precedenza abbiamo soltanto accennato al problema di come si possono trovano i coefficienti dei minimi quadrati; ritorneremo su questo punto in seguito, con una simulazione. Per ora, chiediamoci cosa significano i due coefficienti che abbiamo appena trovato. Il coefficiente \\(a\\) si chiama intercetta. L’intercetta, all’interno del diagramma a dispersione, specifica il punto in cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani. Nel caso presente questo valore non è di alcun interesse, perché corrisponde al valore della retta di regressione quando \\(x = 0\\), ovvero quando l’intelligenza della madre è uguale a 0. Vedremo in seguito come, trasformando i dati, è possibile assegnare al coefficiente \\(a\\) un’interpretazione più utile. Per ora mi limito a fornire l’interpretazione del coefficiente. Passando a \\(b\\), possiamo dire che questo secondo coefficiente va sotto il nome di pendenza della retta di regressione. Ovvero ci dice di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso presente, il coefficiente \\(b\\) ci dice che, se il QI delle madri aumenta di 1 punto, il QI dei bambini aumenta in media di 0.61 punti. È importante capire cosa significa che, in base ai risultati della regressione, \\(y\\) aumenta in media di \\(b\\) punti per ciascun aumento unitario di \\(x\\). Il modello statistico di regressione ipotizza che, per ciascun valore osservato \\(x\\) (per esempio, il valore del QI della prima madre del campione, ovvero \\(x = 121.11753\\)) ci sia una distribuzione di valori \\(y\\) nella popolazione, di cui solo uno è stato osservato nel campione. Possiamo facilmente capire che, se consideriamo tutte le madri con QI di 121.12, il punteggio del QI dei loro figli non sia costante, ma assuma tanti valori possibili. Questa distribuzione di valori possibili si chiama distribuzione \\(y\\) condizionata a \\(x\\), ovvero \\(p(y \\mid x_i)\\). Il modello statistico della regressione lineare non può in alcun modo prevedere il valore assunto da ciascuna delle possibili osservazioni che fanno parte della distribuzione \\(p(y \\mid x_i)\\). Il modello della regressione lineare ha un obiettivo più limitato, ovvero si propone di prevedere le medie delle distribuzioni \\(p(y \\mid x_i)\\) conoscendo i valori \\(x\\). Dunque, quando il coefficiente \\(b\\) è uguale a 0.61, questo significa che il modello di regressione predice che la medie della distribuzione condizionata \\(p(y \\mid x_i)\\) aumenta di 0.61 punti se la variabile \\(x\\) (QI delle madri) aumenta di un punto. Questo significa che il modello di regressione non fa una predizione sul punteggio di ciascun valore \\(y_i\\) (in funzione di \\(x\\)), ma solo della media delle distribuzioni condizionate \\(p(y \\mid x_i)\\) di cui il valore osservato \\(y_i\\) è una realizzazione casuale. Possiamo dire la stessa cosa con parole diverse dicendo che il modello di regressione fa delle predizioni sulla componente deterministica di ciascuna osservazione. È più semplice capire questo aspetto se rappresentiamo in maniera grafica la componente “deterministica” \\(\\hat{y}_i = a + b x_i\\) predetta dal modello di regressione. kidiq$yhat &lt;- fm$fitted.values kidiq %&gt;% ggplot(aes(x = mom_iq, y = yhat)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + geom_point( aes(x=mean(mom_iq), y=mean(kid_score)), colour=&quot;red&quot;, size = 4 ) Il diagramma precedente presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). Si vede che i valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione. In precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione: \\[ e_i = y_i - (a + b x_i). \\] Nel caso nella prima osservazione, ad esempio abbiamo: \\[ y_1 = (a + b x_1) + e_1 \\] Abbiamo kidiq$kid_score[1] #&gt; [1] 65 Dunque \\[ e_1 = (a + b x_1) - y_1 \\] e_1 &lt;- kidiq$kid_score[1] - (a + b * kidiq$mom_iq[1]) e_1 #&gt; [1] -34.67839 Ciò significa che il valore osservato \\(y_1 = 65\\) viene scomposto dal modello di regressione in due componenti. La componente deterministica \\(\\hat{y}_1\\), predicibile da \\(x_1\\), è yhat_1 &lt;- a + b * kidiq$mom_iq[1] yhat_1 #&gt; [1] 99.67839 La somma della componente deterministica e della componente erratica, ovviamente, riproduce il valore osservato. yhat_1 + e_1 #&gt; [1] 65 Se sommiamo tutti i residui calcolati rispetto alla retta di regressione dei minimi quadrati otteniamo zero: sum(fm$res) #&gt; [1] 5.373479e-13 25.1.1 Trasformazione dei dati Consideriamo ora i dati \\(y\\) espressi come differenze dalla media: kidiq$xd &lt;- kidiq$mom_iq - mean(kidiq$mom_iq) Il diagramma a dispersione diventa il seguente. kidiq %&gt;% ggplot(aes(x = xd, y = kid_score)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + geom_point( aes(x=mean(xd), y=mean(kid_score)), colour=&quot;red&quot;, size = 4 ) Nel diagramma precedente, la pendenza della retta di regressione è uguale alla precedente, ma in questo grafico all’intercetta può essere assegnata un’interpretazione dotata di senso. fm1 &lt;- lm(kid_score ~ xd, data = kidiq) coef(fm1) #&gt; (Intercept) xd #&gt; 86.7972350 0.6099746 Nel caso di dati così trasformati, l’intercetta è sempre il punto sull’asse \\(y\\) dove la retta di regressione interseca l’ordinata. Ma, in questo caso, dato che abbiamo traslato i dati di una quantità pari a \\(x - \\bar{x}\\), il valore \\(x = 0\\) corrisponde al valore \\(\\bar{x}\\) nel caso dei dati grezzi. Dunque, l’intercetta avrà la seguente interpretazione: nel caso di dati nei quali \\(x\\) è espresso come differenze dalla media, l’intercetta corrisponde al valore atteso della \\(y\\) in corrispondenza di \\(\\bar{x}\\). In altre parole, per i dati così trasformati, l’intercetta corrisponde al QI atteso (ovvero, medio) dei bambini in corrispondenza del QI medio delle madri. 25.1.2 Il metodo dei minimi quadrati Ora che abbiamo visto come interpretare il coefficienti di regressione, chiediamoci come vengono calcolati. La procedura generale è stata brevemente descritta in precedenza. Vediamo ora come si giunge alla stessa conclusione usando una simulazione. Il problema è di trovare i valori \\(a\\) e \\(b\\) tali per cui la quantità \\(\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\\) assume il valore minore possibile. Questo è un problema di minimizzazione rispetto a due parametri. Per dare un’idea di come si fa, semplifichiamo il problema e supponiamo che uno dei due parametri sia noto, ad esempio \\(a\\), così ci resta una sola incognita. Credo una griglia di valori b_grid possibili, ad esempio: nrep &lt;- 1e5 b_grid &lt;- seq(0, 1, length.out = nrep) Definisco una funzione che calcola la quantità \\(\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\\): sse &lt;- function(a, b, x, y) { sum((y - (a + b * x))^2) } Calcolo la somma degli errori quadratici per ciascun possibile valore b_grid, fissando \\(a = 25.79978\\). sse_res &lt;- rep(NA, nrep) for (i in 1:nrep) { sse_res[i] &lt;- sse(a = 25.79978, b = b_grid[i], x = kidiq$mom_iq, y = kidiq$kid_score) } Esaminiamo il risultato ottenuto. plot( b_grid, sse_res, type = &#39;l&#39; ) Il risultato ottenuto con la simulazione b_grid[which.min(sse_res)] #&gt; [1] 0.6099761 riproduce quello ottenuto per via analitica: b #&gt; [1] 0.6099746 Una simulazione simile, ma computazionalmente più complessa, può essere usata per stimare simultaneamente entrambi i parametri. Ci siamo limitati qui ad una proof of concept del caso più semplice. 25.1.3 L’errore standard della regressione Il secondo obiettivo del modello statistico di regressione lineare è quello di stabilire quanto sia grande la componente \\(y\\) predicibile da \\(x\\), per ciascuna osservazione. Un indice assoluto della bontà di adattamento è fornito dalla deviazione standard dei residui, \\(s_e\\), chiamata anche errore standard della stima. Uno stimatore non distorto della varianza dei residui nella popolazione è dato da \\[ s^2_e = \\frac{1}{n-2}\\sum e_i^2 \\] e quindi l’errore standard della stima sarà \\[\\begin{equation} s_e = \\sqrt{\\frac{1}{n-2}\\sum e_i^2}. \\end{equation}\\] Si noti che questa è la stessa formula della varianza (dato che la media dei residui è zero), tranne per il fatto che al denominatore abbiamo \\(n-2\\). Dato che, per calcolare \\(\\hat{y}\\) abbiamo usato due coefficienti (\\(a\\) e \\(b\\)), si dice che “abbiamo perso due gradi di libertà”. Dato che \\(s_e\\) possiede la stessa unità di misura della variabile \\(y\\), l’errore standard della stima può essere considerato come una sorta di “residuo medio.” – usando la stessa interpretazione che diamo alla deviazione standard in generale. Si noti che la formula precedente non fornisce la “deviazione standard dei residui nel campione” (quella formula avrebbe \\(n\\) al denominatore). Invece, fornisce una stima della deviazione standard dei residui nella popolazione da cui il campione è stato estratto. Verifichiamo quanto detto con i dati a disposizione. I residui possono essere trovati nel modo seguente. e &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq) e[1:10] #&gt; [1] -34.678390 17.691747 -11.217173 -3.461529 32.627697 6.382845 #&gt; [7] -41.521041 3.864881 26.414387 11.208068 Oppure nel modo seguente. fm$residuals[1:10] #&gt; 1 2 3 4 5 6 7 #&gt; -34.678390 17.691747 -11.217173 -3.461529 32.627697 6.382845 -41.521041 #&gt; 8 9 10 #&gt; 3.864881 26.414387 11.208068 Calcolo il residuo medio, prendendo il valore assoluto. mean(abs(e)) #&gt; [1] 14.4686 L’errore standard della regressione è sqrt(sum(e^2) / (length(e) - 2)) #&gt; [1] 18.26612 I due numeri non sono uguali, ma possiamo dire che hanno lo stesso ordine di grandezza. Se usiamo la funzione lm() otteniamo lo stesso valore, chiamato Residual standard error. summary(fm) #&gt; #&gt; Call: #&gt; lm(formula = kid_score ~ mom_iq, data = kidiq) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -56.753 -12.074 2.217 11.710 47.691 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 25.79978 5.91741 4.36 1.63e-05 *** #&gt; mom_iq 0.60997 0.05852 10.42 &lt; 2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 18.27 on 432 degrees of freedom #&gt; Multiple R-squared: 0.201, Adjusted R-squared: 0.1991 #&gt; F-statistic: 108.6 on 1 and 432 DF, p-value: &lt; 2.2e-16 25.2 Indice di determinazione Un importante risultato dei minimi quadrati riguarda la cosiddetta scomposizione della devianza mediante la quale si definisce l’indice di determinazione, il quale fornisce una misura relativa della bontà di adattamento del modello di regressione ai dati del campione. Per una generica osservazione \\(x_i, y_i\\), la variazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere descritta come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\): \\[ y_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}). \\] Se consideriamo tutte le osservazioni, la devianza delle \\(y\\) può essere scomposta nel seguente modo: \\[\\begin{align} \\sum (y_i - \\bar{y})^2 &amp;= \\sum \\left[ e_i + (\\hat{y}_i - \\bar{y}) \\right]^2 = \\sum e_i^2 + \\sum (\\hat{y}_i - \\bar{y})^2 + 2 \\sum e_i (\\hat{y}_i - \\bar{y}) \\notag \\end{align}\\] Per i vincoli imposti sul modello statistico di regressione, il doppio prodotto si annulla, infatti \\[\\begin{align} \\sum e_i (\\hat{y}_i - \\bar{y}) &amp;= \\sum e_i \\hat{y}_i - \\bar{y}\\sum e_i = \\sum e_i (a + b x_i) \\notag \\\\ &amp;= a \\sum e_i + b \\sum e_i x_i = 0 \\notag \\end{align}\\] Il termine \\(b \\sum e_i x_i\\) è uguale a zero perché, come vedremo in seguito, i coefficienti di regressione vengono calcolati in modo tale da rendere nulla \\(\\mbox{Cov}(e, x)\\). Di conseguenza, il termine precedente deve essere nullo. Possiamo dunque concludere che la devianza totale (\\(\\mbox{dev}_T\\)) si scompone nella somma di devianza d’errore (o devianza non spiegata) (\\(\\mbox{dev}_E\\)) e devianza di regressione (o devianza spiegata) (\\(\\mbox{dev}_T\\)): \\[\\begin{align} \\underbrace{\\sum_{i=1}^n (y_i - \\bar{y})^2}_{\\tiny{\\text{Devianza totale}}} &amp;= \\underbrace{\\sum_{i=1}^n e_i^2}_{\\tiny{\\text{Devianza di dispersione}}} + \\underbrace{\\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2}_{\\tiny{\\text{Devianza di regressione}}} \\notag \\end{align}\\] La devianza di regressione, \\(\\mbox{dev_R} \\triangleq \\mbox{dev_T} - \\mbox{dev_E}\\), indica dunque la riduzione degli errori al quadrato che è imputabile alla regressione lineare. Il rapporto \\(\\mbox{dev_R}/\\mbox{dev_T}\\), detto indice di determinazione, esprime tale riduzione degli errori in termini proporzionali e definisce il coefficiente di correlazione al quadrato: \\[\\begin{equation} R^2 \\triangleq \\frac{\\mbox{dev_R}}{\\mbox{dev_T}} = 1 - \\frac{\\mbox{dev_E}}{\\mbox{dev_T}}. \\end{equation}\\] Quando l’insieme di tutte le deviazioni della \\(y\\) dalla media è spiegato dall’insieme di tutte le deviazioni della variabile teorica \\(\\hat{y}\\) dalla media, si ha che l’adattamento (o accostamento) del modello al campione di dati è perfetto, la devianza residua è nulla ed \\(r^2 = 1\\); nel caso opposto, la variabilità totale coincide con quella residua, per cui \\(r^2 = 0\\). Tra questi due estremi, \\(r\\) indica l’intensità della relazione lineare tra le due variabili e \\(r^2\\), con \\(0 \\leq r^2 \\leq 1\\), esprime la porzione della devianza totale della \\(y\\) che è spiegata dalla regressione lineare sulla \\(x\\). Per l’esempio in discussione abbiamo quanto segue. La devianza totale è dev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2) dev_t #&gt; [1] 180386.2 La devianza spiegata è dev_r &lt;- sum((fm$fitted.values - mean(kidiq$kid_score))^2) dev_r #&gt; [1] 36248.82 L’indice di determinazione è R2 &lt;- dev_r / dev_t R2 #&gt; [1] 0.2009512 Nell’output di lm() un tale valore è chiamato Multiple R-squared. summary(fm) #&gt; #&gt; Call: #&gt; lm(formula = kid_score ~ mom_iq, data = kidiq) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -56.753 -12.074 2.217 11.710 47.691 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 25.79978 5.91741 4.36 1.63e-05 *** #&gt; mom_iq 0.60997 0.05852 10.42 &lt; 2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 18.27 on 432 degrees of freedom #&gt; Multiple R-squared: 0.201, Adjusted R-squared: 0.1991 #&gt; F-statistic: 108.6 on 1 and 432 DF, p-value: &lt; 2.2e-16 Il risultato ottenuto si può interpretare dicendo che circa il 20% della variabilità dei punteggi del QI dei bambini può essere predetto conoscendo il QI delle madri. 25.2.1 Inferenza sul modello di regressione La discussione precedente era tutta basata sulla trattazione “classica” del modello lineare, ovvero una trattazione basata sulle stime di massima verosimiglianza (se \\(y \\sim \\mathcal{N}(\\alpha + \\beta x, \\sigma)\\), allora le stime dei minimi quadrati coincidono con le stime di massima verosimiglianza). In altre parole, nella discussione precedente non abbiamo considerato in alcun modo le distribuzioni a priori dei parametri \\(\\alpha\\) e \\(\\beta\\). I risultati precedenti si confermano, in un contesto bayesiano, se e solo se imponiamo sui parametri delle distribuzioni a priori non informative (cioè, uniformi). In tali circostanze, le stime di massima verosimiglianza risultano identiche al massimo a posteriori bayesiano. Detto questo, il tema dell’inferenza viene trattato dall’approccio frequentista costruendo la “distribuzione campionaria” dei parametri (ovvero la distribuzione dei valori che i parametri otterrebbero in infiniti campioni casuali (\\(x, y\\)) di ampiezza \\(n\\) estratti dalla medesima popolazione) e poi calcolando gli errori standard dei parametri e gli intervalli di fiducia dei parametri. Una domanda frequente è, per esempio, se la pendenza della retta di regressione sia maggiore di zero. Per rispondere a tale domanda l’approccio frequentista calcola l’intervallo di fiducia al 95% per il parametro \\(\\beta\\). Se tale intervallo non include lo zero, e se il limite inferiore di tale intervallo è maggiore di zero, allora si conclude, con un grado di confidenza del 95%, che il vero parametro \\(\\beta\\) nella popolazione è maggiore di zero. Ovvero, si conclude che vi sono evidenze di un’associazione lineare positiva tra \\(x\\) e \\(y\\). Alla stessa conclusione si può arrivare calcolando, in un ottica bayesiana, l’intervallo di credibilità al 95% per il parametro \\(\\beta\\). I due intervalli sono identici se usiamo una distribuzione a priori piatta. Sono invece diversi se usiamo una distribuzione a priori debolmente informativa, oppure informativa. Solitamente si usa una distribuzione a priori debolmente informativa centrata sullo zero. In tali circostanze, l’uso della distribuzione a priori ha solo un effetto di regolarizzazione, ovvero di riduzione del peso delle osservazioni estreme – un tale risultato statistico è molto desiderabile, ma è difficile da ottenere in un contesto frequentista. Vedremo nel prossimo capitolo come può essere svolta l’inferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano. Commenti e considerazioni finali Il modello lineare bivariato viene usato per descrivere la relazione tra due variabili e per determinare il segno e l’intensità di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base al valore assunto dalla variabile indipendente. "],["ch-reg-lin-stan.html", "Capitolo 26 Modello di regressione in linguaggio Stan 26.1 Specificazione del modello 26.2 Stima bayesiana in linguaggio Stan Commenti e considerazioni finali", " Capitolo 26 Modello di regressione in linguaggio Stan Passiamo ora alla versione bayesiana del modello di regressione. Mostreremo qui che, se vengono usate delle distribuzioni a priori non informative, si ottengono delle distribuzioni a posteriori dei parametri il cui massimo a posteriori è simile alle stime frequentiste dei minimi quadrati. In questo Capitolo, inoltre, mostreremo come sia possibile usare il linguaggio probabilistico Stan per la stima dei parametri del modello di regressione e per l’inferenza. 26.1 Specificazione del modello La specificazione del modello lineare bayesiano inizia nello stesso modo dell’approccio frequentista, ovvero con la specificazione della seguente equazione: \\[ y_i = \\alpha + \\beta x_i + \\varepsilon_i, \\quad i = 1, \\dots, n. \\] Si assume che gli errori, \\(\\varepsilon_i\\), siano indipendenti e identicamente distribuiti come variabili casuali Normali con media zero e varianza costante \\(\\sigma^2\\). Queste ipotesi sono esattamente uguali a quelle che vengono usato nell’inferenza frequentista. Il nostro obiettivo è aggiornare le distribuzioni a priori dei parametri sconosciuti \\(\\alpha\\) e \\(\\beta\\) alla luce dei dati \\(x_1, y_1, \\dots, x_n, y_n\\). Solitamente, è desiderabile scegliere distribuzioni a priori che hanno uno scarso impatto sulla distribuzione a posteriori. Supponiamo che le nostre credenza a priori sui parametri del modello, \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) siano tra loro indipendenti. Allora possiamo scrivere la distribuzione congiunta dei parametri nel modo seguente: \\[ p(\\alpha, \\beta, \\sigma) = p(\\alpha)p(\\beta)p(\\sigma). \\] Possiamo assumere \\(\\alpha \\sim \\mathcal{N}(\\mu_{\\alpha}, \\sigma_{\\alpha})\\) e \\(\\beta \\sim \\mathcal{N}(\\mu_{\\beta}, \\sigma_{\\beta})\\). Per \\(\\sigma\\) possiamo assumere, ad esempio, \\(\\sigma \\sim \\mbox{Cauchy}(a, b)\\). Moltiplicando la verosimiglianza \\[ \\prod_{i=1}^n p(y_i \\mid x_i; \\alpha, \\beta, \\sigma^2) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{-\\frac{(y_i-(\\alpha + \\beta x_i))^2}{2\\sigma^2}} \\] per le distribuzioni a priori dei parametri, si ottiene la distribuzione a posteriori. Tuttavia, tale distribuzione non è risolvibile per via analitica. Come in precedenza, usiamo invece un algoritmo MCMC per ottenere una sequenza di campioni casuali dalla distribuzione a posteriori. 26.2 Stima bayesiana in linguaggio Stan È conveniente usare il linguaggio Stan per ottenere una sequenza MCMC dalla distribuzione a posteriori dei parametri di un modello di regressione. Continuiamo qui l’esempio precedente in cui ci si poneva il problema di descrivere mediante un modello lineare l’associazione tra il QI dei figli e il QI delle madri. Leggiamo i dati kidiq in \\(\\mathsf{R}\\): library(&quot;rio&quot;) df &lt;- rio::import(here::here(&quot;data&quot;, &quot;kidiq.dta&quot;)) head(df) #&gt; kid_score mom_hs mom_iq mom_work mom_age #&gt; 1 65 1 121.11753 4 27 #&gt; 2 98 1 89.36188 4 25 #&gt; 3 85 1 115.44316 4 27 #&gt; 4 83 1 99.44964 3 25 #&gt; 5 115 1 92.74571 4 27 #&gt; 6 98 0 107.90184 1 18 Per farci un’idea del valore dei parametri, adattiamo il modello lineare ai dati mediante la procedura di massima verosimiglianza (come abbiamo fatto nel capitolo precedente): fm &lt;- lm(kid_score ~ mom_iq, data = df) summary(fm) #&gt; #&gt; Call: #&gt; lm(formula = kid_score ~ mom_iq, data = df) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -56.753 -12.074 2.217 11.710 47.691 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 25.79978 5.91741 4.36 1.63e-05 *** #&gt; mom_iq 0.60997 0.05852 10.42 &lt; 2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 18.27 on 432 degrees of freedom #&gt; Multiple R-squared: 0.201, Adjusted R-squared: 0.1991 #&gt; F-statistic: 108.6 on 1 and 432 DF, p-value: &lt; 2.2e-16 Sulla base delle informazioni precedenti, giungiamo alla seguente formulazione bayesiana del modello di regressione lineare: \\[ \\begin{aligned} y_i &amp;\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\ \\mu_i &amp;= \\alpha + \\beta x_i \\\\ \\alpha &amp;\\sim \\mathcal{N}(25, 10) \\\\ \\beta &amp;\\sim \\mathcal{N}(0, 1) \\\\ \\sigma &amp;\\sim \\text{Cauchy}(18, 5) \\end{aligned} \\] Il segno \\(\\sim\\) (tilde) si può leggere “si distribuisce come”. La prima riga definisce la funzione di verosimiglianza e ci dice che ciascuna osservazione \\(y_i\\) è una variabile casuale che segue la distribuzione gaussiana di parametri \\(\\mu_i\\) e \\(\\sigma\\). Le righe successive definiscono le distribuzioni a priori dei parametri. La seconda riga specifica, in maniera deterministica, ciascun \\(\\mu_i\\) come funzione lineare di \\(x_i\\), con parametri \\(\\alpha\\) e \\(\\beta\\). Le due righe successive specificano le distribuzioni a priori per \\(\\alpha\\) e \\(\\beta\\). La distribuzione a priori di \\(\\alpha\\) è una distribuzione gaussiana di parametri \\(\\mu_{\\alpha} = 25\\) e deviazione standard \\(\\sigma_{\\alpha} = 10\\); la distribuzione a priori di \\(\\beta\\) è una distribuzione gaussiana standardizzata. L’ultima riga definisce la distribuzione a priori di \\(\\sigma\\), ovvero una Cauchy di parametri 18 e 5. Avendo descritto in termini astratti le caratteristiche del modello, passiamo ora alla specificazione in linguaggio Stan. model_string_1 = &quot; data { int&lt;lower=0&gt; N; vector[N] y; vector[N] x; } parameters { real alpha; real beta; real&lt;lower=0&gt; sigma; } model { // priors alpha ~ normal(25, 10); beta ~ normal(0, 1); sigma ~ cauchy(18, 5); // likelihood y ~ normal(alpha + beta * x, sigma); } &quot; writeLines(model_string_1, con = &quot;code/simpleregkidiq.stan&quot;) La funzione modelString() registra una stringa di testo mentre writeLines() crea un file nell’indirizzo specificato. Tale file deve avere l’estensione .stan. Sistemiamo i dati nel formato appropriato per Stan. data_list &lt;- list( N = length(df$kid_score), y = df$kid_score, x = df$mom_iq ) La funzione file.path() ritorna l’indirizzo del file con il codice Stan. file_simple_reg &lt;- file.path(&quot;code&quot;, &quot;simpleregkidiq.stan&quot;) La funzione cmdstan_model() traduce il programma Stan in C++ e crea un eseguibile compilato. mod1 &lt;- cmdstan_model(file_simple_reg) Il codice Stan può essere stampato usando il metodo $print(): mod1$print() L’indirizzo dell’eseguibile compilato viene ritornato da $exe_file(): mod1$exe_file() Applicando il metodo $sample() ad un oggetto CmdStanModel eseguiamo il campionamento MCMC: fit_1 &lt;- mod1$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, parallel_chains = 2L, refresh = 0 ) Un sommario della distribuzione a posteriori per i parametri stimati si ottiene con il metodo $summary(), il quale chiama la funzione summarise_draws() del pacchetto posterior: fit_1$summary(c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 3 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha 25.8 25.8 5.05 5.04 17.5 34.0 1.00 5543. 5781. #&gt; 2 beta 0.610 0.610 0.0501 0.0499 0.528 0.693 1.00 5581. 5684. #&gt; 3 sigma 18.3 18.3 0.605 0.603 17.3 19.3 1.00 6957. 6378. Si noti come la soluzione ottenuta sia molto simile (dal punto di vista pratico, equivalente) a quella ottenuta con il metodo dei minimi quadrati. Dall’output possiamo anche valutare la convergenza del modello osservando i valori di Rhat per ciascun parametro. Quando questi sono pari o vicini a 1, le catene hanno realizzato la convergenza. Ci sono molti altri test diagnostici, ma questo test è il più importante per Stan. Oppure possiamo visualizzare i risultati come indicato di seguito. fit_1$cmdstan_summary() Le statistiche diagnostiche sono fornite dal metodo $cmdstan_diagnose(): fit_1$cmdstan_diagnose() È conveniente creare un oggetto di classe stanfit stanfit_1 &lt;- rstan::read_stan_csv(fit_1$output_files()) per poi potere utilizzare le funzioni del pacchetto bayesplot. Ad esempio: stanfit_1 %&gt;% mcmc_trace(pars = c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;)) Infine, eseguendo la funzione launch_shinystan(fit), è possibile analizzare oggetti di classe stanfit mediante le funzionalità del pacchetto ShinyStan. 26.2.1 Standardizzare i dati Il codice Stan viene eseguito più velocemente se l’input è standardizzato così da avere una media pari a zero e una varianza unitaria. Inoltre, si noti un punto importante. Il fatto di standardizzare i dati fa in modo che le distribuzioni a priori sui parametri vengano espresse sulla scala di una v.c. normale standardizzata. Se centriamo sullo 0 le distribuzioni a priori, con una deviazione standard dell’ordine di grandezza dell’unità, perdono di significato i discorsi sull’arbitrarietà delle distribuzioni a priori: nel caso di dati standardizzati le distribuzioni a priori formulate come indicato sopra sono distribuzioni debolmente informative il cui unico scopo è la regolarizzazione dei dati, ovvero di mantenere le inferenze in una gamma ragionevole di valori. Inoltre, l’uso di distribuzioni a priori debolmente informative ha l’effetto desiderabile di limitare l’influenza eccessiva delle osservazioni estreme (valori anomali). Il punto importante è che una tale scelta delle distribuzioni a priori non introduce alcuna distorsione sistematica nella stima a posteriori. Sono possibili due strade per la standardizzazione dei dati. Se non ci sono ragioni particolari per mantenere l’unità di misura dei dati grezzi (ad esempio, se è sufficiente valutare l’intervallo di credibilità per \\(\\beta\\) per determinare se include o meno lo 0), allora possiamo standardizzare i dati prima di passarli a Stan (questa è la procedura usuale). In alternativa, se vogliamo mantenere la soluzione sulla scala delle variabili originarie, è possibile seguire la procedura indicata di seguito. Si passano a Stan i dati grezzi; i dati vengono standardizzati con una trasformazione di variabili all’interno del codice Stan. Viene poi eseguito il campionamento sui dati standardizzati; infine, le stime dei parametri vengono nuovamente trasformate sulla scala delle variabili originarie29. Per ottenere il risultato descritto sopra, si procede come segue. Ponendo \\(y = (y_1, \\dots, y_n)\\) e \\(x = (x_1, \\dots, x_n)\\), il modello lineare può essere scritto come \\[ y_i = \\alpha + \\beta x_i + \\varepsilon_i, \\] dove \\[ \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma). \\] Seguendo la notazione del manuale Stan, i parametri del modello lineare sono denotati da \\(\\alpha\\) e \\(\\beta\\). Per eseguire la standardizzazione dei dati, è necessario centrare i dati, sottraendo da essi la media campionaria, per poi scalarli dividendo per la deviazione standard campionaria. Una singola osservazione \\(u\\) viene standardizzata dalla funzione \\(z\\) definita da \\[ z_y(u) = \\frac{u - \\bar{y}}{\\texttt{sd}(y)} \\] dove la media \\(\\bar{y}\\) è \\[ \\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i, \\] e la deviazione standard è \\[ \\texttt{sd} = \\left(\\frac{1}{n}\\sum_{i=1}^n(y_i - \\bar{y})^2\\right)^{-\\frac{1}{2}}. \\] La trasformata inversa è definita invertendo i due passaggi precedenti: la deviazione standard è usata per scalare i valori \\(u\\) e la media campionaria è usata per traslare la distribuzione dei valori \\(u\\) scalati: \\[ z_y^{-1}(u) = \\texttt{sd}(y)u + \\bar{y}. \\] I risultati riportati sopra consentono di modificare il modello Stan che abbiamo descritto all’inizio del Capitolo al fine di creare un nuovo modello che realizza un campionamento sulla base dei dati standardizzati. Il blocco data è identico al caso precedente. I predittori e la risposta standardizzati sono definiti nel blocco transformed data. Vengono definte due nuove variabili, x_std e y_std, che corrispondono, appunto, ai valori standardizzati \\(x\\) e \\(y\\). I parametri sono chiamati alpha_std e alpha_std in quanto verranno campionati utilizzando la verosimiglianza che deriva dai dati standardizzati: y_std ~ normal(mu_std, sigma_std);. La media delle distribuzioni condizionate \\(y \\mid x_i\\), ovvero \\(\\hat{y}\\), è calcolata come vector[N] mu_std = alpha_std + beta_std * x_std;, ovvero usando i valori \\(x\\) standardizzati, x_std, e i parametri alpha_std e beta_std. Una tale specificazione è contenuta nel blocco transformed parameters. Nel blocco model sono presenti le distribuzioni a priori dei parametri alpha_std e beta_std. In questo esempio, per entrambi i parametri è stata usata una distribuzione a priori \\(\\mathcal{N}(0, 1)\\). Per semplificare la notazione, nel blocco model l’istruzione di campionamento è espressa in forma vettorializzata: y_std ~ normal(alpha_std + beta_std * x_std, sigma_std);. Si pone ancora il problema di trasformare i parametri dalla scala delle variabili standardizzate alla scala delle variabili originarie. I valori dei parametri sulla scala delle variabili originarie calcolati nel blocco generated quantities. I parametri “naturali” così trasformati vengono chiamati alpha, beta e sigma. Le formule necessarie per questa trasformazione possono essere recuperati con un po’ di algebra. \\[\\begin{align} y_n &amp;= \\textrm{z}_y^{-1}(\\textrm{z}_y(y_n)) \\notag\\\\ &amp;= \\textrm{z}_y^{-1} \\left( \\alpha&#39; + \\beta&#39; \\textrm{z}_x(x_n) + \\epsilon_n&#39; \\right) \\notag\\\\ &amp;= \\textrm{z}_y^{-1} \\left( \\alpha&#39; + \\beta&#39; \\left( \\frac{x_n - \\bar{x}}{\\texttt{sd}(x)} \\right) + \\epsilon_n&#39; \\right) \\notag\\\\ &amp;= \\texttt{sd}(y) \\left( \\alpha&#39; + \\beta&#39; \\left( \\frac{x_n - \\bar{x}}{\\texttt{sd}(x)} \\right) + \\epsilon_n&#39; \\right) + \\bar{y} \\notag\\\\ &amp;= \\left( \\texttt{sd}(y) \\left( \\alpha&#39; - \\beta&#39; \\frac{\\bar{x}}{\\texttt{sd}(x)} \\right) + \\bar{y} \\right) + \\left( \\beta&#39; \\frac{\\texttt{sd}(y)}{\\texttt{sd}(x)} \\right) x_n + \\texttt{sd}(y) \\epsilon&#39;_n, \\end{align}\\] da cui \\[ \\alpha = \\texttt{sd}(y) \\left( \\alpha&#39; - \\beta&#39; \\frac{\\bar{x}}{\\texttt{sd}(x)} \\right) + \\bar{y}; \\qquad \\beta = \\beta&#39; \\frac{\\texttt{sd}(y)}{\\texttt{sd}(x)}; \\qquad \\sigma = \\texttt{sd}(y) \\sigma&#39;. \\] Possiamo dunque scrivere il modello in linguaggio Stan nel modo seguente. model_string_2 = &quot; data { int&lt;lower=0&gt; N; vector[N] y; vector[N] x; } transformed data { vector[N] x_std; vector[N] y_std; x_std = (x - mean(x)) / sd(x); y_std = (y - mean(y)) / sd(y); } parameters { real alpha_std; real beta_std; real&lt;lower=0&gt; sigma_std; } transformed parameters { vector[N] mu_std = alpha_std + beta_std * x_std; } model { alpha_std ~ normal(0, 1); beta_std ~ normal(0, 1); sigma_std ~ normal(0, 1); y_std ~ normal(mu_std, sigma_std); } generated quantities { // transform to the original data scale real alpha; real beta; real&lt;lower=0&gt; sigma; alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y); beta = beta_std * sd(y) / sd(x); sigma = sd(y) * sigma_std; } &quot; writeLines(model_string_2, con = &quot;code/simpleregstd.stan&quot;) Usiamo la funzione file.path() per ottenere l’indirizzo del file con il codice Stan. file_simple_reg_std &lt;- file.path(&quot;code&quot;, &quot;simpleregstd.stan&quot;) Compiliamo in C++. mod2 &lt;- cmdstan_model(file_simple_reg_std) Eseguiamo il campionamento MCMC. fit_2 &lt;- mod2$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Usiamo il metodo $summary() per esaminare i risultati. fit_2$summary(c(&quot;alpha_std&quot;, &quot;beta_std&quot;, &quot;sigma_std&quot;, &quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 6 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha_std 0.000107 -0.000149 0.0432 0.0423 -0.0703 0.0715 1.00 18705. #&gt; 2 beta_std 0.448 0.448 0.0438 0.0443 0.375 0.520 1.00 20084. #&gt; 3 sigma_std 0.897 0.896 0.0311 0.0316 0.848 0.950 1.00 18813. #&gt; 4 alpha 25.9 25.8 6.02 6.02 16.0 35.8 1.00 20176. #&gt; 5 beta 0.609 0.609 0.0596 0.0603 0.511 0.707 1.00 20084. #&gt; 6 sigma 18.3 18.3 0.634 0.644 17.3 19.4 1.00 18813. #&gt; # … with 1 more variable: ess_tail &lt;dbl&gt; Si noti anche in questo caso che, avendo usato delle distribuzioni a priori debolmente informative, le stime dei parametri sono molto simili a quelle ottenute mediante la procedura di massima verosimiglianza. coef(fm) #&gt; (Intercept) mom_iq #&gt; 25.7997778 0.6099746 26.2.2 Interpretazione dei parametri Ripeto qui la discussione del capitolo precedente. Assegniamo ai parametri la seguente interpretazione. L’intercetta pari a 25.9 indica il QI medio dei bambini la cui madre ha un QI = 0. Ovviamente questo non ha alcun significato. Vedremo nel modello successivo come trasformare il modello in modo da potere assegnare all’intercetta un’interpretazione sensata. La pendenza di 0.61 indica che, all’aumentare di un punto del QI delle madri, il QI medio dei loro bambini aumenta di 0.61 unità. Se consideriamo la gamma di variazione del QI delle madri nel campione, il QI medio dei bambini cambia di 41 punti. Questo indica un sostanziale effetto del QI delle madri sul QI dei loro bambini: \\((138.89 - 71.04) * 0.61 = 41.39\\). Il parametro \\(\\sigma\\) = 18.3 fornisce una stima della dispersione delle osservazioni attorno al valore predetto dal modello lineare, ovvero fornisce una stima della deviazione standard dei residui attorno al valore atteso del modello lineare. 26.2.3 Centrare i predittori Come abbiamo detto in precedenza, per migliorare l’interpretazione dell’intercetta possiamo “centrare” la \\(x\\), ovvero esprimere la \\(x\\) in termini di scarti dalla media: \\(x - \\bar{x}\\). In tali circostanze, la pendenza della retta specificata dal modello lineare resta immutata, ma l’intercetta corrisponde a \\(\\mathbb{E}(y \\mid x = \\bar{x})\\). Per ottenere questo risultato, è sufficiente modificare i dati passati a Stan. data2_list &lt;- list( N = length(df$kid_score), y = df$kid_score, x = df$mom_iq - mean(df$mom_iq) ) Adattiamo il modello con il nuovo input. fit_3 &lt;- mod2$sample( data = data2_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Trasformiamo l’oggetto fit in un oggetto di classe stanfit: stanfit_3 &lt;- rstan::read_stan_csv(fit_3$output_files()) Esaminiamo le stime a posteriori dei parametri. fit_3$summary(c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 3 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha 86.8 86.8 0.876 0.871 85.4 88.2 1.00 16318. 11494. #&gt; 2 beta 0.609 0.609 0.0591 0.0589 0.513 0.707 1.00 16206. 11236. #&gt; 3 sigma 18.3 18.3 0.630 0.624 17.3 19.4 1.00 15617. 11986. Si noti la nuova intercetta, ovvero 86.8. Questo valore indica il QI medio dei bambini le cui madri hanno un QI pari alla media del campione. Centrare i dati consente dunque di assegnare all’intercetta un’interpretazione utile. Dall’output ottenuto possiamo ricavare, ad esempio, l’intervallo di credibilità al 90%. Ovvero, con un grado di certezza soggettiva del 90%, possiamo concludere che, se consideriamo solo le madri con un QI pari alla media del presente campione, possiamo prevedere che il QI medio dei loro figli sarà compreso nell’intervallo [85.4, 88.2]. Commenti e considerazioni finali La presente discussione suggerisce che è conveniente standardizzare i dati prima di procedere con l’analisi di regressione lineare. Ciò può essere fatto all’interno del codice Stan, oppure prima di passare i dati a Stan. Se i dati vengono standardizzati è facile specificare delle distribuzioni a priori debolmente informative per i parametri centrate sullo zero. Tali distribuzioni a priori hanno, come unico scopo, quello di regolarizzare i dati e di facilitare la stima dei parametri mediante la procedura MCMC, e non introducono alcuna distorsione “arbitraria” nella soluzione. Nella discussione che segue ripeto pari pari ciò che è riportato nel manuale del linguaggio Stan.↩︎ "],["ch-inference-reg-lin-stan.html", "Capitolo 27 Inferenza sul modello lineare 27.1 Rappresentazione grafica dell’incertezza della stima 27.2 Intervalli di credibilità 27.3 Test di ipotesi 27.4 Modello lineare robusto Commenti e considerazioni finali", " Capitolo 27 Inferenza sul modello lineare Un modo per rappresentare l’incertezza dell’inferenza in un ottica bayesiana è quella di presentare graficamente la retta specificata dal modello di regressione lineare. Continuerò qui la discussione dell’esempio descritto nel Capitolo precedente, ovvero, userò i dati kid_score e i valori mom_iq centrati. 27.1 Rappresentazione grafica dell’incertezza della stima Supponiamo (come indicato nel Capitolo precedente) di avere eseguito il campionamento MCMC mediante la seguente istruzione. fit2 &lt;- mod$sample( data = data2_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Per creare una rappresentazione grafica della retta di regressione stimata dal modello bayesiano, insieme all’incertezza della stima, è necessario manipolare i dati contenuti nell’oggetto creato da mod$sample() che contiene i campioni a posteriori dei parametri del modello di regressione lineare, ovvero fit2. Usando la funzione rstan::read_stan_csv() trasformo fit2 in un oggetto di formato stanfit. output_stanfit &lt;- rstan::read_stan_csv(fit2$output_files()) Dall’oggetto output_stanfit estraggo i campioni a posteriori dei parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) con la funzione extract(). post &lt;- rstan::extract(output_stanfit) L’oggetto post così creato è una lista. class(post) #&gt; [1] &quot;list&quot; Esaminiamo il contenuto di post. glimpse(post) #&gt; List of 7 #&gt; $ alpha_std: num [1:16000(1d)] 0.0582 0.0407 -0.0828 0.0997 0.0886 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL #&gt; $ beta_std : num [1:16000(1d)] 0.421 0.494 0.457 0.496 0.491 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL #&gt; $ sigma_std: num [1:16000(1d)] 0.907 0.899 0.878 0.932 0.972 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL #&gt; $ alpha : num [1:16000(1d)] 88 87.6 85.1 88.8 88.6 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL #&gt; $ beta : num [1:16000(1d)] 0.573 0.672 0.622 0.675 0.668 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL #&gt; $ sigma : num [1:16000(1d)] 18.5 18.3 17.9 19 19.8 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL #&gt; $ lp__ : num [1:16000(1d)] -170 -169 -171 -172 -174 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL L’output di glimpse() ci dice che alpha è un vettore di 16,000 elementi. Ciascuno di questi elementi è un valore estratto a caso dalla distribuzione a posteriori del parametro \\(\\alpha\\). È dunque possibile calcolare una stima puntuale della distribuzione a posteriori del parametro \\(\\alpha\\) semplicemente trovando la media di tali valori. mean(post$alpha) #&gt; [1] 86.7936 Lo stesso si può dire di beta. mean(post$beta) #&gt; [1] 0.6082648 Per creare un diagramma a dispersione dei dati con sovrapposto il valore atteso della \\(y\\) (ovvero, la retta di regressione) usiamo la sintassi seguente. tibble( kid_score = df$kid_score, mom_iq = df$mom_iq - mean(df$mom_iq) ) %&gt;% ggplot(aes(mom_iq, kid_score)) + geom_point() + geom_abline( intercept = mean(post$alpha), slope = mean(post$beta) ) Si noti l’uso della funzione geom_abline() che prende come argomenti l’intercetta e la pendenza di una retta. Nel caso presente, tali argomenti corrispondono a mean(post$alpha) e mean(post$beta), ovvero, specificano i valori a posteriori più plausibili dei parametri \\(\\alpha\\) e \\(\\beta\\). Con le istruzioni precedenti abbiamo disegnato una singola retta. Ma una singola retta non ci fa capire qual è l’incertezza associata alle stime dei parametri \\(\\alpha\\) e \\(\\beta\\). Una tale incertezza può essere visualizzata tracciando molteplici rette, ciascuna delle quali definita da un diverso valore estratto a caso dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\). Per fare ciò dobbiamo estrarre le informazioni richieste dall’oggetto output_stanfit che è stato creato. A tal fine possiamo usare, ad esempio, le funzioni del pacchetto tidybayes. Iniziamo a elencare i nomi degli oggetti contenuti in output_stanfit. tidybayes::get_variables(output_stanfit) #&gt; [1] &quot;alpha_std&quot; &quot;beta_std&quot; &quot;sigma_std&quot; &quot;alpha&quot; #&gt; [5] &quot;beta&quot; &quot;sigma&quot; &quot;lp__&quot; &quot;accept_stat__&quot; #&gt; [9] &quot;treedepth__&quot; &quot;stepsize__&quot; &quot;divergent__&quot; &quot;n_leapfrog__&quot; #&gt; [13] &quot;energy__&quot; Vogliamo creare un DataFrame in formato tidy, cioè, tale per cui le osservazioni stanno sulle righe e le variabili stanno sulle colonne; una colonna per le stime a posteriori di \\(\\alpha\\) e una colonna per le stime a posteriori di \\(\\beta\\). Un tale risultato si ottiene con la funzione spread_draws(). draws &lt;- output_stanfit %&gt;% spread_draws(beta, alpha) Esaminiamo l’oggetto draws. draws %&gt;% head(10) #&gt; # A tibble: 10 × 5 #&gt; .chain .iteration .draw beta alpha #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 1 0.632 88.4 #&gt; 2 1 2 2 0.491 87.5 #&gt; 3 1 3 3 0.717 85.9 #&gt; 4 1 4 4 0.478 87.5 #&gt; 5 1 5 5 0.610 86.4 #&gt; 6 1 6 6 0.570 86.7 #&gt; 7 1 7 7 0.623 87.0 #&gt; 8 1 8 8 0.616 87.2 #&gt; # … with 2 more rows L’oggetto draws contiene le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) nel formato desiderato. Possiamo ora generare un diagramma a dispersione con ggplot() a cui vengono aggiunte tutte le 16,000 rette di regressione definite da ciascuna coppia di valori \\(\\hat{\\alpha}\\) e \\(\\hat{\\beta}\\) contenuti nelle righe del DataFrame draws. tibble( kid_score = df$kid_score, mom_iq = df$mom_iq - mean(df$mom_iq) ) %&gt;% ggplot(aes(mom_iq, kid_score)) + geom_point() + geom_abline( data = draws, aes(intercept = alpha, slope = beta), size = 0.2, alpha = 0.01, color = &quot;darkgray&quot; ) + geom_abline( intercept = mean(post$alpha), slope = mean(post$beta) ) + labs( x = &quot;Quoziente di intelligenza della madre&quot;, y = &quot;Quoziente di intelligenza del bambino&quot; ) Tale risultati si ottiene nella seguente porzione del codice \\(\\mathsf{R}\\). geom_abline( data = draws, aes(intercept = alpha, slope = beta), size = 0.2, alpha = 0.01, color = &quot;darkgray&quot; ) L’argomento grafico alpha = 0.01 passato a geom_abline() specifica la trasparenza del segmento che rappresenta ciascuna retta. Ho usato un valore molto basso per questo argomento per fare in modo che, anche sovrapponendo 16,000 rette, si produca comunque ancora un certo grado di trasparenza. Il grafico mostra che le rette di regressione costruite estraendo a caso valori dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) sono molto simili tra loro. Ciò significa che, se combiniamo le informazioni fornite dai dati con le nostre credenza precedenti (qui, dei prior poco informativi), allora dobbiamo concludere che l’incertezza relativa alla dipendenza lineare del quoziente di intelligenza del bambino da quello della madre è decisamente piccola. In altre parole, siamo molto sicuri che c’è una associazione lineare positiva tra le due variabili: in media il QI dei figli è positivamente associato al QI della madre. Si presti attenzione al fatto che il modello statistico ci conduce a tale conclusione: siamo sicuri dell’esistenza di un’associazione positiva tra il QI dei figli e il QI della madre. Ma il modello statistico non ci dice nulla sulle cause di questa associazione: ci dice soltanto che le due variabili tendono a covariare. Non ci dice che il QI della madre è la “causa” del QI del figlio. Questo è un argomento su cui è stata fatta molta ricerca (e di ciò qui non diremo nulla). Ma, al di là dei risultati di tali ricerche, se consideriamo solo il risultato del modello statistico qui esaminato, nulla si può concludere sui rapporti di causa/effetto tra QI della madre e QI del figlio. La presenza di un’associazione statistica, infatti, è condizione necessaria ma non sufficiente per potere affermare l’esistenza di un nesso causale. 27.2 Intervalli di credibilità Abbiamo visto come l’incertezza sulla stima dei parametri possa essere espressa graficamente. In alternativa, l’incertezza inferenziale sui parametri può essere descritta mediante gli intervalli di credibilità, ovvero gli intervalli che contengono la quota desiderata (es., il 95%) della distribuzione a posteriori. Per l’esempio che stiamo discutendo, gli intervalli di credibilità (a code uguali) al 95% si ottengono nel modo seguente: rstantools::posterior_interval( as.matrix(output_stanfit), prob = 0.95 ) #&gt; 2.5% 97.5% #&gt; alpha_std -0.08427372 0.08441589 #&gt; beta_std 0.36136782 0.53165187 #&gt; sigma_std 0.83902970 0.96033440 #&gt; alpha 85.07713000 88.52020750 #&gt; beta 0.49171840 0.72342520 #&gt; sigma 17.12519250 19.60110750 #&gt; lp__ -173.15907500 -168.54400000 Un grafico che, nel caso dei dati standardizzati, riporta l’intervallo di credibilità al livello di probabilità desiderato per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) si ottiene con l’istruzione seguente. mcmc_areas( fit2$draws(c(&quot;alpha_std&quot;, &quot;beta_std&quot;, &quot;sigma_std&quot;)), prob = 0.8, prob_outer = 0.95 ) Oppure nel modo nel modo seguente. output_stanfit %&gt;% mcmc_intervals( pars = c(&quot;alpha_std&quot;, &quot;beta_std&quot;, &quot;sigma_std&quot;), prob = 0.8, prob_outer = 0.95 ) Gli intervalli di massima densità si trovano nel modo seguente. bayestestR::hdi(output_stanfit, ci = 0.95) #&gt; Highest Density Interval #&gt; #&gt; Parameter | 95% HDI #&gt; -------------------------- #&gt; alpha_std | [-0.08, 0.08] #&gt; beta_std | [ 0.36, 0.53] #&gt; alpha | [85.08, 88.52] #&gt; beta | [ 0.49, 0.72] 27.2.1 Quale soglia usare? Ripeto c’è niente di “magico” o necessario relativamente al livello di 0.95: il valore 0.95 è arbitrario. È quello utilizzato nelle pubblicazioni scientifiche, di consuetudine. Almeno in psicologia. In fisica, ad esempio, si usa un intervallo molto più grande. Kennedy-Shaffer (2019) descrivono l’origine storica di questa scelta. Nel 1925 Ronal Fisher pubblicò la prima edizione della sua influente opera Statistical Methods for Research Workers. In tale testo troviamo il seguente passaggio: The value for which P=.05, or 1 in 20, is 1.96 or nearly 2; it is convenient to take this point as a limit in judging whether a deviation is to be considered significant or not. Deviations exceeding twice the standard deviation are thus formally regarded as significant. Using this criterion we should be led to follow up a negative result only once in 22 trials, even if the statistics are the only guide available. Small effects would still escape notice if the data were insufficiently numerous to bring them out, but no lowering of the standard of significance would meet this difficulty (Fisher, 1925, p. 47) Questo paragrafo rende immediatamente evidente il motivo per cui Fisher afferma che il valore 0.05 è conveniente: è più o meno equivalente alla probabilità di trovarsi a più di due deviazioni standard dalla media di una variabile casuale normalmente distribuita. In questo modo, 0.05 può essere visto non come un numero dotato in un qualche significato importante, ma solo come un valore che risultava dalla necessità di facilità di calcolo, prima che i computer rendessero obsolete le tabelle e le approssimazioni. In seguito, nell’applicare la statistica alla distribuzione χ2, Fisher osserva che [w]e shall not often be astray if we draw a conventional line at .05, and consider that higher values of χ2 indicate a real discrepancy (Fisher, 1925, p. 79). Sulla base di queste affermazioni di Fisher, la soglia di 0.95 è diventata la consuetudine nella comunità scientifica – o almeno, in parte di essa. Ma sono ovviamente possibili tantissime altre soglie per quantificare la nostra incertezza: alcuni ricercatori usano il livello di 0.89, altri quello di 0.5. Se l’obiettivo è quello di descrivere il livello della nostra incertezza relativamente alla stima del parametro, allora dobbiamo riconoscere che la nostra incertezza è descritta dall’intera distribuzione a posteriori. Per cui il metodo più semplice, più diretto e più completo per descrivere la nostra incertezza rispetto alla stima dei parametri è semplicemente quello di riportare graficamente tutta la distribuzione a posteriori. Una rappresentazione della distribuzione a posteriori dei parametri del modello per l’esempio presente si ottiene con la seguente istruzione. rstan::stan_dens( output_stanfit, pars = c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;), fill = &quot;lightgray&quot; ) 27.3 Test di ipotesi È facile valutare ipotesi direzionali usando Stan. Per esempio, la probabilità \\(P(\\hat{\\beta}_1 &gt; 0)\\) è sum(post$beta &gt; 0) / length(post$beta) #&gt; [1] 1 ovvero, la probabilità \\(P(\\hat{\\beta}_1 &lt; 0)\\) è sum(post$beta &lt; 0) / length(post$beta) #&gt; [1] 0 Ciò significa che, relativamente alla presenza di un’associazione lineare positiva tra QI della madre e QI del figlio, la forza dell’evidenza è enorme. 27.4 Modello lineare robusto Spesso i ricercatori devono affrontare il problema degli outlier: in presenza di outlier, un modello statistico basato sulla distribuzione gaussiana produrrà delle stime distorte dei parametri (ovvero stime che non si generalizzano ad altri campioni di dati). Il metodo tradizionale per affrontare questo problema è quello di eliminare gli outlier prima di eseguire l’analisi statistica. Il problema di questo approccio, però, è che il criterio utilizzato per eliminare gli outlier, quale esso sia, è arbitrario; dunque, usando criteri diversi per la rimozione di outlier, i ricercatori finiscono per trovare risultati diversi. Questo problema trova una semplice soluzione nell’approccio bayesiano. Il modello lineare che abbiamo dicusso finora ipotizza una specifica distribuzione degli errori, ovvero \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\). In un modello formulato in questi termini, la presenza di solo un valore anomalo e influente ha un effetto drammatico sulle stime dei parametri. Per fare un esempio, introduciamo un singlo valore anomalo e influente nel set dei dati dell’esempio che stiamo discutendo: df2 &lt;- df df2$kid_score[434] &lt;- -500 df2$mom_iq[434] &lt;- 140 Per comodità, calcoliamo le stime di \\(\\alpha\\) e \\(\\beta\\) con il metodo dei minimi quadrati (tali stime sono simili a quelle che si otterrebbero con un modello bayesiano gaussiano che impiega distribuzioni a priori debolmente informative). Sappiamo che, nel campione originale di dati, \\(\\hat{\\beta} \\approx 0.6\\). In presenza di un solo outlier, la stima di \\(\\beta\\) viene drammaticamente ridotta. lm(kid_score ~ mom_iq, data = df2) %&gt;% coef() #&gt; (Intercept) mom_iq #&gt; 49.187954 0.362552 In generale, però, non è necessario assumere \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\). È altrettanto valido un modello che ipotizza una diversa distribuzione per gli errori come, ad esempio, la distribuzione \\(t\\) di Student con un piccolo numero di gradi di libertà. Una caratteristica della \\(t\\) di Student è che le code della distribuzione contengono una massa di probabilità maggiore della distribuzione gaussiana. Ciò fornisce alla \\(t\\) di Student la possibilità di “rendere conto” della presenza di osservazioni lontane dalla media della distribuzione. In altri termini, se in modello lineare usiamo la \\(t\\) di Student quale distribuzione degli errori, la presenza di outlier avrà un’influenza minore sulle stime dei parametri di quanto avviene nel tradizionale modello lineare gaussiano. Per verificare questa affermazione, modifichiamo il codice Stan usato in precedenza in modo tale da ipotizzare che \\(y\\) segua una distribuzione \\(t\\) di Student con un numero \\(\\nu\\) gradi di libertà stimato dal modello: student_t(nu, mu, sigma).30 modelString &lt;- &quot; data { int&lt;lower=0&gt; N; vector[N] y; vector[N] x; } transformed data { vector[N] x_std; vector[N] y_std; x_std = (x - mean(x)) / sd(x); y_std = (y - mean(y)) / sd(y); } parameters { real alpha_std; real beta_std; real&lt;lower=0&gt; sigma_std; real&lt;lower=1&gt; nu; // degrees of freedom is constrained &gt;1 } model { alpha_std ~ normal(0, 1); beta_std ~ normal(0, 1); sigma_std ~ normal(0, 1); nu ~ gamma(2, 0.1); // Juárez and Steel(2010) y_std ~ student_t(nu, alpha_std + beta_std * x_std, sigma_std); } generated quantities { real alpha; real beta; real&lt;lower=0&gt; sigma; alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y); beta = beta_std * sd(y) / sd(x); sigma = sd(y) * sigma_std; } &quot; writeLines(modelString, con = &quot;code/simpleregstdrobust.stan&quot;) Costruiamo la lista dei dati usando il data.frame df2 che include l’outlier: data3_list &lt;- list( N = length(df2$kid_score), y = df2$kid_score, x = df2$mom_iq - mean(df2$mom_iq) ) Adattiamo il modello lineare robusto ai dati: file &lt;- file.path(&quot;code&quot;, &quot;simpleregstdrobust.stan&quot;) mod &lt;- cmdstan_model(file) fit4 &lt;- mod$sample( data = data3_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Se esaminiamo le stime dei parametri notiamo che la stima di \\(\\beta\\) non è stata influenzata dalla presenza di un’osservazione anomala e influente: fit4$summary(c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;, &quot;nu&quot;)) #&gt; # A tibble: 4 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha 87.8 87.8 0.901 0.898 86.3 89.3 1.00 14740. 12422. #&gt; 2 beta 0.602 0.602 0.0589 0.0587 0.505 0.699 1.00 14903. 11582. #&gt; 3 sigma 15.9 15.9 0.800 0.803 14.6 17.2 1.00 12993. 11619. #&gt; 4 nu 5.58 5.46 1.15 1.09 3.93 7.64 1.00 12998. 11288. I risultati mostrano come il modello lineare robusto non risente della presenza di outlier (almeno nel caso presente). Commenti e considerazioni finali Nell’approccio bayesiano possiamo rappresentare l’incertezza delle nostre credenze a posteriori in due modi: mediante la rappresentazione grafica dell’intera distribuzione a posteriori dei parametri o mediante l’uso degli intervalli di credibilità. Un bonus della discussione del presente Capitolo è quello di mostrare come il modello lineare tradizionale (che assume \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\)) possa essere facilmente esteso nei termini di un modello robusto il quale offre una semplice soluzione al problema di ridurre l’effetto della presenza di osservazioni anomale e influenti. References "],["ch-comp-two-means-stan.html", "Capitolo 28 Confronto tra due gruppi indipendenti 28.1 Modello lineare con una variabile dicotomica 28.2 La dimensione dell’effetto Commenti e considerazioni finali", " Capitolo 28 Confronto tra due gruppi indipendenti Il problema del confronto tra due gruppi indipendenti può essere formulato nei termini di un modello lineare nel quale la variabile \\(X\\) è dicotomica, ovvero assume solo due valori. 28.1 Modello lineare con una variabile dicotomica Se \\(X\\) è una variabile dicotomica con valori 0 e 1, allora per il modello lineare \\(\\mu_i = \\alpha + \\beta x_i\\) abbiamo quanto segue. Quando \\(x=0\\), il modello diventa \\[ \\mu_i = \\alpha \\] mentre, quando \\(x=1\\), il modello diventa \\[ \\mu_i = \\alpha + \\beta. \\] Ciò significa che il parametro \\(\\alpha\\) è uguale al valore atteso del gruppo codificato con \\(X=0\\) e il parametro \\(\\beta\\) è uguale alla differenza tra le medie dei due gruppi (essendo la media del secondo gruppo uguale a \\(\\alpha + \\beta\\)). Il parametro \\(\\beta\\), dunque, codifica l’effetto di una manipolazione sperimentale o di un trattamento, e l’inferenza su \\(\\beta\\) corrisponde direttamente all’inferenza sull’efficacia di un trattamento o di un effetto sperimentale. L’inferenza su \\(\\beta\\), dunque, viene utilizzata per capire quanto “credibile” può essere considerato l’effetto di un trattamento o di una manipolazione sperimentale. 28.1.1 Confronti, non effetti Per “effetto di un trattamento” si intende la differenza tra le medie di due gruppi (per esempio, il gruppo “sperimentale” e il gruppo “di controllo”). Gelman, Hill, and Vehtari (2020) fanno notare come l’uso della terminologia “effetto” implica un modello causale: una variazione di \\(X\\) produce una variazione di \\(Y\\). In generale, il modello lineare descrive una regolarità osservabile nel campione di dati. Ma questa regolarità (ovvero, la presenza di una relazione approssimativamente lineare tra \\(X\\) e \\(Y\\)) non ci dice nulla della presenza (o dell’assenza) di una relazione di causa/effetto tra queste variabili. L’associazione osservata tra le variabili \\(X\\) e \\(Y\\) potrebbe dipendere dall’effetto di una o più altre variabili non misurate, senza che tra \\(X\\) e \\(Y\\) ci sia alcuna relazione causale. In tali circostanze, l’interpretazione più appropriata dei coefficienti del modello lineare è quella che ci porta a pensare ai coefficienti del modello come ai risultati di un confronto. Nel caso presente, il confronto è quello tra il valore atteso del quoziente di intelligenza dei bambini, quando la madre ha oppure non ha completato il ciclo di istruzione secondaria superiore. Dato che l’affermazione precedente è formulata nei termini del valore atteso, questo significa che facciamo riferimento ad un campione di osservazioni. Niente viene detto della relazione causale tra il quoziente di intelligenza del bambino e l’ottenimento del diploma di scuola superiore da parte della madre all’interno del singolo soggetto. Quindi, quando usiamo il termine “effetto” dobbiamo sempre pensare a tale termine come come se fosse contenuto tra virgolette. 28.1.2 Un esempio concreto Esaminiamo nuovamente i dati kid_score discussi da Gelman, Hill, and Vehtari (2020). La domanda della ricerca è se il QI del figlio (misurato sulla scala PIAT) è associato al livello di istruzione della madre. Codifichiamo il livello di istruzione della madre (\\(x\\)) con una variabile indicatrice (ovvero, una variabile che assume solo i valori 0 e 1) tale per cui: \\(x=0\\): la madre non ha completato la scuola secondaria di secondo grado (scuola media superiore); \\(x=1\\): la madre ha completato la scuola media superiore. Supponiamo che i dati siano contenuti nel data.frame df. library(&quot;rio&quot;) df &lt;- rio::import(here(&quot;data&quot;, &quot;kidiq.dta&quot;)) Calcoliamo le statistiche descrittive per i due gruppi: df %&gt;% group_by(mom_hs) %&gt;% summarise( mean_kid_score = mean(kid_score), std = sqrt(var(kid_score)) ) #&gt; # A tibble: 2 × 3 #&gt; mom_hs mean_kid_score std #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 77.5 22.6 #&gt; 2 1 89.3 19.0 Il punteggio medio PIAT è pari a 77.5 per i bambini la cui madre non ha il diploma di scuola media superiore e pari a 89.3 per i bambini la cui madre ha completato la scuola media superiore. Questa differenza suggerisce un’associazione tra le variabili, ma tale differenza potrebbe essere soltanto la conseguenza della variabilità campionaria, senza riflettere una caratteristica generale della popolazione. Come possiamo usare il modello statistico lineare per fare inferenza sulla differenza osservata tra i due gruppi? Non dobbiamo fare nient’altro che usare il modello lineare che abbiamo definito in precedenza. modelString = &quot; data { int&lt;lower=0&gt; N; vector[N] y; vector[N] x; } transformed data { vector[N] x_std; vector[N] y_std; x_std = (x - mean(x)) / sd(x); y_std = (y - mean(y)) / sd(y); } parameters { real alpha_std; real beta_std; real&lt;lower=0&gt; sigma_std; } model { alpha_std ~ normal(0, 2); beta_std ~ normal(0, 2); sigma_std ~ cauchy(0, 2); y_std ~ normal(alpha_std + beta_std * x_std, sigma_std); } generated quantities { real alpha; real beta; real&lt;lower=0&gt; sigma; real cohen_d; alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y); beta = beta_std * sd(y) / sd(x); sigma = sd(y) * sigma_std; cohen_d = beta / sigma; } &quot; writeLines(modelString, con = &quot;code/simpleregstd.stan&quot;) Come in precedenza, salviamo i dati in un oggetto di classe list: data_list &lt;- list( N = length(df$kid_score), y = df$kid_score, x = df$mom_hs ) Compiliamo il modello: file &lt;- file.path(&quot;code&quot;, &quot;simpleregstd.stan&quot;) mod &lt;- cmdstan_model(file) Adattiamo il modello ai dati: fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Creiamo un grafico con i valori predetti dal modello lineare: stanfit &lt;- rstan::read_stan_csv(fit$output_files()) posterior &lt;- extract(stanfit) tibble( kid_score = df$kid_score, mom_hs = df$mom_hs ) %&gt;% ggplot(aes(mom_hs, kid_score)) + geom_point() + geom_abline(intercept = mean(posterior$alpha), slope = mean(posterior$beta)) + labs( y = &quot;Quoziente di intelligenza del bambino&quot;, x = &quot;Diploma di istruzione secondaria di secondo grado della madre\\n(0 = no; 1 = sì)&quot; ) + scale_x_continuous(breaks=c(0, 1)) Le stime a posteriori dei parametri si ottengono con: fit$summary(c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma&quot;, &quot;cohen_d&quot;)) #&gt; # A tibble: 4 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha 77.6 77.5 2.08 2.06 74.1 81.0 1.00 16538. 12192. #&gt; 2 beta 11.8 11.7 2.35 2.34 7.88 15.6 1.00 16718. 12319. #&gt; 3 sigma 19.9 19.9 0.676 0.671 18.8 21.0 1.00 15949. 10908. #&gt; 4 cohen_d 0.592 0.591 0.120 0.119 0.393 0.788 1.00 16771. 12647. I risultati confermano ciò che ci aspettavamo: il coefficiente \\(\\texttt{alpha} = 77.56\\) corrisponde alla media del gruppo codificato con \\(x = 0\\), ovvero la media dei punteggi PIAT per i bambini la cui madre non ha completato la scuola media superiore; il coefficiente \\(\\texttt{beta} = 11.76\\) corrisponde alla differenza tra le medie dei due gruppi, ovvero 89.32 - 77.55 = 11.77 (con piccoli errori di approssimazione). La seguente chiamata ritorna l’intervallo di credibilità al 95% per tutti i parametri del modello: rstantools::posterior_interval( as.matrix(stanfit), prob = 0.95 ) #&gt; 2.5% 97.5% #&gt; alpha_std -0.09401587 0.09248375 #&gt; beta_std 0.14360650 0.32886135 #&gt; sigma_std 0.91337438 1.04372000 #&gt; alpha 73.43237000 81.62094500 #&gt; beta 7.13510525 16.33961500 #&gt; sigma 18.64258750 21.30290500 #&gt; cohen_d 0.35667085 0.82770125 #&gt; lp__ -208.90605000 -204.32400000 Possiamo dunque concludere che i bambini la cui madre ha completato la scuola superiore ottengono in media circa 12 punti in più rispetto ai bambini la cui madre non ha completato la scuola superiore. L’intervallo di credibilità al 95% ci dice che possiamo essere sicuri al 95% che tale differenza sia di almeno 7 punti e possa arrivare fino a ben 16 punti. Per riassumere, possiamo concludere, con un grado di certezza soggettiva del 95%, che c’è un’associazione positiva tra il livello di scolarità della madre e l’intelligenza del bambino: le madri che hanno livello di istruzione più alto della media tendo ad avere bambini il cui QI è anch’esso più alto della media. 28.2 La dimensione dell’effetto Nel caso di due gruppi indipendenti, la dimensione dell’effetto si può stimare con la statistica \\(d\\) di Cohen: \\[ d={\\frac {{\\bar {y}}_{1}-{\\bar {y}}_{2}}{s}}. \\] Nel caso presente, la differenza \\({\\bar {y}}_{1}-{\\bar {y}}_{2}\\) corrisponde a al parametro \\(\\beta\\) del modello lineare. Inoltre, una stima della deviazione starndard comune dei due gruppi è fornita dalla deviazione standard della regressione, ovvero dal parametro \\(\\sigma\\). Nel blocco generated quantities del modello Stan ho calcolato cohen_d = beta / sigma. Ciò significa che Stan calcolerà la distribuzione a posteriori del parametro cohen_d. Possiamo dunque riassumere la distribuzione a posteriori di cohen_d con un qualche indice di tendenza centrale (che sarà la nostra stima della dimensione dell’effetto) e calcolare l’intervallo di credibilità, per esempio al 95%. Questi risultati si ottengono con l’istruzione riportata di seguito: posterior::summarise_draws( stanfit, ~ quantile(.x, probs = c(0.025, 0.5, 0.975)) ) #&gt; # A tibble: 8 × 4 #&gt; variable `2.5%` `50%` `97.5%` #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha_std -0.0940 -0.000366 0.0925 #&gt; 2 beta_std 0.144 0.236 0.329 #&gt; 3 sigma_std 0.913 0.974 1.04 #&gt; 4 alpha 73.4 77.5 81.6 #&gt; 5 beta 7.14 11.7 16.3 #&gt; 6 sigma 18.6 19.9 21.3 #&gt; 7 cohen_d 0.357 0.591 0.828 #&gt; 8 lp__ -209. -205. -204. I risultati dell’analisi bayesiana coincidono con quelli che si ottengono utilizzando la formula del \\(d\\) di Cohen con le medie dei due gruppi e una stima della varianza pooled. Il calcolo della statistica \\(d\\) di Cohen è fornita, ad esempio, dal pacchetto effectsize: library(&quot;effectsize&quot;) (d &lt;- cohens_d(kid_score ~ mom_hs, data = df)) #&gt; Cohen&#39;s d | 95% CI #&gt; -------------------------- #&gt; -0.59 | [-0.83, -0.36] #&gt; #&gt; - Estimated using pooled SD. Il fatto che l’output abbia un segno negativo dipende dal fatto che è stata sottratta la media maggiore dalla media minore (in altri termini, dobbiamo guardare il risultato in valore assoluto). In conclusione, il valore \\(d\\) di Cohen di entità “media” [\\(d\\) &gt; 0.5; Sawilowsky (2009)] può essere interpretato dicendo che la scolarità delle madri ha un’influenza non trascurabile sul QI dei bambini. Commenti e considerazioni finali La dimensione dell’effetto formulata nei termini dell’indice \\(d\\) di Cohen fornisce un indice che non dipende dall’unità di misura delle variabili, ovvero è una differenza media standardizzata. L’interpretazione di \\(d\\) è semplice: la scala di \\(d\\) è la deviazione standard. Se, per esempio, \\(d = 0.5\\), allora la media di un primo gruppo è mezza deviazione standard più grande della media del secondo gruppo. In questo Capitolo abbiamo visto come \\(d\\) possa essere calcolato mediante un modello lineare bayesiano implementato in linguaggio Stan. References "],["ch-pred-checks.html", "Capitolo 29 Predictive checks 29.1 Distribuzione predittiva a posteriori 29.2 Distribuzione predittiva a priori Commenti e considerazioni finali", " Capitolo 29 Predictive checks In precedenza abbiamo visto come si genera la distribuzione predittiva a posteriori nel caso del modello più semplice: quello di un’unica variabile con una data distribuzione di probabilità. In particolare, abbiamo considerato il caso beta-binomiale. In questo Capitolo estenderemo la discussione al caso del modello di regressione lineare. Esamineremo un esempio di posterior predictive check in cui simuleremo \\(p(y^{rep} \\mid \\theta, y)\\) e un esempio di prior predictive check in cui simuleremo \\(p(y^{rep} \\mid \\mathcal{M})\\), ovvero condizionando il modello al meccanismo generatore dei dati \\(\\mathcal{M}\\), ma senza però includere i dati del campione. 29.1 Distribuzione predittiva a posteriori Consideriamo qui un esempio nel quale vengono usati i dati kidiq (Gelman, Hill, and Vehtari 2020). Leggiamo i dati in \\(\\mathsf{R}\\). library(&quot;rio&quot;) df &lt;- rio::import(here(&quot;data&quot;, &quot;kidiq.dta&quot;)) Per svolgere l’analisi bayesiana sistemiamo i dati (standardizzati) nel formato appropriato per Stan: data_list &lt;- list( N = length(df$kid_score), x = scale(df$mom_iq)[, 1], y = scale(df$kid_score)[, 1] ) Il seguente listato specifica il codice Stan necessario per simulare dati dalla distribuzione predittiva a posteriori. stancode &lt;- &#39; data { int&lt;lower=0&gt; N; vector[N] x; vector[N] y; } parameters { real alpha; real beta; real&lt;lower=0&gt; sigma; } model { alpha ~ normal(0, 1); beta ~ normal(0, 1); sigma ~ normal(0, 1); y ~ normal(alpha + beta * x, sigma); } generated quantities { vector[N] y_rep; for (i in 1 : N) { y_rep[i] = normal_rng(alpha + beta * x[i], sigma); } } &#39; writeLines(stancode, con = &quot;code/post_pred_check_1.stan&quot;) Si noti il blocco generated quantities. In tale blocco del codice abbiamo definito la variabile y_rep. In precedenza, tali valori sono stati chiamati \\(\\tilde{y}\\). Dunque, y_rep corrisponde a possibili futuri campioni di dati. La variabile y_rep è un campione di N = 434 possibili osservazioni future. Le abbiamo calcolate usando x, i valori della variabile indipendente del campione presente. Quindi immaginiamo che in tutti i possibili campioni futuri di 434 osservazioni i valori \\(x\\) siano gli stessi del campione osservato. Questa è un’assunzione del modello di regressione lineare: i valori \\(x\\) sono considerati “fissi” nell’universo dei campioni. Nel caso presente, i primi 10 valori \\(x\\) (QI della madre) standardizzati sono i seguenti: scale(df$mom_iq)[, 1][1:10] #&gt; [1] 1.4078352 -0.7092079 1.0295443 -0.0366907 -0.4836193 0.5267892 #&gt; [7] 2.5928737 1.6763413 -1.2253649 -0.3284621 Consideriamo il valore del QI della prima madre del campione, ovvero 1.4078352. Come si trova il valore y associato a 1.4078352 in un possibile campione futuro? Il codice Stan dice che y_rep[i] = normal_rng(alpha + beta * x[i], sigma); Ciò significa che vogliamo prendere un valore a caso dalla distribuzione Normale di parametri \\[ \\alpha + \\beta x \\] e deviazione standard \\(\\sigma\\). Nel caso presente non abbiamo un singolo valore per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Invece abbiamo una distribuzione a posteriori per ciascun parametro, ovvero \\(p(\\alpha \\mid y)\\), \\(p(\\beta \\mid y)\\) e \\(p(\\sigma \\mid y)\\). Quindi come facciamo a calcolare il QI del figlio per la prima madre (avente QI standardizzato pari a 1.4078352) in un possibile campione futuro di osservazioni? Prendiamo un valore a caso dalla seguente distribuzione Normale: \\[ \\mathcal{N}(\\mu = \\alpha + \\beta \\cdot 1.4078352, \\sigma). \\] Restano da specificare i valori \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). In tutti e tre i casi, prendiamo un valore a caso dalla corrispondente distribuzione a posteriori. Per \\(\\alpha\\) scegliamo un valore a caso dalla distribuzione a posteriori \\(p(\\alpha \\mid y)\\), per \\(\\beta\\) scegliamo un valore a caso dalla distribuzione a posteriori \\(p(\\beta \\mid y)\\) e per \\(\\sigma\\) scegliamo un valore a caso dalla distribuzione a posteriori \\(p(\\beta \\mid y)\\). Così facendo otteniamo un valore corrispondente al QI del figlio in un possibile campione futuro di osservazioni. Ripetendo questa procedura N volte (cambiando \\(x_i\\), \\(\\forall i \\; in \\; 1, \\dots, 434\\)), otteniamo un possibile campione futuro di 434 osservazioni. Questa procedura viene ripetuta 16,000 volte, ovvero per il numero complessivo di iterazioni, così da ottenere 16,000 possibili campioni futuri di 434 osservazioni ciascuno. Compiliamo il file con il modello Stan. file &lt;- file.path(&quot;code&quot;, &quot;post_pred_check_1.stan&quot;) mod &lt;- cmdstan_model(file) Eseguiamo il campionamento MCMC. fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Per verificare le affermazioni precedenti, trasformo l’oggetto fit in formato stanfit. output_stanfit &lt;- rstan::read_stan_csv(fit$output_files()) Dall’oggetto output_stanfit estraggo i campioni a posteriori dei parametri alpha, beta, sigma e y_rep con la funzione extract(). post &lt;- rstan::extract(output_stanfit) Esamino il contenuto di post. glimpse(post) #&gt; List of 5 #&gt; $ alpha: num [1:16000(1d)] 0.07146 0.08923 0.00417 0.05471 0.0118 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL #&gt; $ beta : num [1:16000(1d)] 0.5 0.425 0.461 0.467 0.449 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL #&gt; $ sigma: num [1:16000(1d)] 0.924 0.878 0.914 0.928 0.913 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL #&gt; $ y_rep: num [1:16000, 1:434] 2.097 -0.322 0.188 -0.451 1.68 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 2 #&gt; .. ..$ iterations: NULL #&gt; .. ..$ : NULL #&gt; $ lp__ : num [1:16000(1d)] -171 -171 -169 -170 -169 ... #&gt; ..- attr(*, &quot;dimnames&quot;)=List of 1 #&gt; .. ..$ iterations: NULL L’oggetto y_rep è ciò che mi aspettavo, ovvero, una matrice di 16,000 righe e 434 colonne. In tale matrice ogni riga è un campione possibile futuro di 434 osservazioni trovato con la procedura descritta sopra. Un istogramma dei valori \\(y^{rep}\\) può essere generato nel modo seguente. hist(as.matrix(output_stanfit, pars = &quot;y_rep&quot;), breaks = 100) L’istogramma precedente illustra le proprietà medie di un campione futuro di 434 osservazioni, alla luce dei dati campionari osservati e delle ipotesi a priori sui parametri del modello di regressione. Possiamo fare un confronto tra la “distribuzione predittiva a posteriori e i dati del campione che è stato osservato. Iniziamo a costruire un istogramma con i dati \\(y\\) (standardizzati) del campione. df %&gt;% ggplot(aes(scale(kid_score)[, 1])) + geom_histogram() I dati possibili futuri, previsti dal modello di regressione lineare sono contenuti nella matrice y_rep. y_rep &lt;- as.matrix(output_stanfit, pars = &quot;y_rep&quot;) dim(y_rep) #&gt; [1] 16000 434 Il seguente diagramma sovrappone all’istogramma lisciato dei dati \\(y\\), gli istogrammi lisciati di 50 campioni possibili futuri predetti dal modello di regressione lineare. Vediamo che la corrispondenza è solo parziale, nel senso che il modello non riesce a predire la leggera asimmetria positiva presente nel campione. ppc_dens_overlay(data_list$y, y_rep[1:200, ]) Questa discrepanza non emerge se usiamo l’approccio frequentista, il quale non consente di eseguire questo controllo. Un qualche miglioramento nel PPC si ottiene modificando il modello così da assumere un meccanismo generatore dei dati corrispondente ad una gaussiana asimmetrica (dotata di un ulteriore parametro di asimmetria). stancode &lt;- &#39; data { int&lt;lower=0&gt; N; vector[N] x; vector[N] y; } parameters { real alpha; real beta; real&lt;lower=0&gt; sigma; real tau; } model { alpha ~ normal(0, 2); beta ~ normal(0, 2); sigma ~ normal(0, 2); tau ~ normal(0, 10); y ~ skew_normal(alpha + beta * x, sigma, tau); } generated quantities { vector[N] y_rep; for (i in 1 : N) { y_rep[i] = skew_normal_rng(alpha + beta * x[i], sigma, tau); } } &#39; writeLines(stancode, con = &quot;code/post_pred_check_2.stan&quot;) Compiliamo. file2 &lt;- file.path(&quot;code&quot;, &quot;post_pred_check_2.stan&quot;) mod2 &lt;- cmdstan_model(file2) Eseguiamo il campionamento MCMC. fit2 &lt;- mod2$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Trasformiamo l’output. output2_stanfit &lt;- rstan::read_stan_csv(fit2$output_files()) y_rep2 &lt;- as.matrix(output2_stanfit, pars = &quot;y_rep&quot;) dim(y_rep2) #&gt; [1] 16000 434 Eseguiamo il PPC. ppc_dens_overlay(data_list$y, y_rep2[1:200, ]) Si nota un qualche miglioramento, anche se però si può dire che il modello è ancora migliorabile. Esaminiamo le stime a posteriori dei parametri. fit2$summary() #&gt; # A tibble: 439 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 lp__ -165. -164. 1.44 1.25 -167. -163. 1.00 5293. #&gt; 2 alpha 0.881 0.895 0.122 0.0967 0.692 1.04 1.00 3876. #&gt; 3 beta 0.408 0.408 0.0442 0.0450 0.335 0.480 1.00 7384. #&gt; 4 sigma 1.26 1.27 0.0875 0.0809 1.12 1.40 1.00 4142. #&gt; 5 tau -1.90 -1.91 0.416 0.386 -2.56 -1.24 1.00 3852. #&gt; 6 y_rep[1] 0.582 0.649 0.897 0.880 -1.00 1.93 1.00 15664. #&gt; 7 y_rep[2] -0.294 -0.218 0.907 0.881 -1.90 1.07 1.00 15206. #&gt; 8 y_rep[3] 0.415 0.480 0.900 0.886 -1.18 1.77 1.00 14265. #&gt; # … with 431 more rows, and 1 more variable: ess_tail &lt;dbl&gt; bayestestR::hdi(output2_stanfit, ci = 0.95) Con un modello più adeguato, la stima a posteriori del parametro \\(\\beta\\) è diminuita: \\(\\hat{\\beta}\\) = 0.408, 95% CI [0.32, 0.49]. È possibile esplorare la possibilità di qualche meccanismo generatore dei dati maggiormente adeguato ai dati a disposizione. Lo scopo della discussione presente è solo di fare vedere come la stima del parametro di interesse, qui \\(\\beta\\), dipende dalle assunzioni che facciamo sul modello generatore dei dati. La distribuzione predittiva a posteriori è uno degli strumenti che possono essere usati allo scopo di selezionare, tra quelli sensati, il meccanismo generatore dei dati maggiormente appropriato per i dati che sono stati osservati. 29.2 Distribuzione predittiva a priori La distribuzione predittiva a priori equivale alla distribuzione predittiva a posteriori, senza però i dati osservati. Quindi la distribuzione predittiva a priori non è altro che il caso limite della distribuzione predittiva a posteriori, calcolata però senza utilizzare i dati del campione. Il manuale Stan afferma che, se il codice per il il controllo predittivo a posteriori è già stato scritto, ed è possibile impostare il codice in modo che non sia necessario specificare i dati, allora non è necessario fare nient’altro. Per comprendere le assunzioni che abbiamo introdotto nel modello, possiamo generare dati mediante il modello; tali dati, che sono generati interamente dalle distribuzioni a priori, sono chiamati distribuzione predittiva a priori. La generazione della distribuzione predittiva a priori ci aiuta a verificare se le distribuzioni a priori per i parametri del modello hanno senso. Quello che vogliamo sapere qui è: le distribuzioni a priori che abbiamo scelto generano dati che hanno caratteristiche realistiche? Dal punto di vista della programmazione, l’unico cambiamento necessario rispetto al codice utilizzato per la distribuzione predittiva a posteriori è quello di eliminare la porzione di codice che fa riferimento ai dati \\(y\\) – nel caso di un modello lineare, i valori \\(x\\) devono invece essere mantenuti per potere generare \\(y^{sim}\\) (nel codice questa variabile è ancora chiamata y_rep). data_list &lt;- list( N = length(df$kid_score), x = scale(df$mom_iq)[, 1] ) stancode &lt;- &#39; data { int&lt;lower=0&gt; N; vector[N] x; } parameters { real alpha; real beta; real&lt;lower=0&gt; sigma; } model { alpha ~ normal(0, 1); beta ~ normal(0, 1); sigma ~ normal(0, 1); } generated quantities { vector[N] y_rep; for (i in 1 : N) { y_rep[i] = normal_rng(alpha + beta * x[i], sigma); } } &#39; writeLines(stancode, con = &quot;code/prior_pred_check_1.stan&quot;) file &lt;- file.path(&quot;code&quot;, &quot;prior_pred_check_1.stan&quot;) mod &lt;- cmdstan_model(file) fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) stanfit2 &lt;- rstan::read_stan_csv(fit$output_files()) Questo è un istogramma della distribuzione preditiva a priori. Tale distribuzione viene usata per valutare se le distribuzioni a priori dei parametri sono sensate. Concludiamo che sono sensate se la distribuzione preditiva a priori include tutti i valori possibili della distribuzione della \\(y\\), senza scostarsti troppo da essa. hist(as.matrix(stanfit2, pars = &quot;y_rep&quot;), breaks = 100) Commenti e considerazioni finali I due predictive checks che abbiamo esaminato in questo capitolo servono due scopi diversi. La distribuzione predittiva a priori viene utilizzata per comprendere le assunzioni introdotte nel modello. Per fare questo possiamo generare dei dati dal modello. Tali dati, che vengono prodotti interamente dalle distribuzioni a priori, sono chiamati distribuzione predittiva a priori. La distribuzione predittiva a priori ci aiuta a capire se le distribuzioni a priori per i parametri del modello hanno un senso. Quello che ci chiedimo è: le distribuzioni a priori generano dei dati che hanno caratteristiche realistiche? Una risposta affermativa a tale domanda corrisponde ad una distribuzione predittiva a priori che è più ampia della distribuzione dei dati osservati, in linea con il principio dei prior debolmente informativi. Tale distribuzione dovrebbe avere almeno una qualche massa nell’intorno ai valori estremi, ma plausibili dei dati; non dovrebbe, invece, esserci massa in corrispondenza di valori di dati completamente implausibili. La distribuzione predittiva a posteriori viene invece utilizzata per esplorare le caratteristiche che potrebbero avere i possibili dati futuri. L’idea alla base del controllo predittivo a posteriori è semplice: se un modello è appropriato, dovremmo essere in grado di usarlo per generare dati che assomigliano ai dati che abbiamo osservato nel campione. La motivazione è simile a quella che ci ha condotto alla distribuzione predittiva a priori, tranne per il fatto che ora abbiamo un modello generativo dei dati basato sui dati osservati. References "],["ch-anova.html", "Capitolo 30 Confronto di \\(k\\) gruppi 30.1 Le abilità sociali di un robot 30.2 I test statistici dell’Analisi della Varianza 30.3 Codice Stan (versione 2)", " Capitolo 30 Confronto di \\(k\\) gruppi L’Analisi della Varianza (ANOVA) consente ai ricercatori di valutare gli effetti di predittori categoriali su una variabile di esito continua. L’ANOVA è un’analisi di regressione nella quale tutte le variabili indipendenti sono qualitative. 30.1 Le abilità sociali di un robot Per illustrare i concetti chiave dell’ANOVA bayesiana considereremo qui una ricerca di Horstmann et al. (2018). I ricercatori si sono chiesti se le persone impiegano più tempo a spegnere un robot quando questo mostra abilità sociali. Nell’esperimento di Horstmann et al. (2018), 85 partecipanti hanno interagito con un robot per un certo tempo. Ai partecipanti è stato detto che lo scopo della loro interazione con il robot era quella di testare un nuovo algoritmo. Dopo il completamento di due compiti fittizi, ai partecipanti veniva detto che, se volevano, potevano spegnere il robot. La variabile di interesse dell’esperimento era il tempo impiegato dai partecipanti per spegnere il robot. Seguendo Bergh et al. (2020), analizzeremo i tempi di spegnimento trasformati su scala logaritmica perché tale variabile mostra una chiara asimmetria positiva. Horstmann et al. (2018) hanno manipolato due variabili in un disegno tra i soggetti. Interaction type. Le risposte verbali dei robot potevano essere o sociali (ad esempio, “Oh sì, la pizza è ottima. Una volta ho mangiato una pizza grande come me.”) o funzionali (ad esempio, “Preferisci la pizza. Ha funzionato bene. Continuiamo.”). Robot’s objection. Il robot poteva protestare quando stava per essere spento (ad esempio, “No! Per favore, non spegnermi! Ho paura di non riuscire ad accendermi di nuovo!”) oppure no. Pertanto, il disegno di questo studio è un’ANOVA tra i soggetti 2 (Interaction type) \\(\\times\\) 2 (Robot’s objection). Iniziamo a leggere i dati d &lt;- rio::import( here(&quot;data&quot;, &quot;pone.0201581.s001.sav&quot;) ) Per comodità creiamo la variabile cond con quattro modalità (SO, FO, SN, FN), dove S significa social interaction, F sta per funcitonal interaction, O sta per objection e N sta per no objection. d$cond &lt;- factor(d$Condition) d$cond &lt;- factor( d$cond, labels = c(&quot;SO&quot;, &quot;FO&quot;, &quot;SN&quot;, &quot;FN&quot;) ) Ci sono alcuni dati mancanti, quindi verranno omesse le righe con NA. Selezionando le colonne di interesse dal data.frame originario otteniamo: dd &lt;- d %&gt;% dplyr::select(cond, SwitchOff_Time) %&gt;% na.omit() Nelle quattro condizioni si osservano le seguenti medie (si veda la Tabella 3 di Horstmann et al. 2018): dd %&gt;% group_by(cond) %&gt;% summarise( avg_sot = mean(SwitchOff_Time, na.rm = TRUE), sd_sot = sd(SwitchOff_Time, na.rm = TRUE) ) #&gt; # A tibble: 4 × 3 #&gt; cond avg_sot sd_sot #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 SO 6.19 4.61 #&gt; 2 FO 14.4 15.4 #&gt; 3 SN 5.05 2.18 #&gt; 4 FN 4.28 2.49 Visualizziamo i dati: dd_summary &lt;- dd %&gt;% group_by(cond) %&gt;% summarize( sot_mean = mean(SwitchOff_Time), sot_sd = sd(SwitchOff_Time), sot_median = median(SwitchOff_Time) ) %&gt;% ungroup() dd %&gt;% ggplot( aes(x = cond, y = SwitchOff_Time, color = cond) ) + ggforce::geom_sina( aes(color = cond, size = 3, alpha = .5) ) + geom_errorbar( aes( y = sot_median, ymin = sot_median, ymax = sot_median ), data = dd_summary, width = 0.5, size = 3 ) + scale_colour_grey(name = &quot;cond&quot;) + labs( x = &quot;&quot;, y = &quot;SwitchOff Time&quot;, color = &quot;Condizione&quot; ) + theme(legend.position = &quot;none&quot;) Su scala logaritmica, l’asimmetria positiva della variabile dd$SwitchOff_Time viene ridotta. Per i dati trasformati, la mediana in ciascuna condizione è: dd$y &lt;- log(dd$SwitchOff_Time + 0.01) dd %&gt;% group_by(cond) %&gt;% summarise( avg_y = median(y) ) #&gt; # A tibble: 4 × 2 #&gt; cond avg_y #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 SO 1.61 #&gt; 2 FO 2.01 #&gt; 3 SN 1.39 #&gt; 4 FN 1.39 Creiamo ora la variabile x che indicizza le quattro condizioni (la variabile x verrà usata nel modello Stan): dd$x &lt;- as.numeric(dd$cond) head(dd) #&gt; cond SwitchOff_Time y x #&gt; 3 SN 6 1.793425 3 #&gt; 4 FO 7 1.947338 2 #&gt; 5 FO 3 1.101940 2 #&gt; 6 FN 4 1.388791 4 #&gt; 7 FN 4 1.388791 4 #&gt; 8 FO 12 2.485740 2 Il modello bayesiano che usiamo qui per il confronto tra le medie dei quattro gruppi è una semplice estensione del modello per la media di un solo gruppo. Il codice usato è ispirato da quello fornito nella seguente pagina web. Per adattare un modello “robusto”, ipotizzeremo che la y segua una distribuzione \\(t\\) di Student con un numero di gradi di libertà stimato dal modello. Il modello classico dell’ANOVA è basato sulle seguenti assunzioni: i residui (cioè la differenza tra il valore dell’\\(i\\)-esima osservazione e la media di tutte le osservazioni nella \\(k\\)-esima condizione) devono seguire la distribuzione normale (normalità); i residui devono avere la stessa deviazione standard nelle \\(k\\) popolazioni da cui abbiamo estratto i dati (omoschedasticità); il disegno sperimentale utilizzato per raccogliere i dati deve garantire l’indipendenza dei residui. Nella presenta formulazione dell’ANOVA bayesiana, l’assunto di normalità non è richiesto, mentre devono essere soddisfatte le condizioni di omoschedasticità e indipendenza. L’ANOVA bayesiana può comunque essere estesa a condizioni che violano sia l’assunto di omoschedasticità sia quello di indipendenza. Ma qui ci limitiamo a discutere il caso più semplice. modelString = &quot; // Comparison of k groups with common variance (ANOVA) data { int&lt;lower=0&gt; N; // number of observations int&lt;lower=0&gt; K; // number of groups array[N] int&lt;lower=1, upper=K&gt; x; // discrete group indicators vector[N] y; // real valued observations } parameters { vector[K] mu; // group means real&lt;lower=0&gt; sigma; // common standard deviation real&lt;lower=1&gt; nu; } model { mu ~ normal(0, 2); // weakly informative prior sigma ~ normal(0, 1); // weakly informative prior nu ~ gamma(2, 0.1); // Juárez and Steel(2010) y ~ student_t(nu, mu[x], sigma); // observation model / likelihood } &quot; writeLines(modelString, con = &quot;code/grp_aov.stan&quot;) Creiamo un oggetto che contiene i dati nel formato appropriato per Stan: data_grp &lt;- list( N = nrow(dd), K = 4, x = dd$x, y = dd$y ) Compiliamo il modello: file &lt;- file.path(&quot;code&quot;, &quot;grp_aov.stan&quot;) mod &lt;- cmdstan_model(file) Eseguiamo il campionamento MCMC: fit &lt;- mod$sample( data = data_grp, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Esaminando i risultati fit$summary() #&gt; # A tibble: 7 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 lp__ -41.2 -40.9 1.85 1.69 -44.7 -38.9 1.00 6774. 9294. #&gt; 2 mu[1] 1.69 1.68 0.175 0.170 1.41 1.99 1.00 21498. 12257. #&gt; 3 mu[2] 2.05 2.05 0.196 0.196 1.73 2.37 1.00 20722. 10892. #&gt; 4 mu[3] 1.52 1.52 0.122 0.120 1.32 1.72 1.00 22671. 11935. #&gt; 5 mu[4] 1.28 1.28 0.125 0.121 1.07 1.49 1.00 21545. 11572. #&gt; 6 sigma 0.476 0.472 0.0753 0.0736 0.358 0.606 1.00 14197. 11182. #&gt; 7 nu 2.55 2.41 0.821 0.724 1.49 4.07 1.00 14336. 9374. ci rendiamo conto che cìè una buona corrispondenza tra le medie a posteriori e le medie campionarie. Trasformiamo l’oggetto fit in un oggetto di classe stanfit: stanfit &lt;- rstan::read_stan_csv(fit$output_files()) La funzione rstan::extract() estrae i campioni a posteriori da un oggetto di classe stanfit: posterior &lt;- extract(stanfit, permuted = TRUE) Una rappresentazione grafica della distribuzione a posteriori delle quattro medie si ottiene con le seguenti istruzioni: temps &lt;- data.frame(posterior$mu) %&gt;% setNames(c(&#39;SO&#39;, &#39;FO&#39;, &#39;SN&#39;, &#39;FN&#39;)) mcmc_areas(temps, prob = 0.95) + xlab(&#39;Gruppi&#39;) I quattro intervalli di credibilità al 95% sono: ci95 &lt;- rstanarm::posterior_interval( as.matrix(stanfit), prob = 0.95 ) round(ci95, 2) #&gt; 2.5% 97.5% #&gt; mu[1] 1.36 2.05 #&gt; mu[2] 1.67 2.44 #&gt; mu[3] 1.28 1.76 #&gt; mu[4] 1.03 1.53 #&gt; sigma 0.34 0.63 #&gt; nu 1.37 4.56 #&gt; lp__ -45.67 -38.67 30.2 I test statistici dell’Analisi della Varianza L’ANOVA include test statistici di due tipi: i test sull’interazione tra i fattori e i test sugli effetti principali. Per chiarire il significato di “interazione” e di “effetto principale” è necessario prima definire il significato di “effetto statistico”. Definizione 30.1 L’effetto di un fattore rappresenta la variazione media della variabile dipendente al variare dei livelli del fattore stesso. Definizione 30.2 Si parla di interazione quando l’effetto di un fattore sulla variabile dipendente varia a seconda dei livelli di un altro fattore. Vengono presentati qui di seguito alcuni esempi. Le figure seguenti mostrano le medie di ciascuna condizione nel caso di un disegno 3 (fattore riga) \\(\\times\\) 2 (fattore colonna). La spiegazione delle figure è presentata nelle didascalie. FIGURA 30.1: Il fattore colonna è indicato dal colore. Sinistra La figura mostra un effetto principale del fattore riga e un effetto principale del fattore colonna. Non c’è interazione tra i fattori riga e colonna. Destra La figura mostra un effetto principale del fattore riga. L’effetto principale del fattore colonna è zero. Non c’è interazione tra i fattori riga e colonna. FIGURA 30.2: Il fattore colonna è indicato dal colore. Sinistra La figura mostra che l’effetto principale del fattore riga è zero, mentre c’è un effetto principale del fattore colonna. Non c’è interazione tra i fattori riga e colonna. Destra Non c’è né un effetto principale del fattore riga, né un effetto pricipale del fattore colonna, né un’interazione tra i fattori riga e colonna. FIGURA 30.3: Il fattore colonna è indicato dal colore. Entrambe le figure mostrano un’interazione tra i fattori riga e colonna. Nella figura di sinistra gli effetti principali non sono interpretabili; nella figura di destra gli effetti principali sono interpretabili in quanto l’interazione è di lieve entità. Dagli esempi precedenti si evince che c’è un’interazione ogni qualvolta i profili delle medie non sono paralleli. Anche se, nella popolazione, non c’è interazione, a causa della variabilità campionaria i profili delle medie non sono mai perfettamente paralleli nel campione. Il problema è quello di stabilire se l’assenza di parallelismo nel campione fornisce sufficiente evidenza di presenza di interazione nella popolazione. 30.2.1 Test sull’interazione Ritorniamo ora ai dati di Horstmann et al. (2018). Nel caso di un disegno 2 \\(\\times\\) 2, con i fattori Interaction type (social, functional) e Robot’s objection (objection, no objection), è possibile verificare la presenza dell’interazione Interaction type \\(\\times\\) Robot’s objection. Nel modello bayesiano, la distribuzione a posteriori fornisce un enorme numero di stime del valore della media in ciascuna delle quattro condizioni. L’effetto di un fattore corrisponde alla differenza tra le stime della media in corrispondenza di ciascuna modalità del fattore. Nel caso presente abbiamo: mu[1] \\(\\rightarrow\\) SO mu[2] \\(\\rightarrow\\) FO mu[3] \\(\\rightarrow\\) SN mu[4] \\(\\rightarrow\\) FN Quindi, mean(posterior$mu[, 1] - posterior$mu[, 3]) corrisponde alla stima a posteriori dell’effetto di Objection nella condizione Social Interaction. Invece, mean(posterior$mu[, 2] - posterior$mu[, 3]) corrisponde alla stima a posteriori dell’effetto di Objection nella condizione Functional Interaction. In assenza di interazione, questi due effetti devono essere (statisticamente) uguali. Per sottoporre a verifica questa ipotesi, calcoliamo la proporzione di volte in cui questo non si verifica nella distribuzione a posteriori: sum( (posterior$mu[, 1] - posterior$mu[, 3]) &gt; (posterior$mu[, 2] - posterior$mu[, 4]) ) / length(posterior$mu[, 1]) #&gt; [1] 0.0314375 La stima di questa probabilità in un test direzionale è molto simile alla probabilità frequentista riportata da Horstmann et al. (2018), ovvero \\(p = 0.016\\). Horstmann et al. (2018) riportano la presenza di un’interazione tra Interaction type e Robot’s objection (com’è stato anche trovato con la presente ANOVA bayesiana). Per interpretare l’interazione è necessario esaminare le mediane dei quattro gruppi.31 L’esame delle mediane indica che l’effetto del fattore Robot’s objection è più grande quando il fattore Interaction type assume la modalità Functional piuttosto che Social. Ma possiamo anche leggere l’interazione nella direzione opposta: l’effetto del fattore Interaction type è più grande quando il fattore Robot’s objection assume la modalità Objection anziché No objection. 30.2.2 Test sugli effetti principali L’effetto principale descrive l’effetto marginale di un fattore. Nel caso presente, in cui ciascun fattore ha solo due modalità, l’effetto principale corrisponde alla differenze tra le medie delle modalità di ciascun fattore. L’effetto principale del fattore Interaction type è la differenza tra le medie di Social e di Functional, ignorando Robot’s objection. Horstmann et al. (2018) riportano che gli individui che avevano avuto un’interazione funzionale con il robot impiegavano più tempo a spegnere il robot di coloro che avevano avuto un’interazione sociale con il robot (\\(p\\) = 0.045). Il presente modello bayesiano offre scarse evidenze di ciò: mean((exp(posterior$mu[, 2]) + exp(posterior$mu[, 4])) / 2) #&gt; [1] 5.765852 mean((exp(posterior$mu[, 1]) + exp(posterior$mu[, 3])) / 2) #&gt; [1] 5.043196 Infatti, all’evento complementare possiamo associare la seguente probabilità: sum( (posterior$mu[, 2] + posterior$mu[, 4]) &lt; (posterior$mu[, 1] + posterior$mu[, 3]) ) / length(posterior$mu[, 1]) #&gt; [1] 0.344125 L’effetto principale del fattore Robot’s objection è la differenza tra le medie di Objection e di No Objection, ignorando Interaction type. Horstmann et al. (2018) riportano che i partecipanti avevano aspettato più a lungo prima di spegnere il robot quando il robot aveva avanzato un’obiezione rispetto a quando non si era opposto ad essere spento: mean( (exp(posterior$mu[, 1]) + exp(posterior$mu[, 2])) / 2 ) #&gt; [1] 6.701133 mean( (exp(posterior$mu[, 3]) + exp(posterior$mu[, 4])) / 2 ) #&gt; [1] 4.107915 In base al modello bayesiano, la probabilità direzionale per l’evento complementare è sum( (posterior$mu[, 1] + posterior$mu[, 2]) &lt; (posterior$mu[, 3] + posterior$mu[, 4]) ) / length(posterior$mu[, 1]) #&gt; [1] 0.0011875 e corrisponde, in ordine di grandezza, alla probabilità frequentista riportata da Horstmann et al. (2018), ovvero \\(p\\) = 0.004. 30.3 Codice Stan (versione 2) È possibile modificare il codice Stan precedente così da avere i dati grezzi in input ed eseguire la standardizzazione all’interno del programma. modelString = &quot; // Comparison of k groups with common variance (ANOVA) data { int&lt;lower=0&gt; N; // number of observations int&lt;lower=0&gt; K; // number of groups array[N] int&lt;lower=1, upper=K&gt; x; // discrete group indicators vector[N] y; // real valued observations } transformed data { vector[N] y_std; y_std = (y - mean(y)) / sd(y); } parameters { vector[K] mu_std; // group means real&lt;lower=0&gt; sigma_std; // common standard deviation real&lt;lower=1&gt; nu; } model { mu_std ~ normal(0, 2); sigma_std ~ normal(0, 2); nu ~ gamma(2, 0.1); // Juárez and Steel(2010) y_std ~ student_t(nu, mu_std[x], sigma_std); } generated quantities { vector[K] mu; real&lt;lower=0&gt; sigma; for (i in 1 : K) { mu[i] = mu_std[i] * sd(y) + mean(y); } sigma = sd(y) * sigma_std; } &quot; writeLines(modelString, con = &quot;code/grp_aovstd.stan&quot;) file &lt;- file.path(&quot;code&quot;, &quot;grp_aovstd.stan&quot;) mod &lt;- cmdstan_model(file) Eseguiamo il campionamento MCMC usando gli stessi dati discussi in precedenza: fit2 &lt;- mod$sample( data = data_grp, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) I risultati sono equivalenti a quelli trovati in precedenza: fit2$summary(c(&quot;mu&quot;, &quot;sigma&quot;, &quot;nu&quot;)) #&gt; # A tibble: 6 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 mu[1] 1.70 1.70 0.176 0.171 1.42 2.00 1.00 22449. 11510. #&gt; 2 mu[2] 2.07 2.06 0.197 0.196 1.75 2.40 1.00 21774. 12016. #&gt; 3 mu[3] 1.53 1.52 0.122 0.121 1.32 1.73 1.00 21066. 11485. #&gt; 4 mu[4] 1.29 1.28 0.127 0.124 1.08 1.50 1.00 20576. 11730. #&gt; 5 sigma 0.480 0.476 0.0759 0.0744 0.362 0.612 1.00 15958. 12302. #&gt; 6 nu 2.58 2.44 0.831 0.725 1.51 4.13 1.00 15484. 9221. References "],["ch-mod-hier-stan.html", "Capitolo 31 Modello gerarchico 31.1 Modello gerarchico 31.2 Modello ad effetti fissi 31.3 Modello gerarchico", " Capitolo 31 Modello gerarchico 31.1 Modello gerarchico I modelli lineari misti, o modelli lineari gerarchici/multilivello, sono diventati uno strumento fondamentale della ricerca sperimentale in psicologia, linguistica e scienze cognitive, dove i progetti di ricerca a misure ripetute sono la norma. Il presente Capitolo fornisce un’introduzione a tali modelli considerando soltanto il caso più semplice, conosciuto anche col nome di Random Intercept Model. Per fare un esempio concreto useremo il set di dati a misure ripetute con due condizioni di Gibson and Wu (2013; si veda Sorensen and Vasishth 2015). La variabile dipendente rt dell’esperimento di Gibson and Wu (2013) è il tempo di lettura in millisecondi del soggetto di una proposizione relativa in un testo. I tempi di reazione sono stati registrati in due condizioni (ovvero, in presenza di un sostantivo riferito al soggetto oppure riferito all’oggetto della proposizione). I dati di Gibson and Wu (2013) provengono da un esperimento con 37 soggetti e 15 item. Gli item erano presentati in un disegno a quadrato latino, il che produce 37 \\(\\times\\) 15 = 555 dati. Risultano mancanti otto dati di un soggetto (id 27), il che ci porta ad un totale di 555 − 8 = 547 dati. Le prime righe del data.frame sono mostrate di seguito: rdat &lt;- read.table(here::here(&quot;data&quot;, &quot;gibsonwu2012data.txt&quot;)) rdat$so &lt;- ifelse(rdat$type == &quot;subj-ext&quot;, -0.5, 0.5) head(rdat) #&gt; subj item type pos word correct rt region type2 so #&gt; 7 1 13 obj-ext 6 抓住 - 1140 de1 object relative 0.5 #&gt; 20 1 6 subj-ext 6 男孩 - 1197 de1 subject relative -0.5 #&gt; 32 1 5 obj-ext 6 撞 - 756 de1 object relative 0.5 #&gt; 44 1 9 obj-ext 6 監視 - 643 de1 object relative 0.5 #&gt; 60 1 14 subj-ext 6 機師 - 860 de1 subject relative -0.5 #&gt; 73 1 4 subj-ext 6 男孩 - 868 de1 subject relative -0.5 La variabile di interesse che corrisponde alla manipolazione sperimentale è chiamata so ed è stata codificata con -0.5 se il sostantivo era riferito al soggetto e con +0.5 se il sostantivo era riferito all’oggetto della frase. Calcoliamo la media dei tempi di reazione su scala logaritmica e per poi ritrasformare il risultato sulla scala originale: rdat %&gt;% group_by(type2) %&gt;% summarise( avg = exp(mean(log(rt), na.rm = TRUE)) ) #&gt; # A tibble: 2 × 2 #&gt; type2 avg #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 object relative 551. #&gt; 2 subject relative 589. Quando il sostantivo si riferisce al soggetto, i tempi di reazione sono più lenti di circa 30 ms. Questa descrizione dei dati, però non tiene conto né delle differenze tra i soggetti né delle differenze tra gli item. Per tenere in considerazioni queste diverse fonti della variabilità dei dati è necessario utilizzare un modello detto gerarchico. 31.2 Modello ad effetti fissi Iniziamo con il modello “ad effetti fissi” che non tiene conto della struttura gerarchica dei dati, ovvero del fatto che c’è una covariazione all’interno dei cluster di dati definiti dalle variabili “soggetto” e “item”. Assumiamo che la variabile dipendente rt (del tempo di lettura) sia approssimativamente distribuita in modo logaritmico (Rouder 2005). Ciò presuppone che il logaritmo di rt sia distribuito approssimativamente in maniera normale. Il modello per il logaritmo dei tempi di lettura, \\(\\log\\) rt, diventa \\[\\begin{equation} \\log rt_i = \\beta_0 + \\beta_1 so_i + \\varepsilon_i, \\end{equation}\\] ovvero \\[\\begin{equation} rt \\sim LogNormal(\\beta_0 + \\beta_1 so,\\sigma) \\end{equation}\\] dove \\(\\beta_0\\) è la media generale di \\(\\log\\) rt e \\(\\beta_1 so\\) codifica la differenza \\(\\E(\\log rt_{o}) - \\E(\\log rt_{s})\\) quando si passa dalla condizione nella quale il sostantivo è riferito all’oggetto alla condizione nella quale il sostantivo è riferito all’soggetto – valori negativi significano che i tempi di reazioni sono maggiori nella condizione s che nella condizione o. Nel modello useremo le seguenti distribuzioni a priori: \\[\\begin{equation} \\begin{aligned} \\beta[1] &amp;\\sim Normal(6, 1.5) \\\\ \\beta[2] &amp;\\sim Normal(0, 1.0) \\\\ \\sigma &amp;\\sim Cauchy(0, 1)\\\\ \\end{aligned} \\end{equation}\\] In Stan, il modello diventa modelString = &quot; data { int&lt;lower=1&gt; N; //number of data points array[N] real rt; //reading time array[N] real&lt;lower=-0.5, upper=0.5&gt; so; //predictor } parameters { vector[2] beta; //fixed intercept and slope real&lt;lower=0&gt; sigma_e; //error sd } model { real mu; // likelihood beta[1] ~ normal(6, 1.5); beta[2] ~ normal(0, 1); sigma_e ~ cauchy(0, 1); for (i in 1 : N) { mu = beta[1] + beta[2] * so[i]; rt[i] ~ lognormal(mu, sigma_e); } } &quot; writeLines(modelString, con = &quot;code/fixeff_model.stan&quot;) file &lt;- file.path(&quot;code&quot;, &quot;fixeff_model.stan&quot;) mod &lt;- cmdstan_model(file) I dati sono contenuti nella lista stan_dat: stan_dat &lt;- list( rt = rdat$rt, so = rdat$so, N = nrow(rdat) ) Eseguiamo il campionamento MCMC: fit3 &lt;- mod$sample( data = stan_dat, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Otteniamo un oggetto di classe stanfit: stanfit &lt;- rstan::read_stan_csv(fit3$output_files()) Calcoliamo gli intervalli di credibilità al 95%: ci95 &lt;- rstanarm::posterior_interval( as.matrix(stanfit), prob = 0.95 ) round(ci95, 3) #&gt; 2.5% 97.5% #&gt; beta[1] 6.321 6.369 #&gt; beta[2] -0.113 -0.017 #&gt; sigma_e 0.613 0.646 #&gt; lp__ -2617.020 -2612.420 L’effetto medio, sulla scala in millisecondi, si trova nel modo seguente: posterior &lt;- extract(stanfit, permuted = TRUE) exp(mean(posterior$beta[, 1] + posterior$beta[, 2])) - exp(mean(posterior$beta[, 1])) #&gt; [1] -35.99588 31.3 Modello gerarchico Il modello a effetti fissi è inappropriato per i dati di Gibson and Wu (2013) perché non tiene conto del fatto che abbiamo più misure per ogni soggetto e per ogni item. In altre parole, il modello ad effetti fissi viola l’assunzione di indipendenza degli errori. Inoltre, i coefficienti di effetti fissi \\(\\beta_0\\) e \\(\\beta_1\\) rappresentano le medie calcolate su tutti i soggetti e tutti gli item, ignorando il fatto che alcuni soggetti sono più veloci e altri più lenti della media, e il fatto che alcuni item sono stati letti più velocemente della media e altri più lentamente. Nei modelli lineari misti, teniamo in considerazione la variabilità dovuta alle differenze tra soggetti e tra item aggiungendo al modello i termini \\(u_{0j}\\) e \\(w_{0k}\\) che aggiustano \\(\\beta_0\\) stimando una componente specifica al soggetto \\(j\\) e all’item \\(k\\). Questa formulazione del modello scompone parzialmente \\(\\varepsilon_i\\) in una somma di termini \\(u_{0j}\\) e \\(w_{0k}\\) che, geometricamente, corrispondono a degli aggiustamenti dell’intercetta \\(\\beta_0\\) specifici per il soggetto \\(j\\) e per l’item \\(k\\). Se il soggetto \\(j\\) è più lento della media di tutti i soggetti, \\(u_j\\) sarà un numero positivo; se l’item \\(k\\) viene letto più velocemente del tempo di lettura medio di tutti gli item, allora \\(w_k\\) sarà un numero negativo. Viene stimato un aggiustamento \\(u_{0j}\\) per ogni soggetto \\(j\\) e un aggiustamento \\(w_{0k}\\) per ogni item. Gli aggiustamenti \\(u_{0j}\\) e \\(w_{0k}\\) sono chiamati random intercepts o varying intercepts (Gelman, Hill, and Vehtari 2020). La modifica di \\(\\beta_0\\) mediante \\(u_{0j}\\) e \\(w_{0k}\\) consente dunque di tenere in considerazione la variabilità dovuta ai soggetti e agli item. Il random intercept model assume che gli aggiustamenti \\(u_{0j}\\) e \\(w_{0k}\\) siano distribuiti normalmente attorno allo zero con una deviazione standard sconosciuta: \\(u_0 ∼ \\mathcal{N}(0, \\sigma_u)\\) e \\(w_0 ∼ \\mathcal{N}(0, \\sigma_w)\\). Il modello include dunque tre fonti di varianza: la deviazione standard degli errori \\(\\sigma_e\\), la deviazione standard delle random intercepts per i soggetti, \\(\\sigma_u\\), e la deviazione standard delle random intercepts per gli item, \\(\\sigma_w\\). Queste tre fonti di variabilità sono dette componenti della varianza. Possiamo dunque scrivere: \\[\\begin{equation} \\log rt_{ijk} = \\beta_0 + \\beta_1 so_i + u_{0j} + w_{0k} + \\varepsilon_{ijk}. \\end{equation}\\] Il coefficiente \\(\\beta_1\\) è quello di interesse primario. Come conseguenza della codifica usata, avrà il valore \\(-\\beta_1\\) nella condizione in cui il sostantivo è riferito al soggetto e \\(+\\beta_1\\) nella condizione in cui il sostantivo è riferito all’oggetto della frase. In Stan il modello diventa: modelString = &quot; data { int&lt;lower=1&gt; N; //number of data points array[N] real rt; //reading time array[N] real&lt;lower=-0.5, upper=0.5&gt; so; //predictor int&lt;lower=1&gt; J; //number of subjects int&lt;lower=1&gt; K; //number of items array[N] int&lt;lower=1, upper=J&gt; subj; //subject id array[N] int&lt;lower=1, upper=K&gt; item; //item id } parameters { vector[2] beta; //fixed intercept and slope vector[J] u; //subject intercepts vector[K] w; //item intercepts real&lt;lower=0&gt; sigma_e; //error sd real&lt;lower=0&gt; sigma_u; //subj sd real&lt;lower=0&gt; sigma_w; //item sd } model { real mu; //priors u ~ normal(0, sigma_u); //subj random effects w ~ normal(0, sigma_w); //item random effects // likelihood for (i in 1 : N) { mu = beta[1] + u[subj[i]] + w[item[i]] + beta[2] * so[i]; rt[i] ~ lognormal(mu, sigma_e); } } &quot; writeLines(modelString, con = &quot;code/random_intercepts_model.stan&quot;) file &lt;- file.path(&quot;code&quot;, &quot;random_intercepts_model.stan&quot;) mod &lt;- cmdstan_model(file) I dati sono stan_dat &lt;- list( subj = as.integer(as.factor(rdat$subj)), item = as.integer(as.factor(rdat$item)), rt = rdat$rt, so = rdat$so, N = nrow(rdat), J = length(unique(rdat$subj)), K = length(unique(rdat$item)) ) Eseguiamo il campionamento MCMC: fit4 &lt;- mod$sample( data = stan_dat, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) Otteniamo un oggetto di classe stanfit: stanfit &lt;- rstan::read_stan_csv(fit4$output_files()) Le medie a posteriori si ottengono con fit4$summary(c(&quot;beta&quot;, &quot;sigma_e&quot;, &quot;sigma_w&quot;, &quot;sigma_u&quot;)) #&gt; # A tibble: 5 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 beta[1] 6.35 6.35 0.0512 0.0511 6.26 6.43 1.00 1413. #&gt; 2 beta[2] -0.0604 -0.0604 0.0220 0.0218 -0.0974 -0.0243 1.00 17390. #&gt; 3 sigma_e 0.577 0.577 0.00792 0.00784 0.564 0.590 1.00 17746. #&gt; 4 sigma_w 0.120 0.115 0.0291 0.0263 0.0806 0.173 1.00 8584. #&gt; 5 sigma_u 0.238 0.235 0.0319 0.0304 0.191 0.293 1.00 11445. #&gt; # … with 1 more variable: ess_tail &lt;dbl&gt; Gli intervalli di credibilità sono: ci95 &lt;- rstanarm::posterior_interval( as.matrix(stanfit), prob = 0.95 ) round(ci95, 3) #&gt; 2.5% 97.5% #&gt; beta[1] 6.247 6.447 #&gt; beta[2] -0.104 -0.017 #&gt; u[1] -0.208 0.081 #&gt; u[2] -0.304 -0.012 #&gt; u[3] -0.127 0.163 #&gt; u[4] -0.212 0.079 #&gt; u[5] -0.079 0.216 #&gt; u[6] -0.049 0.239 #&gt; u[7] -0.162 0.131 #&gt; u[8] -0.124 0.168 #&gt; u[9] -0.097 0.196 #&gt; u[10] -0.009 0.283 #&gt; u[11] 0.450 0.745 #&gt; u[12] 0.149 0.443 #&gt; u[13] -0.169 0.123 #&gt; u[14] -0.151 0.140 #&gt; u[15] 0.035 0.324 #&gt; u[16] -0.199 0.089 #&gt; u[17] -0.716 -0.418 #&gt; u[18] -0.417 -0.127 #&gt; u[19] -0.295 0.003 #&gt; u[20] 0.162 0.452 #&gt; u[21] 0.050 0.341 #&gt; u[22] 0.123 0.418 #&gt; u[23] -0.197 0.096 #&gt; u[24] -0.084 0.293 #&gt; u[25] 0.000 0.292 #&gt; u[26] -0.494 -0.203 #&gt; u[27] -0.233 0.059 #&gt; u[28] -0.332 -0.038 #&gt; u[29] -0.423 -0.127 #&gt; u[30] -0.406 -0.113 #&gt; u[31] -0.100 0.188 #&gt; u[32] -0.178 0.113 #&gt; u[33] -0.239 0.056 #&gt; u[34] 0.257 0.554 #&gt; u[35] -0.396 -0.104 #&gt; u[36] -0.144 0.145 #&gt; u[37] -0.171 0.118 #&gt; w[1] -0.133 0.061 #&gt; w[2] -0.118 0.075 #&gt; w[3] -0.101 0.093 #&gt; w[4] -0.213 -0.015 #&gt; w[5] -0.006 0.190 #&gt; w[6] -0.141 0.056 #&gt; w[7] -0.281 -0.082 #&gt; w[8] 0.115 0.315 #&gt; w[9] -0.185 0.009 #&gt; w[10] -0.041 0.153 #&gt; w[11] -0.136 0.058 #&gt; w[12] -0.030 0.165 #&gt; w[13] -0.176 0.018 #&gt; w[14] 0.036 0.235 #&gt; w[15] -0.041 0.155 #&gt; sigma_e 0.562 0.593 #&gt; sigma_u 0.183 0.309 #&gt; sigma_w 0.076 0.188 #&gt; lp__ -2332.580 -2311.210 References "],["ch-entropy.html", "Capitolo 32 Entropia 32.1 La generalizzabilità dei modelli 32.2 Capacità predittiva 32.3 Il rasoio di Ockham 32.4 La misura del disordine Commenti e considerazioni finali", " Capitolo 32 Entropia Il principio base del metodo scientifico è la replicabilità delle osservazioni: le osservazioni che non possono essere replicate sono poco interessanti. Parallelamente, una caratteristica fondamentale di un modello scientifico è la generalizzabilità: se un modello è capace di descrivere soltanto le proprietà di uno specifico campione di osservazioni, allora è poco utile. Ma come è possibile valutare la generalizzabilità di un modello statistico? Questa è la domanda a cui cercheremo di rispondere in questa parte della dispensa. In questo Capitolo inizieremo questa discussione introducendo il concetto di entropia. 32.1 La generalizzabilità dei modelli Secondo Johnson, Ott, and Dogucu (2022), nel valutare un modello, il ricercatore deve porsi tre domande critiche. Quali conseguenze più ampie derivano dall’inferenza? Come e chi ha raccolto i dati? Colui che svolge la ricerca otterrebbe di benefici manipolando i dati (escludendo delle osservazioni; selezionando il campione)? Che impatto hanno inferenze che vengono tratte dai dati sugli individui e sulla società? Quali pregiudizi o strutture di potere possono essere coinvolti in questa analisi? Che tipo di distorsioni sistematiche potrebbero essere presenti nell’analisi statistica? Ricordiamo la famosa citazione di George Box: “Tutti i modelli sono sbagliati, ma alcuni sono utili”. È dunque importante sapere quanto è sbagliato il modello. Le assunzioni che stanno alla base del modello sono ragionevoli? Il meccanismo generatore dei dati che è stato ipotizzato è adeguato per il fenomeno in esame? Quanto è accurato il modello? Quanto sono lontane dalla realtà le previsioni del modello? Per approfondire questi temi, si rinvia al testo di Johnson, Ott, and Dogucu (2022). Qui ci concentreremo su uno dei temi critici relativa alla validità di un modello, ovvero sul tema della generalizzabilità del modello. Nella scienza l’utilità di una teoria viene verificata esaminando la corrispondenza tra predizioni teoriche e osservazioni. Se vi sono discrepanze significative tra predizioni e osservazioni ciò suggerisce che la teoria, o nella nostra visione più ristretta, il modello statistico, è poco utile. Il problema della capacità predittiva del modello non riguarda soltanto l’adeguatezza del modello in riferimento ad uno specifico campione di dati, ma riguarda anche la capacità di un modello statistico sviluppato in un campione di dati di ben adattarsi ad altri campioni della stessa popolazione. In generale, i modelli statistici tendono a non generalizzarsi bene a un nuovo campione; questo perché sfruttano le caratteristiche specifiche dei dati del campione e tendono a produrre risultati eccessivamente ottimistici (cioè le dimensioni dell’effetto) che sovrastimano la dimensione dell’effetto atteso sia nella popolazione che in nuovi campioni. Benché i problemi della generalizzabilità dei modelli e il metodo chiave per valutarli – ovvero, la convalida incrociata (cross-validation) – siano stati discussi sin dagli esordi della letteratura psicometrica (Lord 1950), tali temi sono stati sottovalutati nella formazione psicologica contemporanea e nella ricerca. Tuttavia, questi concetti diventeranno sempre più importanti considerata l’enfasi corrente sulla necessità di condurre ricerche replicabili. Un’introduzione a questi temi è fornita, da esempio, da Song, Tang, and Wee (2021). Nello specifico, Song, Tang, and Wee (2021) mostrano che un modello che viene adattato a un campione (campione di calibrazione) non si generalizza bene a un altro campione (campione di convalida): la capacità predittiva del modello è minore quando il modello viene applicato al campione di convalida piuttosto che al campione di calibrazione. Questo problema è detto sovra-adattamento (overfitting). In generale, Song, Tang, and Wee (2021) mostrano come la capacità di generalizzazione del modello diminuisce (a) all’aumentare della complessità del modello, (b) al diminuire dell’ampiezza del campione di calibrazione, e (c) al diminuire della dimensione dell’effetto nella popolazione. Sebbene i modelli statistici producono comunemente un sovra-adattamento, è anche possibile che essi producano un sotto-adattamento (underfitting) dei dati. Tale mancanza di adattamento è dovuta dalla variabilità campionaria e dalla complessità del modello. Il sotto-adattamento porta ad un \\(R^2\\) basso e ad un MSE alto, sia nei campioni di calibrazione che in quelli di convalida. Per questo motivo, la scarsa generalizzabilità del modello può essere dovuta sia al sovra-adattamento che al sotto-adattamento del modello. Per aumentarne la capacità di generalizzazione del modello devono essere soddisfatte tre condizioni: (a) campioni di calibrazione grandi, (b) dimensioni dell’effetto non piccole nella popolazione, e (c) modelli che non siano inutilmente complessi. Tuttavia, nella ricerca psicologica queste tre condizioni sono difficili da soddisfare: l’aumento della dimensione del campione spesso richiede l’utilizzo di maggiori risorse, la dimensione di un dato effetto nella popolazione non è soggetta alla discrezione dei ricercatori e la complessità del modello è spesso guidata da motivazioni teoriche. Pertanto, negli studi psicologici la generalizzabilità dei modelli è spesso problematica. Ciò rende necessario che il ricercatore fornisca informazioni aggiuntive relative alla capacità del modello di generalizzarsi a nuovi campioni. L’obiettivo di questa parte della dispensa è di descrivere come questo possa essere fatto utilizzando l’approccio bayesiano. 32.2 Capacità predittiva Nel framework bayesiano il problema della generalizzabilità di un modello viene affrontato valutando la capacità predittiva del modello, laddove per capacità predittiva si intende la capacità di un modello, i cui parametri sono stati stimati usando le informazioni di un campione, di ben adattarsi ad un campione di osservazioni future. In questo Capitolo cercheremo di rispondere a tre domande. Quali criteri consentono di valutare la capacità predittiva di un modello? Come quantificare la capacità predittiva di un modello usando solo un campione di osservazioni? Come confrontare le capacità predittive di modelli diversi? 32.3 Il rasoio di Ockham Il problema di scegliere il modello più adatto a spiegare un fenomeno di interesse è uno dei più importanti problemi in campo scientifico. I ricercatori si chiedono: il modello è completo? È necessario aggiungere un nuovo parametro al modello? Come può essere migliorato il modello? Se ci sono modelli diversi, qual’è il modello migliore? Per rispondere a queste domande è possibile usare il rasoio di Ockham: frustra fit per plura quod potest fieri per pauciora (“si fa inutilmente con molte cose ciò che si può fare con poche cose”). Parafrasando la massima si potrebbe dire: se due modelli descrivono i dati egualmente bene, viene sempre preferito il modello più semplice. Questo è il principio che sta alla base della ricerca scientifica. Il rasoio di Ockham, però, non consente sempre di scegliere tra modelli alternativi. Se due modelli fanno le stesse predizioni ma differiscono in termini di complessità — per esempio, relativamente al numero di parametri di cui sono costituiti — allora è facile decidere: viene preferito il modello più semplice, anche perché, pragmaticamente, è il più facile da usare. Tuttavia, in generale, i modelli differiscono sia per complessità (ovvero, per il numero di parametri) che per accuratezza (ovvero, per la grandezza degli errori di predizione). In tali circostanze il rasoio di Ockham non è sufficiente: non consente infatti di trovare un equilibrio tra accuratezza e semplicità. In questo Capitolo ci chiederemo come sia possibile misurare l’accuratezza predittiva di un modello. Ciò ci consentirà, in seguito, di usare il rasoio di Ockham: a parità di accuratezza, sarà possibile scegliere il modello più semplice. Ma nella pratica scientifica non si sacrifica mai l’accuratezza per la semplicità: il criterio prioritario è sempre l’accuratezza. 32.3.1 Sovra-adattamento e sotto-adattamento Secondo McElreath (2020), la selezione tra modelli deve evitare due opposti errori: il sovra-adattamento e il sotto-adattamento. Tale problema va sotto il nome di bias-variance trade-off: il sotto-adattamento, infatti, porta a distorsioni (bias) nella stima dei parametri, mentre il sovra-adattamento porta a previsioni scadenti in campioni futuri. Spesso l’incertezza relativa alla scelta del modello (sotto-adattamento versus sovra-adattamento) passa inosservata ma il suo impatto può essere drammatico. Secondo Hoeting et al. (1999), “Standard statistical practice ignores model uncertainty. Data analysts typically select a model from some class of models and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and decisions that are more risky than one thinks they are. In questo Capitolo esamineremo alcune tecniche bayesiane che possono essere utilizzate per operare una selezione tra modelli alternativi, tenendo sotto controllo i pericoli del sovra-adattamento e del sotto-adattamento. In particolare, ci chiederemo quale, tra due o più modelli, sia quello da preferire in base al criterio della capacità predittiva. 32.3.2 Stargazing Nella pratica concreta della ricerca, il metodo più comune per la selezione tra modelli alternativi utilizza i test di ipotesi statistiche di stampo frequentista. Questo metodo viene chiamato stargazing, poiché richiede soltanto l’esame degli asterischi (\\(**\\)) che si trovano nell’output di un software statistico (gli asterischi marcano i coefficienti del modello che sono “statisticamente significativi”): alcuni ricercatori ritengono che il modello con più stelline sia anche il modello migliore. Questo però non è vero. Al di là dei problemi legati ai test dell’ipotesi nulla, è sicuramente un errore usare i test di significatività per la selezione di modelli: i valori-p non consentono di trovare un equilibrio tra underfitting e overfitting. Infatti, le variabili che migliorano la capacità predittiva di un modello non sono sempre statisticamente significative; d’altra parte, le variabili statisticamente significative non sempre migliorano la capacità predittiva di un modello. Quando ci chiediamo quale, tra modelli alternativi, è il modello che meglio rappresenta il “vero” processo di generazione dei dati, ci troviamo di fronte al problema di quantificare il grado di “vicinanza” di un modello al “vero” processo di generazione dei dati. Si noti che, in tale confronto, facciamo riferimento sia alla famiglia distributiva così come ai valori dei parametri. Ad esempio, il modello \\(y_i \\sim \\mathcal{N}(5, 3)\\) è diverso dal modello \\(y_i \\sim \\mathcal{N}(5, 6)\\), ed è anche diverso dal modello \\(y_i \\sim \\Gamma(2, 2)\\). I primi due modelli appartengono alla stessa famiglia distributiva ma differiscono nei termini dei valori dei parametri; gli ultimi due modelli appartengono a famiglie distributive diverse (gaussiano vs. Gamma). Per misurare il grado di “vicinanza” tra due modelli, \\(\\mathcal{M}_1\\) e \\(\\mathcal{M}_2\\), la metrica di gran lunga più popolare è la divergenza di Kullback-Leibler. Per chiarire questo concetto è però prima necessario introdurre la nozione di entropia. 32.4 La misura del disordine Se vogliamo ottenere una comprensione intuitiva del concetto di entropia32 possiamo pensare a quant’è informativa una distribuzione. Maggiore è l’entropia di una distribuzione, meno informativa sarà quella distribuzione e più uniformemente verranno assegnate le probabilità agli eventi. In altri termini, ottenere la risposta di “42” è più informativo della risposta “42 \\(\\pm\\) 5”, che a sua volta è più informativo della risposta “un numero qualsiasi”. L’entropia quantifica questa osservazione qualitativa. Il concetto di entropia si applica sia alle distribuzioni continue sia a quelle discrete, ma è più facile da capire usando le distribuzioni discrete. Negli esempi successivi vedremo alcuni esempi applicati al caso discreto, ma gli stessi concetti si applicano al caso continuo. 32.4.1 Entropia di un singolo evento Il concetto di entropia può essere usato per descrivere la quantità di informazione fornita da un evento. L’intuizione che sta alla base del concetto di entropia è che l’informazione fornita da un evento descrive la sorpresa suscitata dall’evento: gli eventi rari (a bassa probabilità) sono più sorprendenti – e quindi forniscono più informazione – degli eventi comuni (ad alta probabilità). In altre parole, un evento a bassa probabilità è sorprendente e fornisce molta informazione; un evento ad alta probabilità è poco o per niente sorprendente e fornisce poca (o nessuna) informazione. È dunque possibile quantificare l’informazione fornita dal verificarsi di un evento usando la probabilità di quell’evento. Una tale quantità di informazione è chiamata “informazione di Shannon”, “auto-informazione” o semplicemente “informazione” e, per un evento discreto \\(x\\), può essere calcolata come: \\[ \\text{informazione}(x) = -\\log_2 p(x), \\] dove \\(\\log_2\\) è il logaritmo in base 2 e \\(p(x)\\) è la probabilità dell’evento \\(x\\). La scelta del logaritmo in base 2 significa che l’unità di misura dell’informazione è il bit (cifre binarie). Questo può essere interpretato dicendo che l’informazione misura il numero di bit richiesti per rappresentare un evento.33 Solitamente, si denota la quantità di informazione con \\(h()\\): \\[ h(x) = -\\log p(x). \\] Il segno negativo garantisce che il risultato sia sempre positivo o zero. L’informazione è zero quando la probabilità dell’evento è 1.0, ovvero quando l’evento è certo (assenza di sorpresa). Esempio 32.1 Consideriamo il lancio di una moneta equilibrata. La probabilità di testa (e croce) è 0.5. La quantità di informazione di ottenere “testa” è dunque -log2(0.5) #&gt; [1] 1 Per rappresentare questo evento abbiamo bisogno di 1 bit di informazione. Se la stessa moneta venisse lanciata \\(n\\) volte, la quantità di informazione necessaria per rappresentare questo evento (ovvero, questa sequenza di lanci) sarebbe pari a \\(n\\) bit. Se la moneta non è equilibrata e la probabilità di testa è 0.1, allora l’evento “testa” è più raro e richiede più di 3 bit di informazione: -log2(0.1) #&gt; [1] 3.321928 Consideriamo ora il lancio di un dado. Quanta informazione viene fornita, ad esempio, dall’evento “esce il numero 6”? Dato che la probabilità di ottenere un 6 nel lancio di un dado è più piccola della probabilità di ottenere “testa” nel lancio di una moneta, il risultato del lancio di un dado deve produrre una sorpresa maggiore del risultato del lancio di una moneta. Per cui, la quantità di informazione associata all’evento “è uscito 6”, dovrà essere maggiore di quella associata all’evento “testa”. Infatti, la quantità di informazione dell’evento “è uscito un 6” è più che doppia rispetto alla quantità di informazione dell’evento “testa”: -log2(1/6) #&gt; [1] 2.584963 Esempio 32.2 Nella figura successiva viene esaminata la relazione tra probabilità e informazione, per valori di probabilità nell’intervallo tra 0 e 1. p &lt;- seq(0, 1, length.out = 1000) h &lt;- -log2(p) ggplot(tibble(p, h), aes(p, h)) + geom_line() + labs( x = &quot;Probabilità&quot;, y = &quot;Informazione&quot; ) La figura mostra che questa relazione non è lineare, è infatti leggermente sublineare. Questo ha senso dato che abbiamo usato una funzione logaritmica. 32.4.2 Entropia di una variabile casuale Possiamo estendere questa discussione pensando ad un insieme di eventi, ovvero ad una distribuzione. Nella teoria della probabilità usiamo la nozione di variabile casuale per fare riferimento ad un insieme di eventi e alle probabilità associate a tali eventi. L’entropia quantifica l’informazione che viene fornita da una variabile casuale. Definizione 32.1 Sia \\(Y = y_1, \\dots, y_n\\) una variabile casuale e \\(p_t(y)\\) una distribuzione di probabilità su \\(Y\\). Si definisce la sua entropia (detta di Shannon) come: \\[\\begin{equation} H(Y) = - \\sum_{i=1}^n p_t(y_i) \\cdot \\log_2 p_t(y_i). \\tag{32.1} \\end{equation}\\] Per interpretare la (32.1), consideriamo un esempio discusso da Martin, Kumar, and Lao (2022). FIGURA 32.1: Funzioni di massa di probabilità e associata entropia. Nella figura 32.1 sono rappresentate sei distribuzioni. viene anche riportato il valore di entropia di ciascuna distribuzione. La distribuzione con il picco più pronunciato o con la dispersione minore è q, e questa è la distribuzione con il valore di entropia più basso tra le sei distribuzioni considerate. Per q la distribuzione è q ~ binom(n = 10, p = 0.75); quindi ci sono 11 possibili eventi. qu ha una distribuzione uniforme sugli stessi 11 possibili eventi. L’entropia di qu è maggiore dell’entropia di q. Infatti, se calcoliamo l’entropia di distribuzioni binomiali con \\(n = 10\\) (con valori diversi di \\(p\\)) ci rendiamo conto che nessuna di tali distribuzioni ha un’entropia maggiore di qu. Dobbiamo aumentare \\(n ≈ 3\\) volte per trovare la prima distribuzione binomiale con entropia maggiore di qu. Passiamo alla riga successiva. Generiamo la distribuzione r spostando a destra q e normalizzando (per garantire che la somma di tutte le probabilità sia 1). Poiché r ha una dispersione maggiore di q, la sua entropia è maggiore. ru è una distribuzione uniforme con lo stesso numero di eventi possibili come r (ovvero 22) – si noti che sono stati inclusi come valori possibili anche quelli nella “valle” tra i due picchi. Ancora una volta, la distribuzione uniforme ha l’entropia più grande. Gli esempi discussi finora sembrano suggerire che l’entropia è proporzionale alla varianza della distribuzione. Verifichiamo questa intuizione esaminiamo le ultime due distribuzioni della figura 32.1. La distribuzione s è simile a r ma presenta una separazione maggiore tra i due picchi della distribuzione – dunque, ha una varianza più grande. Ciò nonostante, l’entropia non varia. Quindi la relazione tra entropia e varianza non è così semplice come ci sembrava. Il risultato che abbiamo trovato può essere spiegato dicendo che, nel calcolo dell’entropia, non vengono considerati gli eventi con probabilità nulla (per questa ragione, nell’esempio, è stato possibile aumentare la varianza senza cambiare l’entropia). La distribuzione su è stata costruita sostituendo i due picchi in s con qu (e normalizzando). Possiamo vedere che su ha un’entropia minore di ru, anche se su ha una dispersione maggiore di ru. Questo è dovuto al fatto che su distribuisce la probabilità totale tra un numero minore di eventi (22) di ru (che ne conta 23); quindi è sensato attribuire a su un’entropia minore di ru. Esempio 32.3 Consideriamo ora un esempio riguardante le previsioni del tempo. Supponiamo che le probabilità di pioggia e sole siano, rispettivamente, \\(p_1 = 0.3\\) e \\(p_2 = 0.7\\). Quindi \\[ H(p) = − [p(y_1) \\log_2 p(y_1) + p(y_2) \\log_2 p(y_2)] \\approx 0.61. \\] Se però viviamo a Las Vegas, allora le probabilità di pioggia e sole saranno simili a \\(p(y_1) = 0.01\\) e \\(p(y_2) = 0.99\\). In questo secondo caso, l’entropia è 0.06, ovvero, molto minore di prima. Infatti, a Las Vegas non piove quasi mai, per cui quando abbiamo imparato che, in un certo giorno, non ha piovuto, abbiamo imparato molto poco rispetto a quello che già sapevamo in precedenza. Esempio 32.4 Nell’esempio precedente abbiamo visto che, se gli esiti possibili sono pioggia o sole con \\(p(y_1) = 0.7\\), \\(p(y_2) = 0.3\\), allora l’entropia è -(0.7 * log(0.7) + 0.3 * log(0.3)) #&gt; [1] 0.6108643 Ma se gli esiti possibili sono pioggia, neve o sole con \\(p(y_1) = 0.7\\), \\(p(y_2) = 0.15\\) e \\(p(y_3) = 0.15\\), rispettivamente, allora l’entropia cresce: -(0.7 * log(0.7) + 0.15 * log(0.15) + 0.15 * log(0.15)) #&gt; [1] 0.8188085 Commenti e considerazioni finali In questo Capitolo abbiamo visto come sia possibile quantificare l’incertezza tramite l’entropia. Ma come è possibile usare l’entropia dell’informazione per specificare la “distanza” tra un modello e il vero meccanismo generatore dei dati? La risposta a questa domanda è fornita dalla divergenza di Kullback-Leibler che verrà discussa nel Capitolo ??. References "],["ch-kl.html", "Capitolo 33 La divergenza di Kullback-Leibler 33.1 La perdita di informazione 33.2 La divergenza dipende dalla direzione 33.3 Confronto tra modelli 33.4 Expected log predictive density Commenti e considerazioni finali", " Capitolo 33 La divergenza di Kullback-Leibler È comune in statistica utilizzare una distribuzione di probabilità \\(q\\) per approssimare un’altra distribuzione \\(p\\) – generalmente, questo viene fatto se \\(p\\) non è conosciuta o è troppo complessa. In questi casi possiamo chiederci quanta informazione venga perduta usando \\(q\\) al posto di \\(p\\), o equivalentemente, quanta incertezza aggiuntiva viene introdotta nell’analisi statistica. La quantificazione di questo incremento di incertezza è fornita dalla divergenza di Kullback-Leibler. 33.1 La perdita di informazione Intuitivamente, per quantificare l’informazione che si perde quando una distribuzione approssimata \\(q\\) viene usata in luogo della distribuzione corretta \\(p\\) sembra necessaria una quantità che ha valore zero quando \\(q = p\\), e un valore positivo altrimenti. Seguendo la definizione (32.1) di entropia, possiamo quantificare una tale perdita di informazione mediante il valore atteso della differenza tra \\(\\log(p)\\) e \\(\\log(q)\\). Questa quantità è chiamata entropia relativa o divergenza di Kullback-Leibler: \\[\\begin{equation} \\mathbb{KL} (p \\mid\\mid q) = \\mathbb{E} (\\log p - \\log q). \\tag{33.1} \\end{equation}\\] La divergenza \\(\\mathbb{KL} (p \\mid\\mid q)\\) corrisponde alla differenza media nelle probabilità logaritmiche quando \\(q\\) viene usato per approssimare \\(p\\). Poiché gli eventi si manifestano secondo \\(p\\), è necessario calcolare il valore atteso rispetto a \\(p\\). Per distribuzioni discrete dunque abbiamo: \\[\\begin{equation} \\mathbb{KL} (p \\mid\\mid q) = \\sum_i^n p_i (\\log p_i - \\log q_i) = \\sum_i^n p_i \\log \\frac{p_i}{q_i}. \\end{equation}\\] Riarrangiando i termini otteniamo: \\[\\begin{equation} \\mathbb{KL} (p \\mid\\mid q) = -\\sum_i^n p_i (\\log q_i - \\log p_i), \\end{equation}\\] ovvero, \\[\\begin{equation} \\mathbb{KL} (p \\mid\\mid q) = \\underbrace{-\\sum_i^n p_i \\log q_i}_{h(p, q)} - \\underbrace{\\left(-\\sum_i^n p_i \\log p_i\\right)}_{h(p)}, \\end{equation}\\] laddove \\(h(p)\\) è l’entropia di \\(p\\) e \\(h(p, q) = − \\mathbb{E} [\\log q]\\) può essere intesa come l’entropia di \\(q\\), ma valutata secondo i valori di probabilità \\(p\\). Riarrangiando l’equazione precedente otteniamo: \\[\\begin{equation} h(p, q) = h(p) + \\mathbb{KL} (p \\mid\\mid q), \\end{equation}\\] il che mostra come la divergenza \\(\\mathbb{KL}\\) possa essere interpretata come l’incremento di entropia, rispetto a \\(h(p)\\), quando \\(q\\) viene usata per rappresentare \\(p\\). Esempio 33.1 (da McElreath 2020) Sia la distribuzione target \\(p = \\{0.3, 0.7\\}\\). Supponiamo che la distribuzione approssimata \\(q\\) possa assumere valori da \\(q = \\{0.01, 0.99\\}\\) a \\(q = \\{0.99, 0.01\\}\\). Calcoliamo la divergenza KL. Le istruzioni \\(\\mathsf{R}\\) sono le seguenti: t &lt;- tibble( p_1 = .3, p_2 = .7, q_1 = seq(from = .01, to = .99, by = .01) ) %&gt;% mutate( q_2 = 1 - q_1 ) %&gt;% mutate( d_kl = (p_1 * log(p_1 / q_1)) + (p_2 * log(p_2 / q_2)) ) head(t) #&gt; # A tibble: 6 × 5 #&gt; p_1 p_2 q_1 q_2 d_kl #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.3 0.7 0.01 0.99 0.778 #&gt; 2 0.3 0.7 0.02 0.98 0.577 #&gt; 3 0.3 0.7 0.03 0.97 0.462 #&gt; 4 0.3 0.7 0.04 0.96 0.383 #&gt; 5 0.3 0.7 0.05 0.95 0.324 #&gt; 6 0.3 0.7 0.06 0.94 0.276 Nella figura seguente sull’asse delle ascisse sono rappresentati i valori \\(q\\) e sull’asse delle ordinante sono riportati i corrispondenti valori \\(\\mathbb{KL}\\). t %&gt;% ggplot(aes(x = q_1, y = d_kl)) + geom_vline(xintercept = .3, linetype = 2) + geom_line(size = 1) + annotate(geom = &quot;text&quot;, x = .4, y = 1.5, label = &quot;q = p&quot;, size = 3.5) + labs(x = &quot;q[1]&quot;, y = &quot;Divergenza di q da p&quot;) Tanto meglio la distribuzione \\(q\\) approssima la distribuzione target tanto più piccolo è il valore di divergenza \\(\\mathbb{KL}\\). Esempio 33.2 Sia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\) n &lt;- 4 p &lt;- 0.2 true_py &lt;- dbinom(0:n, n, 0.2) true_py #&gt; [1] 0.4096 0.4096 0.1536 0.0256 0.0016 Sia \\(q_1\\) una approssimazione a \\(p\\): q1 &lt;- c(0.46, 0.42, 0.10, 0.01, 0.01) q1 #&gt; [1] 0.46 0.42 0.10 0.01 0.01 Sia \\(q_2\\) una distribuzione uniforme: q2 &lt;- rep(0.2, 5) q2 #&gt; [1] 0.2 0.2 0.2 0.2 0.2 La divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) è sum(true_py * log(true_py / q1)) #&gt; [1] 0.02925199 La divergenza \\(\\mathbb{KL}\\) di \\(q_2\\) da \\(p\\) è: sum(true_py * log(true_py / q2)) #&gt; [1] 0.4863578 È chiaro che perdiamo una quantità maggiore di informazioni se, per descrivere la distribuzione binomiale \\(p\\), usiamo la distribuzione uniforme \\(q_2\\) anziché \\(q_1\\). 33.2 La divergenza dipende dalla direzione La divergenza \\(\\mathbb{KL}\\) non è una vera e propria metrica: per esempio, non è simmetrica. In generale, \\(\\mathbb{KL}(p \\mid\\mid q) \\neq \\mathbb{KL}(q \\mid\\mid p)\\), ovvero la \\(\\mathbb{KL}\\) da \\(p\\) a \\(q\\) è diversa dalla \\(\\mathbb{KL}\\) da \\(q\\) a \\(p\\). Esempio 33.3 Usando le seguenti istruzioni \\(\\mathsf{R}\\) otteniamo: tibble(direction = c(&quot;Da q a p&quot;, &quot;Da p a q&quot;), p_1 = c(.01, .7), q_1 = c(.7, .01)) %&gt;% mutate(p_2 = 1 - p_1, q_2 = 1 - q_1) %&gt;% mutate(d_kl = (p_1 * log(p_1 / q_1)) + (p_2 * log(p_2 / q_2))) #&gt; # A tibble: 2 × 6 #&gt; direction p_1 q_1 p_2 q_2 d_kl #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Da q a p 0.01 0.7 0.99 0.3 1.14 #&gt; 2 Da p a q 0.7 0.01 0.3 0.99 2.62 33.3 Confronto tra modelli La divergenza \\(\\mathbb{KL}\\) viene utilizzata nel confronto tra modelli, ovvero ci consente di quantificare l’informazione che viene perduta quando utilizziamo la distribuzione di probabilità ipotizzata da un modello, chiamiamola \\(p_{\\mathcal{M}}\\), per approssimare la distribuzione di probabilità del vero modello generatore dei dati, \\(p_t\\). In precedenza abbiamo introdotto il concetto di distribuzione predittiva a posteriori: \\[ p(\\tilde{y} \\mid y) = \\int_\\Theta p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta . \\] La distribuzione predittiva a posteriori descrive il tipo di dati che ci aspettiamo vengano prodotti dal modello generativo \\(\\mathcal{M}\\), alla luce delle nostre credenze iniziali, \\(p(\\theta)\\) e dei dati osservati \\(y\\). Quando valutiamo un modello ci chiediamo in che misura \\(p_{\\mathcal{M}}(\\tilde{y} \\mid y)\\) approssimi \\(p_t(\\tilde{y})\\). Cioè, ci chiediamo quanto siano simili i dati \\(p_{\\mathcal{M}}(\\cdot)\\) prodotti dal modello \\(\\mathcal{M}\\) ai dati prodotti dal vero processo generatore dei dati \\(p_t(\\cdot)\\). Una misura della “somiglianza” tra la distribuzione \\(q_{\\mathcal{M}}\\) ipotizzata dal modello \\(\\mathcal{M}\\) e la distribuzione \\(p_t\\) del vero modello generatore dei dati è fornita dalla divergenza di Kullback-Leibler \\(\\mathbb{KL}(p_t \\mid\\mid q_{\\mathcal{M}})\\). Supponendo di avere \\(k\\) modelli della distribuzione a posteriori, \\(\\{q_{\\mathcal{M}_1}, q_{\\mathcal{M}_2}, \\dots, q_{\\mathcal{M}_k}\\}\\), e di conoscere il vero modello generatore dei dati, possiamo scrivere \\[\\begin{align} \\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_1}) &amp;= \\mathbb{E} (\\log p_{\\mathcal{M}_0}) - \\mathbb{E} (\\log q_{\\mathcal{M}_1})\\notag\\\\ \\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_2}) &amp;= \\mathbb{E} (\\log p_t) - \\E (\\log q_{\\mathcal{M}_2})\\notag\\\\ &amp;\\cdots\\notag\\\\ \\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_k}) &amp;= \\mathbb{E} (\\log p_{\\mathcal{M}_0}) - \\mathbb{E} (\\log q_{\\mathcal{M}_k}). \\tag{33.2} \\end{align}\\] La (33.2) può sembrare un esercizio futile poiché nella vita reale non conosciamo il vero modello generatore dei dati. È però facile rendersi conto che, poiché \\(p_t\\) è la stessa per tutti i confronti, diventa possibile costruire un ordinamento dei modelli basato unicamente sul secondo termine della (33.2), ovvero senza nessun riferimento al vero modello generatore dei dati. Per un generico modello \\(\\mathcal{M}\\), il secondo termine della (33.2) può essere scritto come: \\[\\begin{equation} \\mathbb{E} \\log p_{\\mathcal{M}}(y) = \\int_{-\\infty}^{+\\infty}p_{t}(y)\\log p_{\\mathcal{M}}(y) \\,\\operatorname {d}\\!y . \\tag{33.3} \\end{equation}\\] 33.4 Expected log predictive density Le previsioni del modello \\(\\mathcal{M}\\) sui nuovi dati futuri sono date dalla distribuzione predittiva a posteriori. Possiamo dunque riscrivere la (33.3) come \\[\\begin{equation} \\mbox{elpd} = \\int_{\\tilde{y}} p_{t}(\\tilde{y}) \\log p(\\tilde{y} \\mid y) \\,\\operatorname {d}\\!\\tilde{y}. \\tag{33.4} \\end{equation}\\] La (33.4) è chiamata expected log predictive density (\\(\\mbox{elpd}\\)) e fornisce la risposta al problema che ci eravamo posti: nel confronto tra modelli, come è possibile scegliere il modello più simile al vero meccanismo generatore dei dati? Possiamo pensare alla (33.4) dicendo che descrive la distribuzione predittiva a posteriori del modello ponderando la verosimiglianza dei possibili (sconosciuti) dati futuri (\\(\\tilde{y}\\)) con la vera distribuzione \\(p_t\\). Di conseguenza, valori \\(\\mbox{elpd}\\) più grandi identificano il modello che risulta più simile al vero meccanismo generatore dei dati. Non dobbiamo preoccuparci di trovare una formulazione analitica della distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\) perché è possibile approssimare tale distribuzione mediante simulazione. Notiamo però che la (33.4) include un termine, \\(p_t(\\tilde{y})\\), il quale descrive la distribuzione dei dati futuri \\(\\tilde{y}\\) secondo il vero modello generatore dei dati. Il termine \\(p_t\\), ovviamente, è ignoto.34 Di conseguenza, la quantità \\(\\mbox{elpd}\\) non può mai essere calcolata in maniera esatta, ma può solo essere stimata. Il secondo problema di questo Capitolo è capire come la (33.4) possa essere stimata utilizzando un campione di osservazioni. 33.4.1 Log pointwise predictive density Ingenuamente, potremmo pensare di stimare la (33.4) ipotizzando che la distribuzione del campione coincida con \\(p_t\\). Usare la distribuzione del campione come proxy del vero modello generatore dei dati (ovvero, ipotizzare che la distribuzione del campione rappresenti fedelmente \\(p_t\\)) comporta due conseguenze: non è necessario ponderare per \\(p_t\\), in quanto assumiamo che la distribuzione empirica del campione corrisponda a \\(p_t\\) (ciò significa assumere che i valori più comunemente osservati nel campione siano anche quelli più verosimili nella vera distribuzione \\(p_t\\)); dato che il campione è finito, anziché eseguire un’operazione di integrazione possiamo semplicemente sommare la densità predittiva a posteriori delle osservazioni. Questo conduce alla seguente equazione:35 \\[\\begin{equation} \\frac{1}{n} \\sum_{i=1}^n \\log p(y_i^{rep} \\mid y). \\tag{33.5} \\end{equation}\\] La quantità (33.5), senza il passaggio finale della divisione per il numero di osservazioni, è chiamata log pointwise predictive density (\\(\\mbox{lppd}\\)) \\[\\begin{equation} \\mbox{lppd} = \\sum_{i=1}^n \\log p(y_i^{rep} \\mid y) \\tag{33.6} \\end{equation}\\] e corrisponde alla somma delle densità predittive logaritmiche delle \\(n\\) osservazioni. Valori più grandi della (33.6) sono da preferire perché indicano una maggiore accuratezza media. È anche comune vedere espressa la quantità precedente nei termini della devianza, ovvero alla \\(\\mbox{lppd}\\) moltiplicata per -2. In questo secondo caso sono da preferire valori piccoli. È importante notare che \\(\\lppd\\) fornisce una sovrastima della (33.4). Tale sovrastima è dovuta al fatto che, nel calcolo della (33.6), abbiamo usato \\(p(y^{rep} \\mid y)\\) al posto di \\(p(\\tilde{y} \\mid y)\\): in altri termini, abbiamo considerato le osservazioni del campione come se fossero un nuovo campione di dati. In una serie di simulazioni, McElreath (2020) esamina il significato di questa sovrastima. Nelle simulazioni la devianza viene calcolata come funzione della complessità (ovvero, il numero di parametri) del modello. La simulazione mostra che \\(\\mbox{lppd}\\) aumenta al crescere del numero di parametri del modello. Ciò significa che \\(\\mbox{lppd}\\) mostra lo stesso limite del coefficiente di determinazione: aumenta all’aumentare della complessità del modello. Esempio 33.4 Esaminiamo un esempio tratto da Bayesian Data Analysis for Cognitive Science nel quale la \\(\\mbox{lppd}\\) viene calcolata in forma esatta oppure mediante approssimazione. Supponiamo di disporre di un campione di \\(n\\) osservazioni. Supponiamo inoltre di conoscere il vero processo generativo dei dati (qualcosa che in pratica non è mai possibile), ovvero: \\[ p_t(y) = \\mbox{Beta}(1, 3). \\] I dati sono set.seed(75) n &lt;- 10000 y_data &lt;- rbeta(n, 1, 3) head(y_data) #&gt; [1] 0.55062422 0.13346270 0.80250987 0.21430898 0.01913430 0.08676517 Supponiamo inoltre di avere adattato ai dati un modello bayesiano \\(\\mathcal{M}\\) e di avere ottenuto la distribuzione a posteriori per i parametri del modello. Inoltre, supponiamo di avere derivato la forma analitica della distribuzione predittiva a posteriori per il modello: \\[ p(y^{rep} \\mid y) \\sim \\mbox{Beta}(2, 2). \\] Questa distribuzione ci dice quanto sono credibili i possibili dati futuri. Conoscendo la vera distribuzione dei dati \\(p_t(y)\\) possiamo calcolare in forma esatta la quantità \\(\\mbox{elpd}\\), ovvero \\[ \\mbox{elpd} = \\int_{y^{rep}}p_{t}(y^{rep})\\log p(y^{rep} \\mid y) \\,\\operatorname {d}\\!y^{rep}. \\] Svolgiamo i calcoli in \\(\\mathsf{R}\\) otteniamo: # True distribution p_t &lt;- function(y) dbeta(y, 1, 3) # Predictive distribution p &lt;- function(y) dbeta(y, 2, 2) # Integration integrand &lt;- function(y) p_t(y) * log(p(y)) integrate(f = integrand, lower = 0, upper = 1) #&gt; -0.3749072 with absolute error &lt; 6.8e-07 Tuttavia, in pratica non conosciamo mai \\(p_t(y)\\). Quindi approssimiamo \\(\\mbox{elpd}\\) usando la (33.4): \\[ \\frac{1}{n} \\sum_{i=1}^n \\log p(y_i \\mid y). \\] Così facendo, e svolgendo i calcoli in \\(\\mathsf{R}\\), otteniamo un valore diverso da quello trovato in precedenza: 1/n * sum(log(p(y_data))) #&gt; [1] -0.3639141 Commenti e considerazioni finali Dato che non conosciamo il vero meccanismo generatore dei dati \\(p\\), possiamo usare la distribuzione dei dati osservata come proxy per la vera distribuzione \\(p\\). Quindi, invece di ponderare la distribuzione predittiva in base alla densità reale di tutti i possibili dati futuri, utilizziamo semplicemente le \\(n\\) osservazioni che abbiamo. Possiamo farlo perché assumiamo che le nostre osservazioni costituiscano un campione dalla vera distribuzione dei dati: in base a questa ipotesi, nel campione ci aspettiamo di osservare più frequentemente quelle osservazioni che hanno una maggiore verosimiglianza nella vera distribuzione \\(p\\). È così possibile giungere ad una stima numerica della \\(\\mbox{elpd}\\) chiamata log pointwise predictive density (\\(\\mbox{lppd}\\)). References "],["ch-info-crit.html", "Capitolo 34 Criterio di informazione e convalida incrociata 34.1 AIC, DIC e WAIC 34.2 Convalida incrociata K-fold 34.3 Confronto tra AIC e LOO-CV 34.4 Confronto tra modelli mediante LOO-CV 34.5 Outlier 34.6 Regolarizzazione Commenti e considerazioni finali", " Capitolo 34 Criterio di informazione e convalida incrociata Nel Capitolo precedente abbiamo visto che la (33.6) fornisce una sovrastima della \\(\\mbox{elpd}\\). Il modo migliore per stimare \\(\\mbox{elpd}\\) è raccogliere un nuovo campione indipendente di dati, che si ritiene condivida lo stesso processo di generazione dei dati del campione corrente, e stimare \\(\\mbox{elpd}\\) sul nuovo campione. Questa procedura è chiamata out-of-sample validation. Il problema, però, è che solitamente non abbiamo le risorse per raccogliere un nuovo campione di osservazioni. Di conseguenza, gli statistici hanno messo a punto vari metodi per evitare la sovrastima della \\(\\mbox{elpd}\\) che deriva dal solo utizzo del campione corrente. Ci sono due approcci generali: l’introduzione di un fattore di correzione; la convalida incrociata cosiddetta K-fold. Lo scopo del presente Capitolo è di fornire una breve introduzione ai criteri dell’informazione e alla procedura della convalida incrociata. 34.1 AIC, DIC e WAIC Allo scopo di evitare la sovrastima della (33.6), le statistiche Akaike Information Criterion (AIC), Deviance Information Criterion (DIC) e Widely Applicable Information Criterion (WAIC) introducono un fattore di correzione. Le statistiche DIC e WAIC sono più complesse di AIC, ma producono un’approssimazione migliore. Tuttavia, i valori AIC, DIC e WAIC sono spesso molto simili tra loro. Per convenienza, dunque, qui ci accontenteremo di esaminare in dettaglio la statistica più semplice, ovvero AIC. 34.1.1 Criterio d’informazione di Akaike Il criterio d’informazione di Akaike (in inglese Akaike information criterion, indicato come AIC) fornisce un metodo molto semplice per approssimare \\(\\mbox{elpd}\\). Definizione 34.1 Il criterio d’informazione di Akaike è definito come \\[\\begin{equation} AIC = -2 \\log p(y \\mid \\hat{\\theta}_{MLE}) + 2k, \\end{equation}\\] dove \\(k\\) è il numero di parametri stimati nel modello e \\(p(y \\mid \\hat{\\theta}_{MLE})\\) è il valore massimizzato della funzione di verosimiglianza del modello stimato. Dividendo per -2, otteniamo \\(\\mbox{elpd}_{AIC}\\): \\[\\begin{equation} \\widehat{\\mbox{elpd}}_{AIC} = \\log p(y \\mid \\hat{\\theta}_{MLE}) - k, \\end{equation}\\] dove \\(k\\) è il fattore di correzione introdotto per evitare la sovrastima discussa in precedenza. AIC è di interesse principalmente storico e produce una approssimazione attendibile di \\(\\mbox{elpd}\\) quando: le distribuzioni a priori sono non informative; la distribuzione a posteriori è approssimativamente gaussiana multivariata; la dimensione \\(n\\) del campione è molto maggiore del numero \\(k\\) dei parametri. Esempio 34.1 Per meglio comprendere la statistica \\(\\widehat{\\mbox{elpd}}_{AIC}\\), esaminiamo un esempio discusso da Gelman, Hwang, and Vehtari (2014). Sia \\(y_1, \\dots, y_n \\sim \\mathcal{N}(\\mu, 1)\\) un campione di osservazioni. Nel caso di una distribuzione a priori non-informativa \\(p(\\theta) \\propto 1\\), la stima di massima verosimiglianza è \\(\\bar{y}\\). La verosimiglianza è \\[ f(Y \\mid \\mu, \\sigma) = \\prod_{i=1}^n f(y \\mid \\mu, \\sigma) \\] e la log-verosimiglianza diventa \\[ \\ell(Y \\mid \\mu, \\sigma) = \\sum_{i=1}^n \\log (f(y \\mid \\mu, \\sigma)). \\] Ovvero, \\[\\begin{align} \\ell(Y \\mid \\mu, \\sigma) &amp;= \\sum_{i=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi\\sigma^2 }}}\\exp \\left(-{\\frac {1}{2}}{\\frac {(y_i-\\mu )^{2}}{\\sigma^{2}}}\\right) \\right)\\notag\\\\ &amp;= \\sum_{i=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi \\sigma^2}}} \\right) - \\sum_{i=1}^n{\\frac {1}{2}}{\\frac {(y_i-\\mu )^{2}}{\\sigma ^{2}}} \\notag\\\\ &amp;= \\sum_{i=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi \\sigma^2}}} \\right) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2} \\notag \\\\ &amp;= \\sum_{i=1}^n \\log (1) - \\sum_{i=1}^n\\log \\sqrt{2\\pi \\sigma^2} - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2} \\notag\\\\ &amp;= - \\sum_{i=1}^n\\frac{1}{2} \\log (2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2} \\notag\\\\ &amp;= - \\frac{n}{2} \\log (2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2}. \\notag \\end{align}\\] Se \\(y \\sim \\mathcal{N}(\\mu, 1)\\), usando lo stimatore di massima verosimiglianza per \\(\\mu\\), la log-verosimiglianza diventa \\[\\begin{align} \\log p(y \\mid \\hat{\\theta}_{MLE}) &amp;= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2}\\sum_{i=1}^n (y_i - \\bar{y})^2 \\notag\\\\ &amp;= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2} (n-1)s_y^2, \\end{align}\\] dove \\(s_y^2\\) è la varianza campionaria. Nel caso di un modello gaussiano con con varianza nota e una distribuzione a priori uniforme viene stimato un solo parametro, per cui \\[\\begin{align} \\widehat{\\mbox{elpd}}_{AIC} &amp;= \\log p(y \\mid \\hat{\\theta}_{MLE}) - k \\notag \\\\ &amp;= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2} (n-1)s_y^2 - 1. \\end{align}\\] 34.2 Convalida incrociata K-fold La sovrastima della (33.6) può anche essere evitata usando una tecnica chiamata K-fold cross-validation. Mediante questo metodo vengono stimati i parametri del modello tralasciando una porzione di osservazioni (chiamata fold) dal campione per poi valutare il modello sulle osservazioni che sono state escluse. Una stima complessiva dell’accuratezza si ottiene poi calcolando la media del punteggio di accuratezza ottenuto in ogni fold. Il numero minimo di fold è 2; all’altro estremo, è possibile impiegare una singola osservazione in ciascun fold e adattare il modello tante volte (\\(n\\)) quante sono le singole osservazioni. Questa strategia è chiamata leave-one-out cross-validation (LOO-CV). 34.2.1 Importance sampling La strategia LOO-CV è computazionalmente onerosa (ovvero, richiede un tempo di esecuzione molto lungo). È però possibile approssimare LOO-CV mediante un metodo chiamato Pareto-smoothed importance sampling cross-validation [PSIS; Vehtari, Gelman, and Gabry (2017)]. Tralasciando qui i dettagli matematici, l’intuizione di base è che PSIS fa leva sul punteggio di “importanza” posseduto da ciascuna osservazione all’interno della distribuzione a posteriori. Per “importanza” si intende il fatto che alcune osservazioni hanno un impatto maggiore sulle proprietà della distribuzione a posteriori di altre: se viene rimossa un’osservazione importante, le proprietà della distribuzione a posteriori cambiano molto; se viene rimossa un’osservazione poco importante, la distribuzione a posteriori cambia poco. L’“importanza” così intesa viene chiamata “peso” (weight) e tali pesi vengono utilizzati per stimare l’accuratezza out-of-sample del modello. PSIS-LOO-CV richiede che il modello venga adattato una volta soltanto ai dati e fornisce una stima della devianza out-of-sample che evita la sovrastima della (33.6). Inoltre, PSIS-LOO-CV fornisce un feedback sulla propria affidabilità identificando le osservazioni i cui pesi molto elevati potrebbero rendere imprecisa la predizione. Valori \\(\\widehat{\\mbox{elpd}}_{LOO}\\) più grandi indicano una maggiore accuratezza predittiva. In alternativa, anziché considerare \\(\\widehat{\\mbox{elpd}}\\), è possibile usare la quantità \\(-2 \\cdot \\widehat{\\mbox{elpd}}\\), la quale è chiamata LOO Information Criterion (LOOIC). In questo secondo caso, valori LOOIC più piccoli sono da preferire. La quantità \\(\\widehat{\\mbox{elpd}}_{LOO}\\) viene calcolata dai pacchetti loo e brms ed è chiamata elpd_loo o elpd_kfold. È anche possibile calcolare la differenza della quantità elpd_loo per modelli alternativi, insieme alla deviazione standard della distribuzione campionaria di tale differenza. 34.3 Confronto tra AIC e LOO-CV Per fare un esempio, faremo qui un confronto tra \\(\\widehat{\\mbox{elpd}}_{AIC}\\) e \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\). Esaminiamo nuovamente l’associazione tra il QI dei figli e il QI delle madri nel campione di dati discusso da Gelman, Hill, and Vehtari (2020). Una tale relazione può essere descritta da un modello di regressione nel quale la \\(y\\) corrisponde al QI dei figli e la \\(x\\) al QI delle madri. Leggiamo i dati in : library(&quot;foreign&quot;) df &lt;- read.dta(here(&quot;data&quot;, &quot;kidiq.dta&quot;)) df$y &lt;- scale(df$kid_score)[, 1] df$x1 &lt;- scale(df$mom_iq)[, 1] head(df) #&gt; kid_score mom_hs mom_iq mom_work mom_age y x1 #&gt; 1 65 1 121.11753 4 27 -1.06793237 1.4078352 #&gt; 2 98 1 89.36188 4 25 0.54886757 -0.7092079 #&gt; 3 85 1 115.44316 4 27 -0.08805362 1.0295443 #&gt; 4 83 1 99.44964 3 25 -0.18604150 -0.0366907 #&gt; 5 115 1 92.74571 4 27 1.38176451 -0.4836193 #&gt; 6 98 0 107.90184 1 18 0.54886757 0.5267892 Dato che AIC non è una statistica bayesiana, può essere calcolata mediante strumenti frequentisti: m1_freq &lt;- lm(y ~ x1, data = df) AIC(m1_freq) / -2 #&gt; [1] -569.6384 Per ottenere LOO-CV adattiamo ai dati un modello di regressione bayesiano: modelString = &quot; data { int&lt;lower=0&gt; N; vector[N] x1; vector[N] y; } parameters { real alpha; real beta1; real&lt;lower=0&gt; sigma; } transformed parameters { vector[N] mu; for (n in 1 : N) { mu[n] = alpha + beta1 * x1[n]; } } model { alpha ~ normal(0, 1); beta1 ~ normal(0, 1); sigma ~ cauchy(0, 1); y ~ normal(mu, sigma); } generated quantities { vector[N] y_rep; vector[N] log_lik; for (n in 1 : N) { y_rep[n] = normal_rng(mu[n], sigma); log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1, sigma); } } &quot; writeLines(modelString, con = &quot;code/simplereg.stan&quot;) data1_list &lt;- list( N = length(df$kid_score), y = df$y, x1 = df$x1 ) file1 &lt;- file.path(&quot;code&quot;, &quot;simplereg.stan&quot;) mod1 &lt;- cmdstan_model(file1) Eseguiamo il campionamento MCMC: fit1 &lt;- mod1$sample( data = data1_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, cores = 4L, refresh = 0 ) Calcoliamo infine la quantità \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\): loo1_result &lt;- fit1$loo(cores = 4) print(loo1_result) #&gt; #&gt; Computed from 16000 by 434 log-likelihood matrix #&gt; #&gt; Estimate SE #&gt; elpd_loo -568.6 14.5 #&gt; p_loo 1.9 0.2 #&gt; looic 1137.2 28.9 #&gt; ------ #&gt; Monte Carlo SE of elpd_loo is 0.0. #&gt; #&gt; All Pareto k estimates are good (k &lt; 0.5). #&gt; See help(&#39;pareto-k-diagnostic&#39;) for details. Si noti la somiglianza tra \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\) e \\(\\widehat{\\mbox{elpd}}_{AIC}\\). In conclusione, possiamo dunque dire che \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\) è la risposta bayesiana allo stesso problema che trova una soluzione frequentista nella statistica \\(\\widehat{\\mbox{elpd}}_{AIC}\\). 34.4 Confronto tra modelli mediante LOO-CV Come menzionato in precedenza, l’obiettivo centrale della misurazione dell’accuratezza predittiva è il confronto di modelli. Una volta capito come calcolare LOO-CV con un condice scritto in linguaggio Stan, svolgeremo ora un confronto di modelli.36 Considereremo qui un confronto di modelli di regressione. Il modello di regressione discusso nel Paragrafo precedente prevede il QI dei bambini dal QI delle madri. Aggiungiamo a tale modello un secondo predittore che corrisponde all’età della madre. L’aggiunta di tale predittore migliori l’accuratezza predittiva del modello? modelString = &quot; data { int&lt;lower=0&gt; N; vector[N] x1; vector[N] x2; vector[N] y; } parameters { real alpha; real beta1; real beta2; real&lt;lower=0&gt; sigma; } transformed parameters { vector[N] mu; for (n in 1 : N) { mu[n] = alpha + beta1 * x1[n] + beta2 * x2[n]; } } model { alpha ~ normal(0, 1); beta1 ~ normal(0, 1); beta2 ~ normal(0, 1); sigma ~ cauchy(0, 1); y ~ normal(mu, sigma); } generated quantities { vector[N] y_rep; vector[N] log_lik; for (n in 1 : N) { y_rep[n] = normal_rng(mu[n], sigma); log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x2[n] * beta2, sigma); } } &quot; writeLines(modelString, con = &quot;code/mreg2.stan&quot;) df$x2 &lt;- scale(df$mom_age)[, 1] data2_list &lt;- list( N = length(df$kid_score), y = df$y, x1 = df$x1, x2 = df$x2 ) file2 &lt;- file.path(&quot;code&quot;, &quot;mreg2.stan&quot;) # compile model mod2 &lt;- cmdstan_model(file2) # Running MCMC fit2 &lt;- mod2$sample( data = data2_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, cores = 4L, refresh = 0 ) fit2$summary(c(&quot;alpha&quot;, &quot;beta1&quot;, &quot;beta2&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 4 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha -0.000255 -0.000162 0.0431 0.0427 -0.0714 0.0705 1.00 19419. #&gt; 2 beta1 0.442 0.442 0.0427 0.0427 0.372 0.512 1.00 17850. #&gt; 3 beta2 0.0515 0.0514 0.0427 0.0428 -0.0179 0.121 1.00 16802. #&gt; 4 sigma 0.896 0.895 0.0305 0.0303 0.848 0.948 1.00 19032. #&gt; # … with 1 more variable: ess_tail &lt;dbl&gt; loo2_result &lt;- fit2$loo(cores = 4) print(loo2_result) #&gt; #&gt; Computed from 16000 by 434 log-likelihood matrix #&gt; #&gt; Estimate SE #&gt; elpd_loo -568.9 14.5 #&gt; p_loo 3.0 0.3 #&gt; looic 1137.8 29.0 #&gt; ------ #&gt; Monte Carlo SE of elpd_loo is 0.0. #&gt; #&gt; All Pareto k estimates are good (k &lt; 0.5). #&gt; See help(&#39;pareto-k-diagnostic&#39;) for details. Consideriamo infine un terzo modello che utilizza come predittori, oltre al QI della madre, una variabile dicotomica (codificata 0 o 1) che distingue madri che hanno completato le scuole superiori da quelle che non le hanno completate. Nuovamente, la domanda è se l’aggiunta di tale predittore migliori la capacità predittiva del modello. modelString = &quot; data { int&lt;lower=0&gt; N; vector[N] x1; vector[N] x3; vector[N] y; } parameters { real alpha; real beta1; real beta3; real&lt;lower=0&gt; sigma; } transformed parameters { vector[N] mu; for (n in 1 : N) { mu[n] = alpha + beta1 * x1[n] + beta3 * x3[n]; } } model { alpha ~ normal(0, 1); beta1 ~ normal(0, 1); beta3 ~ normal(0, 1); sigma ~ cauchy(0, 1); y ~ normal(mu, sigma); } generated quantities { vector[N] y_rep; vector[N] log_lik; for (n in 1 : N) { y_rep[n] = normal_rng(mu[n], sigma); log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x3[n] * beta3, sigma); } } &quot; writeLines(modelString, con = &quot;code/mreg3.stan&quot;) df$x3 &lt;- df$mom_hs data3_list &lt;- list( N = length(df$kid_score), y = df$y, x1 = df$x1, x3 = df$x3 ) file3 &lt;- file.path(&quot;code&quot;, &quot;mreg3.stan&quot;) mod3 &lt;- cmdstan_model(file3) fit3 &lt;- mod3$sample( data = data3_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, cores = 4L, refresh = 0 ) fit3$summary(c(&quot;alpha&quot;, &quot;beta1&quot;, &quot;beta3&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 4 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 alpha -0.225 -0.224 0.0947 0.0945 -0.382 -0.0705 1.00 8433. 9191. #&gt; 2 beta1 0.415 0.414 0.0449 0.0450 0.341 0.488 1.00 10941. 10324. #&gt; 3 beta3 0.286 0.285 0.108 0.108 0.111 0.465 1.00 8452. 8606. #&gt; 4 sigma 0.890 0.889 0.0302 0.0302 0.842 0.941 1.00 10828. 9623. loo3_result &lt;- fit3$loo(cores = 4) print(loo3_result) #&gt; #&gt; Computed from 16000 by 434 log-likelihood matrix #&gt; #&gt; Estimate SE #&gt; elpd_loo -584.2 16.4 #&gt; p_loo 7.5 0.6 #&gt; looic 1168.3 32.8 #&gt; ------ #&gt; Monte Carlo SE of elpd_loo is 0.0. #&gt; #&gt; All Pareto k estimates are good (k &lt; 0.5). #&gt; See help(&#39;pareto-k-diagnostic&#39;) for details. Per eseguire un confronto tra modelli in termini della loro capacità predittiva esaminiamo la differenza di LOO-CV tra coppie di modelli. Le seguenti istruzioni \\(\\mathsf{R}\\) producono la quantità elpd_diff, ovvero la differenza tra stime della \\(elpd\\) fornite da due modelli. Il primo argomento della funzione loo_compare() specifica il modello che viene usato come confronto. Nella prima riga dell’output, il valore elpd_diff è 0 (cioè, \\(x − x = 0\\)). Nelle righe successive sono riportate le differenze rispetto al modello di confronto (in questo caso, il modello 1). La colonna se_diff riporta l’errore standard di tali differenze. L’incertezza della stima dell’accuratezza out-of-sample si distribuisce in maniera approssimativamente normale con media uguale al valore riportato dal software e deviazione standard uguale a ciò che è indicato nell’output come errore standard. Quando il campione è piccolo, questa approssimazione produce una forte sottostima dell’incertezza, ma fornisce comunque una stima migliore di AIC, DIC e WAIC. w &lt;- loo_compare(loo1_result, loo2_result, loo3_result) print(w) #&gt; elpd_diff se_diff #&gt; model1 0.0 0.0 #&gt; model2 -0.3 1.3 #&gt; model3 -15.6 6.0 Per interpretare l’output, usiamo il criterio suggerito da Gelman et al. (1995): consideriamo “credibile” una differenza se elpd_diff è almeno due volte maggiore di se_diff. Nel caso presente, dunque, il confronto tra il modello 2 e il modello 1 indica che la quantità elpd_diff è molto piccola rispetto al suo errore standard. Questo accade se un predittore è associato in modo trascurabile con la variabile dipendente. I dati presenti, dunque, non offrono alcuna evidenza che aggiungere dell’età della madre come predittore migliori la capacità predittiva del modello. Nel confronto tra modello 3 e modello 1, invece, la quantità elpd_diff è maggiore di due volte il valore dell’errore standard. Questo suggerisce un incremento della capacità predittiva del modello quiando il livello di istruzione della madre viene incluso tra i predittori. È anche possibile calcolare l’intervallo di credibilità per elpd_diff: 15.5 + c(-1, 1) * qnorm(.95, 0, 1) * 6.0 #&gt; [1] 5.630878 25.369122 34.5 Outlier Si è soliti pensare che la maggior parte delle osservazioni del campione sia prodotta da un unico meccanismo generatore dei dati, mentre le rimanenti osservazioni sono la realizzazione di un diverso processo stocastico. Le osservazioni che appartengono a questo secondo gruppo si chiamano outlier. È dunque necessario identificare gli outlier e limitare la loro influenza sull’inferenza.37 Poniamoci ora il problema di identificare gli outlier con la tecnica PSIS-LOO-CV. Quando PSIS-LOO-CV viene calcolato con il pacchetto loo, l’output riporta il parametro di forma della distribuzione di Pareto (valore k). Tale valore può essere utilizzato per identificare gli outlier. Infatti, il valore k valuta, per ciascun punto del campione, l’approssimazione usata da PSIS-LOO-CV. Se \\(k &lt; 0.5\\), i pesi di importanza vengono stimati in modo accurato; se il valore \\(k\\) di Pareto di un punto è \\(&gt; 0.7\\), i pesi di importanza possono essere inaccurati. Le osservazioni con \\(k &gt; 0.7\\) sono dunque osservazioni outlier. Per fare un esempio concreto, introduciamo nel campione dell’esempio precedente una singola osservazione outlier. df1 &lt;- df dim(df1) #&gt; [1] 434 9 df1$x1[434] &lt;- 10 df1$y[434] &lt;- 10 Sistemiamo i dati nel formato appropriato per Stan: data1a_list &lt;- list( N = length(df1$kid_score), y = df1$y, x1 = df1$x1 ) Adattiamo nuovamente il modello 1 ad un campione di dati che contiene un outlier. fit1a &lt;- mod1$sample( data = data1a_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, refresh = 0 ) loo1a_result &lt;- fit1a$loo(cores = 4) Una tabella diagnostica che riassume le stime dei parametri di forma della distribuzione di Pareto si ottiene nel modo seguente: print(loo1a_result) #&gt; #&gt; Computed from 16000 by 434 log-likelihood matrix #&gt; #&gt; Estimate SE #&gt; elpd_loo -586.2 19.9 #&gt; p_loo 6.6 5.0 #&gt; looic 1172.5 39.8 #&gt; ------ #&gt; Monte Carlo SE of elpd_loo is NA. #&gt; #&gt; Pareto k diagnostic values: #&gt; Count Pct. Min. n_eff #&gt; (-Inf, 0.5] (good) 433 99.8% 10708 #&gt; (0.5, 0.7] (ok) 0 0.0% &lt;NA&gt; #&gt; (0.7, 1] (bad) 1 0.2% 75 #&gt; (1, Inf) (very bad) 0 0.0% &lt;NA&gt; #&gt; See help(&#39;pareto-k-diagnostic&#39;) for details. Un grafico che riporta le stime dei parametri di forma della distribuzione di Pareto per ciascuna osservazione è dato da: plot(loo1a_result) Il valore k stimato da PSIS-LOO-CV mette chiaramente in luce il fatto che il valore introdotto nel campione è un outlier. L’indice dell’osservazione outlier è identificato con: pareto_k_ids(loo1a_result, threshold = 0.7) #&gt; [1] 434 34.6 Regolarizzazione Abbiamo motivato la presente discussione affermando che uno dei problemi più grandi che i ricercatori devono afforntare è quello della generalizzabilità dei loro risultati. McElreath (2020) fa notare che un modo per favorire la capacità del modello di generalizzarsi a nuovi campioni è quello di fare in modo che produca un adattamento peggiore ai dati del campione presente. Il problema del sovra-adattamento (e quindi di una bassa generalizzabilità) dipende dal fatto che tutte le regolarità presenti nei dati del campione (e dunque, anche quelle che costituiscono un aspetto idiosincratico del campione presente) “vengono egualmente prese sul serio” da un modello che utilizza prior uniformi per i parametri. In tali circostanze, qualsiasi valore dei parametri viene considerato plausibile. Un modo per evitare un tale modo di procedere, che sicuramente è inadeguato, è quello di utilizzare dei prior che McElreath (2020) chiama “scettici”. I priori “scettici” più comuni sono quelli che hanno una funzione di regolarizzazione. Tali prior, se calibrati correttamente, riducono il sovra-adattamento pur consentendo al modello di rappresentare le regolarità che emergono dai dati del campione. Se il prior è “troppo scettico”, tuttavia, le regolarità dei dati campionari non vengono rappresentate dal modello; di conseguenza, ciò produce un sotto-adattamento. Il problema è quello di trovare un equilibrio tra gli opposti pericoli del sovra-adattamento e del sotto-adattamento. La buona notizia è che anche un prior “moderatamente scettico” è in grado di fornire un grande aiuto al modello, e questo è tutto quello che possiamo sperare di ottenere dato che, in generale, non ci sono né modelli ottimali né distribuzioni a priori ottimali (ovvero, modelli e distribuzioni a priori che non possono essere migliorati). Un esempio di una distribuzione a priori di regolarizzazione può essere fornito facendo riferimento al modello lineare, per esempio. Se standardizziamo i dati, un prior \\(\\beta \\sim \\mathcal{N}(0, 1)\\) per il parametro che codifica la pendenza della retta di regressione ci dice che, prima di osservare i dati, il modello “è molto scettico” rispetto ai valori possibili di \\(\\beta\\) esterni all’intervallo \\([-2, 2]\\) deviazioni standard. In altri termini, ritiene che sia molto improbabile che un cambiamento di 1 deviazione standard nella \\(x\\) sia associato ad un cambiamento medio superiore a 2 unità di deviazione standard nella \\(y\\). Ma potremmo anche usare una distribuzione a priori gaussiana con parametro \\(\\sigma\\) uguale a 0.5 oppure a 0.2. Quale prior usare dipende dal modello e dai dati – non c’è una raccomandazione che risulta sempre valida. L’effetto maggiore dei prior “molto scettici” si manifesta nel caso di modelli complessi e nel caso di piccole numerosità campionarie – ovvero, proprio nei casi in cui il rischio del sovra-adattamento è più grande. Se invece il campione è sufficientemente grande e il modello non è eccessivamente complesso, i prior, quali essi siano, hanno invece un effetto trascurabile sulla stima della distribuzione a posteriori. Commenti e considerazioni finali In questo Capitolo, utilizzando Stan insieme al pacchetto loo, abbiamo imparato ad usare la convalida incrociata K-fold e la convalida incrociata leave-one-out. Abbiamo esaminato alcuni esempi nei quali la convalida incrociata ci consente di distinguere tra due modelli. In generale, la convalida incrociata si dimostra utile utile quando vengono confrontati modelli piuttosto diversi; quando i modelli sono molto simili, invece, risulta spesso difficile distinguerli con le tecniche qui discusse. In particolare, risulta spesso difficile ottenere risultati conclusivi dal confronto di modelli tramite la convalida incrociata se l’effetto è molto piccolo e/o se il campione di dati è piccolo. In questi casi, alcuni ricercatori ritengono che siano più adatti altri metodi di confronto dei modelli, come ad esempio i fattori di Bayes. L’uso dei fattori di Bayes, tuttavia, è controverso, dato che essi dipendono fortemente dalla scelta delle distribuzioni a priori. Se possibile è preferibile utilizzare le procedure descritte in questa parte della dispensa, con campioni di ampiezza adeguata. References "],["ch-ttest.html", "Capitolo 35 Inferenza sulla media 35.1 La ripetizione dell’esperimento casuale 35.2 La distribuzione campionaria della media 35.3 Inferenza frequentista Commenti e considerazioni finali", " Capitolo 35 Inferenza sulla media 35.1 La ripetizione dell’esperimento casuale L’approccio frequentista si basa sulla nozione di probabilità intesa come frequenza relativa di un grande numero di ripetizioni dell’esperimento casuale. Iniziamo a definire una statistica test, ovvero una qualche statistica che si può calcolare con i dati campionari. Per facilitare la comprensione, consideriamo un disegno sperimentale pre-test/post-test. Supponiamo di esaminare un campione casuale di pazienti OCD e di sottoporli ad un intervento psicologico volto alla riduzione dei sintomi. Usiamo un test per la valutazione del disturbo ossessivo-compulsivo prima del trattamento e dopo il trattamento. Ad esempio, possiamo usare l’Obsessive-Compulsive Inventory (OCI; Sica et al., 2009), ovvero un questionario self-report costituito da 42 item valutati su scala Likert a 5 punti (da 0=“per nulla” a 4=“moltissimo”). Valori alti del punteggio totale indicano una situazione di particolare difficoltà e una presenza clinicamente significativa di ossessioni e/o compulsioni. Se il trattamento è efficace, ci possiamo aspettare una riduzione del punteggio totale OCI nel post-test rispetto al pre-test. Una differenza negativa post-test meno pre-test fornisce dunque evidenze dell’efficacia dell’intervento. Invece, una differenza pari a zero indicherà nessun effetto del trattamento. Infine, una differenza (post-test meno pre-test) positiva indicherà che il trattamento ottiene il risultato opposto a quello previsto. La differenza del punteggio totale OCI nel post-test rispetto al pre-test costituirà dunque, nel caso presente, la nostra statistica test. L’approccio frequentista ragiona nel modo seguente. Sappiamo che il ricercatore trova un qualche valore della statistica test in un particolare campione. Ma cosa succede se esaminiamo un’altro campione? Sicuramente troveremo risultati diversi. Il ricercatore frequentista si pone dunque la seguente domanda: è possibile descrivere tutti i risultati possibili che si potrebbero ottenere se la statistica test venisse calcolata su infiniti campioni casuali estratti tutti dalla medesima popolazione virtuale? Questa sembra una domanda a cui è impossibile rispondere. Ma in realtà è molto facile rispondere a questa domanda, se usiamo la teoria delle probabilità. 35.2 La distribuzione campionaria della media L’insieme di valori che cerchiamo va sotto il nome di distribuzione (di una statistica) campionaria. Nel caso presente, la media di un campione. Il fatto che tale media sia stata calcolata come la differenza tra i punteggi post-test e pre-test per lo stesso soggetto non cambia nulla: a ciascun soggetto viene assegnato un unico punteggio (la differenza post-test/pre-test); quello che ci chiediamo è come varia la media di questi punteggi su campioni diversi. Se i nostri dati provengono da un campione casuale, allora possiamo dire che ciascuna osservazione (differenza post-test/pre-test per un determinato paziente) è la realizzazione di una variabile casuale e il campione è costituito da \\(n\\) realizzazioni di variabili casuali indipendenti e identicamente distribuite. Dato che il valore di ciascun paziente è dato dalla differenza tra due valori, ciascuno dei quali calcolato come la somma di 42 valori, possiamo usare il Teorema del limite centrale e assumere che la nostra statistica test, che chiameremo \\(X\\), segue la legge Normale. Assumiamo inoltre che la deviazione standard \\(\\sigma\\) sia la stessa per tutti i pazienti. Dunque possiamo dire che i dati campionari possono essere concepiti coma la sequenza di \\(n\\) variabili casuali iid, ciascuna distribuita come \\(\\mathcal{N}(\\mu, \\sigma)\\). I parametri di tale distribuzione Normale sono ovviamente incogniti. La statistica target a cui siamo interessati è la media del campione. Vogliamo sapere, nelle circostanze descritte sopra, come varia la media del campione all’interno dell’universo dei campioni di ampiezza \\(n\\). La statistica test è \\[ \\bar{X} = \\frac{1}{n} \\sum_i X_i. \\] Il valore atteso di \\(\\bar{X}\\) è \\[ \\begin{align} \\mathbb{E}(\\bar{X}) &amp;= \\mathbb{E} \\left( \\frac{1}{n} \\sum_i X_i \\right)\\notag\\\\ &amp;= \\frac{1}{n} \\mathbb{E} \\left( \\sum_i X_i \\right)\\notag\\\\ &amp;= \\frac{1}{n} \\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n) \\notag\\\\ &amp;= \\frac{1}{n} n \\mu \\notag\\\\ &amp;= \\mu \\end{align} \\] Questo vuol dire che la media della distribuzione campionaria delle medie dei campioni è uguale alla media della popolazione. La varianza di \\(\\bar{X}\\) è \\[ \\begin{align} \\mathbb{V}(\\bar{X}) &amp;= \\mathbb{V} \\left( \\frac{1}{n} \\sum_i X_i \\right)\\notag\\\\ &amp;= \\frac{1}{n^2} \\mathbb{V} \\left( \\sum_i X_i \\right)\\notag\\\\ &amp;= \\frac{1}{n^2} \\mathbb{V}(X_1) + \\dots + \\mathbb{V}(X_n) \\notag\\\\ &amp;= \\frac{1}{n^2} n \\sigma^2 \\notag\\\\ &amp;= \\frac{\\sigma^2}{n}. \\end{align} \\] In altri termini, la varianza delle medie dei campioni è uguale alla varianza della popolazione divisa per \\(n\\) – ciò significa che la varianza della distribuzione campionaria delle medie dei campioni è sempre più piccola della varianza della popolazione. Se il campione è di ampiezza \\(n = 1\\), la varianza della distribuzione campionaria delle medie dei campioni è uguale alla varianza della popolazione (estrarre infinite volte un’osservazione da una popolazione e “calcolare la media” di quell’unica osservazione non fa altro che riprodurre la popolazione di partenza); se il campione è di ampiezza uguale a quella della popolazione, \\(n = \\infty\\) e la varianza è nulla: la media del “campione” è uguale alla media della popolazione (essendo il campione uguale alla popolazione). Tanto maggiore è l’ampiezza del campione, tanto di meno varierà la media del campione tra campioni diversi e, dunque, tanto più piccola sarà la varianza della media dei campioni. Resta ancora una domanda a cui rispondere: qual è la legge distributiva della media dei campioni? Anche a tale domanda si può rispondere usando il Teorema del limite centrale che dice, appunto, che per campioni estratti da una popolazione Normale, la distribuzione delle medie seguirà esattamente la legge Normale. Abbiamo dunque la nostra risposta: se la popolazione di partenza è Normale, la distribuzione delle medie dei campioni di ampiezza \\(n\\) sarà una Normale di parametri media = \\(\\mu\\) e varianza = \\(\\frac{\\sigma^2}{n}\\): \\[ \\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right). \\] 35.3 Inferenza frequentista Il risultato precedente specifica completamente la distribuzione campionaria delle medie dei campioni. Ma, ovviamente, i parametri \\(\\mu\\) e \\(\\sigma\\) sono incogniti. Il ragionamento frequentista, dunque, continua nel modo seguente. Se conoscessimo \\(\\sigma\\), l’unica incognita sarebbe \\(\\mu\\), e da lì è facile procedere. Per ora, dunque, assumiamo che \\(\\sigma\\) sia conosciuta – vedremo poi come affrontare il problema che in realtà \\(\\sigma\\) è incognita. Se \\(\\sigma\\) è conosciuta l’unico parametro sconosciuto è \\(\\mu\\). Per fare inferenza su \\(\\mu\\), l’approccio frequentista fornisce al ricercatore due strumenti: il test dell’ipotesi nulla, la stima dell’intervallo di fiducia. 35.3.1 Il test dell’ipotesi nulla Iniziamo con il test dell’ipotesi nulla. Nell’esempio che stiamo discutendo, quello sull’efficacia dell’intervento per la riduzione dei sintomi OCD, la statistica test è la differenza post-pre. Se tale statistica test assumesse il valore di 0 nella popolazione questo significherebbe che il trattamento è completamente inefficace. Questa è l’ipotesi nulla. L’approccio frequentista si chiede: se l’ipotesi nulla fosse vera, qual è la probabilità di osservare, per caso, un valore della statistica test uguale a quello del campione, o più estremo? Nel porsi questa domanda, l’approccio frequentista gioca a fare l’avvocato del diavolo, ovvero si chiede: dobbiamo veramente attribuire la riduzione dei sintomi OCD che abbiamo osservato nel campione all’effetto del trattamento? Oppure una tale riduzione dei sintomi è compatibile con un semplice effetto del caso, ovvero con la variabilità campionaria (in certi pazienti i sintomi diminuiscono, indipendentemente dal trattamento; in altri pazienti, aumentano)? Per fare l’avvocato del diavolo, il ricercatore frequentista usa il risultato che abbiamo illustrato in precedenza, ovvero la specificazione della distribuzione campionaria della media dei campioni di ampiezza \\(n\\). Se \\(\\sigma\\) è conosciuto, allora l’unica incognita è \\(\\mu\\). Ma, dal punto di vista dell’avvocato del diavolo, il parametro \\(\\mu\\), in realtà, è conosciuto. Infatti, secondo tale punto di vista il trattamento non ha alcun effetto e, dunque, \\(\\mu = 0\\). In questi termini, dunque, la distribuzione campionaria della media dei campioni di ampiezza \\(n\\) è completamente specificata. Supponiamo che, per un campione di \\(n = 30\\) pazienti, la differenza post-pre sia uguale a -5 punti sulla scala OCI. Supponiamo inoltre di sapere che i punteggi OCI sono distribuiti normalmente con una deviazione standard \\(\\sigma = 13.9\\) (ho preso questo valore dall’articolo di Sica et al. (2009)). Dobbiamo dunque calcolare la probabilità di osservare un valore minore o uguale a -5 nel caso di una variabile casuale che segue la legge Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = \\frac{13.9}{\\sqrt{30}}\\). Otteniamo il seguente risultato: pnorm(-5, 0, 13.9 /sqrt(30)) #&gt; [1] 0.02440629 Questa probabilità viene chiamata dall’approccio frequentista valore-\\(p\\). Nel caso presente ci dice che, se fosse vero che il trattamento non è efficace, allora la probabilità di osservare una differenza dei sintomi di 5 punti o più (sulla scala OCI) sarebbe uguale a solo 0.024. In altre parole, se fosse vera l’ipotesi nulla (il trattamento non è efficace), per effetto del caso soltanto si osserverebbe una riduzione dei sintomi uguale o maggiore di quella osservata nel campione esaminato solo nel 2.4% dei casi, se venissero esaminati infiniti campioni di ampiezza \\(n = 30\\). Dunque, la situazione è questa. L’avvocato del diavolo ci dice che i risultati osservati sono solo frutto del caso (il trattamento non è efficace). La teoria della probabilità ci dice che, se l’avvocato del diavolo ha ragione (il trattamento non è efficace), allora osservare una riduzione dei sintomi uguale o maggiore di quella che abbiamo effettivamente osservato si verifica in solo 2.4% degli infiniti campioni di ampiezza \\(n\\) che si possono estrarre dalla popolazione di parametri \\(\\mu = 0\\) e \\(\\sigma = \\frac{13.9}{\\sqrt{30}}\\). Quindi, in base al ragionamento dell’avvocato del diavolo (il trattamento non è efficace) noi dovremmo trovare una riduzione dei sintomi pari a 0. Oppure poco distante da 0, come semplice effetto del caso. Ma noi abbiamo trovato un valore (-5) che, se l’avvocato del diavolo avesse ragione (il trattamento non è efficace) si dovrebbe osservare solo nel 2.4% di infiniti campioni possibili? In tali circostanze, dobbiamo credere all’avvocato del diavolo che ci dice che il trattamento non è efficace? L’approccio frequentista decide nel modo seguente. Se, assumendo che l’avvocato del diavolo abbia ragione (ovvero, se assumento che il trattamento non è efficace), la probabilità di osservare i risultati campionari è bassa, allora non crediamo più all’avvocato del diavolo ma accettiamo l’ipotesi complementare. Se rifiutiamo l’ipotesi dell’avvocato del diavolo che il trattamento non è efficace, dobbiamo concludere che il trattamento è efficace. Ma quale soglia dobbiamo usare per rifiutare l’ipotesi dell’avvocato del diavolo (ovvero, l’ipotesi nulla)? Per consuetudine, la soglia da superare è quella del 5%. Risultati che producono un valore-\\(p &lt; 0.05\\) vengono detti statisticamente significativi. Ci sono due tipi di test di ipotesi, quelli unidirezionali (mettiamo tutta la regione di rifiuto dell’ipotesi nulla in una coda della distribuzione campionaria della statistica test) e quelli bidirezionali (la regione di rifiuto dell’ipotesi nulla è suddivisa nelle due code). Supponiamo di usare un test bidirezionale (quello che si usa normalmente). Quindi, rifiutiamo l’ipotesi nulla (la proposta dell’avvocato del diavolo) sia quando c’è una grande riduzione dei sintomi, sia quando osserviamo un grande aumento dei sintomi. Quindi, se per la nostra scelta abbiamo deciso di usare un livello di probabilità complessivo, chiamato \\(\\alpha\\), di 0.05, nel caso di un test bidirezionale avremo due regioni di rifiuto dell’ipotesi nulla: l’intervallo da \\(-\\infty\\) fino al quantile che lascia sotto di sé una probabilità pari a \\(\\alpha/2\\), e l’intervallo dal quantile che lascia sopra di sé una probabilità pari a \\(\\alpha/2\\) a \\(+\\infty\\). Per rifiutare l’ipotesi dell’avvocato del diavolo dovremo dunque osservare una riduzione dei sintomi che, nella distribuzione campionaria costruita assumendo come vera l’ipotesi nulla, lascia sotto di sé una probabilità minore di \\(\\alpha/2\\). Un risultato di questo tipo viene detto “statisticamente significativo”. Nel caso presente, essendo il valore-\\(p\\) = 0.0244 &lt; 0.025, il ricercatore frequentista rigetta l’ipotesi nulla di assenza di effetto del trattamento e conclude che il trattamento considerato è efficace per la riduzione dei sintomi OCD. 35.3.1.1 Il test \\(t\\) di Student Nella discussione precedente abbiamo assunto \\(\\sigma\\) noto, in quanto abbiamo recuperato tale valore da ricerche precedenti. Solitamente, però, si procede in un modo ancora più semplice, ovvero si stima \\(\\sigma\\) mediante la deviazione standard del campione (usando \\(n-1\\) al denominatore). In tali circostanze, ovvero quando stimiamo \\(\\sigma\\) con \\(s\\), la teoria delle probabilità ci dice che la distribuzione delle medie campionarie non segue più la legge Normale ma segue invece un’altra legge distributiva, ovvero la \\(t\\) di Student, con un numero di gradi di libertà pari a \\(\\nu = n-1\\). La probabilità cercata, dunque, diventa la seguente. Dobbiamo trovare la probabilità che una variabile casuale assuma un valore minore o uguale a -5 quando tale variabile segue la distribuzione \\(t\\) di Student con \\(30 - 1\\) gradi di libertà. Supponiamo che la deviazione standard del campione sia \\(s = 14.5\\). Dobbiamo trovare il quantile della distribuzione \\(t\\) di Student e l’associata probabilità nella coda inferiore della distribuzione. Il quantile è dato da \\[ T = \\frac{\\bar{X} - 0}{s/\\sqrt{n}}. \\] Per l’esempio presente avremo T &lt;- (-5 - 0) / (14.5 / sqrt(30)) T #&gt; [1] -1.888698 Calcoliamo la probabilità di osservare un valore minore o uguale a -1.89 in una distribuzione \\(t\\) di Student con 29 gradi di libertà. pt(T, 29) #&gt; [1] 0.03448568 In questo caso, con un test bidirezionale, il valore-\\(p\\) è maggiore di \\(\\alpha/2\\). Dunque, in base alla procedura decisionale scelta, il ricercatore frequentista non può rifiutare il punto di vista dell’avvocato del diavolo. Ovviamente, la discussione presente non prova che l’avvocato del diavolo abbia ragione, ma non ci sono evidenze sufficienti per rigettare l’ipotesi nulla. In tali circostanze, cautamente, il ricercatore sospende il giudizio. In \\(\\textsf{R}\\), il test che abbiamo descritto sopra, detto test \\(t\\) di Student, si svolte mediante la funzione t.test(). 35.3.2 L’Intervallo di fiducia Il test di ipotesi statistiche porta il ricercatore ad una scelta binaria: o rifiuta l’ipotesi nulla \\(H_0\\) o sospende il giudizio. Tale scelta binaria dipende dal valore \\(\\alpha\\), ovvero dal livello di significatività che viene scelto. Convenzionalmente, \\(\\alpha = 0.05\\) e il test è bidirezionale. Essendo una risposta binaria, il risultato di un test di ipotesi statistiche frequentista non è molto informativo. Infatti, si usa sempre di meno. Maggiori fortuna nella comunità scientifica ha l’altra proposta inferenziale frequentista, ovvero l’intervallo di fiducia. Per proseguire con l’esempio in discussione, consideriamo qui il caso dell’intervallo di fiducia per la media di una popolazione Normale di varianza conosciuta. 35.3.2.1 Popolazione con varianza nota Sia \\(X_1,\\dots, X_n\\) un campione casuale estratto da una popolazione di legge normale di media \\(\\mu\\) e varianza \\(\\sigma^2\\). Abbiamo visto in precedenza come la media campionaria, essendo una combinazione lineare di \\(n\\) variabili casuali normali, è anch’essa una variabile normale: \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/n)\\). La \\[\\begin{equation} \\frac{\\bar{X} - \\mu}{\\sigma} \\sqrt{n}\\sim \\mathcal{N}(0, 1)\\notag \\end{equation}\\] segue dunque una distribuzione normale con media zero e deviazione standard unitaria. Fissato il livello fiduciario \\(\\gamma = 1 - \\alpha\\) (tipicamente 0.95, corrispondente a \\(\\alpha = 0.05\\)), indichiamo con \\(z\\) il quantile di ordine \\(1 - \\alpha/2\\) della distribuzione normale standard in modo che \\[\\begin{equation} P(-z \\leq Z \\leq z) = 1 - \\alpha.\\notag \\end{equation}\\] Otteniamo dunque \\[\\begin{equation} P\\bigg(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma} \\sqrt{n} \\leq z\\bigg) = 1 - \\alpha.\\notag \\end{equation}\\] Applicando qualche manipolazione algebrica, la diseguaglianza precedente si può scrivere nel modo seguente: \\[\\begin{align} P\\bigg(-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq \\bar{X} - \\mu \\leq z \\frac{\\sigma}{\\sqrt{n}}\\bigg) &amp;= 1 - \\alpha\\notag\\\\ P\\bigg(-\\bar{X}-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq -\\mu \\leq -\\bar{X} + z \\frac{\\sigma}{\\sqrt{n}}\\bigg) &amp;= 1 - \\alpha\\notag\\\\ P\\bigg(\\bar{X}+z \\frac{\\sigma}{\\sqrt{n}} \\geq \\mu \\geq \\bar{X} -z \\frac{\\sigma}{\\sqrt{n}}\\bigg) &amp;= 1 - \\alpha.\\notag \\end{align}\\] Se definiamo \\[\\begin{equation} \\hat{a} \\triangleq \\bar{X}-z \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} \\triangleq \\bar{X} +z \\frac{\\sigma}{\\sqrt{n}}, \\label{eq:lim_int_fid_norm} \\end{equation}\\] avremo che \\[\\begin{equation} P(\\hat{a} \\leq \\mu \\leq \\hat{b}) = 1 - \\alpha.\\notag \\end{equation}\\] L’intervallo \\([\\hat{a}, \\hat{b}]\\) è detto intervallo di fiducia per una stima della media della popolazione al livello fiduciario \\(\\gamma = 1 -\\alpha\\). Per l’esempio in discussione, assumendo \\(\\sigma = 13.9\\), abbiamo -5 + c(-1, 1) * qnorm(0.025, 0, 1) * 13.9 /sqrt(30) #&gt; [1] -0.02604028 -9.97395972 35.3.2.2 Popolazione con varianza incognita In ogni applicazione concreta, lo sperimentatore estrae un solo campione \\(x_1, \\dots, x_n\\) dalla popolazione e la varianza \\(\\sigma^2\\), in aggiunta alla media \\(\\mu\\) da determinare, è sconosciuta. In tal caso, per effettuare una stima intervallare di \\(\\mu\\) ci si basa sulla densità \\(t\\) di Student. In tali circostanze, si può dimostrare che \\[\\begin{equation} P\\bigg(-t^{\\ast} \\leq \\frac{\\bar{X} - \\mu}{s} \\sqrt{n} \\leq t^{\\ast}\\bigg) = 1 -\\alpha, \\end{equation}\\] dove \\(s\\) è lo stimatore non distorto di \\(\\sigma\\) e \\(t^{\\ast} \\triangleq t_{n-1,1-\\alpha/2}\\) è il quantile di ordine \\(1 - \\alpha/2\\) della distribuzione \\(t_{n-1}\\). Pertanto, il limite inferiore \\(\\hat{a}\\) e il limite superiore \\(\\hat{b}\\) dell’intervallo di fiducia diventano, rispettivamente, uguali a: \\[\\begin{equation} \\hat{a} \\triangleq \\bar{X} -t^{\\ast} \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} \\triangleq \\bar{X} + t^{\\ast} \\frac{s}{\\sqrt{n}}. \\label{eq:lim_int_fid_t} \\end{equation}\\] Si noti che, nel caso di una popolazione con varianza incognita, i limiti fiduciari si ottengono dall’equazione ottenuta nel paragrafo precedente sostituendo \\(\\sigma\\), ora incognito, con \\(s\\) (per una ampiezza campionaria \\(n\\) qualsiasi), e il coefficiente \\(z\\) con \\(t_{n-1,1-\\alpha/2}\\). Per l’esempio in discussione, assumendo \\(s = 14.5\\), abbiamo -5 + c(-1, 1) * qt(0.025, 29) * 14.5 /sqrt(30) #&gt; [1] 0.414389 -10.414389 35.3.2.3 Livello di copertura Il valore \\(1-\\alpha\\) indica il livello di copertura fornito dall’intervallo di fiducia. Il termine “probabilità di copertura” si riferisce alla probabilità che la procedura per la costruzione degli intervalli di fiducia produca un intervallo che contiene (o copre) il valore reale del parametro di interesse. Esiste sempre una probabilità pari ad \\(\\alpha\\) che i dati campionari producano un intervallo che non contiene il valore reale del parametro di interesse. Ricordiamo che l’approccio frequentista interpreta la probabilità di un evento come la proporzione di volte che si verifica un tale evento osservando a lungo termine delle ripetizioni indipendenti di un esperimento casuale. Nel caso presente, l’evento in questione è la risposta alla domanda “l’intervallo di fiducia contiene il valore del parametro?” mentre l’esperimento casuale corrisponde al calcolo dell’intervallo di fiducia della media di una popolazione in un campione casuale di ampiezza \\(n\\). La seguente simulazione chiarisce l’interpretazione frequentista della nozione di “livello di copertura”. Consideriamo il caso di una popolazione normale con varianza incognita. Utilizziamo come parametri quelli della distribuzione dell’altezza: è infatti risaputo che l’altezza degli individui segue la distribuzione normale. L’altezza media di un italiano adulto maschio è di \\(175\\) cm, con una varianza di \\(49\\) cm\\(^2\\). Definiamo dunque i parametri della simulazione, nella quale prevediamo 100 ripetizioni dell’esperimento casuale che corrisponde nell’estrazione di un campione di ampiezza \\(n = 20\\) dalla popolazione \\(\\mathcal{N}(175, 7)\\). set.seed(1235) nrep &lt;- 100 sampling_distribution &lt;- matrix(NA, nrow = nrep, ncol = 2) point_estimate &lt;- rep(NA, nrep) sample_size &lt;- 20 mu &lt;- 175 sigma &lt;- 7 Per ciascun campione casuale calcoliamo l’intervallo di fiducia del 95% tramite la funzione e salviamo il limite inferiore e il limite superiore di ciascun intervallo nella matrice . for (i in 1:nrep) { y &lt;- rnorm(sample_size, mu, sigma) temp &lt;- t.test(y, conf.level = 0.95) sampling_distribution[i, ] &lt;- temp$conf.int point_estimate[i] &lt;- temp$estimate } Creiamo poi un data.frame a cui aggiungiamo una colonna che riporta i valori delle medie campionarie. colnames(sampling_distribution) &lt;- c(&quot;lcl&quot;, &quot;ucl&quot;) sampling_distribution &lt;- as.data.frame(sampling_distribution) sampling_distribution$mean &lt;- as.numeric(point_estimate) sampling_distribution$replicate &lt;- 1:nrep sampling_distribution$captured &lt;- factor(ifelse( sampling_distribution$lcl &lt;= mu &amp; sampling_distribution$ucl &gt;= mu, 1, 0 )) levels(sampling_distribution$captured) &lt;- c(&#39;No&#39;, &#39;Si&#39;) Utilizzando gplot(() creiamo la seguente figura. p &lt;- ggplot(sampling_distribution) + geom_point( aes( x = point_estimate, y = replicate, color = captured) ) + geom_segment(aes( y = replicate, yend = replicate, x = lcl, xend = ucl, color = captured )) + geom_vline( xintercept = 175, linetype = 2, color = &quot;white&quot; ) + labs( x = &quot;Stima puntuale&quot;, y = &quot;Campioni simulati&quot; ) + guides(color=guide_legend(&quot;Parametro contenuto nell&#39;intervallo&quot;)) p + theme(legend.position = &quot;bottom&quot;) La figura mostra che alcuni intervalli di fiducia del 95% contengono il valore del parametro, altri non lo contengono. Se ripetiamo la simulazione 10,000 volte troviamo un livello di copertura (ovvero, una proporzione di intervalli di fiducia del 95% che contengono il parametro) pari a 0.9468. Questo valore è molto prossimo al livello nominale \\(1 - \\alpha = 0.95\\). 35.3.2.4 Interpretazione dell’intervallo di fiducia La cosa più difficile a proposito degli intervalli di fiducia è capire cosa significano. Ogni volta che gli studenti e i ricercatori incontrano gli intervalli di fiducia, il primo istinto è quasi sempre quello di interpretarli dicendo che “c’è una probabilità del 95% che la vera media della popolazione si trovi all’interno dell’intervallo di fiducia”. Questa è un’interpretazione semplice e cattura l’idea del senso comune secondo la quale una probabilità di 0.95 significa “sono sicuro al 95%”. Sfortunatamente, l’interpretazione precedente è del tutto sbagliata. La precedente interpretazione si basa sulla convinzione `soggettiva’ di quale potrebbe essere il valore della media della popolazione. Dico che sono fiducioso al 95% perché quella è la mia opinione. Nella vita di tutti i giorni va benissimo, ma parlare di opinioni soggettive e di fiducia è un’idea bayesiana. Tuttavia, gli intervalli di fiducia sono una procedura statistica di stampo frequentista, non bayesiano. Se usiamo degli strumenti statistici frequentisti non possiamo attribuire loro un’interpretazione bayesiana. Se usiamo dei metodi frequentisti, dobbiamo usare delle interpretazioni frequentiste—anche perché gli intervalli di fiducia frequentisti e gli intervalli di credibilità bayesiani sono numericamente diversi! Se l’interpretazione presentata sopra non è corretta, qual è l’interpretazione giusta? Ricordaci quello che abbiamo detto sulla probabilità frequentista: l’unico modo in cui siamo autorizzati a fare affermazioni relative alla probabilità degli eventi è di riferirci ad una sequenza di ripetizioni dell’esperimento casuale e di contare la frequenza con cui si è verificato un qualche evento. Dunque, l’interpretazione frequentista dell’intervallo di fiducia deve avere a che fare con la ripetizione di un esperimento casuale. Nello specifico, per l’intervallo di fiducia al 95% possiamo dire quanto segue: “se ripetessimo molte volte l’esperimento casuale del campionamento e se, per ciascuna ripetizione dell’esperimento, calcolassimo un intervallo di fiducia del 95%, allora il 95% degli intervalli così calcolati conterrebbe la vera media della popolazione”. Più in generale, se si estraggono molteplici campioni indipendenti dalla stessa popolazione e si determinano i relativi intervalli di fiducia seguendo la procedura sopra illustrata, il \\(100 (1-\\alpha)\\)% di tali intervalli conterrà il vero valore del parametro incognito. Questa idea è illustrata nella figura precedente che mostra 100 intervalli di fiducia costruiti per stabilire l’altezza media di un italiano adulto maschio sulla base di campioni casuali di ampiezza \\(n = 30\\). Alcuni di questi intervalli di fiducia contengono il valore del parametro, altri non lo contengono. Se la simulazione venisse ripetuta infinite volte si scoprirebbe che esattamente il 95% degli intervalli così calcolati effettivamente contiene il valore del parametro (e il 5% non lo contiene), dato che, per costruire gli intervalli di fiducia abbiamo usato \\(\\alpha = 0.05\\). Commenti e considerazioni finali È risaputo che i ricercatori (non solo gli studenti!) spesso attribuiscono agli intervalli di fiducia un’interpretazione errata. Non poche volte nelle riviste specialistiche si leggono affermazioni del tipo: “la probabilità che la media della popolazione \\(\\mu\\) sia contenuta nell’intervallo \\([\\hat{a}, \\hat{b}]\\) è 0.95”, mentre in realtà si dovrebbe scrivere: “la procedura tramite la quale l’intervallo \\([\\hat{a}, \\hat{b}]\\) è stato calcolato include \\(\\mu\\) nel 95% dei casi”. La differenza fondamentale è che le affermazioni di tipo bayesiano sono delle affermazioni probabilistiche sul valore dei parametri (qui, la media della popolazione (cioè, descrivono nostra incertezza relativamente al valore di un parametro incognito). Tuttavia, affermazioni di questo tipo non sono consentite nell’interpretazione frequentista della probabilità. Nell’interpretazione frequentista, la media della popolazione è fissa e nessuna interpretazione `probabilistica’ può essere fatta sul valore di un rtale parametro (o di alcun altro parametro). Gli estremi dell’intervallo di fiducia, invece, sono delle quantità aleatorie che dipendono da un esperimento casuale: ogni volta che osserviamo un nuovo campione casuale, il limite inferiore e il limite superiore dell’intervallo di fiducia assumeranno valori diversi. Pertanto è sensato pensare che la procedura di costruzione dell’intervallo di fiducia possa essere ripetuta. È in riferimento a tali ripetizioni che l’approccio frequentista assegna una probabilità agli intervalli di fiducia: la probabilità è la frequenza relativa (in queste infinite ipotetiche ripetizioni) che un certo evento si verifichi (dove l’evento in questione è il fatto che l’intervallo include il valore del parametro). Pertanto, dal punto di vista frequentista, è lecito parlare della probabilità che l’intervallo di fiducia (una variabile aleatoria) contenga il parametro; non è invece lecito dire alcunché sulla probabilità che il parametro (un evento non ripetibile) assuma un certo valore (il valore del parametro è fisso: non può essere descritto da una probabilità). Questa non è solo una differenza `semantica’. Come ho accennato sopra, le procedure di calcolo per gli intervalli di fiducia frequentisti sono diverse dalle procedure di calcolo per gli intervalli di credibilità bayesiani. In maniera corrispondente, nei due casi anche le interpretazioni che assegnamo agli intervalli sono diverse. Un altro modo per descrivere questa situazione è quello di dire che ciò che vorremmo conoscere è \\(p(\\theta \\mid y)\\), mentre in realtà quello che l’approccio frequentista ci fornisce è \\(p(y \\mid \\theta)\\). Solo se vengono utilizzati i metodi della statistica bayesiana è possibile costruire un “intervallo di credibilità” che corrisponde a \\(p(\\theta \\mid y)\\). "],["la-crisi-della-replicabilità-dei-risultati-della-ricerca.html", "Capitolo 36 La crisi della replicabilità dei risultati della ricerca 36.1 Che cos’è un valore-\\(p\\)? 36.2 L’uso del valore-\\(p\\) nel mondo della ricerca 36.3 \\(P\\)-hacking 36.4 Critiche al valore-\\(p\\) 36.5 L’effetto sperimentale è esattamente nullo? 36.6 Simulazione", " Capitolo 36 La crisi della replicabilità dei risultati della ricerca Cito da Wikipedia La crisi della replicazione (chiamata anche crisi della replicabilità e crisi della riproducibilità) è una crisi metodologica per cui è stato riscontrato che molti studi scientifici sono difficili o impossibili da replicare o riprodurre. La crisi della replicazione colpisce più gravemente le scienze sociali e la medicina, mentre i dati delle rilevazioni indicano fortemente che anche tutte le scienze naturali sono probabilmente implicate. La frase è stata coniata nei primi anni 2010 come parte di una crescente consapevolezza del problema. La crisi della replicazione rappresenta un importante corpo di ricerca nel campo delle metascienze. Poiché la riproducibilità dei risultati sperimentali è una parte essenziale del metodo scientifico, l’incapacità di replicare gli studi di altri ha conseguenze potenzialmente gravi per molti campi della scienza in cui teorie significative sono fondate su un lavoro sperimentale irriproducibile. La crisi della replicazione è stata ampiamente discussa nei campi della medicina, dove sono stati fatti numerosi sforzi per riesaminare i risultati classici, per determinare sia l’attendibilità dei risultati sia, se ritenuto inattendibile, le ragioni del fallimento di replica. Questa “crisi metodologica” riguarda molto da vicino la psicologia. Questa crisi ha molteplici cause. Tra tali cause, particolare importanza (in senso negativo) è stata assegnata ad un uso “spensierato” dell’approccio frequentista da parte dei ricercatori. L’obiettivo di questo capitolo è mostrare come l’uso delle procedure di test dell’ipotesi nulla necessariamente conduce, nella pratica corrente, ad una sistematica distorsione dei risultati della ricerca. Ovvero, aumenta a dismisura i “falsi positivi” e troppo spesso impedisce la replicazione dei risultati degli studi empirici. 36.1 Che cos’è un valore-\\(p\\)? Il valore-\\(p\\) viene spesso riportato da coloro che svolgono l’inferenza statistica mediante l’approccio frequentista. Tuttavia, nonostante questa nozione statistica sia spesso usata, il significato di valore-\\(p\\) è spesso frainteso. Un errore che viene spesso commesso nell’interpretare il valore-\\(p\\) è quello di assegnare ad esso l’interpretazione secondo la quale un valore-\\(p\\), diciamo, pari a 0.01, significa che c’è solo una probabilità dell’1% che il risultato osservato sia un falso positivo. È importante evitare i falsi positivi, per esempio quando si valuta l’efficacia di un intervento psicologico, perché affermare che un trattamento è efficace quando in realtà ciò non è vero (falso positivo) conduce alla successiva applicazione di quel trattamento, con il rischio di danni negli utenti e di discredito della professione. L’interpretazione precedente, però, è sbagliata. Il valore-\\(p\\) non può dirci questo: non può mai essere usato per descrivere il mondo reale. Greenland et al. (2016) esprimono questo punto nel modo seguente: Thus to claim that the null P value is the probability that chance alone produced the observed association is completely backwards: The P value is a probability computed assuming chance was operating alone. The absurdity of the common backwards interpretation might be appreciated by pondering how the P value, which is a probability deduced from a set of assumptions (the statistical model), can possibly refer to the probability of those assumptions. Quello che può fare il valore-\\(p\\) è riassumere i dati ottenuti dal ricercatore assumendo vera una specifica ipotesi nulla: il valore-\\(p\\) descrive quello che succederebbe in un mondo ipotetico, se l’ipotesi nulla fosse vera. Nello specifico, il ricercatore si chiede: se fosse vera l’ipotesi nulla (ad esempio, se il trattamento non fosse efficace così da non avere nessuna differenza tra il gruppo del trattamento e il gruppo di controllo), quale sarebbe la probabilità di osservare un valore uguale a quello della statistica osservata nel campione, o un valore ancora più estremo di tale statistica? In altri termini, il valore-\\(p\\) descrive quello che succederebbe in un mondo ipotetico, il mondo basato sull’idea che l’ipotesi nulla sia vera e nel quale vengono rispettate tutte le assunzioni del modello statistico. Nulla ci dice, il valore-\\(p\\), della plausibilità delle assunzioni che sono state fatte, né tanto meno sulle proprietà del mondo empirico. Per fare delle inferenze sul mondo empirico è necessario possedere altre informazioni, per esempio, la verosimiglianza dell’effetto considerato. Nuzzo (2014) ci propone il seguente esempio. Ci svegliamo la mattina con il mal di testa e concludiamo che abbiamo un raro tumore al cervello. È possibile che questo sia vero, ma è molto improbabile. Per concludere che abbiamo un tumore sono necessarie evidenze ulteriori, oltre al mal di testa, dato che il mal di testa può essere provocato da tantissime cause diverse dal tumore. Tanto più è inverosimile l’ipotesi del ricercatore (il tumore dell’esempio, ma anche la telepatia, l’omeopatia e l’esistenza degli alieni), tanto maggiore è la probabilità che il risultato osservato sia un falso allarme, indipendentemente da quello che ci dice il valore-\\(p\\). In altri termini, è la verosimiglianza di un evento che determina la probabilità di un falso allarme, non il valore-\\(p\\). Nel 2016 l’American Statistical Association ha pubblicato un articolo nel quale Wasserstein and Lazar (2016) esprimono la loro preoccupazione relativamente all’uso inappropriato che viene fatto del valore-\\(p\\) nella pratica scientifica. Il punto che abbiamo discusso in precedenza è espresso nei termini seguenti: \\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself. 36.2 L’uso del valore-\\(p\\) nel mondo della ricerca Tra i tanti articoli che sono stati dedicati a questo tema, possiamo citare qui un articolo di Nuzzo (2014) che descrive i limiti dell’uso del valore-\\(p\\) all’interno della pratica scientifica. Nuzzo (2014) ci ricorda che Ronald Fisher ha introdotto il valore-\\(p\\) negli anni ‘20, ma non ha mai pensato ad esso come ad un test formale. Per Fisher, il valore-\\(p\\) era uno strumento per giudicare informalmente se l’evidenza empirica fosse “significativa”, laddove il termine “significativo” veniva inteso nel senso colloquiale del termine, ovvero come qualcosa che merita di essere considerata con attenzione. Secondo Fisher, lo sperimentatore propone un’“ipotesi nulla” che spera di dimostrare falsa (per esempio, l’assenza di differenza tra due gruppi). Poi gioca a fare l’avvocato del diavolo e assumere che l’ipotesi nulla sia vera. Questo gli consente di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello trovato, se il risultato trovato è interamente dovuto alla sola variabilità campionaria. Questa probabilità è appunto il valore-\\(p\\). Lo scopo di questo modo di procedere è quello di valutare l’ipotesi nulla: secondo Fisher, la probabilità che l’ipotesi nulla sia falsa è tanto più grande quanto più piccolo è il valore-\\(p\\). Anche se il valore-\\(p\\) è un numero calcolato con una procedura matematica, per Fisher esso è solo uno strumento da usare all’interno di un processo (inferenziale) non numerico capace di combinare le evidenze empiriche correnti con le conoscenze precedenti del ricercatore. Il processo di decisione che il ricercatore mette in atto quando valuta i risultati di un esperimento venne formalizzato, alla fine degli anni ’20, da due rivali di Fisher, il matematico Jerzy Neyman e lo statistico Egon Pearson. Neyman e Pearson si posero problema di rendere il processo di decisione “rigoroso e obiettivo”. Allo scopo di fare questo, Neyman e Pearson introdussero, tra l’altro, i concetti di potere statistico e di falso positivo (i concetti che abbiamo visto nei paragrafi precedenti). Non usarono invece, all’interno della procedura proposta, la nozione di valore-\\(p\\). Questi due approcci contrapposti portarono ad un dibattito molto acceso tra di due gruppi: Neyman descrisse il lavoro di Fisher come matematicamente “worse than useless”; Fisher chiamò l’approccio di Neyman “childish” e “horrifying [for] intellectual freedom in the west”. Mentre questo dibattito si sviluppava, altri autori iniziarono a scrivere dei manuali di statistica allo scopo di fornire uno strumento di lavoro ai ricercatori. Dato che molti di questi autori non erano statistici, non avevano una comprensione profonda di cosa distinguesse l’approccio di Fisher, da una parte, e l’approccio di Neyman e Pearson, dall’altra, e finirono per creare un sistema ibrido che utilizzava il valore-\\(p\\) proposto da Fisher (che era un numero facile da calcolare) all’interno del “sistema rigoroso” proposto da Neyman e Pearson. È in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne definita “statisticamente significativa”. Dal punto di vista storico, dunque, si può dire che il valore-\\(p\\) proposto da Fisher non fu mai pensato come qualcosa che può essere usato nel modo in cui il valore-\\(p\\) viene usato al giorno d’oggi nel mondo della ricerca. In uno dei sei “principi” che vengono enunciati, l’ASA continua dicendo quanto segue: Scientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold.Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become “true” on one side of the divide and “false” on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, “yes-no” decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as “\\(p \\leq 0.05\\)”) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process. 36.3 \\(P\\)-hacking La fallacia maggiore associata all’uso del valore-\\(p\\) è chiamata “\\(P\\)-hacking” (o anche “data-dredging”, “snooping”, “fishing”, “significance-chasing”, “double-dipping”). Secondo Uri Simonsohn della Università della Pennsylvania, “\\(P\\)-hacking is trying multiple things until you get the desired result.” Esempi di \\(P\\)-hacking sono: “That finding seems to have been obtained through \\(p\\)-hacking, the authors dropped one of the conditions so that the overall \\(p\\)-value would be less than .05”, oppure “She is a \\(p\\)-hacker, she always monitors data while it is being collected.” La pratica del \\(P\\)-hacking ha l’effetto di trasformare uno studio esplorativo (che dovrebbe essere sempre considerato con cautela) in uno studio (apparentemente) confermativo, con la conseguenza di proporre risultati che hanno una probabilità pressoché nulla di essere replicati in studi successivi. Le simulazioni di Simonsohn hanno mostrato come il cambiamento di poche decisioni all’interno del processo di analisi dei dati possa aumentare fino al 60% il tasso di falsi positivi in un singolo studio. La pratica del \\(P\\)-hacking emerge soprattutto negli studi che si pongono il problema di dimostrare piccoli effetti usando dati molto rumorosi. In un’analisi della letteratura psicologica, Simonsohn ha trovato che i valori-\\(p\\) riportati dagli psicologi tendono a concentrarsi su valori appena superiori alla soglia “minima” dello 0.05 (figura 36.1). Questo risultato può essere interpretato come conseguenza della pratica del \\(P\\)-hacking: infatti, i ricercatori sembrano seguire la prarica che li porta ad eseguire molteplici test di significatività statistica, fino a trovare un risultato “statisticamente significativo”, per poi pubblicare quello. Come mostra la figura 36.1, questa pratica non riguarda solo la psicologia ma è diffusa in tutti i campi della ricerca scientifica. FIGURA 36.1: Distribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia. 36.4 Critiche al valore-\\(p\\) Il valore-\\(p\\) è stato paragonato alle zanzare (creature noiose e impossibili da mandare via), ai vestiti nuovi dell’imperatore (ovvero, il fatto per cui la maggioranza sceglie di non riconoscere i problemi che sono ovvi a tutti, ma preferisce fingere di non vederli), o ad un “sterile intellectual rake” che non produce nulla. È stato ironizzato che l’unica ragione di chiamare questa procedura “statistical hypothesis inference testing” è per l’acronimo che tale espressione produce. È stato messo in evidenza il fatto che valore-\\(p\\) incoraggia un modo di pensare sbagliato, in quanto sposta l’attenzione dal problema centrale della ricerca, ovvero il problema della dimensione dell’effetto, verso un problema irrilevante, ovvero quello di dimostrare falsa un’ipotesi fantoccio che sappiamo essere falsa (l’ipotesi nulla). L’esempio che Nuzzo (2014) propone è quello di uno studio su più di 19,000 individui che ha mostrato come coloro che incontrano il loro partner online hanno una probabilità minore di divorziare (\\(p &lt;\\) 0.002) e mostrano livelli maggiori di soddisfazione maritale (\\(p &lt;\\) 0.001) rispetto alle coppie che non si sono conosciute online. Questo può sembrare un risultato interessante fino a quando non consideriamo la dimensione dell’effetto: per coloro che si sono conosciuti online il tasso di divorzi diminuisce dal 7.67% al 5.96%, mentre l’indice di soddisfazione maritale aumenta solo da 5.48 a 5.64 su una scala a sette passi. In generale, la domanda da porsi, infatti, non è “c’è un effetto?” ma bensì “quanto è grande l’effetto?” 36.5 L’effetto sperimentale è esattamente nullo? Una delle critiche più ovvie alla logica della verifica delle ipotesi statistiche riguarda il fatto che non è ragionevole supporre che l’effetto della manipolazione sperimentale sia esattamente nullo. Un esempio preso dalla fisica illustra questo punto. Borel (1914) ha dimostrato che lo spostamento di un centimetro di un grammo di massa in una stella a qualche anno luce da noi modifica il movimento delle molecole di un gas sulla terra. Se, come sembra, tutto è collegato con tutto, allora è ragionevole supporre che la manipolazione sperimentale, quale essa sia, un qualche effetto lo produca sempre. Come Andrew Gelman ha ripetuto molte volte, il punto non è dimostrare falsa l’affermazione secondo cui la manipolazione sperimentale produce un effetto esattamente nullo. Importante invece è stabilire se la dimensione dell’effetto sia sufficientemente grande da avere una qualche importanza dal punto di vista pratico, e stabilire se l’effetto sia riproducibile. Se questi sono gli obiettivi, allora la logica della verifica dell’ipotesi nulla si dimostra problematica. Infatti, come abbiamo visto sopra, nel caso di piccoli campioni e di piccoli effetti (caso, questo, che descrive la quasi la totalità delle ricerche in psicologia), le procedure frequentiste conducono ad una notevole sovrastima della dimensione dell’effetto. Inoltre, tendono a favorire un un pensiero binario basato sulla dicotomia vero/falso, mentre quello che è importante non è rifiutare un’ipotesi (nulla) che è sicuramente falsa, ma riuscire ad ottenere una stima non distorta della vera dimensione dell’effetto. La simulazione descritta sopra non mostra soltanto che, nelle condizioni considerate, la stima della grandezza dell’effetto risulti fortemente esagerata, ma anche che la direzione dell’effetto possa anche essere stimata incorrettamente. Nella simulazione descritta, questo si verifica solo in un campione su 40 tra quelli che producono un valore-\\(p &gt;\\) 0.05, ma l’esame di dati reali tratti dalla letteratura psicologica mostra che la probabilità di questo errore di segno possa essere molto maggiore. Gelman and Carlin (2014) chiamano i due tipi di errori che abbiamo discusso qui errori di Tipo S (Sign) e errori di Tipo M (Magnitude). Gelman and Carlin (2014) sono molto critici rispetto all’uso corrente che porta a descrivere i dati degli esperimenti per mezzo di concetti quali la “significatività statistica”, il “potere statistico”, l’“errore di tipo I” e l’“errore di tipo II” e affermano che sia più utile mettere in evidenza la probabilità di un errore di Tipo S e di Tipo M (uno script \\(\\mathsf{R}\\) che consente di calcolare la probabilità di errore di Tipo S e di Tipo M è fornito nel loro articolo). Gelman and Carlin (2014) concludono il loro articolo con la raccomandazione secondo la quale, per minimizzare i falsi positivi in psicologia, è necessario aumentare notevolmente la dimensione del campione rispetto agli standard correnti. Un punto analogo è anche fornito nell’articolo di Loken and Gelman (2017). 36.6 Simulazione In questa simulazione esaminiamo le conseguenze che derivano dall’applicazione della procedura del test dell’ipotesi nulla al caso di una piccola dimensione dell’effetto nella popolazione e di un campione di piccole dimensioni – ovvero viene considerato il caso tipico di un esperimento di psicologia. L’idea è stata proposta da Gelman and Carlin (2014). 36.6.1 La dimensione dell’effetto La dimensione dell’effetto si calcola con la statistica \\(d\\) di Cohen definita come segue: \\[ d = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p} \\] dove \\[ s_p = \\sqrt{ \\frac{s_1^2 (n_1 - 1) + s_2^2 (n_2 - 1)}{n_1 + n_2 - 2} } \\] La statistica \\(d\\) di Cohen si interpreta nel modo seguente: d = 0.2 effetto piccolo d = 0.5 effetto medio d = 0.8 effetto grande 36.6.2 Una piccola dimensione dell’effetto nella popolazione Consideriamo due ‘popolazioni’ la cui distribuzione è Normale di media 103 (la prima) e 100 (la seconda). Per entrambe, la deviazione standard è uguale a 15. # Popolazione 1 mu_1 &lt;- 103 # Popolazione 2 mu_2 &lt;- 100 # SD comune sigma &lt;- 15 La dimensione dell’effetto nella popolazione è dunque uguale a (mu_2 - mu_1) / sigma #&gt; [1] -0.2 Se prendiamo dei campioni enormi x1 &lt;- rnorm(1e5, mu_1, sigma) x2 &lt;- rnorm(1e5, mu_2, sigma) e applichiamo la formula precedente, otteniamo una stima non distorta della vera dimensione dell’effetto. nn &lt;- length(x1) - 1 sp &lt;- sqrt( (var(x1) * nn + var(x2) * nn) / (nn + nn) ) sp #&gt; [1] 14.98042 (mean(x1) - mean(x2)) / sp #&gt; [1] 0.200439 Oppure, in maniera equivalente dc &lt;- cohen.d(x1, x2) dc #&gt; #&gt; Cohen&#39;s d #&gt; #&gt; d estimate: 0.200439 (small) #&gt; 95 percent confidence interval: #&gt; lower upper #&gt; 0.1916517 0.2092262 Ma vediamo cosa succede quando i campioni sono piccoli, ovvero simili a quelli che si usano normalmente in psicologia. Supponiamo che \\(n\\) = 30. Nella simulazione consideriamo 100,000 coppie di campioni di 30 osservazioni estratte da ciascuna delle due popolazioni. Per ciascuna coppia di 30 osservazioni, calcoliamo un test di significatività statistica (il famoso test \\(t\\) di Student) e il \\(d\\) di Cohen. Alcuni di questi confronti non raggiungono la soglia \\(p\\) = 0.05 e quindi li escludiamo. Infatti, la consuetudine è di non pubblicare i risultati che non sono “statisticamente significativi” (ovvero, con un valore-\\(p\\) &lt; 0.05). Conserviamo invece i campioni che sono risultati “statisticamente significativi”. La domanda che ci poniamo è: in che misura i campioni “statisticamente significativi” rispecchiano le caratteristiche della popolazione da cui sono stati estratti? nrep &lt;- 1e5 nsample &lt;- 30 alpha &lt;- 0.05 significant &lt;- rep(NA, nrep) cohen_d &lt;- rep(NA, nrep) for (i in 1:nrep) { x1 &lt;- rnorm(nsample, mu_1, sigma) x2 &lt;- rnorm(nsample, mu_2, sigma) out &lt;- t.test(x1, x2) significant[i] &lt;- ifelse(out$p.value &lt; alpha, 1, 0) dc &lt;- cohen.d(x1, x2) cohen_d[i] &lt;- dc$estimate } Intanto calcolo il la proporzione di campioni che producono risultati “pubblicabili”. summary(significant) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 0.0000 0.0000 0.0000 0.1189 0.0000 1.0000 Dopo avere selezionato soltanto i risultati “statisticamente significativi” d &lt;- data.frame( is_significant = significant, d = cohen_d ) dim(d) #&gt; [1] 100000 2 d_pub &lt;- d %&gt;% dplyr::filter( is_significant == 1 ) dim(d_pub) #&gt; [1] 11893 2 creo un istogramma della dimensione dell’effetto (calcolata soltanto sui campioni nei quali l’effetto è “statisticamente significativo”). hist( d_pub$d, xlab = &quot;Indice d di Cohen&quot;, ylab = &quot;Densità&quot;, main = &quot;Soltanto risultati pubblicabili&quot;, freq = FALSE ) abline(v = 0.2, lty = 2, col = &quot;blue&quot;) La simulazione mostra due risultati degni di nota. Complessivamente, la dimensione dell’effetto viene di molto sovrastimata. In una proporzione non trascurabile di casi, la direzione dell’effetto è sbagliata. Questa simulazione dunque mostra come, seguendo la procedura frequentista, si ottiene proprio il risultato che si voleva evitare: si giunge “normalmente” alla risposta sbagliata. 36.6.3 Una soluzione (sbagliata) Per risolvere questo problema è stato proposto da diversi ricercatori di utilizzare un livello \\(\\alpha\\) più “conservativo”. nrep &lt;- 1e5 nsample &lt;- 30 alpha &lt;- 0.001 significant &lt;- rep(NA, nrep) cohen_d &lt;- rep(NA, nrep) for (i in 1:nrep) { x1 &lt;- rnorm(nsample, mu_1, sigma) x2 &lt;- rnorm(nsample, mu_2, sigma) out &lt;- t.test(x1, x2) significant[i] &lt;- ifelse(out$p.value &lt; alpha, 1, 0) dc &lt;- cohen.d(x1, x2) cohen_d[i] &lt;- dc$estimate } d &lt;- data.frame( is_significant = significant, d = cohen_d ) d_pub &lt;- d %&gt;% dplyr::filter( is_significant == 1 ) hist( d_pub$d, xlab = &quot;Indice d di Cohen&quot;, ylab = &quot;Densità&quot;, main = &quot;Soltanto risultati pubblicabili&quot;, freq = FALSE ) abline(v = 0.2, lty = 2, col = &quot;blue&quot;) Come mostrato dai risultati della simulazione, l’uso di una soglia più “conservativa” non ha altro effetto che quello di esacerbare il problema: la sovrastima della dimensione dell’effetto aumenta. In conclusione, si può dire che l’uso dell’approccio frequentista garantisce, senza possibilità di dubbio, il fatto di giungere alla conclusione inferenziale sbagliata. References "],["bibliografia.html", "Capitolo 37 Bibliografia", " Capitolo 37 Bibliografia "],["simbologia-di-base.html", "Appendice A Simbologia di base", " Appendice A Simbologia di base Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici. \\(\\log(x)\\): il logaritmo naturale di \\(x\\). L’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole). Il quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato. Il quantificatore universale \\(\\forall\\) vuol dire “per ogni.” \\(\\mathcal{A, S}\\): insiemi. \\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\). L’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\). L’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca. Il simbolo \\(\\vert\\) si legge “tale che.” Il simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.” Il simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo. Il simbolo \\(\\propto\\) si legge “proporzionale a.” Il simbolo \\(\\approx\\) si legge “circa.” Il simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.” Il simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.” Il simbolo \\(\\#\\) indica la cardinalità di un insieme. Il simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi. Il simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile. In matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto. \\(a, c, \\alpha, \\gamma\\): scalari. \\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori. \\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici. \\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\). \\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità. \\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\). \\(f(x)\\): una funzione arbitraria di \\(x\\). \\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\). \\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\). \\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\). \\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\). \\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza). \\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo). \\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo). \\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\). "],["numeri-binari-interi-razionali-irrazionali-e-reali.html", "Appendice B Numeri binari, interi, razionali, irrazionali e reali B.1 Numeri binari B.2 Numeri interi B.3 Numeri razionali B.4 Numeri irrazionali B.5 Numeri reali B.6 Intervalli", " Appendice B Numeri binari, interi, razionali, irrazionali e reali B.1 Numeri binari I numeri più semplici sono quelli binari, cioè zero o uno. Useremo spesso numeri binari per indicare se qualcosa è vero o falso, presente o assente. I numeri binari sono molto utili per ottenere facilmente delle statistiche riassuntive in \\(\\mathsf{R}\\).Supponiamo di chiedere a 10 studenti “Ti piacciono i mirtilli?” Poniamo che le risposte siano le seguenti: opinion &lt;- c( &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot; ) opinion #&gt; [1] &quot;Yes&quot; &quot;No&quot; &quot;Yes&quot; &quot;No&quot; &quot;Yes&quot; &quot;No&quot; &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; Tali risposte possono essere ricodificate nei termini di valori di verità, ovvero, vero e falso, generalmente denotati rispettivamente come 1 e 0. In \\(\\R\\) tale ricodifica può essere effettuata mediante l’operatore == che è un test per l’uguaglianza e restituisce il valore logico VERO se i due oggetti valutati sono uguali e FALSO se non lo sono: opinion &lt;- opinion == &quot;Yes&quot; opinion #&gt; [1] TRUE FALSE TRUE FALSE TRUE FALSE TRUE TRUE TRUE TRUE R considera i valori di verità e i numeri binari in modo equivalente, con TRUE uguale a 1 e FALSE uguale a zero. Di conseguenza, possiamo effettuare operazioni algebriche sui valori logici VERO e FALSO. Nell’esempio, possiamo sommare i valori di verità e dividere per 10 sum(opinion) / length(opinion) #&gt; [1] 0.7 in modo tale da calcolare una propozione, il che ci consente di concludere che 7 risposte su 10 sono positive. B.2 Numeri interi Un numero intero è un numero senza decimali. Si dicono naturali i numeri che servono a contare, come 1, 2, … L’insieme dei numeri naturali si indica con il simbolo \\(\\mathbb{N}\\). È anche necessario introdurre i numeri con il segno per poter trattare grandezze negative. Si ottengono così l’insieme numerico dei numeri interi relativi: \\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\) B.3 Numeri razionali I numeri razionali sono i numeri frazionari \\(m/n\\), dove \\(m, n \\in N\\), con \\(n \\neq 0\\). Si ottengono così i numeri razionali: \\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\in \\mathbb{Z}, n \\neq 0\\}\\). È evidente che \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\). Anche in questo caso è necessario poter trattare grandezze negative. I numeri razionali non negativi sono indicati con \\(\\mathbb{Q^+} = \\{q \\in \\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\). B.4 Numeri irrazionali Tuttavia, non tutti i punti di una retta \\(r\\) possono essere rappresentati mediante i numeri interi e razionali. È dunque necessario introdurre un’altra classe di numeri. Si dicono irrazionali, e sono denotati con \\(\\mathbb{R}\\), i numeri che possono essere scritti come una frazione \\(a / b\\), con \\(a\\) e \\(b\\) interi e \\(b\\) diverso da 0. I numeri irrazionali sono i numeri illimitati e non periodici che quindi non possono essere espressi sotto forma di frazione. Per esempio, \\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\({\\displaystyle \\pi =3,141592\\ldots}\\) sono numeri irrazionali. B.5 Numeri reali I punti della retta \\(r\\) sono quindi “di più” dei numeri razionali. Per poter rappresentare tutti i punti della retta abbiamo dunque bisogno dei numeri reali. I numeri reali possono essere positivi, negativi o nulli e comprendono, come casi particolari, i numeri interi, i numeri razionali e i numeri irrazionali. Spesso in statisticac il numero dei decimali indica il grado di precisione della misurazione. B.6 Intervalli Un intervallo si dice chiuso se gli estremi sono compresi nell’intervallo, aperto se gli estremi non sono compresi. Le caratteristiche degli intervalli sono riportate nella tabella seguente. Intervallo chiuso \\([a, b]\\) \\(a \\leq x \\leq b\\) aperto \\((a, b)\\) \\(a &lt; x &lt; b\\) chiuso a sinistra e aperto a destra \\([a, b)\\) \\(a \\leq x &lt; b\\) aperto a sinistra e chiuso a destra \\((a, b]\\) \\(a &lt; x \\leq b\\) "],["insiemistica.html", "Appendice C Insiemi C.1 Operazioni tra insiemi C.2 Diagrammi di Eulero-Venn C.3 Coppie ordinate e prodotto cartesiano C.4 Cardinalità", " Appendice C Insiemi Un insieme (o collezione, classe, gruppo, …) è un concetto primitivo, ovvero è un concetto che già possediamo. Georg Cantor l’ha definito nel modo seguente: un insieme è una collezione di oggetti, determinati e distinti, della nostra percezione o del nostro pensiero, concepiti come un tutto unico; tali oggetti si dicono elementi dell’insieme. Mentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali: \\[ \\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}. \\] Gli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con \\[ A = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con~} n &gt; 0. \\] La scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\) Per quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme: \\[ A = \\{x ~\\vert~ \\text{proprietà posseduta da~} x\\}, \\] che si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere: \\[ A = \\{(x,y) ~\\vert~ y = x^2 + 1\\}. \\] Dati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\): \\[ A \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B). \\] Se esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\): \\[ A \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A). \\] Un altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è: \\[ \\mathcal{P}(A) = \\{ \\emptyset, \\{a\\}, \\{b\\}, \\{c\\}, \\{a, b\\}, \\{a, c\\}, \\{c, b\\}, \\{a, b, c\\} \\}. \\] C.1 Operazioni tra insiemi Si definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\): \\[ A \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}. \\] Si definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè \\[ A \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}. \\] Differenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\): \\[ A \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}. \\] Insieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\). Dato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che \\[ S = S_1 \\cup S_2 \\cup \\dots S_k \\] e \\[ S_i \\cap S_j, \\quad \\text{con~} i \\neq j. \\] La relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan: \\[ (A \\cup B)^c = A^c \\cap B^c, \\] \\[ (A \\cap B)^c = A^c \\cup B^c. \\] C.2 Diagrammi di Eulero-Venn In molte situazioni è utile servirsi dei cosiddetti diagrammi di Eulero-Venn per rappresentare gli insiemi e verificare le proprietà delle operazioni tra insiemi (si veda la figura C.1. I diagrammi di Venn sono così nominati in onore del matematico inglese del diciannovesimo secolo John Venn anche se Leibnitz e Eulero avevano già in precedenza utilizzato rappresentazioni simili. In tale rappresentazione, gli insiemi sono individuati da regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare esplicitamente alcuni elementi di un insieme mediante punti, quando si possono anche evidenziare tutti gli elementi degli insiemi considerati. FIGURA C.1: In tutte le figure \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura. I diagrammi di Eulero-Venn che forniscono una dimostrazione delle leggi di DeMorgan sono forniti nella figura C.2. FIGURA C.2: Dimostrazione delle leggi di DeMorgan. C.3 Coppie ordinate e prodotto cartesiano Una coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata), \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano: \\[ A \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}. \\] Ad esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora, \\[ \\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}. \\] C.4 Cardinalità Si definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\). "],["sommatorie.html", "Appendice D Simbolo di somma (sommatorie) D.1 Manipolazione di somme D.2 Doppia sommatoria D.3 Sommatorie (e produttorie) e operazioni vettoriali in R", " Appendice D Simbolo di somma (sommatorie) Le somme si incontrano costantemente in svariati contesti matematici e statistici quindi abbiamo bisogno di una notazione adeguata che ci consenta di gestirle. La somma dei primi \\(n\\) numeri interi può essere scritta come \\(1+2+\\dots+(n-1)+n\\), dove `\\(\\dots\\)’ ci dice di completare la sequenza definita dai termini che vengono prima e dopo. Ovviamente, una notazione come \\(1+7+\\dots+73.6\\) non avrebbe alcun senso senza qualche altro tipo di precisazione. In generale, nel seguito incontreremo delle somme nella forma \\[\\begin{equation} x_1+x_2+\\dots+x_n,\\notag \\end{equation}\\] dove \\(x_i\\) è un numero che è stato definito altrove. La notazione precedente, che fa uso dei tre puntini di sospensione, è utile in alcuni contesti ma in altri risulta ambigua. Pertanto la notazione di uso corrente è del tipo \\[\\begin{equation} \\sum_{i=1}^n x_i\\notag \\end{equation}\\] e si legge “sommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (lettera sigma maiuscola dell’alfabeto greco) indica l’operazione di somma, il simbolo \\(x_i\\) indica il generico addendo della sommatoria, le lettere \\(1\\) ed \\(n\\) indicano i cosiddetti estremi della sommatoria, ovvero l’intervallo (da \\(1\\) fino a \\(n\\) estremi inclusi) in cui deve variare l’indice \\(i\\) allorché si sommano gli addendi \\(x_i\\). Solitamente l’estremo inferiore è \\(1\\) ma potrebbe essere qualsiasi altri numero \\(m &lt; n\\). Quindi \\[ \\sum_{i=1}^n x_i = x_1 + x_{2} + \\dots + x_{n}. \\] Per esempio, se i valori \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), si avrà \\[ \\sum_{i=1}^4 x_i = 3+11+4+7 = 25 \\] laddove \\(x_1 = 3\\), \\(x_2 = 11\\), eccetera. La quantità \\(x_i\\) nella formula precedente si dice l’argomento della sommatoria, mentre la variabile \\(i\\), che prende i valori naturali successivi indicati nel simbolo, si dice indice della sommatoria. La notazione di sommatoria può anche essere fornita nella forma seguente \\[\\begin{equation} \\sum_{P(i)} x_i\\notag \\end{equation}\\] dove \\(P(i)\\) è qualsiasi proposizione riguardante \\(i\\) che può essere vera o falsa. Quando è ovvio che si vogliono sommare tutti i valori di \\(n\\) osservazioni, la notazione può essere semplificata nel modo seguente: \\(\\sum_{i} x_i\\) oppure \\(\\sum x_i\\). Al posto di \\(i\\) si possono trovare altre lettere: \\(k, j, l, \\dots\\),. D.1 Manipolazione di somme È conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l’operatore della sommatoria. D.1.1 Proprietà 1 La sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) è pari a \\(n\\) volte la costante stessa: \\[ \\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a}_{n~\\text{volte}} = n a. \\] D.1.2 Proprietà 2 (proprietà distributiva) Nel caso in cui l’argomento contenga una costante, è possibile riscrivere la sommatoria. Ad esempio con \\[ \\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n \\] è possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere \\[ \\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i. \\] D.1.3 Proprietà 3 (proprietà associativa) Nel caso in cui \\[ \\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots (a + x_n) \\] si ha che \\[ \\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i. \\] È dunque chiaro che in generale possiamo scrivere \\[ \\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i. \\] D.1.4 Proprietà 4 Se deve essere eseguita un’operazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull’argomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio, \\[ \\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2. \\] D.1.5 Proprietà 5 Nel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo: \\[ \\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n, \\] infatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\). D.2 Doppia sommatoria È possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice: \\[ \\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}. \\] La doppia sommatoria comporta che per ogni valore dell’indice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi, \\[ \\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}). \\] Un caso particolare interessante di doppia sommatoria è il seguente: \\[ \\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j \\] Si può osservare che nella sommatoria interna (quella che dipende dall’indice \\(j\\)), la quantità \\(x_i\\) è costante, ovvero non dipende dall’indice (che è \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall’operatore di sommatoria interna e scrivere \\[ \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right). \\] Allo stesso modo si può osservare che nell’argomento della sommatoria esterna la quantità costituita dalla sommatoria in \\(j\\) non dipende dall’indice \\(i\\) e quindi questa quantità può essere estratta dalla sommatoria esterna. Si ottiene quindi \\[ \\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n}\\ x_i \\sum_{j=1}^{n} y_j. \\] Esercizio D.1 Si verifichi quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto così ottenuto sia uguale al prodotto delle due sommatorie. \\[\\begin{align} \\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &amp;= x_1y_1 + x_1y_2 + x_1y_3 + x_2y_1 + x_2y_2 + x_2y_3 + x_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\ &amp;= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag \\end{align}\\] ovvero \\[ (2 + 3 + 1) \\times (1+4+9) = 84. \\] D.3 Sommatorie (e produttorie) e operazioni vettoriali in R Si noti che la notazione \\[ \\sum_{n=0}^4 3n \\] non è altro che un ciclo for: sum &lt;- 0 for (n in 0:4) { sum = sum + 3 * n } sum #&gt; [1] 30 In maniera equivalente, e più semplice, possiamo scrivere sum(3 * (0:4)) #&gt; [1] 30 Allo stesso modo, la notazione \\[ \\prod_{n=1}^{4} 2n \\] è anch’essa equivalente al ciclo for prod &lt;- 1 for (n in 1:4) { prod &lt;- prod * 2 * n } prod #&gt; [1] 384 che si può scrivere, più semplicemente, come prod(2 * (1:4)) #&gt; [1] 384 In entrambi i casi precedenti, abbiamo sostituito le operazioni aritmetiche eseguite all’interno di un ciclo for con le stesse operazioni aritmetiche eseguite sui vettori elemento per elemento. "],["appendix:future-exp.html", "Appendice E Le aspettative future dei pazienti depressi E.1 La ricerca di Zetsche, Bürkner, and Renneberg (2019)", " Appendice E Le aspettative future dei pazienti depressi E.1 La ricerca di Zetsche, Bürkner, and Renneberg (2019) Per descrivere vari aspetti dell’analisi bayesiana utilizzeremo dei dati reali, nello specifico quelli raccolti da Zetsche, Bürkner, and Renneberg (2019). Questi ricercatori si sono chiesti se gli individui depressi manifestino delle aspettative accurate circa il loro umore futuro, oppure se tali aspettative siano distorte negativamente. Esamineremo qui i 30 partecipanti dello studio di Zetsche, Bürkner, and Renneberg (2019) che hanno riportato la presenza di un episodio di depressione maggiore in atto. All’inizio della settimana di test, a questi pazienti è stato chiesto di valutare l’umore che si aspettavano di esperire nei giorni seguenti della settimana. Mediante una app, i partecipanti dovevano poi valutare il proprio umore in cinque momenti diversi di ciascuno dei cinque giorni successivi. Lo studio considera diverse emozioni, ma qui ci concentriamo solo sulla tristezza. Sulla base dei dati forniti dagli autori, abbiamo calcolato la media dei giudizi relativi al livello di tristezza raccolti da ciascun partecipante tramite la app. Tale media è stata poi sottratta dall’aspettativa del livello di tristezza fornita all’inizio della settimana. La discrepanza tra aspettative e realtà è stata considerata come un evento dicotomico: valori positivi di tale differenza indicano che le aspettative circa il livello di tristezza erano maggiori del livello di tristezza effettivamente esperito — ciò significa che le aspettative future risultano negativamente distorte (evento codificato con “1”). Viceversa, si ha che le aspettative risultano positivamente distorte se la differenza descritta in precedenza assume un valore negativo (evento codificato con “0”). Nel campione dei 30 partecipanti clinici di Zetsche, Bürkner, and Renneberg (2019), le aspettative future di 23 partecipanti risultano distorte negativamente e quelle di 7 partecipanti risultano distorte positivamente. Chiameremo \\(\\theta\\) la probabilità dell’evento “le aspettative del partecipante sono distorte negativamente”. Ci poniamo il problema di ottenere una stima a posteriori di \\(\\theta\\) avendo osservato 23 “successi” in 30 prove. Si noti un punto importante: dire semplicemente che la stima di \\(\\theta\\) è uguale a 23/30 = 0.77 ci porta ad ignorare il livello di incertezza associato a tale stima. Infatti, lo stesso valore (0.77) si può ottenere come 23/30, o 230/300, o 2300/3000, o 23000/30000, ma l’incertezza di una stima pari a 0.77 è molto diversa nei quattro casi. Quando si traggono conclusioni dai dati è invece necessario quantificare il livello della nostra incertezza relativamente alla stima del parametro di interesse (nel caso presente, \\(\\theta\\)). Lo strumento ci consente di quantificare tale incertezza è la distribizione a posteriori \\(p(\\theta \\mid y)\\). Ovviamente, \\(p(\\theta \\mid y)\\) assume forme molto diverse nei quattro casi descritti sopra. References "],["appendix:beta-binom.html", "Appendice F Modello Beta-binomiale F.1 Funzione per il modello Beta-binomiale", " Appendice F Modello Beta-binomiale F.1 Funzione per il modello Beta-binomiale La seguente funzione può essere usata per rappresentare la distribuzione a priori, la distribuzione a posteriori e la versosimiglianza (normalizzata) nel caso del modello Beta-binomiale. I parametri in input sono, nell’ordine, i parametri \\(\\alpha\\) e \\(\\beta\\) della distribuzione a priori Beta, \\(y\\) (numero di successi) e \\(n\\) (numero di prove). plot_beta_bin &lt;- function(a, b, y, n) { library(&quot;tidyverse&quot;) df1 &lt;- data.frame(theta = seq(0.001, 1, 0.001)) prior_un &lt;- dbeta(df1$theta, a, b) df1$prior &lt;- prior_un / sum(prior_un) # Likelihood like_un &lt;- dbinom(y, n, prob = seq(0.001, 1, 0.001)) df1$like &lt;- like_un / sum(like_un) # Posterior post_un &lt;- df1$prior * df1$like df1$post &lt;- post_un / sum(post_un) df2 &lt;- df1 %&gt;% pivot_longer(!theta, names_to = &quot;grp&quot;, values_to = &quot;val&quot;) df2$grp &lt;- factor(df2$grp) # levels(df2$grp) df2$grp &lt;- factor(df2$grp, levels = c(&quot;prior&quot;, &quot;like&quot;, &quot;post&quot;)) levels(df2$grp) &lt;- c( &quot;Distribuzione a priori&quot;, &quot;Verosimiglianza&quot;, &quot;Distribuzione a posteriori&quot; ) p &lt;- ggplot(data = df2) + geom_line(aes(theta, val)) + facet_wrap(~grp, ncol = 1, scales = &quot;free_y&quot;) + coord_cartesian(xlim = c(0, 1)) + scale_y_continuous(breaks = NULL) + labs(x = &quot;&quot;, y = &quot;&quot;) p } "],["appendix:const-norm-bino23.html", "Appendice G Verosimiglianza marginale G.1 Derivazione analitica della costante di normalizzazione", " Appendice G Verosimiglianza marginale G.1 Derivazione analitica della costante di normalizzazione Riportiamo di seguito la derivazione analitica per la costante di normalizzazione discussa nella Sezione 14.4, ovvero dell’integrale (14.3). Dimostrazione. Sia la distribuzione a priori \\(\\theta \\sim \\mbox{Beta}(a, b)\\) e sia \\(y = \\{y_1, \\dots, y_n\\} \\sim \\Bin(\\theta, n)\\). Scrivendo la funzione beta come \\[ \\B(a, b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}, \\] la verosimiglianza marginale diventa \\[\\begin{align} p(y) &amp;= \\int p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\!\\theta \\notag\\\\ &amp;= \\int_0^1 \\binom{n}{y}\\theta^{y} (1 - \\theta)^{n- y} \\frac{1}{\\B(a,b)} \\theta^{a-1} (1-\\theta)^{b-1} \\,\\operatorname {d}\\!\\theta \\notag\\\\ &amp;= \\binom{n}{y}\\frac{1}{\\B(a,b)} \\int_0^1 \\theta^{y + a - 1} (1-\\theta)^{n- y + b-1} \\,\\operatorname {d}\\!\\theta \\notag\\\\ &amp;= \\binom{n}{y}\\frac{\\Beta(y + a, n- y + b)}{\\Beta(a,b)}, \\tag{G.1} \\end{align}\\] in quanto \\[\\begin{align} \\int_0^1 \\frac{1}{\\Beta(a,b)} \\theta^{a-1} (1-\\theta)^{b-1} \\,\\operatorname {d}\\! \\theta &amp;= 1\\notag\\\\ \\frac{1}{\\Beta(a,b)} \\int_0^1 \\theta^{a-1} (1-\\theta)^{b-1} \\,\\operatorname {d}\\! \\theta &amp;= 1\\notag\\\\ \\int_0^1 \\theta^{a-1} (1-\\theta)^{b-1} \\,\\operatorname {d}\\!\\theta &amp;= \\Beta(a,b). \\notag \\end{align}\\] In conclusione, nel caso di una verosimiglianza binomiale \\(y = \\sim \\Bin(\\theta, n)\\) e di una distribuzione a priori \\(\\theta \\sim \\mbox{Beta}(a, b)\\), la verosimiglianza marginale diventa uguale alla (G.1). Esercizio G.1 Si verifichi la (G.1) mediante di dati di Zetsche, Bürkner, and Renneberg (2019). Per replicare mediante la (G.1) il risultato trovato per via numerica nella Sezione 14.4 assumiamo una distribuzione a priori uniforme, ovvero \\(\\mbox{Beta}(1, 1)\\). I valori del problema dunque diventano i seguenti: a &lt;- 1 b &lt;- 1 y &lt;- 23 n &lt;- 30 Definiamo B &lt;- function(a, b) { (gamma(a) * gamma(b)) / gamma(a + b) } Il risultato cercato è choose(30, 23) * B(y + a, n - y + b) / B(a, b) #&gt; [1] 0.03225806 References "],["markov-chains.html", "Appendice H Le catene di Markov H.1 Simulare una catena di Markov", " Appendice H Le catene di Markov Per introdurre il concetto di catena di Markov, supponiamo che una persona esegua una passeggiata casuale sulla retta dei numeri naturali considerando solo i valori 1, 2, 3, 4, 5, 6.38 Se la persona è collocata su un valore interno dei valori possibili (ovvero, 2, 3, 4 o 5), nel passo successivo è altrettanto probabile che rimanga su quel numero o si sposti su un numero adiacente. Se si muove, è ugualmente probabile che si muova a sinistra o a destra. Se la persona si trova su uno dei valori estremi (ovvero, 1 o 6), nel passo successivo è altrettanto probabile che rimanga rimanga su quel numero o si sposti nella posizione adiacente. Questo è un esempio di una catena di Markov discreta. Una catena di Markov descrive il movimento probabilistico tra un numero di stati. Nell’esempio ci sono sei possibili stati, da 1 a 6, i quali corrispondono alle possibili posizioni della passeggiata casuale. Data la sua posizione corrente, la persona si sposterà nelle altre posizioni possibili con delle specifiche probabilità. La probabilità che si sposti in un’altra posizione dipende solo dalla sua posizione attuale e non dalle posizioni visitate in precedenza. È possibile descrivere il movimento tra gli stati nei termini delle cosiddette probabilità di transizione, ovvero le probabilità di movimento tra tutti i possibili stati in un unico passaggio di una catena di Markov. Le probabilità di transizione sono riassunte in una matrice di transizione \\(P\\): p &lt;- c(0, 0, 1, 0, 0, 0) P &lt;- matrix( c(.5, .5, 0, 0, 0, 0, .25, .5, .25, 0, 0, 0, 0, .25, .5, .25, 0, 0, 0, 0, .25, .5, .25, 0, 0, 0, 0, .25, .5, .25, 0, 0, 0, 0, .5, .5 ), nrow = 6, ncol = 6, byrow = TRUE) kableExtra::kable(P) 0.50 0.50 0.00 0.00 0.00 0.00 0.25 0.50 0.25 0.00 0.00 0.00 0.00 0.25 0.50 0.25 0.00 0.00 0.00 0.00 0.25 0.50 0.25 0.00 0.00 0.00 0.00 0.25 0.50 0.25 0.00 0.00 0.00 0.00 0.50 0.50 La prima riga della matrice di transizione \\(P\\) fornisce le probabilità di passare a ciascuno degli stati da 1 a 6 in un unico passaggio a partire dalla posizione 1; la seconda riga fornisce le probabilità di transizione in un unico passaggio dalla posizione 2 e così via. Per esempio, il valore \\(P[1, 1]\\) ci dice che, se la persona è nello stato 1, avrà una probabilità di 0.5 di rimanere in quello stato; \\(P[1, 2]\\) ci dice che c’è una probabilità di 0.5 di passare dallo stato 1 allo stato 2. Gli altri elementi della prima riga sono 0 perché, in un unico passaggio, non è possibile passare dallo stato 1 agli stati 3, 4, 5 e 6. Il valore \\(P[2, 1]\\) ci dice che, se la persona è nello stato 1 (seconda riga), avrà una probabilità di 0.25 di passare allo stato 1; avra una probabilità di 0.5 di rimanere in quello stato, \\(P[2, 2]\\); e avrà una probabilità di 0.25 di passare allo stato 3, \\(P[2, 3]\\); eccetera. Si notino alcune importanti proprietà di questa particolare catena di Markov. È possibile passare da ogni stato a qualunque altro stato in uno o più passaggi: una catena di Markov con questa proprietà si dice irriducibile. Dato che la persona si trova in un particolare stato, se può tornare a questo stato solo a intervalli regolari, si dice che la catena di Markov è periodica. In questo esempio la catena è aperiodica poiché la passeggiata casuale non può eitornare allo stato attuale a intervalli regolari. Un’importante proprietà di una catena di Markov irriducibile e aperiodica è che il passaggio ad uno stato del sistema dipende unicamente dallo stato immediatamente precedente e non dal come si è giunti a tale stato (dalla storia). Per questo motivo si dice che un processo markoviano è senza memoria. Tale “assenza di memoria” può essere interpretata come la proprietà mediante cui è possibile ottenere un insieme di campioni casuali da una distribuzione di interesse. Nel caso dell’inferenza bayesiana, la distribuzione di interesse è la distribuzione a posteriori, \\(p(\\theta \\mid y)\\). Le catene di Markov consentono di stimare i valori di aspettazione di variabili rispetto alla distribuzione a posteriori. La matrice di transizione che si ottiene dopo un enorme numero di passi di una passeggiata casuale markoviana si chiama distribuzione stazionaria. Se una catena di Markov è irriducibile e aperiodica, allora ha un’unica distribuzione stazionaria \\(w\\). La distribuzione limite di una tale catena di Markov, quando il numero di passi tende all’infinito, è uguale alla distribuzione stazionaria \\(w\\). H.1 Simulare una catena di Markov Un metodo per dimostrare l’esistenza della distribuzione stazionaria di una catena di Markov è quello di eseguire un esperimento di simulazione. Iniziamo una passeggiata casuale partendo da un particolare stato, diciamo la posizione 3, e quindi simuliamo molti passaggi della catena di Markov usando la matrice di transizione \\(P\\). Al crescere del numero di passi della catena, le frequenze relative che descrivono il passaggio a ciascuno dei sei possibili nodi della catena approssimano sempre meglio la distribuzione stazionaria \\(w\\). Senza entrare nei dettagli della simulazione, la figura H.1 mostra i risultati ottenuti in 10,000 passi di una passeggiata casuale markoviana. Si noti che, all’aumentare del numero di iterazioni, le frequenze relative approssimano sempre meglio le probabilità nella distribuzione stazionaria \\(w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1)\\). set.seed(123) s &lt;- vector(&quot;numeric&quot;, 10000) s[1] &lt;- 3 for (j in 2:10000) { s[j] &lt;- sample(1:6, size = 1, prob = P[s[j - 1], ]) } S &lt;- data.frame( Iterazione = 1:10000, Location = s ) S %&gt;% mutate( L1 = (Location == 1), L2 = (Location == 2), L3 = (Location == 3), L4 = (Location == 4), L5 = (Location == 5), L6 = (Location == 6) ) %&gt;% mutate( Proporzione_1 = cumsum(L1) / Iterazione, Proporzione_2 = cumsum(L2) / Iterazione, Proporzione_3 = cumsum(L3) / Iterazione, Proporzione_4 = cumsum(L4) / Iterazione, Proporzione_5 = cumsum(L5) / Iterazione, Proporzione_6 = cumsum(L6) / Iterazione ) %&gt;% dplyr::select( Iterazione, Proporzione_1, Proporzione_2, Proporzione_3, Proporzione_4, Proporzione_5, Proporzione_6 ) -&gt; S1 gather(S1, Outcome, Probability, -Iterazione) -&gt; S2 ggplot(S2, aes(Iterazione, Probability)) + geom_line() + facet_wrap(~Outcome, ncol = 3) + ylim(0, .4) + ylab(&quot;Frequenza relativa&quot;) + # theme(text=element_text(size=14)) + scale_x_continuous(breaks = c(0, 3000, 6000, 9000)) FIGURA H.1: Frequenze relative degli stati da 1 a 6 in funzione del numero di iterazioni per la simulazione di una catena di Markov. Il metodo di campionamento utilizzato dagli algoritmi MCMC consente di creare una catena di Markov irriducibile e aperiodica, la cui distribuzione stazionaria equivale alla distribuzione a posteriori \\(p(\\theta \\mid y)\\). Seguiamo qui la presentazione fornita da Bob Carpenter.↩︎ "],["regr-ml.html", "Appendice I Adattare il modello lineare ai dati I.1 Minimi quadrati I.2 Calcolare la somma dei quadrati Commenti e considerazioni finali", " Appendice I Adattare il modello lineare ai dati In questo Capitolo verranno esposte alcune nozioni matematiche che stanno alla base dell’inferenza sul modello lineare. I.1 Minimi quadrati Nel modello lineare classico, \\(y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\), i coefficienti \\(\\beta_0\\) e \\(\\beta_1\\) sono stimati in modo tale da minimizzare gli errori \\(\\varepsilon_i\\). Se il numero dei dati \\(n\\) è maggiore di 2, non è generalmente possibile trovare una retta che passi per tutte le osservazioni (\\(x, y\\)) (sarebbe \\(y_i = \\beta_0 + \\beta_1 x_i\\), senza errori, per tutti i punti \\(i = 1, \\dots, n\\)). L’obiettivo della stima dei minimi quadrati è quello di scegliere i valori (\\(\\hat{\\beta}_0, \\hat{\\beta}_1\\)) che minimizzano la somma dei quadrati dei residui, \\[\\begin{equation} e_i = y_i − (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)\\,. \\end{equation}\\] Distinguiamo tra i residui \\(e_i = y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)\\) e gli errori \\(\\varepsilon_i = y_i − (\\beta_0 + \\beta_1 x_i)\\). Il modello di regressione è scritto in termini degli errori, ma possiamo solo lavorare con i residui: non possiamo calcolare gli errori perché per farlo sarebbe necessario conoscere i parametri ignoti \\(\\beta_0\\) e \\(\\beta_1\\). La somma dei residui quadratici (residual sum of squares) è \\[\\begin{equation} \\text{RSS} = \\sum_{i=1}^n (y_i = (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2\\,. \\end{equation}\\] I coefficienti (\\(\\hat{\\beta}_0, \\hat{\\beta}_1\\)) che minimizzano RSS sono chiamati stime dei minimi quadrati, o minimi quadrati ordinari (ordinari least squares), o stime OLS. I.1.1 Stima della deviazione standard dei residui \\(\\sigma\\) Nel modello lineare, gli errori \\(\\varepsilon_i\\) provengono da una distribuzione con media 0 e deviazione standard \\(\\sigma\\): la media è zero per definizione (qualsiasi media diversa da zero viene assorbita nell’intercetta, \\(\\beta_0\\)), e la deviazione standard degli errori può essere stimata dai dati. Un modo apparentemente naturale per stimare \\(\\sigma\\) potrebbe essere quello di calcolare la deviazione standard dei residui, \\(\\sqrt{\\frac{1}{n} \\sum_{i=1}^n e_i^2} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^n y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2}\\), ma questo approccio finisce per sottostimare \\(\\sigma\\). La correzione standard di questa sottostima consiste nel sostituire \\(n\\) con \\(n - 2\\) al denominatore (la sottrazione di 2 deriva dal fatto che il valore atteso del modello lineare è stato calcolato utilizzando i due coefficienti nel modello, l’intercetta e la pendenza, i quali sono stati stimati dai dati campionari – si dice che, in questo modo, abbiamo perso due gradi di libertà). Così facendo otteniamo \\[\\begin{equation} \\hat{\\sigma} = \\sqrt{\\frac{1}{n-2} \\sum_{i=1}^n (y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2}\\, . \\end{equation}\\] Quando \\(n = 1\\) o \\(2\\) l’equazione precedente è priva di significato, il che ha senso: con solo due osservazioni è possibile adattare esattamente una retta al diagramma di dispersione e quindi non c’è modo di stimare l’errore dai dati. I.2 Calcolare la somma dei quadrati Seguendo Solomon Kurz, creiamo una funzione per calcolare la somma dei quadrati per diversi valori di \\(\\beta_0\\) e \\(\\beta_1\\) che, per semplicità, qui verranno chiamati \\(a\\) e \\(b\\): rss &lt;- function(x, y, a, b) { # x and y are vectors, # a and b are scalars resid &lt;- y - (a + b * x) return(sum(resid^2)) } Per fare un esempio concreto useremo un famoso dataset chiamato kidiq (Gelman, Hill, and Vehtari 2020) che riporta i dati di un’indagine del 2007 su un campione di donne americane adulte e sui loro bambini di età compresa tra i 3 e i 4 anni. I dati sono costituiti da 434 osservazioni e 4 variabili: kid_score: QI del bambino; è il punteggio totale del Peabody Individual Achievement Test (PIAT) costituito dalla somma dei punteggi di tre sottoscale (Mathematics, Reading comprehension, Reading recognition); mom_hs: variabile dicotomica (0 or 1) che indica se la madre del bambino ha completato le scuole superiori (1) oppure no (0); mom_iq: QI della madre; mom_age: età della madre. library(&quot;rio&quot;) df &lt;- rio::import(here::here(&quot;data&quot;, &quot;kidiq.dta&quot;)) head(df) #&gt; kid_score mom_hs mom_iq mom_work mom_age #&gt; 1 65 1 121.11753 4 27 #&gt; 2 98 1 89.36188 4 25 #&gt; 3 85 1 115.44316 4 27 #&gt; 4 83 1 99.44964 3 25 #&gt; 5 115 1 92.74571 4 27 #&gt; 6 98 0 107.90184 1 18 Calcoliamo alcune statistiche descrittive: summary(df) #&gt; kid_score mom_hs mom_iq mom_work #&gt; Min. : 20.0 Min. :0.0000 Min. : 71.04 Min. :1.000 #&gt; 1st Qu.: 74.0 1st Qu.:1.0000 1st Qu.: 88.66 1st Qu.:2.000 #&gt; Median : 90.0 Median :1.0000 Median : 97.92 Median :3.000 #&gt; Mean : 86.8 Mean :0.7857 Mean :100.00 Mean :2.896 #&gt; 3rd Qu.:102.0 3rd Qu.:1.0000 3rd Qu.:110.27 3rd Qu.:4.000 #&gt; Max. :144.0 Max. :1.0000 Max. :138.89 Max. :4.000 #&gt; mom_age #&gt; Min. :17.00 #&gt; 1st Qu.:21.00 #&gt; Median :23.00 #&gt; Mean :22.79 #&gt; 3rd Qu.:25.00 #&gt; Max. :29.00 Il QI medio dei bambini è di circa 87 mentre quello della madre è di 100. La gamma di età delle madri va da 17 a 29 anni con una media di circa 23 anni. Si noti infine che il 79% delle mamme ha un diploma di scuola superiore. Ci poniamo ora il problema di descrivere l’associazione tra il QI dei figli, kid_score, e il QI delle madri, mom_iq, mediante un modello lineare. Le stime dei minimi quadrati sono fornite dalla funzione lm(): fm &lt;- lm(kid_score ~ mom_iq, data = df) fm %&gt;% tidy() %&gt;% filter(term == c(&quot;(Intercept)&quot;, &quot;mom_iq&quot;)) %&gt;% pull(estimate) #&gt; [1] 25.7997778 0.6099746 Calcoliamo la somma dei residui quadratici in base al modello di regressione \\(\\hat{y}_i = 25.8 + 0.61 x_i\\): rss(df$mom_iq, df$kid_score, 25.8, 0.61) #&gt; [1] 144137.3 Per sviluppare una comprensione intuitiva del metodo dei minimi quadrati, esploriamo i valori assunti da rss per diversi valori di \\(a\\) e \\(b\\). Per semplicità, manteniamo costante b = 0.61 e variamo i valori a. tibble(a = seq(20, 30, length.out = 30)) %&gt;% mutate( rss = purrr::map_dbl( a, rss, x = df$mom_iq, y = df$kid_score, b = 0.61) ) %&gt;% ggplot(aes(x = a, y = rss)) + geom_point() + labs(subtitle = &quot;Il valore b è tenuto costante (b = 0.61)&quot;) Il minimo della funzione che qui abbiamo discretizzato costituisce la stima dei minimi quadrati del parametro \\(\\beta_0\\). Lo stesso può essere fatto per \\(b\\): tibble(b = seq(0.4, 0.8, length.out = 30)) %&gt;% mutate( rss = purrr::map_dbl( b, rss, x = df$mom_iq, y = df$kid_score, a = 25.8) ) %&gt;% ggplot(aes(x = b, y = rss)) + geom_point() + labs(subtitle = &quot;Il valore a è tenuto costante (a = 25.8)&quot;) Il minimo della funzione rappresentata qui sopra costituisce la stima dei minimi quadrati del parametro \\(\\beta_1\\). In generale, possiamo dire che il metodo dei minimi quadrati consente di minimizzare la funzione quadratica \\(RSS = \\sum_{i=1}^n \\left(y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)\\right)^2\\) rispetto alle due incognite \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\). Numericamente, ciò corrisponde a variare sia a che b simultaneamente in un listato simile a quello riportato sopra. Anche se il codice \\(\\R\\) necessario per ottenere questo risultato è più complesso di quello qui esaminato, l’idea di base non cambia. Osservazione. Nelle precedenti istruzioni \\(\\R\\) abbiamo utilizzato la funzione purrr::map_dbl(). Questo oggetto \\(\\R\\) consente di applicare una funzione (in questo caso, rss()) a ciascun elemento di un vettore in input (nel caso presente, il vettore a oppure il vettore b). La funzione purrr::map_dbl() ritorna un numero reale. Commenti e considerazioni finali Se gli errori del modello lineare sono indipendenti e distribuiti normalmente, in modo che \\(y_i \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x_i, \\sigma^2)\\) per ogni \\(i\\), allora la stima ai minimi quadrati di (\\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\)) coincide con la stima di massima verosimiglianza di questi parametri. In un modello lineare, la funzione di verosimiglianza è definita come la densità di probabilità delle osservazioni, dati i parametri e i predittori, ovvero, \\[\\begin{equation} p(y \\mid \\beta_0, \\beta_1, \\sigma, x) = \\prod_{i=1}^n \\mathcal{N}(y_i \\mid \\beta_0 + \\beta_1 x_i, \\sigma^2), \\tag{I.1} \\end{equation}\\] dove \\(\\mathcal{N}(\\cdot | \\cdot, \\cdot)\\) è la funzione gaussiana. Un studio della (I.1) mostra che la massimizzazione della verosimiglianza richiede la minimizzazione della somma dei quadrati dei residui. Se gli errori sono indipendenti e distribuiti normalmente, quindi, la stima dei minimi quadrati \\(\\hat{\\beta} = (\\hat{\\beta}_0, \\hat{\\beta}_1)\\) coincide con la stima di massima verosimiglianza per i parametri del modello lineare. References "],["introduzione-al-linguaggio-r.html", "Appendice J Introduzione al linguaggio R J.1 Prerequisiti J.2 Installare cmdstan J.3 Sintassi di base J.4 Strutture di dati J.5 Strutture di controllo J.6 Input/Output J.7 Manipolazione dei dati J.8 Flusso di lavoro riproducibile J.9 Dati mancanti", " Appendice J Introduzione al linguaggio R In questa sezione della dispensa saranno presentate le caratteristiche di base e la filosofia dell’ambiente \\(\\mathsf{R}\\), passando poi a illustrare le strutture dati e le principali strutture di controllo. Verranno introdotte alcune funzioni utili per la gestione dei dati e verranno forniti i rudimenti per realizzare semplici funzioni. Verranno introdotti i tipi di file editabili in RStudio (script, markdown, …). Nello specifico, dopo aver accennato alcune caratteristiche del sistema tidyverse, verranno illustrate le principali funzionalità dell’IDE RStudio e dei pacchetti dplyr e ggplot2. Sul web sono disponibili tantissime introduzioni all’uso di \\(\\mathsf{R}\\) come, ad esempio, Hands-On Programming with R, R for Data Science, Data Science for Psychologists, e Introduction to Data Science. J.1 Prerequisiti Al fine di utilizzare \\(\\mathsf{R}\\) è necessario eseguire le seguenti tre operazioni nell’ordine dato: Installare \\(\\mathsf{R}\\); Installare RStudio; Installare R-Packages (se necessario). Di seguito viene descritto come installare \\(\\mathsf{R}\\) e RStudio. J.1.1 Installare R e RStudio \\(\\mathsf{R}\\) è disponibile gratuitamente ed è scaricabile dal sito http://www.rproject.org/. Dalla pagina principale del sito r-project.org andiamo sulla sezione Download e scegliamo un server a piacimento per scaricare il software d’installazione. Una volta scaricato l’installer, lo installiamo come un qualsiasi software, cliccando due volte sul file d’istallazione. Esistono versioni di \\(\\mathsf{R}\\) per tutti i più diffusi sistemi operativi (Windows, Mac OS X e Linux). Il R Core Development Team lavora continuamente per migliorare le prestazioni di \\(\\mathsf{R}\\), per correggere errori e per consentire l’uso di con nuove tecnologie. Di conseguenza, periodicamente vengono rilasciate nuove versioni di \\(\\mathsf{R}\\). Informazioni a questo proposito sono fornite sulla pagina web https://www.r-project.org/. Per installare una nuova versione di \\(\\mathsf{R}\\) si segue la stessa procedura che è stata seguita per la prima installazione. Insieme al software si possono scaricare dal sito principale sia manuali d’uso che numerose dispense per approfondire diversi aspetti di \\(\\mathsf{R}\\). In particolare, nel sito http://cran.r-project.org/other-docs.html si possono trovare anche numerose dispense in italiano (sezione “Other languages”). Dopo avere installato \\(\\mathsf{R}\\) è opportuno installare anche RStudio. RStudio si può scaricare da https://www.rstudio.com/. Anche RStudio è disponibile per tutti i più diffusi sistemi operativi. J.1.2 Utilizzare RStudio per semplificare il lavoro Possiamo pensare ad \\(\\mathsf{R}\\) come al motore di un automobile e a RStudio come al cruscotto di un automobile. Più precisamente, \\(\\mathsf{R}\\) è un linguaggio di programmazione che esegue calcoli mentre RStudio è un ambiente di sviluppo integrato (IDE) che fornisce un’interfaccia grafica aggiungendo una serie di strumenti che facilitano la fase di sviluppo e di esecuzione del codice. Utilizzeremo dunque \\(\\mathsf{R}\\) mediante RStudio. In altre parole, non aprite aprite invece L’ambiente di lavoro di RStudio è costituito da quattro finestre: la finestra del codice (scrivere-eseguire script), la finestra della console (riga di comando - output), la finestra degli oggetti (elenco oggetti-cronologia dei comandi) e la finestra dei pacchetti-dei grafici-dell’aiuto in linea. La console di RStudio. J.1.3 Eseguire il codice Mediante il menu a tendina di RStudio, scegliendo il percorso File &gt; New File &gt; R Notebook oppure File &gt; New File &gt; R Script l’utente può aprire nella finestra del codice (in alto a destra) un \\(\\mathsf{R}\\) Notebook o un \\(\\mathsf{R}\\) script dove inserire le istruzioni da eseguire. In un \\(\\mathsf{R}\\) script, un blocco di codice viene eseguito selezionando un insieme di righe di istruzioni e digitando la sequenza di tasti Command + Invio sul Mac, oppure Control + Invio su Windows. In un R Notebook, un blocco di codice viene eseguito schiacciando il bottone con l’icona \\(\\color{red}\\blacktriangleright\\) (“Run current chunk”) posizionata a destra rispetto al codice. J.2 Installare cmdstan È possibile installare cmdstan in almento tre modi. Per informazioni dettagliate, si vedano le istruzioni CmdStan Installation. Prima di installare cmdstan, tre raccomandazioni generali: usare la versione più recente del sistema operativo; usare la versione più recente di RStudio; usare la versione più recente di \\(\\mathsf{R}\\). Se i tre vincoli precedenti sono soddisfatti, l’installazione di cmdstan dovrebbe procedere senza intoppi. Altrimenti si possono creare dei problemi di non facile soluzione. Il modo più semplice per installare cmdstan è quello di installare prima cmdstanr per poi utilizzare le funzionalità di quel pacchetto per l’installazione di cmdstan. Un secondo metodo (che è quello che io uso normalmente) è quello di installare dal sorgente, seguendo le istruzioni riportante su CmdStan Installation. Un terzo metodo (che richiede una minima comprensione delle funzionalità della shell e di Python) richiede, avendo prima installato Anaconda, di digitare sulla console del proprio computer (la shell) le seguenti istruzioni: conda create -n stan-env -c conda-forge cmdstan conda activate stan-env Su macos, prima di installare cmdstan, è necessario installare la versione più recente di Xcode. Dopo avere installato Xcode, aprire la app. Verrà chiesto all’utente se si vogliono istallare delle componenti aggiuntive. Questo passaggio è cruciale, perché senza queste componenti aggiuntive cmdstan non funzionerà. Dopo avere installato le componenti aggiuntive, aprire Xcode e, in caso, accettare i termini della licenza. A quel punto si può chiudere Xcode. Ogni volta che Xcode viene aggiornato (deve sempre essere aggiornato quando un aggiornamento è disponibile), queste operazioni vanno ripetute. J.3 Sintassi di base \\(\\mathsf{R}\\) è un linguaggio di programmazione orientato all’analisi dei dati, il calcolo e la visualizzazione grafica. È disponibile su Internet una vasta gamma di materiali utile per avvicinarsi all’ambiente \\(\\mathsf{R}\\) e aiutare l’utente nell’apprendimento di questo software statistico. Cercheremo qui di fornire alcune indicazioni e una breve descrizione delle risorse di base di \\(\\mathsf{R}\\). Aggiungo qui sotto alcune considerazioni che ho preso, pari pari, da un testo che tratta di un altro linguaggio di programmazione, ma che si applicano perfettamente anche al caso nostro. “Come in ogni linguaggio, per parlare in R è necessario seguire un insieme di regole. Come in tutti i linguaggi di programmazione, queste regole sono del tutto inflessibili e inderogabili. In R, un enunciato o è sintatticamente corretto o è incomprensibile all’interprete, che lo segnalerà all’utente. Questo aspetto non è esattamente amichevole per chi non è abituato ai linguaggi di programmazione, e si trova così costretto ad una precisione di scrittura decisamente poco”analogica”. Tuttavia, ci sono due aspetti positivi nello scrivere codice, interrelati tra loro. Il primo è lo sforzo analitico necessario, che allena ad un’analisi precisa del problema che si vuole risolvere in modo da poterlo formalizzare linguisticamente. Il secondo concerne una forma di autoconsapevolezza specifica: salvo “bachi” nel linguaggio (rarissimi sebbene possibili), il mantra del programmatore è “Se qualcosa non ti funziona, è colpa tua” (testo adattato da Andrea Valle). A chi preferisce un approccio più “giocoso” posso suggerire il seguente link. J.3.1 Utilizzare la console \\(\\mathsf{R}\\) come calcolatrice La console di RStudio contiene un cursore rappresentato dal simbolo “&gt;” (linea di comando) dove si possono inserire i comandi e le funzioni – in realtà è sempre meglio utilizzare un \\(\\mathsf{R}\\) Notebook anziché la console, ma per ora esaminiamo il funzionamento di quest’ultima. La console di RStudio può essere utilizzata come semplice calcolatrice. I comandi elementari consistono di espressioni o di assegnazioni. Le operazioni aritmetiche vengono eseguite mediante simboli “standard:” +, *, -, /, sqrt(), log(), exp(), … I comandi sono separati da un carattere di nuova linea (si immette un carattere di nuova linea digitando il tasto Invio). Se un comando non è completo alla fine della linea, \\(\\mathsf{R}\\) darà un prompt differente che per default è il carattere + sulla linea seguente e continuerà a leggere l’input finché il comando non è sintatticamente completo. Ad esempio, 4 - + + 1 #&gt; [1] 3 \\(\\mathsf{R}\\) è un ambiente interattivo, ossia i comandi producono una risposta immediata. Se scriviamo 2 + 2 e premiamo il tasto di invio, comparirà nella riga successiva il risultato: 2 + 2 #&gt; [1] 4 Il risultato è preceduto da [1], il che significa che il risultato dell’operazione che abbiamo appena eseguito è il primo valore di questa linea. Alcune funzioni ritornano più di un singolo numero e, in quel caso, l’informazione fornita da \\(\\mathsf{R}\\) è più utile. Per esempio, l’istruzione 100:130 ritorna \\(31\\) valori, ovvero i numeri da \\(100\\) a \\(130\\): 100:130 #&gt; [1] 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 #&gt; [20] 119 120 121 122 123 124 125 126 127 128 129 130 In questo caso, sul mio computer, [24] indica che il valore \\(123\\) è il ventiquattresimo numero che è stato stampato sulla console – su un altro computer le cose possono essere diverse in quanto il risultato, credo, dipende dalla grandezza dello schermo. J.3.2 Espressioni In questo corso, cercheremo di evitare i numeri nei nomi R, così come le lettere maiuscole e .. Useremo quindi nomi come: my_data, anova_results, square_root, ecc. Un’espressione in \\(\\mathsf{R}\\) è un enunciato finito e autonomo del linguaggio: una frase conclusa, si potrebbe dire. Si noti che le espressioni in \\(\\mathsf{R}\\) non sono delimitate dal ; come succede in alcuni linguaggi di programmazione. L’ordine delle espressioni è l’ordine di esecuzione delle stesse. L’a capo non è rilevante per \\(\\mathsf{R}\\). Questo permette di utilizzare l’a capo per migliorare la leggibilità del codice. J.3.3 Oggetti \\(\\mathsf{R}\\) è un linguaggio di programmazione a oggetti, quindi si basa sulla creazione di oggetti e sulla possibilità di salvarli nella memoria del programma. \\(\\mathsf{R}\\) distingue tra maiuscole e minuscole come la maggior parte dei linguaggi basati su UNIX, quindi A e a sono nomi diversi e fanno riferimento a oggetti diversi. I comandi elementari di \\(\\mathsf{R}\\) consistono in espressioni o assegnazioni. Se un’espressione viene fornita come comando, viene valutata, stampata sullo schermo e il valore viene perso, come succedeva alle operazioni aritmetiche che abbiamo presentato sopra discutendo l’uso della console \\(\\mathsf{R}\\) come calcolatrice. Un’assegnazione crea un oggetto oppure valuta un’espressione e passa il valore a un oggetto, ma il risultato non viene stampato automaticamente sullo schermo. Per l’operazione di assegnazione si usa il simbolo &lt;-. Ad esempio, per creare un oggetto che contiene il risultato dell’operazione 2 + 2 procediamo nel modo seguente: res_sum &lt;- 2 + 2 res_sum #&gt; [1] 4 L’operazione di assegnazione (&lt;-) copia il contenuto dell’operando destro (detto r-value) nell’operando sinistro detto (l-value). Il valore dell’espressione assegnazione è r-value. Nell’esempio precedente, res_sum (l-value) assume il valore di \\(4\\). J.3.4 Variabili L’oggetto res_sum è una variabile. Una spiegazione di ciò che questo significa è riportata qui sotto. “Una variabile è un segnaposto. Tutte le volte che si memorizza un dato lo si assegna ad una variabile. Infatti, se il dato è nella memoria, per potervi accedere, è necessario conoscere il suo indirizzo, la sua “etichetta” (come in un grande magazzino in cui si va a cercare un oggetto in base alla sua collocazione). Se il dato è memorizzato ma inaccessibile (come nel caso di un oggetto sperso in un magazzino), allora non si può usare ed è soltanto uno spreco di spazio. La teoria delle variabili è un ambito molto complesso nella scienza della computazione. Ad esempio, una aspetto importante può concernere la tipizzazione delle variabili. Nei linguaggi “tipizzati” (ad esempio C), l’utente dichiara che userà quella etichetta (la variabile) per contenere solo ed esclusivamente un certo tipo di oggetto (ad esempio, un numero intero), e la variabile non potrà essere utilizzata per oggetti diversi (ad esempio, una stringa). In questo caso, prima di usare una variabile se ne dichiara l’esistenza e se ne specifica il tipo. I linguaggi non tipizzati non richiedono all’utente di specificare il tipo, che viene inferito in vario modo (ad esempio, in funzione dell’assegnazione del valore alla variabile). Alcuni linguaggi (ad esempio Python) non richiedono neppure la dichiarazione della variabile, che viene semplicemente usata. È l’interprete che inferisce che quella stringa è una variabile. La tipizzazione impone vincoli d’uso sulle variabili e maggiore scrittura del codice, ma assicura una chiara organizzazione dei dati. In assenza di tipizzazione, si lavora in maniera più rapida e snella, ma potenzialmente si può andare incontro a situazioni complicate, come quando si cambia il tipo di una variabile “in corsa” senza accorgersene” (Andrea Valle). \\(\\mathsf{R}\\) è un linguaggio non tipicizzato, come Python. In \\(\\mathsf{R}\\) non è necessario dichiarare le variabili che si intendono utilizzare, né il loro tipo. J.3.5 R console La console di RStudio fornisce la possibilità di richiamare e rieseguire i comandi. I tasti freccia verticale, \\(\\uparrow\\) e \\(\\downarrow\\), sulla tastiera possono essere utilizzati per scorrere avanti e indietro i comandi già immessi. Appena trovato il comando che interessa, lo si può modificare, ad esempio, con i tasti freccia orizzontali, immettendo nuovi caratteri o cancellandone altri. Se viene digitato un comando che \\(\\mathsf{R}\\) non riconosce, sulla console viene visualizzato un messaggio di errore; ad esempio, 3 % 9 Errore: unexpected input in &quot;3 % 9&quot; J.3.6 Parentesi Le parentesi in \\(\\mathsf{R}\\) (come in generale in ogni linguaggio di programmazione) assegnano un significato diverso alle porzioni di codice che delimitano. Le parentesi tonde funzionano come nell’algebra. Per esempio 2 + 3 * 4 #&gt; [1] 14 non è equivalente a (2 + 3) * 4 #&gt; [1] 20 Le due istruzioni precedenti producono risultati diversi perché, se la sequenza delle operazioni algebriche non viene specificata dalle parentesi, \\(\\mathsf{R}\\) assegna alle operazioni algebriche il seguente ordine di priorità decrescente: esponenziazione, moltiplicazione / divisione, addizione / sottrazione, confronti logici (&lt;, &gt;, &lt;=, &gt;=, ==, !=). È sempre una buona idea rendere esplicito l’ordine delle operazioni algebriche che si vuole eseguire mediante l’uso delle parentesi tonde. Le parentesi tonde vengono anche utilizzate per le funzioni, come vedremo nei prossimi paragrafi. Tra le parentesi tonde avremo dunque l’oggetto a cui vogliamo applicare la funzione e gli argomenti passati alla funzione. Le parentesi graffe sono destinate alla programmazione. Un blocco tra le parentesi graffe viene letto come un oggetto unico che può contenere una o più istruzioni. Le parentesi quadre vengono utilizzate per selezionare degli elementi, per esempio all’interno di un vettore, o di una matrice, o di un data.frame. L’argomento entro le parentesi quadre può essere generato da espressioni logiche. J.3.7 I nomi degli oggetti Le entità create e manipolate da \\(\\mathsf{R}\\) si chiamano ‘oggetti’. Tali oggetti possono essere variabili (come nell’esempio che abbiamo visto sopra), array di numeri, caratteri, stringhe, funzioni, o più in generale strutture costruite a partire da tali componenti. Durante una sessione di R gli oggetti sono creati e memorizzati attraverso opportuni nomi. I nomi possono contenere un qualunque carattere alfanumerico e come carattere speciale il trattino basso (_) o il punto. R fornisce i seguenti vincoli per i nomi degli oggetti: i nomi degli oggetti non possono mai iniziare con un carattere numerico e non possono contenere i seguenti simboli: $, @, !, ^, +, -, /, *. È buona pratica usare nomi come ratio_of_sums. È fortemente sconsigliato utilizzare nei nomi degli oggetti caratteri accentati o, ancora peggio, apostrofi. Per questa ragione è sensato creare i nomi degli oggetti utilizzando la lingua inglese. È anche bene che i nomi degli oggetti non coincidano con nomi di funzioni. Ricordo nuovamente che \\(\\mathsf{R}\\) è case sensitive, cioè A e a sono due simboli diversi e identificano due oggetti differenti. In questo corso cercheremo di evitare i numeri nei nomi degli oggetti \\(\\mathsf{R}\\), così come le lettere maiuscole e il punto. Useremo quindi nomi come: my_data, regression_results, square_root, ecc. J.3.8 Permanenza dei dati e rimozione di oggetti Gli oggetti vengono salvati nello “spazio di lavoro” (workspace). Il comando ls() può essere utilizzato per visualizzare i nomi degli oggetti che sono in quel momento memorizzati in \\(\\mathsf{R}\\). Per eliminare oggetti dallo spazio di lavoro è disponibile la funzione rm(); ad esempio rm(x, y, z, ink, junk, temp, foo, bar) cancella tutti gli oggetti indicati entro parentesi. Per eliminare tutti gli oggetti presenti nello spazio di lavoro si può utilizzare la seguente istruzione: rm(list = ls()) J.3.9 Chiudere R Quando si chiude RStudio il programma ci chiederà se si desidera salvare l’area di lavoro sul computer. Tale operazione è da evitare in quanto gli oggetti così salvati andranno ad interferire con gli oggetti creati in un lavoro futuro. Si consiglia dunque di rispondere negativamente a questa domanda. In RStudio, selezionare Preferences dal menu a tendina e, in R General Workspace, deselezionare l’opzione Restore .RData into workspace at start- up e scegliere l’opzione Never nella finestra di dialogo Save workspace to .RData on exit. In R, selezionare Preferences dal menu a tendina e, in Startup, selezionare l’opzione No in corrispondenza dell’item Save workspace on exit from R. J.3.10 Creare ed eseguire uno script R con un editore È molto più facile interagire con R manipolando uno script con un editore piuttosto che inserendo direttamente le istruzioni nella console. \\(\\mathsf{R}\\) fornisce il Text Editor dove è possibile inserire il codice (File \\(\\to\\) New Script). Per salvare il file basta utilizzare l’apposito menù a tendina (estensione .R). Tale file potrà poi essere riaperto ed utilizzato in un momento successivo. L’editore comunica con \\(\\mathsf{R}\\) nel modo seguente: dopo avere selezionato la porzione di codice che si vuole eseguire, si digita un’apposita sequenza di tasti (Command + Enter su Mac OS X e ctrl + r in Windows). ctrl + r significa premere il tasto ctrl e, tenendolo premuto, premere il tasto \\(\\mathsf{R}\\) della tastiera. Così facendo, \\(\\mathsf{R}\\) eseguirà le istruzioni selezionate e l’output verrà stampato sulla console. Il Text Editor fornito da \\(\\mathsf{R}\\) è piuttosto primitivo: è fortemente consigliato utilizzare RStudio. J.3.11 Commentare il codice Un “commento” è una parte di codice che l’interprete non tiene in considerazione. Quando l’interprete arriva ad un segnalatore di commento salta fino al segnalatore di fine commento e di lì riprende il normale processo esecutivo. I commenti sono parole in linguaggio naturale (nel nostro caso l’italiano), che permettono agli utilizzatori di capire il flusso logico del codice e a chi lo ha scritto di ricordare il perché di determinate istruzioni. In \\(\\mathsf{R}\\), le parole dopo il simbolo # sono considerate commenti e sono ignorate; ad esempio: # Questo e&#39; un commento J.3.12 Cambiare la cartella di lavoro Quando si inizia una sessione di lavoro, \\(\\mathsf{R}\\) sceglie una cartella quale “working directory”. Sarà in tale cartella che andrà a cercare gli script definiti dall’utilizzatore e i file dei dati. È possibile determinare quale sia la corrente “working directory” digitando sulla console di RStudio l’istruzione: getwd() Per cambiare la cartella di lavoro (in maniera tale che corrisponda alla cartella nella quale sono stati salvati i dati e gli script da eseguire) si sceglie la voce Set Working Directory sul menù a tendina di RStudio e si selezione la voce Choose Directory… Nella finestra che compare, si cambia la cartella con quella che si vuole. J.3.13 L’oggetto base di R: il vettore \\(\\mathsf{R}\\) opera su strutture di dati; la più semplice di tali strutture è il vettore numerico, che consiste in un insieme ordinato di numeri; ad esempio: x &lt;- c(7.0, 10.2, -2.9, 21.4) Nell’istruzione precedente, c() è una funzione. In R gli argomenti sono passati alle funzioni inserendoli all’interno delle parentesi tonde. Si noti che gli argomenti (in questo caso, i numeri \\(7.0, 10.2, -2.9, 21.4\\)) sono separati a virgole. La funzione c() può prendere un numero arbitrario di argomenti e genera un vettore concatenando i suoi argomenti. L’operatore &lt;- assegna un nome al vettore che è stato creato. Nel caso presente, digitando x possiamo visualizzare il vettore che abbiamo creato: x #&gt; [1] 7.0 10.2 -2.9 21.4 Se invece eseguiamo l’istruzione c(7.0, 10.2, -2.9, 21.4) #&gt; [1] 7.0 10.2 -2.9 21.4 senza assegnazione, il valore dell’espressione sarà visualizzato nella console, ma il vettore non potrà essere utilizzato in nessun altro modo. J.3.14 Operazioni vettorializzate Molte operazioni in \\(\\mathsf{R}\\) sono vettorializzate, il che significa che esse sono eseguite in parallelo in determinati oggetti. Ciò consente di scrivere codice che sia efficiente, conciso e più facile da leggere rispetto al codice che contiene istruzioni non vettorializzate. J.3.15 Vettori aritmetici L’esempio più semplice che illustra come si svolgono le operazioni vettorializzate riguarda le operazioni algebriche applicate ai vettori. I vettori, infatti, possono essere utilizzati in espressioni numeriche nelle quali le operazioni algebriche vengono eseguite “elemento per elemento”. Per illustrare questo concetto, definiamo il vettore die che contiene i possibili risultati del lancio di un dado: die &lt;- c(1, 2, 3, 4, 5, 6) die #&gt; [1] 1 2 3 4 5 6 Supponiamo di volere sommare \\(10\\) a ciascun elemento del vettore die. Dato che le operazioni sui vettori sono eseguite elemento per elemento, per ottenere questo risultato è sufficiente eseguire l’istruzione: die + 10 #&gt; [1] 11 12 13 14 15 16 Si noti come la costante \\(10\\) sia stata sommata a ciascun elemento del vettore. In maniera corrispondente, l’istruzione die - 1 #&gt; [1] 0 1 2 3 4 5 sottrarrà un’unità da ciascuno degli elementi del vettore die. Se l’operazione aritmetica coinvolge due o più vettori, R allinea i vettori ed esegue una sequenza di operazioni elemento per elemento. Per esempio, l’istruzione die * die #&gt; [1] 1 4 9 16 25 36 fa sì che i due vettori vengano disposti l’uno di fianco all’altro per poi moltiplicare gli elementi corrispondenti: il primo elemento del primo vettore per il primo elemento del secondo vettore e così via. Il vettore risultante avrà la stessa dimensione dei due vettori che sono stati moltiplicati, come indicato qui sotto: \\[ \\begin{array}{ccccc} 1 &amp; \\times &amp; 1 &amp; \\to &amp; 1 \\\\ 2 &amp; \\times &amp; 2 &amp; \\to &amp; 4 \\\\ 3 &amp; \\times &amp; 3 &amp; \\to &amp; 9 \\\\ 4 &amp; \\times &amp; 4 &amp; \\to &amp; 16 \\\\ 5 &amp; \\times &amp; 5 &amp; \\to &amp; 25 \\\\ 6 &amp; \\times &amp; 6 &amp; \\to &amp; 36 \\\\ \\hline \\verb+die+ &amp; * &amp; \\verb+die+ &amp; = &amp; \\end{array} \\] Oltre agli operatori aritmetici elementari +, -, *, /, e ^ per l’elevamento a potenza, sono disponibili le più comuni funzioni matematiche: log(), exp(), sin(), cos(), tan(), sqrt(), max(), min() e così via. Altre funzioni di uso comune sono: range() che restituisce un vettore c(min(x), max(x)); sort() che restituisce un vettore ordinato; length(x) che restituisce il numero di elementi di x; sum(x) che dà la somma degli elementi di x, mentre prod(x) dà il loro prodotto. Due funzioni statistiche di uso comune sono mean(x), la media aritmetica, e var(x), la varianza. J.3.16 Generazione di sequenze regolari \\(\\mathsf{R}\\) possiede un ampio numero di funzioni per generare sequenze di numeri. Ad esempio, c(1:10) è il vettore c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10). L’espressione c(30:1) può essere utilizzata per generare una sequenza all’indietro. La funzione seq() genera un vettore che contiene una sequenza regolare di numeri, generata in base a determinate regole. Può avere 5 argomenti: i primi due rappresentano l’inizio (from) e la fine (to) della sequenza, il terzo specifica l’ampiezza del passo (by), il quarto la lunghezza della sequenza (length.out) e infine il quinto (along.with), che se utilizzato deve essere l’unico parametro presente, è il nome di un vettore, ad esempio x, creando in tal modo la sequenza 1, 2, …, length(x). Esempi di utilizzo della funzione seq() sono i seguenti: seq(from = 1, to = 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 seq(-5, 5, by = 2.5) #&gt; [1] -5.0 -2.5 0.0 2.5 5.0 seq(from = 1, to = 7, length.out = 4) #&gt; [1] 1 3 5 7 seq(along.with = die) #&gt; [1] 1 2 3 4 5 6 Altra funzione utilizzata per generare sequenze è rep() che può essere utilizzata per replicare un oggetto in vari modi. Ad esempio: die3 &lt;- rep(die, times = 3) die3 #&gt; [1] 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6 metterà tre copie di die nell’oggetto die3. J.3.17 Generazione di numeri casuali La funzione sample() è una delle tante funzioni che possono essere usate per generare numeri casuali. Per esempio, la seguente istruzione simula dieci lanci di un dado a sei facce: roll &lt;- sample(1:6, 10, replace = TRUE) roll #&gt; [1] 1 3 3 6 3 1 2 2 6 6 Il primo argomento di sample() è il vettore da cui la funzione estrarrà degli elementi a caso; il secondo argomento specifica che dovranno essere effettuate 10 estrazioni casuali; il terzo argomento specifica che le estrazioni sono con rimessa (cioè, lo stesso elemento può essere estratto più di una volta). Scegliere un elemento a caso dal vettore \\(\\{1, 2, 3, 4, 5, 6\\}\\) è equivalente a lanciare un dado e osservare la faccia che si presenta. L’istruzione precedente corrisponde dunque alla simulazione di dieci lanci di un dado a sei facce. J.3.18 Vettori logici Quando si manipolano i vettori, talvolta si vogliono trovare gli elementi che soddisfano determinate condizioni logiche. Per esempio, in dieci lanci di un dado, quante volte è uscito \\(5\\)? Per rispondere a questa domanda si possono usare gli operatori logici &lt;, &gt; e == per le operazioni di “minore di,” “maggiore di” e “uguale a”. Se scriviamo roll == 5 #&gt; [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE creiamo un vettore costituito da elementi TRUE/FALSE i quali identificano gli elementi del vettore che soddisfano la condizione logica specificata. Possiamo trattare tale vettore come se fosse costituito da elementi di valore \\(0\\) e \\(1\\). Sommando gli elementi di tale vettore, infatti, possiamo contare il numero di “5”: sum(roll == 5) #&gt; [1] 0 J.3.19 Dati mancanti Quando si è in presenza di un dato mancante, R assegna il valore speciale NA, che sta per Not Available. In generale, un’operazione su un NA dà come risultato un NA. Nell’uso delle funzioni che operano sui dati sarà dunque necessario specificare che, qualunque operazione venga effettuata, gli NA devono essere esclusi. J.3.20 Vettori di caratteri e fattori I vettori di caratteri si creano formando una sequenza di caratteri delimitati da doppie virgolette e possono essere concatenati in un vettore attraverso la funzione c(). Successivamente, si può applicare la funzione factor(), che definisce automaticamente le modalità della variabile categoriale. Ad esempio, soc_status &lt;- factor( c(&quot;low&quot;, &quot;high&quot;, &quot;medium&quot;, &quot;high&quot;, &quot;low&quot;, &quot;medium&quot;, &quot;high&quot;) ) levels(soc_status) #&gt; [1] &quot;high&quot; &quot;low&quot; &quot;medium&quot; Talvolta l’ordine dei livelli del fattore non importa, mentre altre volte l’ordine è importante, per esempio, quando una variable categoriale viene rappresentata in un grafico. Per specificare l’ordine dei livelli del fattore si usa la seguente sintassi: soc_status &lt;- factor(soc_status, levels = c(&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;)) levels(soc_status) #&gt; [1] &quot;low&quot; &quot;medium&quot; &quot;high&quot; J.3.21 Funzioni \\(\\mathsf{R}\\) offre la possibilità di utilizzare un’enorme libreria di funzioni che permettono di svolgere operazioni complicate, quali ad esempio, il campionamento casuale. Esaminiamo ora con più attenzione le proprietà delle funzioni di \\(\\mathsf{R}\\) utilizzando ancora l’esempio del lancio di un dado. Abbiamo visto in precedenza come il lancio di un dado possa essere simulato da R con la funzione sample(). La funzione sample() prende tre argomenti: il nome di un vettore, un numero chiamato size e un argomento chiamato replace. La funzione sample() ritorna un numero di elementi del vettore pari a size. Ad esempio sample(die, 2, replace = TRUE) #&gt; [1] 3 4 Assegnando TRUE all’argomento replace specifichiamo che vogliamo un campionamento con rimessa. Se volgiamo eseguire una serie di lanci indipendenti di un dado, eseguiamo ripetutamente la funzione sample() ponendo size uguale a 1: sample(die, 1, replace = TRUE) #&gt; [1] 3 sample(die, 1, replace = TRUE) #&gt; [1] 2 sample(die, 1, replace = TRUE) #&gt; [1] 5 Come si fa a sapere quanti e quali argomenti sono richiesti da una funzione? Tale informazione viene fornita dalla funzione args(). Nel nostro caso args(sample) #&gt; function (x, size, replace = FALSE, prob = NULL) #&gt; NULL ci informa che il primo argomento è un vettore chiamato x, il secondo argomento è chiamato size ed ha il significato descritto sopra, il terzo argomento, replace, specifica se il campionamento è eseguito con o senza reimmissione, e il quarto argomento, prob, assegna delle probabilità agli elementi del vettore. Il significato degli argomenti viene spiegato nel file di help della funzione. Si noti che agli ultimi due argomenti sono stati assegnati dei valori, detti di default. Ciò significa che, se l’utilizzatore non li cambia, verranno usati da . La specificazione replace = FALSE significa che il campionamento viene eseguito senza reimmissione. Se desideriamo un campionamento con reimmissione, basta specificare replace = TRUE (nel caso di una singola estrazione è ovviamente irrilevante). Ad esempio, l’istruzione seguente simula i risultati di 10 lanci indipendenti di un dado: sample(die, 10, replace = TRUE) #&gt; [1] 3 6 1 3 3 4 3 6 3 4 Infine, prob = NULL specifica che non viene alterata la probabilità di estrazione degli elementi del vettore. In generale, gli argomenti di una funzione possono essere oggetti come vettori, matrici, altre funzioni, parametri o operatori logici. \\(\\mathsf{R}\\) ha un sistema di help interno in formato HTML che si richiama con help.start(). Per avere informazioni su qualche funzione specifica, per esempio la funzione sample(), il comando da utilizzare è help(sample) oppure ?sample. J.3.22 Scrivere proprie funzioni Abbiamo visto in precedenza come sia possibile simulare i risultati prodotti da dieci lanci di un dado o, in maniera equivalente, dal singolo lancio di dieci dadi. Possiamo replicare questo processo digitando ripetutamente le stesse istruzioni nella console. Otterremo ogni volta risultati diversi perché, ad ogni ripetizione, il generatore di numeri pseudo-casuali di R dipende dal valore ottenuto dal clock interno della macchina. La funzione set.seed() ci permette di replicare esattamente i risultati della generazione di numeri casuali. Per ottenere questo risultato, basta assegnare al seed un numero arbitrario, es. set.seed(12345). Tuttavia, questa procedura è praticamente difficile da perseguire se il numero di ripetizioni è alto. In tal caso è vantaggioso scrivere una funzione contenente il codice che specifica il numero di ripetizioni. In questo modo, per trovare il risultato cercato basterà chiamare la funzione una sola volta. Le funzioni utilizzate da \\(\\mathsf{R}\\) sono costituite da tre elementi: il nome, il blocco del codice e una serie di argomenti. Per creare una funzione è necessario immagazzinare in R questi tre elementi e function() consente di ottenere tale risultato usando la sintassi seguente: nome_funzione &lt;- function(arg1, arg2, ...) { espressione1 espressione2 return(risultato) } Una chiamata di funzione è poi eseguita nel seguente modo: nome_funzione(arg1, arg2, ...) Per potere essere utilizzata, una funzione deve essere presente nella memoria di lavoro di \\(\\mathsf{R}\\). Le funzioni salvate in un file possono essere richiamate utilizzando la funzione source(), ad esempio, source(\"file_funzioni.R\"). Consideriamo ora la funzione two_rolls() che ritorna la somma dei punti prodotti dal lancio di due dadi non truccati: two_rolls &lt;- function() { die &lt;- 1:6 res &lt;- sample(die, size = 2, replace = TRUE) sum_res &lt;- sum(res) return(sum_res) } La funzione two_rolls() inizia con il creare il vettore die che contiene sei elementi: i numeri da \\(1\\) a \\(6\\). Viene poi utilizzata la funzione sample() con gli gli argomenti, die, size = 2 e replace = TRUE. Tale funzione restituisce il risultato del lancio di due dadi. Il risultato fornito da sample(die, size = 2, replace = TRUE) viene assegnato all’oggetto res. L’oggetto res corrisponde dunque ad un vettore di due elementi. L’istruzione sum(res) somma gli elementi del vettore res e attribuisce il risultato di questa operazione a sum_res. Infine, la funzione return() ritorna il contenuto dell’oggetto sum_res. Invocando la funzione two_rolls() si ottiene dunque la somma del lancio di due dadi. In generale, la funzione two_rolls() produrrà un risultato diverso ogni volta che viene usata: two_rolls() #&gt; [1] 9 two_rolls() #&gt; [1] 4 two_rolls() #&gt; [1] 7 La formattazione del codice mediante l’uso di spazi e rientri non è necessaria ma è altamente raccomandata per minimizzare la probabilità di compiere errori. J.3.23 Pacchetti Le funzioni di \\(\\mathsf{R}\\) sono organizzate in pacchetti, i più importanti dei quali sono già disponibili quando si accede al programma. J.3.24 Istallazione e upgrade dei pacchetti Alcuni pacchetti non sono presenti nella release di base di \\(\\mathsf{R}\\). Per installare un pacchetto non presente è sufficiente scrivere nella console: install.packages(&quot;nome_pacchetto&quot;) Ad esempio, install.packages(&quot;ggplot2&quot;) La prima volta che si usa questa funzione durante una sessione di lavoro si dovrà anche selezionare da una lista il sito mirror da cui scaricare il pacchetto. Gli autori dei pacchetti periodicamente rilasciano nuove versioni dei loro pacchetti che contengono miglioramenti di varia natura. Per eseguire l’upgrade dei pacchetti ggplot2 e dplyr, ad esempio, si usa la seguente istruzione: update.packages(c(&quot;ggplot2&quot;, &quot;dplyr&quot;)) Per eseguire l’upgrade di tutti i pacchetti l’istruzione è update.packages() J.3.25 Caricare un pacchetto in R L’istallazione dei pacchetti non rende immediatamente disponibili le funzioni in essi contenute. L’istallazione di un pacchetto semplicemente copia il codice sul disco rigido della macchina in uso. Per potere usare le funzioni contenute in un pacchetto installato è necessario caricare il pacchetto in . Ciò si ottiene con il comando: library(&quot;ggplot2&quot;) se si vuole caricare il pacchetto ggplot2. A questo punto diventa possibile usare le funzioni contenute in ggplot2. Queste operazioni si possono anche eseguire usando dal menu a tendina di RStudio. Per sapere quali sono i pacchetti già presenti nella release di \\(\\mathsf{R}\\) con cui si sta lavorando, basta scrivere: library() J.4 Strutture di dati Solitamente gli psicologi raccolgono grandi quantità di dati. Tali dati vengono codificati in R all’interno di oggetti aventi proprietà diverse. Intuitivamente, in R un oggetto è qualsiasi cosa a cui è possibile assegnare un valore. I dati possono essere di tipo numerico o alfanumerico. Di conseguenza, Rdistingue tra oggetti aventi modi diversi. Inoltre, i dati possono essere organizzati in righe e colonne in base a diversi tipi di strutture che R chiama classi. J.4.1 Classi e modi degli oggetti Gli oggetti R si distinguono a seconda della loro classe (class) e del loro modo (mode). La classe definisce il tipo di oggetto. In R, vengono utilizzate cinque strutture di dati che corrispondono a cinque classi differenti: vector, matrix, array, list e data.frame. Un’altra classe di oggetti R è function (ad essa appartengono le funzioni). La classe di appartenenza di un oggetto si stabilisce usando le funzioni class(), oppure is.list(), is.function(), is.logical(), e così via. Queste funzioni restituisco TRUE e FALSE in base all’appartenenza o meno dell’argomento a quella determinata classe. Gli oggetti R possono anche essere classificati in base al loro ‘modo’. I modi ‘atomici’ degli oggetti sono: numeric, complex, character e logical. Per esempio, x &lt;- c(4, 9) mode(x) #&gt; [1] &quot;numeric&quot; cards &lt;- c(&quot;9 of clubs&quot;, &quot;10 of hearts&quot;, &quot;jack of hearts&quot;) mode(cards) #&gt; [1] &quot;character&quot; Nel seguito verranno esaminate le cinque strutture di dati utilizzate da R. J.4.2 Vettori I vettori sono la classe di oggetto più importante in R. Un vettore può essere creato usando la funzione c(): y &lt;- c(2, 1, 6, -3, 9) y #&gt; [1] 2 1 6 -3 9 Le dimensioni di un vettore presente nella memoria di lavoro possono essere trovare con la funzione length(); ad esempio, length(y) #&gt; [1] 5 ci dice che y è un vettore costituito da cinque elementi. La somma, il minimo e il massimo degli elementi contenuti in un vettore si trovano con le seguenti istruzioni: sum(y) #&gt; [1] 15 min(y) #&gt; [1] -3 max(y) #&gt; [1] 9 Mentre ci sono sei ‘tipi’ di vettori ‘atomici’ in R, noi ci focalizzeremo sui tipi seguenti: ‘numeric’ (‘integer’: e.g., 5; ‘double’: e.g., 5.5), ‘character’ (e.g., ‘pippo’) e ‘logical’ (e.g., TRUE, FALSE). Usiamo la funzione typeof() per determinare il ‘tipo’ di un vettore atomico. Tutti gli elementi di un vettore atomico devono essere dello stesso tipo. La funzione str() rende visibile in maniera compatta la struttura interna di un oggetto. J.4.3 Matrici Una matrice è una collezione di vettori. Il comando per generare una matrice è matrix(): X &lt;- matrix(1:20, nrow = 4, byrow = FALSE) X #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1 5 9 13 17 #&gt; [2,] 2 6 10 14 18 #&gt; [3,] 3 7 11 15 19 #&gt; [4,] 4 8 12 16 20 Il primo argomento è il vettore i cui elementi andranno a disporsi all’interno della matrice. È poi necessario specificare le dimensioni della matrice e il modo in cui R dovrà riempire la matrice. Date le dimensioni del vettore, la specificazione del numero di righe (secondo argomento) è sufficiente per determinare le dimensioni della matrice. L’argomento byrow = FALSE è il default. In tal caso, R riempie la matrice per colonne. Se vogliamo che R riempia la matrice per righe, usiamo byrow = TRUE: Y &lt;- matrix(1:20, nrow = 4, byrow = TRUE) Y #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1 2 3 4 5 #&gt; [2,] 6 7 8 9 10 #&gt; [3,] 11 12 13 14 15 #&gt; [4,] 16 17 18 19 20 Le dimensioni di una matrice presente nella memoria di lavoro possono essere trovare con la funzione dim(); ad esempio, dim(Y) #&gt; [1] 4 5 ci dice che Y è una matrice con quattro righe e cinque colonne. J.4.4 Array Un array è una collezione di matrici (si veda la Figura 1.1). Per costruire un array con la funzione array() è necessario specificare un vettore come primo argomento e un vettore di dimensioni, chiamato dim, quale secondo argomento: ar &lt;- array( c(11:14, 21:24, 31:34), dim = c(2, 2, 3) ) Un sottoinsieme di questi dati può essere selezionato, per esempio, nel modo seguente: ar[, , 3] #&gt; [,1] [,2] #&gt; [1,] 31 33 #&gt; [2,] 32 34 J.4.5 Operazioni aritmetiche su vettori, matrici e array J.4.5.1 Operazioni aritmetiche su vettori I vettori e le matrici (o gli array) possono essere utilizzati in espressioni aritmetiche. Il risultato è un vettore o una matrice (o un array) formato dalle operazioni fatte elemento per elemento sui vettori o sulle matrici. Ad esempio, y + 3 #&gt; [1] 5 4 9 0 12 restituisce un vettore di dimensioni uguali alle dimensioni di y, i cui elementi sono dati dalla somma tra ciascuno degli elementi originari di y e la costante “3”. Ovviamente, ad un vettore possono essere applicate tutte le altre operazioni algebriche, sempre elemento per elemento. Ad esempio, 3 * y #&gt; [1] 6 3 18 -9 27 restituisce un vettore i cui elementi sono uguali agli elementi di y moltiplicati per 3. Se sono costituiti dallo stesso numero di elementi, due vettori possono essere sommati, sottratti, moltiplicati e divisi, laddove queste operazioni algebriche vengono eseguite elemento per elemento. Per esempio, x &lt;- c(1, 1, 2, 1, 3) y &lt;- c(2, 1, 6, 3, 9) x + y #&gt; [1] 3 2 8 4 12 x - y #&gt; [1] -1 0 -4 -2 -6 x * y #&gt; [1] 2 1 12 3 27 x / y #&gt; [1] 0.5000000 1.0000000 0.3333333 0.3333333 0.3333333 J.4.5.2 Operazioni aritmetiche su matrici Le operazioni algebriche elemento per elemento si possono estendere al caso delle matrici. Per esempio, se X, Y sono entrambe matrici di dimensioni \\(4 \\times 5\\), allora la seguente operazione M &lt;- 2 * (X + Y) - 3 crea una matrice D anch’essa di dimensioni \\(4 \\times 5\\) i cui elementi sono ottenuti dalle operazioni fatte elemento per elemento sulle matrici e sugli scalari: M #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1 11 21 31 41 #&gt; [2,] 13 23 33 43 53 #&gt; [3,] 25 35 45 55 65 #&gt; [4,] 37 47 57 67 77 J.4.5.3 Operazioni aritmetiche su array Le stesse considerazioni si estendono al caso degli array. J.4.6 Liste Le liste assomigliano ai vettori perché raggruppano i dati in un insieme unidimensionale. Tuttavia, le liste non raggruppano elementi individuali ma bensì oggetti di R, quali vettori e altre liste. Per esempio, list1 &lt;- list(&quot;R&quot;, list(TRUE, FALSE), 20:24) list1 #&gt; [[1]] #&gt; [1] &quot;R&quot; #&gt; #&gt; [[2]] #&gt; [[2]][[1]] #&gt; [1] TRUE #&gt; #&gt; [[2]][[2]] #&gt; [1] FALSE #&gt; #&gt; #&gt; [[3]] #&gt; [1] 20 21 22 23 24 Le doppie parentesi quadre identificano l’elemento della lista a cui vogliamo fare riferimento. Per esempio, list1[[3]] #&gt; [1] 20 21 22 23 24 list1[[3]][2] #&gt; [1] 21 J.4.7 Data frame I data.frame sono strutture tipo matrice, in cui le colonne possono essere vettori di tipi differenti. La funzione usata per generare un data frame è data.frame(), che permette di unire più vettori di uguale lunghezza come colonne del data frame, ognuno dei quali si riferisce ad una diversa variabile. Ad esempio, df &lt;- data.frame( face = c(&quot;ace&quot;, &quot;two&quot;, &quot;six&quot;), suit = c(&quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;), value = c(1, 2, 3) ) df #&gt; face suit value #&gt; 1 ace clubs 1 #&gt; 2 two clubs 2 #&gt; 3 six clubs 3 L’estrazione di dati da un data.frame può essere effettuata in maniera simile a quanto avviene per i vettori. Ad esempio, per estrarre la variabile value dal data.frame df si può indicare l’indice della terza colonna: df[, 3] #&gt; [1] 1 2 3 Dal momento che le colonne sono delle variabili, è possibile estrarle anche indicando nome della variabile, scrivendo nome_data_frame$nome_variabile: df$value #&gt; [1] 1 2 3 Per fare un esempio, creiamo un data.frame che contenga tutte le informazioni di un mazzo di carte da poker (Grolemund 2014). In tale data.frame, ciascuna riga corrisponde ad una carta – in un mazzo da poker ci sono 52 carte, perciò il data.frame avrà 52 righe. Il vettore face indica con una stringa di caratteri il valore di ciascuna carta, il vettore suit indica il seme e il vettore value indica con un numero intero il valore di ciascuna carta. Quindi, il data.frame avrà 3 colonne. deck &lt;- data.frame( face = c(&quot;king&quot;, &quot;queen&quot;, &quot;jack&quot;, &quot;ten&quot;, &quot;nine&quot;, &quot;eight&quot;, &quot;seven&quot;, &quot;six&quot;, &quot;five&quot;, &quot;four&quot;, &quot;three&quot;, &quot;two&quot;, &quot;ace&quot;, &quot;king&quot;, &quot;queen&quot;, &quot;jack&quot;, &quot;ten&quot;, &quot;nine&quot;, &quot;eight&quot;, &quot;seven&quot;, &quot;six&quot;, &quot;five&quot;, &quot;four&quot;, &quot;three&quot;, &quot;two&quot;, &quot;ace&quot;, &quot;king&quot;, &quot;queen&quot;, &quot;jack&quot;, &quot;ten&quot;, &quot;nine&quot;, &quot;eight&quot;, &quot;seven&quot;, &quot;six&quot;, &quot;five&quot;, &quot;four&quot;, &quot;three&quot;, &quot;two&quot;, &quot;ace&quot;, &quot;king&quot;, &quot;queen&quot;, &quot;jack&quot;, &quot;ten&quot;, &quot;nine&quot;, &quot;eight&quot;, &quot;seven&quot;, &quot;six&quot;, &quot;five&quot;, &quot;four&quot;, &quot;three&quot;, &quot;two&quot;, &quot;ace&quot;), suit = c(&quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;), value = c(13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1) ) Avendo salvato tutte queste informazioni nell’oggetto deck, possiamo stamparle sullo schermo semplicemente digitando il nome dell’oggetto che le contiene: deck #&gt; face suit value #&gt; 1 king spades 13 #&gt; 2 queen spades 12 #&gt; 3 jack spades 11 #&gt; 4 ten spades 10 #&gt; 5 nine spades 9 #&gt; 6 eight spades 8 #&gt; 7 seven spades 7 #&gt; 8 six spades 6 #&gt; 9 five spades 5 #&gt; 10 four spades 4 #&gt; 11 three spades 3 #&gt; 12 two spades 2 #&gt; 13 ace spades 1 #&gt; 14 king clubs 13 #&gt; 15 queen clubs 12 #&gt; 16 jack clubs 11 #&gt; 17 ten clubs 10 #&gt; 18 nine clubs 9 #&gt; 19 eight clubs 8 #&gt; 20 seven clubs 7 #&gt; 21 six clubs 6 #&gt; 22 five clubs 5 #&gt; 23 four clubs 4 #&gt; 24 three clubs 3 #&gt; 25 two clubs 2 #&gt; 26 ace clubs 1 #&gt; 27 king diamonds 13 #&gt; 28 queen diamonds 12 #&gt; 29 jack diamonds 11 #&gt; 30 ten diamonds 10 #&gt; 31 nine diamonds 9 #&gt; 32 eight diamonds 8 #&gt; 33 seven diamonds 7 #&gt; 34 six diamonds 6 #&gt; 35 five diamonds 5 #&gt; 36 four diamonds 4 #&gt; 37 three diamonds 3 #&gt; 38 two diamonds 2 #&gt; 39 ace diamonds 1 #&gt; 40 king hearts 13 #&gt; 41 queen hearts 12 #&gt; 42 jack hearts 11 #&gt; 43 ten hearts 10 #&gt; 44 nine hearts 9 #&gt; 45 eight hearts 8 #&gt; 46 seven hearts 7 #&gt; 47 six hearts 6 #&gt; 48 five hearts 5 #&gt; 49 four hearts 4 #&gt; 50 three hearts 3 #&gt; 51 two hearts 2 #&gt; 52 ace hearts 1 Si noti che, a schermo, R stampa un numero progressivo che corrisponde al numero della riga. J.4.7.1 Selezione di elementi Una volta creato un data.frame, ad esempio quello che contiene un mazzo virtuale di carte (si veda l’esempio \\[exmp:deck_of_cards\\]), è necessario sapere come manipolarlo. La funzione head() mostra le prime sei righe del data.frame: head(deck) #&gt; face suit value #&gt; 1 king spades 13 #&gt; 2 queen spades 12 #&gt; 3 jack spades 11 #&gt; 4 ten spades 10 #&gt; 5 nine spades 9 #&gt; 6 eight spades 8 Poniamoci ora il problema di mescolare il mazzo di carte e di estrarre alcune carte dal mazzo. Queste operazioni possono essere eseguite usando il sistema notazionale di R. Il sistema di notazione di R consente di estrarre singoli elementi dagli oggetti definiti da R. Per estrarre un valore da un data.frame, per esempio, dobbiamo scrivere il nome del data.frame seguito da una coppia di parentesi quadre: deck[, ] All’interno delle parentesi quadre ci sono due indici separati da una virgola. R usa il primo indice per selezionare un sottoinsieme di righe del data.frame e il secondo indice per selezionare un sottoinsieme di colonne. L’indice è il numero d’ordine che etichetta progressivamente ognuno dei valori del vettore. Per esempio, deck[9, 2] #&gt; [1] &quot;spades&quot; restituisce l’elemento che si trova nella nella nona riga della seconda colonna di deck. In R ci sono sei modi diversi per specificare gli indici di un oggetto: interi positivi, interi negativi, zero, spazi vuoti, valori logici e nomi. Esaminiamoli qui di seguito. J.4.7.2 Interi positivi Gli indici \\(i, j\\) possono essere degli interi positivi che identificano l’elemento nella \\(i\\)-esima riga e nella \\(j\\)-esima colonna del data.frame. Per l’esempio relativo al mazzo di carte, l’istruzione deck[1, 1] #&gt; [1] &quot;king&quot; ritorna il valore nella prima riga e nella prima colonna. Per estrarre più di un valore, usiamo un vettore di interi positivi. Per esempio, la prima riga di deck si trova con deck[1, c(1:3)] #&gt; face suit value #&gt; 1 king spades 13 Tale sistema notazionale non si applica solo ai data.frame ma può essere usato anche per gli altri oggetti di R. L’indice usato da R inizia da 1. In altri linguaggi di programmazione, per esempio C, inizia da 0. J.4.7.3 Interi negativi Gli interi negativi fanno l’esatto contrario degli interi positivi: R ritornerà tutti gli elementi tranne quelli specificati dagli interi negativi. Per esempio, la prima riga del data.frame può essere specificata nel modo seguente deck[-(2:52), 1:3] #&gt; face suit value #&gt; 1 king spades 13 ovvero, escludendo tutte le righe seguenti. J.4.7.4 Zero Quando lo zero viene usato come indice, R non ritorna nulla dalla dimensione a cui lo zero si riferisce. L’istruzione deck[0, 0] #&gt; data frame con 0 colonne e 0 righe ritorna un data.frame vuoto. Non molto utile. J.4.7.5 Spazio ’ ’ Uno spazio viene usato quale indice per comunicare a R di estrarre tutti i valori in quella dimensione. Questo è utile per estrarre intere colonne o intere righe da un data.frame. Per esempio, l’istruzione deck[3, ] #&gt; face suit value #&gt; 3 jack spades 11 ritorna la terza riga del data.frame deck. J.4.7.6 Valori booleani Se viene fornito un vettore di stringhe TRUE, FALSE, R selezionerà gli elementi riga o colonna corrispondenti ai valori booleani TRUE usati quali indici. Per esempio, l’istruzione deck[3, c(TRUE, TRUE, FALSE)] #&gt; face suit #&gt; 3 jack spades ritorna i valori delle prime due colonne della terza riga di deck. J.4.7.7 Nomi È possibile selezionare gli elementi del data.frame usando i loro nomi. Per esempio, deck[1, c(&quot;face&quot;, &quot;suit&quot;, &quot;value&quot;)] #&gt; face suit value #&gt; 1 king spades 13 deck[, &quot;value&quot;] #&gt; [1] 13 12 11 10 9 8 7 6 5 4 3 2 1 13 12 11 10 9 8 7 6 5 4 3 2 #&gt; [26] 1 13 12 11 10 9 8 7 6 5 4 3 2 1 13 12 11 10 9 8 7 6 5 4 3 #&gt; [51] 2 1 J.4.8 Giochi di carte Avendo presentato le nozioni base del sistema di notazione di R, utilizziamo tali conoscenze per manipolare il data.frame. L’istruzione deck[1:52, ] ritorna tutte le righe e tutte e le colonne del data.frame deck. Le righe sono identificate dal primo indice, che va da 1 a 52. Permutare in modo casuale l’indice delle righe equivale a mescolare il mazzo di carte. Per fare questo, utilizziamo la funzione sample() ponendo replace=FALSE e size uguale alla dimensione del vettore che contiene gli indici da 1 a 52: random &lt;- sample(1:52, size = 52, replace = FALSE) random #&gt; [1] 41 35 51 22 3 10 2 15 11 16 46 21 7 19 43 17 27 50 39 44 14 18 40 47 31 #&gt; [26] 30 52 37 20 33 6 9 5 49 13 4 8 28 32 45 42 26 36 1 48 23 24 29 34 25 #&gt; [51] 38 12 Utilizzando il vettore random di indici permutati otteniamo il risultato cercato: deck_shuffled &lt;- deck[random, ] head(deck_shuffled) #&gt; face suit value #&gt; 41 queen hearts 12 #&gt; 35 five diamonds 5 #&gt; 51 two hearts 2 #&gt; 22 five clubs 5 #&gt; 3 jack spades 11 #&gt; 10 four spades 4 Possiamo ora scrivere una funzione che include le precedenti istruzioni: shuffle &lt;- function(cards) { random &lt;- sample(1:52, size = 52, replace = FALSE) return(cards[random, ]) } Invocando la funzione shuffle() possiamo generare un data.frame che rappresenta un mazzo di carte mescolato: deck_shuffled &lt;- shuffle(deck) Se immaginiamo di distribuire le carte di questo mazzo a due giocatori di poker, per il primo giocatore avremo: deck_shuffled[c(1, 3, 5, 7, 9), ] #&gt; face suit value #&gt; 26 ace clubs 1 #&gt; 44 nine hearts 9 #&gt; 29 jack diamonds 11 #&gt; 42 jack hearts 11 #&gt; 22 five clubs 5 e per il secondo: deck_shuffled[c(2, 4, 6, 8, 10), ] #&gt; face suit value #&gt; 24 three clubs 3 #&gt; 47 six hearts 6 #&gt; 34 six diamonds 6 #&gt; 51 two hearts 2 #&gt; 17 ten clubs 10 J.4.9 Variabili locali Si noti che, nell’esempio precedente, abbiamo passato l’argomento deck alla funzione shuffle(), perché questo è il nome del data.frame che volevamo manipolare. Nella definizione della funzione shuffle(), però, l’argomento della funzione era chiamato cards. Il nome degli argomenti è diverso nei due casi. Allora perché l’istruzione shuffle(deck) non dà un messaggio d’errore? La risposta a questa domanda è che nelle funzioni le variabili nascono quando la funzione entra in esecuzione e muoiono al termine dell’esecuzione della funzione. Per questa ragione, sono dette ‘locali’. La variabile cards, in questo esempio, esiste soltanto all’interno della funzione. Dunque non deve (necessariamente) avere lo stesso nome di un altro oggetto che esiste al di fuori della funzione, nello spazio di lavoro di R (anzi, è meglio se il nome degli oggetti usati all’interno delle funzioni è diverso da quello degli oggetti che esistono fuori dalle funzioni). R sa che l’oggetto deck passato a shuffle() corrisponde a cards all’interno della funzione perché assegna il nome cards a qualunque oggetto venga passato alla funzione shuffle() come primo (e, in questo caso, unico) argomento. J.5 Strutture di controllo In R il flusso della computazione segue l’ordine di lettura delle espressioni. I controlli di flusso sono quei costrutti sintattici che possono modificare quest’ordine di computazione. Ad esempio, un ciclo for ripete le istruzioni annidate al suo interno per un certo numero di volte, e quindi procede sequenzialmente da lì in avanti, mentre un condizionale if valuta una condizione rispetto alla quale il flusso di informazioni si biforca (se è vero / se è falso). Ci limitiamo qui ad introdurre il ciclo for. J.5.1 Il ciclo for Il ciclo for è una struttura di controllo iterativa che determina l’esecuzione di una porzione di codice ripetuta per un certo numero noto di volte. Il linguaggio R usa la seguente sintassi per il ciclo for: for (indice in valori_indice) { operazioni } il che significa “esegui le operazioni operazioni per i diversi valori di indice compresi nel vettore valori_indice”. Per esempio, il seguente ciclo for non fa altro che stampare il valore della variabile contatore in ciascuna esecuzione del ciclo: for (i in 1:3) { print(i) } #&gt; [1] 1 #&gt; [1] 2 #&gt; [1] 3 Un esempio (leggermente) più complicato è il seguente: x_list &lt;- seq(1, 9, by = 2) x_list #&gt; [1] 1 3 5 7 9 sum_x &lt;- 0 for (x in x_list) { sum_x &lt;- sum_x + x cat(&quot;L&#39;indice corrente e&#39;&quot;, x, &quot;\\n&quot;) cat(&quot;La frequenza cumulata e&#39;&quot;, sum_x, &quot;\\n&quot;) } #&gt; L&#39;indice corrente e&#39; 1 #&gt; La frequenza cumulata e&#39; 1 #&gt; L&#39;indice corrente e&#39; 3 #&gt; La frequenza cumulata e&#39; 4 #&gt; L&#39;indice corrente e&#39; 5 #&gt; La frequenza cumulata e&#39; 9 #&gt; L&#39;indice corrente e&#39; 7 #&gt; La frequenza cumulata e&#39; 16 #&gt; L&#39;indice corrente e&#39; 9 #&gt; La frequenza cumulata e&#39; 25 Per esempio, quanti numeri pari sono contenuti in un vettore? La risposta a questa domanda viene fornita dalla funzione countEvenNumbers() che possiamo definire come indicato qui sotto: countEvenNumbers &lt;- function(x) { count &lt;- 0 for (i in 1:length(x)) { if (x[i] %% 2 == 0) count = count + 1 } count } Nella funzione countEvenNumbers() abbiamo inizializzato la variabile count a zero. Prima dell’esecuzione del ciclo for, dunque, count vale zero. Il ciclo for viene eseguito tante volte quanti sono gli elementi che costituiscono il vettore x. L’indice i dunque assume valori compresi tra 1 e il valore che corrisponde al numero di elementi di x. L’operazione modulo, indicato con %% dà come risultato il resto della divisione euclidea del primo numero per il secondo. Per esempio, 9 %% 2 dà come risultato \\(1\\) perché questo è il resto della divisione \\(9/2\\). L’operazione modulo dà come risultato \\(0\\) per tutti i numeri pari. In ciascuna esecuzione del ciclo for l’operazione modulo viene eseguita, successivamente, su uno degli elementi di x. Se l’operazione modulo dà \\(0\\) come risultato, ovvero se il valore considerato è un numero pari, allora la variabile count viene incrementata di un’unità. L’istruzione return() ritorna il numero di valori pari contenuti nel vettore di input alla funzione. Si noti che è necessario usare return(): la funzione ritornerà qualunque cosa sia stampato nell’ultima riga della funzione stessa. Facciamo un esempio: x &lt;- c(1, 2, 1, 4, 6, 3, 9, 12) countEvenNumbers(x) #&gt; [1] 4 J.6 Input/Output I dati raccolti dallo psicologo sono contenuti in file aventi formati diversi: solo testo, CSV, Excel, eccetera. R prevede diverse funzioni di importazione dei dati. Esamineremo qui la funzione read.table() per l’importazione di dati in formato solo testo, ma funzioni analoghe possono essere usate per molti altri formati possibili. J.6.1 La funzione read.table() Ci sono tanti modi per importare un file dal nostro computer. R permette di utilizzare delle funzioni che sono già nella libreria di base, oppure possiamo utilizzare delle funzioni specifiche, a seconda del tipo di file da importare, che sono contenute in pacchetti aggiuntivi. Per leggere i dati da file in R è conveniente preliminarmente generare un file di dati in formato ASCII, disponendoli come si farebbe in una matrice di dati, e mettere questo file nella cartella di lavoro corrente. Fatto questo, si può utilizzare la funzione read.table() presente nella libreria di base per leggere l’intero dataset. Se la prima riga del file contiene l’intestazione delle variabili, allora read.table(\"my_file.txt\", header = TRUE) interpreterà la prima riga del file come una riga dove sono contenuti i nomi delle variabili, assegnando ciascun nome alle variabili del data frame: mydata &lt;- read.table(&quot;my_file.txt&quot;, header = TRUE) In alternativa, si può impiegare la funzione read.csv(), che è adatta a leggere dati salvati in .csv. Utilizzando altre funzioni, si possono leggere in R i dati contenuti in file aventi formati diversi da quelli considerati qui, quali Excel, SPSS, ecc. J.6.2 File di dati forniti da R In R esistono comunque oltre 50 insiemi di dati contenuti nel package base e altri sono disponibili in altri packages. Per vedere l’elenco degli insiemi di dati disponibili nel package base basta usare l’istruzione data(); per caricare un particolare insieme di dati, ad esempio cars, basta utilizzare l’istruzione data(cars) Nella maggior parte dei casi questo corrisponde a caricare un oggetto, solitamente un data.frame dello stesso nome: per l’esempio considerato si avrebbe un data frame di nome cars. J.6.3 Esportazione di un file Per esportare un data.frame in formato .csv possiamo scrivere il seguente codice write.csv(df_esempio, file = &quot;esempio.csv&quot;, row.names = FALSE) dove df_esempio è il data.frame da salvare e esempio.csv è il file che verrà salvato all’interno della nostra cartellla di lavoro. J.6.4 Pacchetto rio Un’alternativa più semplice è fornita dalle funzioni fornite dal pacchetto rio. Per importare i dati da un file in qualsiasi formato si usa my_data_frame &lt;- rio::import(&quot;my_file.csv&quot;) Per esportare i dati in un file avente qualsiasi formato si usa invece rio::export(my_data_frame, &quot;my_file.csv&quot;) J.6.5 Dove sono i miei file? Quello che abbiamo detto finora, a proposito dell’importazione ed esportazione dei file, si riferisce a file che si trovano nella cartella di lavoro (working directory). Ma non sempre ci troviamo in questa situazione, il che è una buona cosa, perché se dobbiamo gestire un progetto anche leggermente complesso è sempre una buona idea salvare i file che usiamo in cartelle diverse. Per esempio, possiamo usare una cartella chiamata psicometria dove salviamo tutto il materiale di questo insegnamento. Nella cartella psicometria ci potrà essere una cartella chiamata scripts dove salveremo gli script con il codice R utilizzato per i vari esercizi, e una cartella chiamata data dove possiamo salvare i dati. Questa organizzazione minimale ci pone, però, difronte ad un problema: i dati che vogliamo caricare in R non si trovano nella cartella dove sono contenuti gli script. Quando importiamo un file di dati dobbiamo dunque specificare il percorso che identifica la posizione del file sul nostro computer. Questo problema può essere risolto in due modi: speficicando l’indirizzo assoluto del file, o l’indirizzo relativo. Specificare l’indirizzo assoluto di un file comporta una serie di svantaggi. Il più grande è che non sarà possibile utilizzare quell’istruzione su una macchina diversa. Dunque, è molto più conveniente specificare l’indirizzo dei file in modo relativo. Ma relativo rispetto a cosa? Rispetto alla working directory che definirà l’origine del nostro percorso. È ovvio che la working directory cambia da progetto a progetto. Infatti, per ciascun progetto dobbiamo specificare una diversa working directory. Per esempio, potremmo avere un progetto relativo all’insegnamento di Psicometria e un progetto relativo alla prova finale. Per organizzaere il lavoro in questo modo, si procede come segue. Supponiamo di creare una cartella chiamata psicometria che contiene, al suo interno, le cartelle scripts e data: psicometria/ ├── data ├── scripts Supponiamo che queste cartelle contengano i file che ho specificato sopra. Chiudiamo RStudio, se è aperto, e lo riapriamo di nuovo. Dal menu selezioniamo File -&gt; New Project... In questo modo si aprirà un menu che ci chiederà, tra le altre cose, se vogliamo creare un nuovo progetto (New project). Selezioniamo quell’opzione e navighiamo fino alla cartella psicometria e selezioniamo open. Questo creerà un file chiamato psicometria.Rproj nella cartella psicometria. Chiudiamo ora RStudio. Se vogliamo accedere al progetto “psicometria”, che abbiamo appena creato, dobbiamo semplicemente cliccare sul file psicometria.Rproj. Questo aprirà RStudio e farà in modo che la working directory coincida con la cartalla psicometria. Ogni volta che vogliamo lavorare sui dati del progetto “psicometria” chiudiamo dunque RStudio (se è già aperto) e lo riapriamo cliccando sul file psicometria.Rproj. A questo punto possiamo definire l’indirizzo dei file in modo relativo – ovvero, relativo alla cartella psicometria. Per fare questo usiamo le funzionalità del pacchetto here. Supponiamo di volere caricare un file di dati che si chiama dati_depressione.txt e si trova nella cartella psicometria/data. Per importare i dati (dopo avere caricato i pacchetti rio e here) useremo l’istruzione seguente: rio::import(here(&quot;data&quot;, &quot;dati_depressione.txt&quot;)) In altre parole, così facendo specifichiamo il percorso relativo del file dati_depressione.txt (in quanto l’origine corrisponde alla cartella psicometria). L’istruzione precedente significa che, partendo dalla cartella che coincide con la working directory (ovvero, psicometria) ci spostiamo nella cartella data e lì dentro troviamo il file chiamato dati_depressione.txt. J.7 Manipolazione dei dati J.7.1 Motivazione Si chiamano “dati grezzi” quelli che provengono dal mondo circostanze, i dati raccolti per mezzo degli strumenti usati negli esperimenti, per mezzo di interviste, di questionari, ecc. Questi dati (chiamati dataset) raramente vengono forniti con una struttura logica precisa. Per potere elaborarli mediante dei software dobbiamo prima trasformarli in maniera tale che abbiano una struttura logica organizzata. La struttura che solitamente si utilizza è quella tabellare (matrice dei dati), ovvero si dispongono i dati in una tabella nella quale a ciascuna riga corrisponde ad un’osservazione e ciascuna colonna corrisponde ad una variabile rilevata. In R una tale struttura è chiamata data frame. Utilizzando i pacchetti del tidyverse (tidyverse è un insieme, o bundle, di pacchetti R), le operazioni di trasformazione dei dati risultano molto semplificate. Nel tidyverse i data frame vengono leggermente modificati e si chiamano tibble. Per la manipolazione dei dati vengono usati i seguenti pacchetti del tidyverse: dplyr tidyr (tibbles, dataframe e tabelle) stringr (stringhe) Il pacchetto dplyr (al momento uno dei pacchetti più famosi e utilizzati per la gestione dei dati) offre una serie di funzionalità che consentono di eseguire le operazioni più comuni di manipolazione dei dati in maniera più semplice rispetto a quanto succeda quando usiamo le funzioni base di R. J.7.2 Trattamento dei dati con dplyr Il pacchetto dplyr include sei funzioni base: filter(), select(), mutate(), arrange(), group_by() e summarise(). Queste sei funzioni costituiscono i verbi del linguaggio di manipolazione dei dati. A questi sei verbi si aggiunge il pipe %&gt;% che serve a concatenare più operazioni. In particolare, considerando una matrice osservazioni per variabili, select() e mutate() si occupano di organizzare le variabili, filter() e arrange() i casi, e group_by() e summarise() i gruppi. Per introdurre le funzionalità di dplyr, utilizzeremo i dati msleep forniti dal pacchetto ggplot2. Tali dati descrivono le ore di sonno medie di 83 specie di mammiferi (Savage et al. 2007). Carichiamo il boundle tidyverse (che contiene ggplot2) e leggiamo nella memoria di lavoro l’oggetto msleep: library(&quot;tidyverse&quot;) data(msleep) dim(msleep) #&gt; [1] 83 11 J.7.2.1 Operatore pipe Prima di presentare le funzionalità di dplyr, introduciamo l’operatore pipe %&gt;% del pacchetto magrittr – ma ora presente anche in base R nella versione |&gt;. L’operatore pipe, %&gt;% o |&gt;, serve a concatenare varie funzioni insieme, in modo da inserire un’operazione dietro l’altra. Una spiegazione intuitiva dell’operatore pipe è stata fornita in un tweet di @andrewheiss. Consideriamo la seguente istruzione in pseudo-codice R: leave_house( get_dressed( get_out_of_bed( wake_up(me, time = &quot;8:00&quot;), side = &quot;correct&quot;), pants = TRUE, shirt = TRUE), car = TRUE, bike = FALSE ) Il listato precedente descrive una serie di (pseudo) funzioni concatenate, le quali costituiscono gli argomenti di altre funzioni. Scritto così, il codice è molto difficile da capire. Possiamo però ottenere lo stesso risultato utilizzando l’operatore pipe che facilita enormememnte la leggibilità del codice: me %&gt;% wake_up(time = &quot;8:00&quot;) %&gt;% get_out_of_bed(side = &quot;correct&quot;) %&gt;% get_dressed(pants = TRUE, shirt = TRUE) %&gt;% leave_house(car = TRUE, bike = FALSE) In questa seconda versione del (pseudo) codice R si capisce molto meglio ciò che vogliamo fare. Il tibble me viene passato alla funzione wake_up(). La funzione wake_up() ha come argomento l’ora del giorno: time = \"8:00\". Una volta “svegliati” (wake up) dobbiamo scendere dal letto. Quindi l’output di wake_up() viene passato alla funzione get_out_of_bed() la quale ha come argomento side = \"correct\" perché vogliamo scendere dal letto dalla parte giusta. E così via. Questo pseudo-codice chiarisce il significato dell’operatore pipe. L’operatore %&gt;% è “syntactic sugar” per una serie di chiamate di funzioni concatenate, ovvero, detto in altre parole, consente di definire la relazione tra una serie di funzioni nelle quali il risultato (output) di una funzione viene utilizzato come l’input di una funzione successiva. J.7.2.2 Estrarre una singola colonna con pull() Ritorniamo ora all’esempio precedente. Iniziamo a trasformare il data frame msleep in un tibble (che è identico ad un data frame ma viene stampato sulla console in un modo diverso): msleep &lt;- tibble(msleep) Estraiamo da msleep la variabile sleep_total usando il verbo pull(): msleep %&gt;% pull(sleep_total) #&gt; [1] 12.1 17.0 14.4 14.9 4.0 14.4 8.7 7.0 10.1 3.0 5.3 9.4 10.0 12.5 10.3 #&gt; [16] 8.3 9.1 17.4 5.3 18.0 3.9 19.7 2.9 3.1 10.1 10.9 14.9 12.5 9.8 1.9 #&gt; [31] 2.7 6.2 6.3 8.0 9.5 3.3 19.4 10.1 14.2 14.3 12.8 12.5 19.9 14.6 11.0 #&gt; [46] 7.7 14.5 8.4 3.8 9.7 15.8 10.4 13.5 9.4 10.3 11.0 11.5 13.7 3.5 5.6 #&gt; [61] 11.1 18.1 5.4 13.0 8.7 9.6 8.4 11.3 10.6 16.6 13.8 15.9 12.8 9.1 8.6 #&gt; [76] 15.8 4.4 15.6 8.9 5.2 6.3 12.5 9.8 J.7.2.3 Selezionare più colonne con select() Se vogliamo selezionare da msleep un insieme di variabili, ad esempio name, vore e sleep_total, possiamo usare il verbo select(): dt &lt;- msleep %&gt;% dplyr::select(name, vore, sleep_total) dt #&gt; # A tibble: 83 × 3 #&gt; name vore sleep_total #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Cheetah carni 12.1 #&gt; 2 Owl monkey omni 17 #&gt; 3 Mountain beaver herbi 14.4 #&gt; 4 Greater short-tailed shrew omni 14.9 #&gt; 5 Cow herbi 4 #&gt; 6 Three-toed sloth herbi 14.4 #&gt; 7 Northern fur seal carni 8.7 #&gt; 8 Vesper mouse &lt;NA&gt; 7 #&gt; # … with 75 more rows laddove la sequenza di istruzioni precedenti significa che abbiamo passato msleep alla funzione select() contenuta nel pacchetto dplyr e l’output di select() è stato salvato (usando l’operatore di assegnazione, &lt;-) nell’oggetto dt. Alla funzione select() abbiamo passato gli argomenti name, vore e sleep_total. J.7.2.4 Filtrare le osservazioni (righe) con filter() Il verbo filter() consente di selezionare da un tibble un sottoinsieme di righe (osservazioni). Per esempio, possiamo selezionare tutte le osservazioni nella variabile vore contrassegnate come carni (ovvero, tutti i carnivori): dt %&gt;% dplyr::filter(vore == &quot;carni&quot;) #&gt; # A tibble: 19 × 3 #&gt; name vore sleep_total #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Cheetah carni 12.1 #&gt; 2 Northern fur seal carni 8.7 #&gt; 3 Dog carni 10.1 #&gt; 4 Long-nosed armadillo carni 17.4 #&gt; 5 Domestic cat carni 12.5 #&gt; 6 Pilot whale carni 2.7 #&gt; 7 Gray seal carni 6.2 #&gt; 8 Thick-tailed opposum carni 19.4 #&gt; # … with 11 more rows Per utilizzare il verbo filter() in modo efficace è neccessario usare gli operatori relazionali (Tabella ??) e gli operatori logici (Tabella ??) di R. Per un approfondimento, si veda il Capitolo Comparisons di R for Data Science. J.7.2.5 Creare una nuova variabile con mutate() Talvolta vogliamo creare una nuova variabile, per esempio, sommando o dividendo due variabili, oppure calcolandone la media. A questo scopo si usa il verbo mutate(). Per esempio, se vogliamo esprimere i valori di sleep_total in minuti, moltiplichiamo per 60: dt %&gt;% mutate( sleep_minutes = sleep_total * 60 ) %&gt;% dplyr::select(sleep_total, sleep_minutes) #&gt; # A tibble: 83 × 2 #&gt; sleep_total sleep_minutes #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 12.1 726 #&gt; 2 17 1020 #&gt; 3 14.4 864 #&gt; 4 14.9 894 #&gt; 5 4 240 #&gt; 6 14.4 864 #&gt; 7 8.7 522 #&gt; 8 7 420 #&gt; # … with 75 more rows J.7.2.6 Ordinare i dati con arrange() Il verbo arrange() ordina i dati in base ai valori di una o più variabili. Per esempio, possiamo ordinare la variabile sleep_total dal valore più alto al più basso in questo modo: dt %&gt;% arrange( desc(sleep_total) ) #&gt; # A tibble: 83 × 3 #&gt; name vore sleep_total #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Little brown bat insecti 19.9 #&gt; 2 Big brown bat insecti 19.7 #&gt; 3 Thick-tailed opposum carni 19.4 #&gt; 4 Giant armadillo insecti 18.1 #&gt; 5 North American Opossum omni 18 #&gt; 6 Long-nosed armadillo carni 17.4 #&gt; 7 Owl monkey omni 17 #&gt; 8 Arctic ground squirrel herbi 16.6 #&gt; # … with 75 more rows J.7.2.7 Raggruppare i dati con group_by() Il verbo group_by() raggruppa insieme i valori in base a una o più variabili. Lo vedremo in uso in seguito insieme a summarise(). Nota: con dplyr(), le operazioni raggruppate vengono iniziate con la funzione group_by(). È una buona norma utilizzare ungroup() alla fine di una serie di operazioni raggruppate, altrimenti i raggruppamenti verranno mantenuti nelle analisi successiva, il che non è sempre auspicabile. J.7.2.8 Sommario dei dati con summarise() Il verbo summarise() collassa il dataset in una singola riga dove viene riportato il risultato della statistica richiesta. Per esempio, la media del tempo totale del sonno è dt %&gt;% summarise( m_sleep = mean(sleep_total, na.rm = TRUE) ) #&gt; # A tibble: 1 × 1 #&gt; m_sleep #&gt; &lt;dbl&gt; #&gt; 1 10.4 J.7.2.9 Operazioni raggruppate Sopra abbiamo visto come i mammiferi considerati dormano, in media, 10.4 ore al giorno. Troviamo ora il sonno medio in funzione di vore: dt %&gt;% group_by(vore) %&gt;% summarise( m_sleep = mean(sleep_total, na.rm = TRUE), n = n() ) #&gt; # A tibble: 5 × 3 #&gt; vore m_sleep n #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 carni 10.4 19 #&gt; 2 herbi 9.51 32 #&gt; 3 insecti 14.9 5 #&gt; 4 omni 10.9 20 #&gt; 5 &lt;NA&gt; 10.2 7 Si noti che, nel caso di 7 osservazioni, il valore di vore non era specificato. Per tali osservazioni, dunque, la classe di appartenenza è NA. J.7.2.10 Applicare una funzione su più colonne: across() È spesso utile eseguire la stessa operazione su più colonne, ma copiare e incollare è sia noioso che soggetto a errori: df %&gt;% group_by(g1, g2) %&gt;% summarise( a = mean(a), b = mean(b), c = mean(c), d = mean(d) ) In tali circostanze è possibile usare la funzione across() che consente di riscrivere il codice precedente in modo più succinto: df %&gt;% group_by(g1, g2) %&gt;% summarise(across(a:d, mean)) Per i dati presenti, ad esempio, possiamo avere: msleep %&gt;% group_by(vore) %&gt;% summarise(across(starts_with(&quot;sleep&quot;), ~ mean(.x, na.rm = TRUE))) #&gt; # A tibble: 5 × 4 #&gt; vore sleep_total sleep_rem sleep_cycle #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 carni 10.4 2.29 0.373 #&gt; 2 herbi 9.51 1.37 0.418 #&gt; 3 insecti 14.9 3.52 0.161 #&gt; 4 omni 10.9 1.96 0.592 #&gt; 5 &lt;NA&gt; 10.2 1.88 0.183 J.7.3 Dati categoriali in R Consideriamo una variabile che descrive il genere e include le categorie male, female e non-conforming. In R, ci sono due modi per memorizzare queste informazioni. Uno è usare la classe character strings e l’altro è usare la classe factor. Non ci addentrimo qui nelle sottigliezze di questa distinzione, motivata in gran parte per le necessità della programmazione con le funzioni di tidyverse. Per gli scopi di questo insegnamento sarà sufficiente codificare le variabili qualitative usando la classe factor. Una volta codificati i dati qualitativi utilizzando la classe factor, si pongono spesso due problemi: modificare le etichette dei livelli (ovvero, le modalità) di un fattore, riordinare i livelli di un fattore. J.7.3.1 Modificare le etichette dei livelli di un fattore Esaminiamo l’esempio seguente. f_1 &lt;- c(&quot;old_3&quot;, &quot;old_4&quot;, &quot;old_1&quot;, &quot;old_1&quot;, &quot;old_2&quot;) f_1 &lt;- factor(f_1) y &lt;- 1:5 df &lt;- tibble(f_1, y) df #&gt; # A tibble: 5 × 2 #&gt; f_1 y #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 old_3 1 #&gt; 2 old_4 2 #&gt; 3 old_1 3 #&gt; 4 old_1 4 #&gt; 5 old_2 5 Supponiamo ora di volere che i livelli del fattore f_1 abbiano le etichette new_1, new_2, ecc. Per ottenere questo risultato usiamo la funzione forcats::fct_recode(): df &lt;- df %&gt;% mutate(f_1 = forcats::fct_recode( f_1, &quot;new_poco&quot; = &quot;old_1&quot;, &quot;new_medio&quot; = &quot;old_2&quot;, &quot;new_tanto&quot; = &quot;old_3&quot;, &quot;new_massimo&quot; = &quot;old_4&quot; ) ) df #&gt; # A tibble: 5 × 2 #&gt; f_1 y #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 new_tanto 1 #&gt; 2 new_massimo 2 #&gt; 3 new_poco 3 #&gt; 4 new_poco 4 #&gt; 5 new_medio 5 J.7.3.2 Riordinare i livelli di un fattore Spesso i livelli dei fattori hanno un ordinamento naturale. Quindi, gli utenti devono avere un modo per imporre l’ordine desiderato sulla codifica delle loro variabili qualitative. Se per qualche motivo vogliamo ordinare i livelli f_1 in ordine inverso, ad esempio, possiamo procedere nel modo seguente. df$f_1 &lt;- factor(df$f_1, levels = c( &quot;new_massimo&quot;, &quot;new_tanto&quot;, &quot;new_medio&quot;, &quot;new_poco&quot; ) ) summary(df$f_1) #&gt; new_massimo new_tanto new_medio new_poco #&gt; 1 1 1 2 Per approfondire le problematiche della manipolazione di variabili qualitative in R, si veda McNamara and Horton (2018). J.7.4 Creare grafici con ggplot2() Il pacchetto ggplot2() è un potente strumento per rappresentare graficamente i dati. Le iniziali del nome, gg, si riferiscono alla “Grammar of Graphics”, che è un modo di pensare le figure come una serie di layer stratificati. Originariamente descritta da Wilkinson (2012), la grammatica dei grafici è stata aggiornata e applicata in R da Hadley Wickham, il creatore del pacchetto. La funzione da cui si parte per inizializzare un grafico è ggplot(). La funzione ggplot() richiede due argomenti. Il primo è l’oggetto di tipo data.frame che contiene i dati da visualizzare – in alternativa al primo argomento, un dataframe può essere passato a ggplot() mediante l’operatore pipe. Il secondo è una particolare lista che viene generata dalla funzione aes(), la quale determina l’aspetto (aesthetic) del grafico. La funzione aes() richiede necessariamente di specificare “x” e “y”, ovvero i nomi delle colonne del data.frame che è stato utilizzato quale primo argomento di ggplot() (o che è stato passato da pipe), le quali rappresentano le variabili da porre rispettivamente sugli assi orizzontale e verticale. La definizione della tipologia di grafico e i vari parametri sono poi definiti successivamente, aggiungendo all’oggetto creato da ggplot() tutte le componenti necessarie. Saranno quindi altre funzioni, come geom_bar(), geom_line() o geom_point() a occuparsi di aggiungere al livello di base barre, linee, punti, e così via. Infine, tramite altre funzioni, ad esempio labs(), sarà possibile definire i dettagli più fini. Gli elementi grafici (bare, punti, segmenti, …) usati da ggplot2 sono chiamati geoms. Mediante queste funzioni è possibile costruire diverse tipologie di grafici: geom_bar(): crea un layer con delle barre; geom_point(): crea un layer con dei punti (diagramma a dispersione); geom_line(): crea un layer con una linea retta; geom_histogram(): crea un layer con un istogramma; geom_boxplot(): crea un layer con un box-plot; geom_errorbar(): crea un layer con barre che rappresentano intervalli di confidenza; geom_hline() e geom_vline() : crea un layer con una linea orizzontale o verticale definita dall’utente. Un comando generico ha la seguente forma: my_graph &lt;- my_data %&gt;% ggplot(aes(x_var, y_var)) + geom_...() La prima volta che si usa il pacchetto ggplot2 è necessario installarlo. Per fare questo possiamo installare tidyverse che, oltre a caricare ggplot2, carica anche altre utili funzioni per l’analisi dei dati. Ogni volta che si inizia una sessione R è necessario attivare i pacchetti che si vogliono usare, ma non è necessario istallarli una nuova volta. Se è necessario specificare il pacchetto nel quale è contenuta la funzione che vogliamo utilizzare, usiamo la sintassi package::function(). Per esempio, l’istruzione ggplot2::ggplot() rende esplicito che stiamo usando la funzione ggplot() contenuta nel pacchetto ggplot2. J.7.5 Diagramma a dispersione Consideriamo nuovamenti i dati contenuti nel tibble msleep e poniamoci il problema di rappresentare graficamente la relazione tra il numero medio di ore di sonno giornaliero (sleep_total) e il peso dell’animale (bodywt). Usando le impostazioni di default di ggplot2, con le istruzioni seguenti, otteniamo il grafico fornito dalla figura seguente. data(&quot;msleep&quot;) p &lt;- msleep %&gt;% ggplot( aes(x = bodywt, y = sleep_total) ) + geom_point() print(p) Coloriamo ora in maniera diversa i punti che rappresentano animali carnivori, erbivori, ecc. p &lt;- msleep %&gt;% ggplot( aes(x = bodywt, y = sleep_total, col = vore) ) + geom_point() print(p) È chiaro, senza fare alcuna analisi statistica, che la relazione tra le due variabili non è lineare. Trasformando in maniera logaritmica i valori dell’asse \\(x\\) la relazione si linearizza. p &lt;- msleep %&gt;% ggplot( aes(x = log(bodywt), y = sleep_total, col = vore) ) + geom_point() print(p) Infine, aggiustiamo il “tema” del grafico (si noti l’utilizzo di una tavolozza di colori adatta ai daltonici mediante il pacchetto viridis), aggiungiamo le etichette sugli assi e il titolo. library(&quot;viridis&quot;) msleep %&gt;% ggplot( aes(x = log(bodywt), y = sleep_total, col = vore) ) + geom_point(size = 2, alpha = .8) + labs( x = &quot;Peso corporeo (log)&quot;, y = &quot;Ore di sonno&quot;, title = &quot;Il sonno in 83 specie di mammiferi&quot;, subtitle = &quot;Un esempio di visualizzazione con ggplot()&quot;, caption = &quot;Fonte: Savage e West (2007)&quot; ) + scale_fill_viridis(discrete = TRUE, option = &quot;viridis&quot;) + theme_minimal() + theme(legend.title = element_blank()) La visualizzazione può essere migliorata cambiando le etichette della legenda del grafico. Per fare questo è necessario intervenire sui dati prima di usare ggplot() – per esempio, come abbiamo fatto in precedenza con la funzione forcats::fct_recode(). J.7.5.1 Istogramma Creiamo ora un istogramma che rappresenta la distribuzione del (logaritmo del) peso medio del cervello delle 83 specie di mammiferi considerate da Savage and West (2007). L’argomento aes(y = ..density..) in geom_histogram() produce le frequenze relative. L’opzione di default (senza questo argomento) porta ggplot() a rappresentare le frequenze assolute. msleep %&gt;% ggplot( aes(log(brainwt)) ) + geom_histogram(aes(y = ..density..)) + labs( x = &quot;Peso del cervello (log)&quot;, y = &quot;Frequenza relativa&quot; ) + theme(legend.title = element_blank()) J.7.6 Scrivere il codice R con stile Uno stile di programmazione è un insieme di regole per la gestione dell’indentazione dei blocchi di codice, per la creazione dei nomi dei file e delle variabili e per le convenzioni tipografiche che vengono usate. Scrivere il codice in R con stile consente di creare listati più leggibili e semplici da modificare, minimizza la possibilità di errore, e consente correzioni e modifiche più rapide. Vi sono molteplici stili di programmazione che possono essere utilizzati dall’utente, anche se è bene attenersi a quelle che sono le convenzioni maggiormente diffuse, allo scopo di favorire la comunicazione. In ogni caso, l’importante è di essere coerenti, ovvero di adottare le stesse convenzioni in tutte le parti del codice che si scrive. Ad esempio, se si sceglie di usare lo stile snake_case per il nome composto di una variabile (es., personality_trait), non è appropriato usare lo stile lower Camel case per un’altra variabile (es., socialStatus). Dato che questo argomento è stato trattato ampiamente in varie sedi, mi limito qui a rimandare ad uno stile di programmazione molto popolare, quello proposto da Hadley Wickham, il creatore di tidyverse. La soluzione più semplice è quella installare stiler, che è uno RStudio Addin, e formattare il codice in maniera automatica utilizzando lo stile proposto da Hadley Wickham. Si possono ottenere informazioni su stiler seguendo questo link. J.8 Flusso di lavoro riproducibile J.8.1 La crisi della riproducibilità “Per il metodo scientifico è essenziale che gli esperimenti siano riproducibili. Vale a dire che una persona diversa dallo sperimentatore originale deve essere in grado di ottenere gli stessi risultati seguendo lo stesso protocollo sperimentale (Gilbert Chin).” Ma in psicologia (e non solo) la riproducibilità è inferiore a quanto previsto o desiderato. In un famoso studio pubblicato su Science, un ampio gruppo di ricercatori (Open Science Collaboration and others 2015) è riuscito a replicare solo il 40 per cento circa dei risultati di 100 studi di psicologia cognitiva e sociale pubblicati in precedenza. I risultati di questo studio, e di molti altri pubblicati in seguito, sono stati interpretati in modi diversi. La preoccupazione sulla riproducibilità della ricerca è stata espressa mediante l’affermare secondo la quale “la maggior parte dei risultati della ricerca sono falsi” (Ioannidis 2005) oppure mediante l’affermazione secondo cui “dobbiamo apportare modifiche sostanziali al modo in cui conduciamo la ricerca” (Cumming 2014). Alcuni ricercatori sono arrivati a definire la presente situazione come una “crisi della riproducibilità dei risultati della ricerca”. Il termine “riproducibilità” (o “replicabilità”) è stato definito in vari modi. Consideriamo la definizione fornita da Goodman, Fanelli, and Ioannidis (2016): la riproducibilità dei metodi “si riferisce al fatto che il ricercatore fornisce dettagli sufficienti sulle procedure e sui dati dello studio in modo che le stesse procedure possano … essere replicate esattamente” (pag. 2) con gli stessi dati; la riproducibilità dei risultati “si riferisce all’ottenimento degli stessi risultati dalla conduzione di uno studio indipendente le cui procedure replicano il più esattamente possibile quelle dell’esperimento originale” (pag. 2-3) con dati indipendenti; la riproducibilità inferenziale “si riferisce alla possibilità di trarre conclusioni qualitativamente simili da una replica indipendente di uno studio o da una nuova analisi dello studio originale” (pag. 4). Per gli scopi presenti, ci focalizzeremo qui sulla riproducibilità dei metodi. Cioè, discuteremo di come R può aiutarci a migliorare questo aspetto della riproducibilità. In questo capitolo mostreremo come R possa essere utilizzato all’interno di un flusso di lavoro (workflow) riproducibile che integra (1) il codice di analisi dei dati, (2) i dati medesimi e (3) il testo della relazione che comunica i risultati dello studio. A tal fine utilizzeremo due pacchetti R: rmarkdown e knitr. Questi pacchetti consentono di unire il codice R ad un linguaggio di marcatura (o di markup) chiamato Markdown. Il linguaggio di markup Markdown sta diventando sempre più popolare e viene usato, oltre che per creare reports di analisi di dati, anche per creare siti web, blog, libri, articoli accademici, curriculum vitae, slide, tesi di laurea. Per esempio, il presente sito web è stato scritto usando R-markdown. J.8.2 R-markdown Un linguaggio di markup permette di aggiungere mediante marcatori (tag) informazioni sulla struttura e sulla formattazione da applicare ad un documento. Un’introduzione al linguaggio Markdown può essere trovata, per esempio, qui oppure qui. In questo capitolo ci focalizzeremo però sugli aspetti più importanti di R-markdown che permette di costruire documenti in cui combinare testo formattato (quindi non solo commenti ma anche formule, titoli etc) e istruzioni codice (R e non solo) con i corrispettivi output. Informazioni dettagliate su R-markdown sono disponibili qui e qui. Un file R-markdown è composto da tre tipi di oggetti: header in formato YAML delimitato da ---, testo in formato markdown, blocchi (“chunks”) di codice R, delimitati da tre apici. J.8.2.1 Header L’intestazione di un documento .Rmd (R-markdown) corrisponde al cosiddetto YAML header (un acronimo che significa Yet Another Markup Language). Lo YAML header controlla le caratteristiche generali del documento, incluso il tipo di documento che viene prodotto (un documento HTML che può essere visualizzato su tutti i principali browser, un documento Microsoft Word o un PDF se abbiamo installato LaTeX sul nostro computer), la dimensione del carattere, lo stile, il titolo, l’autore, ecc. Nello YAML header (a differenza del codice R) è necessario rispettare la spaziatura prestabilita delle istruzioni che vengono elencate. Gli elementi principali sono title:, author:, output:. L’argomento di output: è dove diciamo a R-markdown quale tipo di file vogliamo che venga prodotto. Il tipo più flessibile, che non richiede alcuna configurazione, è html_document. J.8.2.2 Testo Alla conclusione dello YAML header inizia il documento R-markdown. Da questo punto in poi possiamo utilizzare testo normale, codice R e sintassi Markdown per controllare cosa viene mostrato e come. J.8.2.3 Formattazione È possibile contrassegnare intestazioni, grassetto e corsivo come indicato di seguito. # Intestazione 1 ## Intestazione 2 ### Intestazione 3 #### Intestazione 4 ##### Intestazione 5 ###### Intestazione 6 Questo è un testo normale. Possiamo scrivere in **grassetto** il testo usando due asterischi. Possiamo scrivere in *corsivo* usando un asterisco. &gt;Questa è un’**area rientrata**. Questa riga invece non è più rientrata. J.8.2.4 Elenchi Per creare un elenco puntato si utilizza il segno più, il trattino o l’asterisco. Tutte le tre soluzioni portano allo stesso risultato. - Punto 1 della lista - Punto 2 della lista - Punto 3 della lista Un elenco numerato, invece, si crea con un numero seguito da un punto. 1. Punto 1 della lista 2. Punto 2 della lista 3. Punto 3 della lista J.8.2.5 Hyperlink Per inserire un hyperlink ci sono due metodi: specificare solo il percorso &lt;http://rmarkdown.rstudio.com&gt;, http://rmarkdown.rstudio.com creare un link con [link](http://rmarkdown.rstudio.com) J.8.2.6 Immagini Per inserire un’immagine la sintassi è molto simile: ![Esempio di immagine inserita in un documento R-markdown.](images/hex-rmarkdown.png){width=20%}: Esempio di immagine inserita in un documento R-markdown. J.8.2.7 Codice inline Per contrassegnare un’area di testo come codice, markdown utilizza il cosiddetto backtick, noto anche come gravis o accento grave, da non confondere con la virgoletta singola. La marcatura prevede un accento all’inizio e uno alla fine dell’area di testo corrispondente. Questo è `codice`. J.8.2.8 Equazioni Equazioni possono essere inserite in un documento R-markdown usando la sintassi . Qualsiasi cosa all’interno del segno di dollaro $ viene trattata come un’equazione “inline”. Qualunque cosa all’interno di due segni di dollaro $$ viene trattata come un’equazione a sé stante. Per esempio, questa è la formula della distribuzione Normale espressa in notazione LaTeX e riprodotta all’interno di un documento R-markdown: f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right) \\[ f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right) \\] J.8.2.9 Codice R In un documento R-markdown istruzioni di codice vengono inserite in blocchi delimitati da tre apici. Ciò consente di valutare il codice all’interno del documento e di produrre un output che verrà stampato nel documento stesso. Possiamo dunque stampare tabelle e figure prodotti direttamente dal codice R. Ciò significa inoltre, che se qualcosa cambia nei dati o nelle analisi dei dati, le tabelle e le figure si aggiorneranno automaticamente. Un chunk R viene valutato proprio come il normale codice R, quindi si applica tutto ciò che abbiamo imparato nei capitoli precedenti. Se il chunk R produce un output, questo output verrà visualizzato nel documento. J.8.3 Compilare la presentazione R-markdown Ma dove si trova questo magico documento che include il testo e l’output prodotto dal codice R? Ottima domanda. Siamo stati abituati ai programmi di videoscrittura (come Microsoft Word) che si conformano al cosiddetto stile “WYSIWYG” (What You See Is What You Get) – cioè, si vede come apparirà il documento stampato mentre lo si digita. Questo può avere alcuni vantaggi ma può anche essere molto limitante. R-Markdown, d’altra parte, funziona in modo diverso. Ovvero, deve essere “compilato” (knitted) per passare dal file sorgente al documento formattato. In RStudio, tale operazione è semplice: c’è un pulsante in alto a sinistra nel pannello di scripting di un documento .Rmd. È sufficiente selezionare tale pulsante e il nostro documento verrà creato. È importante notare che il codice del documento deve essere autonomo. Ciò significa che tutto ciò che vogliamo che venga eseguito deve essere incluso nel documento, indipendentemente da ciò che era già stato eseguito al di fuori di esso. Ad esempio, è perfettamente legittimo (e anche molto utile) testare il codice R al di fuori del documento Rmd. Tuttavia, quando compiliamo il documento Rmd, tutto ciò che è stato fatto al di fuori del documento Rmd viene dimenticato. Ciò consente di creare un documento autosufficiente che favorisce la riproducibilità dei metodi di analisi dei dati: utilizzando uno specifico documento Rmd con un campione di dati si giunge sempre allo stesso risultato e alla stessa interpretazione. Ciò non è invece vero se si utilizza un software con un interfaccia point-and-click. J.9 Dati mancanti J.9.1 Motivazione La pulizia dei dati (data cleaning) in R è fondamentale per effettuare qualsiasi analisi. Uno degli aspetti più importanti della pulizia dei dati è la gestione dei dati mancanti. I valori mancanti (missing values) vengono indicati dal codice NA, che significa not available — non disponibile. J.9.2 Trattamento dei dati mancanti Se una variabile contiene valori mancanti, R non è in grado di applicare ad essa alcune Funzioni, come ad esempio la media. Per questa ragione, la gran parte delle funzioni di R prevedono modi specifici per trattare i valori mancanti. Ci sono diversi tipi di dati “mancanti” in R; NA - generico dato mancante; NaN - il codice NaN (Not a Number) indica i valori numerici impossibili, quali ad esempio un valore 0/0; Inf e -Inf - Infinity, si verifca, ad esempio, quando si divide un numero per 0. La funzione is.na() ritorna un output che indica con TRUE le celle che contengono NA o NaN. Si noti che se is.na(x) è TRUE, allora !is.na(x) è FALSE; all(!is.na(x)) ritorna TRUE se tutti i valori x sono NOT NA; any(is.na(x)) risponde alla domanda: c’è qualche valore NA (almeno uno) in x?; complete.cases(x) ritorna TRUE se ciascun elemento di x è is NOT NA; ritorna FALSE se almeno un elemento di x è NA; Le funzioni R is.nan() e is.infinite() si applicano ai tipi di dati NaN e Inf. Per esempio, consideriamo il seguente data.frame: d &lt;- tibble( w = c(1, 2, NA, 3, NA), x = 1:5, y = 1, z = x ^ 2 + y, q = c(3, NA, 5, 1, 4) ) d #&gt; # A tibble: 5 × 5 #&gt; w x y z q #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 1 2 3 #&gt; 2 2 2 1 5 NA #&gt; 3 NA 3 1 10 5 #&gt; 4 3 4 1 17 1 #&gt; 5 NA 5 1 26 4 is.na(d$w) #&gt; [1] FALSE FALSE TRUE FALSE TRUE is.na(d$x) #&gt; [1] FALSE FALSE FALSE FALSE FALSE Per creare un nuovo Dataframe senza valori mancanti: d_clean &lt;- d[complete.cases(d), ] d_clean #&gt; # A tibble: 2 × 5 #&gt; w x y z q #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 1 2 3 #&gt; 2 3 4 1 17 1 Oppure, se vogliamo eliminare le righe con NA solo in una variabile: d1 &lt;- d[!is.na(d$q), ] d1 #&gt; # A tibble: 4 × 5 #&gt; w x y z q #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 1 2 3 #&gt; 2 NA 3 1 10 5 #&gt; 3 3 4 1 17 1 #&gt; 4 NA 5 1 26 4 Se vogliamo esaminare le righe con i dati mancanti in qualunque colonna: d_na &lt;- d[!complete.cases(d), ] d_na #&gt; # A tibble: 3 × 5 #&gt; w x y z q #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 2 1 5 NA #&gt; 2 NA 3 1 10 5 #&gt; 3 NA 5 1 26 4 Spesso i valori mancanti vengono sostiuti con valori “ragionevoli”, come ad esempio la media dei valori in quella colonna del Dataframe. Oppure, vengono considerati come “ragionevoli” i valori che vengono predetti conoscendo le altre variabili del Dataframe. Questa procedura si chiama imputazione multipla. Questo è però un argomento avanzato che non verrà trattato in questo insegnamento. La cosa più semplice da fare, in presenza di dati mancanti, è semplicemente quella di escludere tutte le righe nelle quali ci sono degli NAs. References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
