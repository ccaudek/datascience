[{"path":"index.html","id":"prefazione","chapter":"Prefazione","heading":"Prefazione","text":"Data Science per psicologi contiene il materiale delle lezioni dell’insegnamento di Psicometria B000286 (.. 2021/2022) rivolto agli studenti del primo anno del Corso di Laurea Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze. Psicometria si propone di fornire agli studenti un’introduzione ’analisi dei dati psicologia. Le conoscenze/competenze che verranno sviluppate questo insegnamento sono quelle della Data science, ovvero un insieme di conoscenze/competenze che si pongono ’intersezione tra statistica (ovvero, richiedono la capacità di comprendere teoremi statistici) e informatica (ovvero, richiedono la capacità di sapere utilizzare un software).","code":""},{"path":"index.html","id":"la-psicologia-e-la-data-science","chapter":"Prefazione","heading":"La psicologia e la Data science","text":"Sembra sensato spendere due parole su un tema che è importante per gli studenti: quello indicato dal titolo di questo Capitolo. È ovvio che agli studenti di psicologia la statistica non piace. Se piacesse, forse studierebbero Data science e non psicologia; ma non lo fanno. Di conseguenza, gli studenti di psicologia si chiedono: “perché dobbiamo perdere tanto tempo studiare queste cose quando realtà quello che ci interessa è tutt’altro?” Questa è una bella domanda.C’è una ragione molto semplice che dovrebbe farci capire perché la Data science è così importante per la psicologia. Infatti, ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia gli individui ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, certi casi, predire. questo senso, la psicologia è molto diversa dall’ingegneria, per esempio. Le proprietà di un determinato ponte sotto certe condizioni, ad esempio, sono molto simili quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non può dirsi degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l’oggetto di studio proprio della psicologia: è dunque chiaro che problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri. Questa è la ragione per cui abbiamo tanto bisogno della Data science psicologia: perché la Data science ci consente di descrivere la variazione e il cambiamento. E queste sono appunto le caratteristiche di base dei fenomeni psicologici.Sono sicuro che, leggendo queste righe, molti studenti sarà venuta mente la seguente domanda: perché non chiediamo qualche esperto di fare il “lavoro sporco” (ovvero le analisi statistiche) per noi, mentre noi (gli psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli “tecnici” della Data science? La risposta questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della Data science. Le tematiche della Data science non possono essere ignorate né dai ricercatori psicologia né da coloro che svolgono la professione di psicologo al di fuori dell’Università. Infatti, anche professionisti al di fuori dall’università non possono fare meno di leggere la letteratura psicologica più recente: il continuo aggiornamento delle conoscenze è infatti richiesto dalla deontologia della professione. Ma per potere fare questo è necessario conoscere un bel po’ di Data science! Basta aprire caso una rivista specialistica di psicologia per rendersi conto di quanto ciò sia vero: gli articoli che riportano risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. E la comprensione della letteratura psicologica rappresenta un requisito minimo nel bagaglio professionale dello psicologo.Le considerazioni precedenti cercano di chiarire il seguente punto: la Data science non è qualcosa da studiare malincuore, un singolo insegnamento universitario, per poi poterla tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano gli strumenti della Data science tantissimi ambiti della loro attività professionale: particolare quando costruiscono, somministrano e interpretano test psicometrici. È dunque chiaro che possedere delle solide basi di Data science è un tassello imprescindibile del bagaglio professionale dello psicologo. questo insegnamento verrano trattati temi base della Data science e verrà adottato un punto di vista bayesiano, che corrisponde ’approccio più recente e sempre più diffuso psicologia.","code":""},{"path":"index.html","id":"come-studiare","chapter":"Prefazione","heading":"Come studiare","text":"Il giusto metodo di studio per prepararsi ’esame di Psicometria è quello di seguire attivamente le lezioni, assimilare concetti via via che essi vengono presentati e verificare autonomia le procedure presentate lezione. Incoraggio gli studenti farmi domande per chiarire ciò che non è stato capito appieno. Incoraggio gli studenti utilizzare forum attivi su Moodle e, soprattutto, svolgere gli esercizi proposti su Moodle. problemi forniti su Moodle rappresentano il livello di difficoltà richiesto per superare l’esame e consentono allo studente di comprendere se le competenze sviluppate fino quel punto sono sufficienti rispetto alle richieste dell’esame.La prima fase dello studio, che è sicuramente individuale, è quella cui è necessario acquisire le conoscenze teoriche relative ai problemi che saranno presentati ’esame. La seconda fase di studio, che può essere facilitata da scambi con altri e da incontri di gruppo, porta ad acquisire la capacità di applicare le conoscenze: è necessario capire come usare un software (\\(\\textsf{R}\\)) per applicare concetti statistici alla specifica situazione del problema che si vuole risolvere. Le due fasi non sono però separate: il saper fare molto spesso ci aiuta capire meglio.","code":""},{"path":"index.html","id":"sviluppare-un-metodo-di-studio-efficace","chapter":"Prefazione","heading":"Sviluppare un metodo di studio efficace","text":"Avendo insegnato molte volte passato un corso introduttivo di analisi dei dati ho notato nel corso degli anni che gli studenti con l’atteggiamento mentale che descriverò qui sotto generalmente ottengono ottimi risultati. Alcuni studenti sviluppano naturalmente questo approccio allo studio, ma altri hanno bisogno di fare uno sforzo per maturarlo. Fornisco qui sotto una breve descrizione del “metodo di studio” che, nella mia esperienza, è il più efficace per affrontare le richieste di questo insegnamento.Dedicate un tempo sufficiente al materiale di base, apparentemente facile; assicuratevi di averlo capito bene. Cercate le lacune nella vostra comprensione. Leggere presentazioni diverse dello stesso materiale (libri o articoli diversi) può fornire nuove intuizioni.Gli errori che facciamo sono nostri migliori maestri. Istintivamente cerchiamo di dimenticare subito nostri errori. Ma il miglior modo di imparare è apprendere dagli errori che commettiamo. questo senso, una soluzione corretta è meno utile di una soluzione sbagliata. Quando commettiamo un errore questo ci fornisce un’informazione importante: ci fa capire qual è il materiale di studio sul quale dobbiamo ritornare e che dobbiamo capire meglio.C’è ovviamente un aspetto “psicologico” nello studio. Quando un esercizio o problema ci sembra incomprensibile, la cosa migliore da fare è dire: “mi arrendo”, “non ho idea di cosa fare!”. Questo ci rilassa: ci siamo già arresi, quindi non abbiamo niente da perdere, non dobbiamo più preoccuparci. Ma non dobbiamo fermarci qui. Le cose “migliori” che faccio (se ci sono) le faccio quando non ho voglia di lavorare. Alle volte, quando c’è qualcosa che non fare e non ho idea di come affontare, mi dico: “oggi non ho proprio voglia di fare fatica”, non ho voglia di mettermi nello stato mentale per cui “10 minuti devo risolvere il problema perché dopo devo fare altre cose”. Però ho voglia di divertirmi con quel problema e allora mi dedico qualche aspetto “marginale” del problema, che come affrontare, oppure considero l’aspetto più difficile del problema, quello che non come risolvere, ma invece di cercare di risolverlo, guardo come altre persone hanno affrontato problemi simili, opppure lo stesso problema un altro contesto. Non mi pongo l’obiettivo “risolvi il problema 10 minuti”, ma invece quello di farmi un’idea “generale” del problema, o quello di capire un caso più specifico e più semplice del problema. Senza nessuna pressione. Infatti, quel momento ho deciso di non lavorare (ovvero, di non fare fatica). Va benissimo se “parto per la tangente”, ovvero se mi metto leggere del materiale che sembra avere poco che fare con il problema centrale (le nostre intuizioni e la nostra curiosità solitamente ci indirizzano sulla strada giusta). Quando faccio così, molto spesso trovo la soluzione del problema che mi ero posto e, paradossalmente, la trovo un tempo minore di quello che, precedenza, avevo dedicato “lavorare” al problema. Allora perché non faccio sempre così? C’è ovviamente l’aspetto dei “10 minuti” che non è sempre facile da dimenticare. Sotto pressione, possiamo solo agire maniera automatica, ovvero possiamo solo applicare qualcosa che già sappiamo fare. Ma se dobbiamo imparare qualcosa di nuovo, la pressione è un impedimento.È utile farsi da soli delle domande sugli argomenti trattati, senza limitarsi cercare di risolvere gli esercizi che vengono assegnati. Quando studio qualcosa mi viene mente: “se questo è vero, allora deve succedere quest’altra cosa”. Allora verifico se questo è vero, di solito con una simulazione. Se risultati della simulazione sono quelli che mi aspetto, allora vuol dire che ho capito. Se risultati sono diversi da quelli che mi aspettavo, allora mi rendo conto di non avere capito e ritorno indietro studiare con più attenzione la teoria che pensavo di avere capito – e ovviamente mi rendo conto che c’era un aspetto che avevo frainteso. Questo tipo di verifica è qualcosa che dobbiamo fare da soli, prima persona: nessun altro può fare questo al posto nostro.Non aspettatevi di capire tutto la prima volta che incontrate un argomento nuovo.1 È utile farsi una nota mentalmente delle lacune nella vostra comprensione e tornare su di esse seguito per carcare di colmarle. L’atteggiamento naturale, quando non capiamo dettagli di qualcosa, è quello di pensare: “non importa, ho capito maniera approssimativa questo punto, non devo preoccuparmi del resto”. Ma realtà non è vero: se la nostra comprensione è superficiale, quando il problema verrà presentato una nuova forma, non riusciremo risolverlo. Per cui dubbi che ci vengono quando studiamo qualcosa sono il nostro alleato più prezioso: ci dicono esattamente quali sono gli aspetti che dobbiamo approfondire per potere migliorare la nostra preparazione.È utile sviluppare una visione d’insieme degli argomenti trattati, capire l’obiettivo generale che si vuole raggiungere e avere chiaro il contributo che vari pezzi di informazione forniscono al raggiungimento di tale obiettivo. Questa organizzazione mentale del materiale di studio facilita la comprensione. È estremamente utile creare degli schemi di ciò che si sta studiando. Non aspettate che sia io fornirvi un riepilogo di ciò che dovete imparare: sviluppate da soli tali schemi e tali riassunti.Tutti noi dobbiamo imparare l’arte di trovare le informazioni, non solo nel caso di questo insegnamento. Quando vi trovate di fronte qualcosa che non capite, o ottenete un oscuro messaggio di errore da un software, ricordatevi: “Google friend”!\nCorrado Caudek\nMarzo 2022\n","code":""},{"path":"ch-key-notions.html","id":"ch-key-notions","chapter":"Capitolo 1 Concetti chiave","heading":"Capitolo 1 Concetti chiave","text":"La data science si pone ’intersezione tra statistica e informatica. La statistica è un insieme di metodi ugilizzati per estrarre informazioni dai dati; l’informatica implementa tali procedure un software. questo Capitolo vengono introdotti concetti fondamentali.","code":""},{"path":"ch-key-notions.html","id":"popolazioni-e-campioni","chapter":"Capitolo 1 Concetti chiave","heading":"1.1 Popolazioni e campioni","text":"Popolazione. L’analisi dei dati inizia con l’individuazione delle unità portatrici di informazioni circa il fenomeno di interesse. Si dice popolazione (o universo) l’insieme \\(\\Omega\\) delle entità capaci di fornire informazioni sul fenomeno oggetto dell’indagine statistica. Possiamo scrivere \\(\\Omega = \\{\\omega_i\\}_{=1, \\dots, n}= \\{\\omega_1, \\omega_2, \\dots, \\omega_n\\}\\), oppure \\(\\Omega = \\{\\omega_1, \\omega_2, \\dots \\}\\) nel caso di popolazioni finite o infinite, rispettivamente.L’obiettivo principale della ricerca psicologica è conoscere gli esiti psicologici e loro fattori trainanti nella popolazione. Questo è l’obiettivo delle sperimentazioni psicologiche e della maggior parte degli studi osservazionali psicologia. È quindi necessario essere molto chiari sulla popolazione cui si applicano risultati della ricerca. La popolazione può essere ben definita, ad esempio, tutte le persone che si trovavano nella città di Hiroshima al momento del bombardamento atomico e sono sopravvissute per un anno, o può essere ipotetica, ad esempio, tutte le persone depresse che hanno subito o saranno sottoposte ad un intervento psicologico. Il ricercatore deve sempre essere grado di determinare se un soggetto appartiene alla popolazione oggetto di interesse.Una sotto-popolazione è una popolazione che soddisfa proprietà ben definite. Ad esempio, potremmo essere interessati alla sotto-popolazione di uomini di età inferiore ai 20 anni o alla sotto-popolazione di pazienti depressi sottoposti ad uno specifico intervento psicologico. Molte domande scientifiche riguardano le differenze tra sotto-popolazioni; ad esempio, il confronto tra un gruppo sottoposto psicoterapia e un gruppo di controllo per determinare se il trattamento è stato efficace.Campione. Gli elementi \\(\\omega_i\\) dell’insieme \\(\\Omega\\) sono detti unità statistiche. Un sottoinsieme della popolazione, ovvero un insieme di elementi \\(\\omega_i\\), viene chiamato campione. Ciascuna unità statistica \\(\\omega_i\\) (abbreviata con u.s.) è portatrice dell’informazione che verrà rilevata mediante un’operazione di misurazione.Un campione è dunque un sottoinsieme della popolazione utilizzato per conoscere tale popolazione. differenza di una sotto-popolazione definita base chiari criteri, un campione viene generalmente selezionato tramite un procedura casuale. Il campionamento casuale consente allo scienziato di trarre conclusioni sulla popolazione e, soprattutto, di quantificare l’incertezza sui risultati. campioni di un sondaggio sono esempi di campioni casuali, ma molti studi osservazionali non sono campionati casualmente. Possono essere campioni di convenienza, come coorti di studenti un unico istituto, che consistono di tutti gli studenti sottoposti ad un certo intervento psicologico quell’istituto. Indipendentemente da come vengono ottenuti campioni, il loro uso al fine di conoscere una popolazione target significa che problemi di rappresentatività sono inevitabili e devono essere affrontati.","code":""},{"path":"ch-key-notions.html","id":"variabili-e-costanti","chapter":"Capitolo 1 Concetti chiave","heading":"1.2 Variabili e costanti","text":"Una variabile è qualsiasi proprietà o descrittore che può assumere più valori (numerici o categoriali). Una variabile può essere pensata come una domanda cui il valore è la risposta. Ad esempio, “Quanti anni ha questo partecipante?” “38 anni”. Qui, “età” è la variabile e “38” è il suo valore. La probabilità che la variabile \\(X\\) assuma valore \\(x\\) si scrive \\(P(X = x)\\). Questo è spesso abbreviato \\(P(x)\\). Possiamo anche esaminare la probabilità di più valori contemporaneamente; per esempio, la probabilità che \\(X = x\\) e \\(Y = y\\) è scritta \\(P(X = x, Y = y)\\) o \\(P(x, y)\\). Si noti che \\(P(X = 38)\\) è interpretato come la probabilità che un individuo selezionato casualmente dalla popolazione abbia 38 anni. Il termine “variabile” si contrappone al termine “costante” che descrive una proprietà invariante di tutte le unità statistiche.Si dice modalità ciascuna delle varianti con cui una variabile statistica può presentarsi. Definiamo insieme delle modalità di una variabile statistica l’insieme \\(M\\) di tutte le possibili espressioni con cui la variabile può manifestarsi. Le modalità osservate e facenti parte del campione si chiamano dati (si veda la Tabella 1.1).Esempio 1.1  Supponiamo che il fenomeno studiato sia l’intelligenza. uno studio, la popolazione potrebbe corrispondere ’insieme di tutti gli italiani adulti. La variabile considerata potrebbe essere il punteggio del test standardizzato WAIS-IV. Le modalità di tale variabile potrebbero essere \\(112, 92, 121, \\dots\\). Tale variabile è di tipo quantitativo discreto.Esempio 1.2  Supponiamo che il fenomeno studiato sia il compito Stroop. La popolazione potrebbe corrispondere ’insieme dei bambini dai 6 agli 8 anni. La variabile considerata potrebbe essere il reciproco dei tempi di reazione secondi. Le modalità di tale variabile potrebbero essere \\(1.93, 2.35, 1.32, 1.49, 1.62, 2.93, \\dots\\). La variabile è di tipo quantitativo continuo.Esempio 1.3  Supponiamo che il fenomeno studiato sia il disturbo di personalità. La popolazione potrebbe corrispondere ’insieme dei detenuti nelle carceri italiane. La variabile considerata potrebbe essere l’assessment del disturbo di personalità tramite interviste cliniche strutturate. Le modalità di tale variabile potrebbero essere Cluster , Cluster B, Cluster C descritti dal DSM-V. Tale variabile è di tipo qualitativo.","code":""},{"path":"ch-key-notions.html","id":"variabili-casuali","chapter":"Capitolo 1 Concetti chiave","heading":"1.2.1 Variabili casuali","text":"Il termine variabile usato nella statistica è equivalente al termine variabile casuale usato nella teoria delle probabilità. Lo studio dei risultati degli interventi psicologici è lo studio delle variabili casuali che misurano questi risultati. Una variabile casuale cattura una caratteristica specifica degli individui nella popolazione e suoi valori variano tipicamente tra gli individui. Ogni variabile casuale può assumere teoria una gamma di valori sebbene, pratica, osserviamo un valore specifico per ogni individuo. Quando faremo riferiremo alle variabili casuali considerate termini generali useremo lettere maiuscole come \\(X\\) e \\(Y\\); quando faremo riferimento ai valori che una variabile casuale assume determinate circostanze useremo lettere minuscole come \\(x\\) e \\(y\\).","code":""},{"path":"ch-key-notions.html","id":"variabili-indipendenti-e-variabili-dipendenti","chapter":"Capitolo 1 Concetti chiave","heading":"1.2.2 Variabili indipendenti e variabili dipendenti","text":"Un primo compito fondamentale qualsiasi analisi dei dati è l’identificazione delle variabili dipendenti (\\(Y\\)) e delle variabili indipendenti (\\(X\\)). Le variabili dipendenti sono anche chiamate variabili di esito o di risposta e le variabili indipendenti sono anche chiamate predittori o covariate. Ad esempio, nell’analisi di regressione, che esamineremo seguito, la domanda centrale è quella di capire come \\(Y\\) cambia al variare di \\(X\\). Più precisamente, la domanda che viene posta è: se il valore della variabile indipendente \\(X\\) cambia, qual è la conseguenza per la variabile dipendente \\(Y\\)? parole povere, le variabili indipendenti e dipendenti sono analoghe “cause” ed “effetti”, laddove le virgolette usate qui sottolineano che questa è solo un’analogia e che la determinazione delle cause può avvenire soltanto mediante l’utilizzo di un appropriato disegno sperimentale e di un’adeguata analisi statistica.Se una variabile è una variabile indipendente o dipendente dipende dalla domanda di ricerca. volte può essere difficile decidere quale variabile è dipendente e quale è indipendente, particolare quando siamo specificamente interessati ai rapporti di causa/effetto. Ad esempio, supponiamo di indagare l’associazione tra esercizio fisico e insonnia. Vi sono evidenze che l’esercizio fisico (fatto al momento giusto della giornata) può ridurre l’insonnia. Ma l’insonnia può anche ridurre la capacità di una persona di fare esercizio fisico. questo caso, dunque, non è facile capire quale sia la causa e quale l’effetto, quale sia la variabile dipendente e quale la variabile indipendente. La possibilità di identificare il ruolo delle variabili (dipendente/indipendente) dipende dalla nostra comprensione del fenomeno esame.Esempio 1.4  Uno psicologo convoca 120 studenti universitari per un test di memoria.\nPrima di iniziare l’esperimento, metà dei soggetti viene detto che si\ntratta di un compito particolarmente difficile; agli altri soggetti non\nviene data alcuna indicazione. Lo psicologo misura il punteggio nella\nprova di memoria di ciascun soggetto.questo esperimento, la variabile indipendente è l’informazione sulla difficoltà della prova. La variabile indipendente viene manipolata dallo sperimentatore assegnando soggetti (di solito maniera causale) o alla condizione (modalità) “informazione assegnata” o “informazione non data”. La\nvariabile dipendente è ciò che viene misurato nell’esperimento, ovvero\nil punteggio nella prova di memoria di ciascun soggetto.","code":""},{"path":"ch-key-notions.html","id":"la-matrice-dei-dati","chapter":"Capitolo 1 Concetti chiave","heading":"1.2.3 La matrice dei dati","text":"Le realizzazioni delle variabili esaminate una rilevazione statistica\nvengono organizzate una matrice dei dati. Le colonne della matrice\ndei dati contengono gli insiemi dei dati individuali di ciascuna\nvariabile statistica considerata. Ogni riga della matrice contiene tutte\nle informazioni relative alla stessa unità statistica. Una generica\nmatrice dei dati ha l’aspetto seguente:\\[\nD_{m,n} =\n\\begin{pmatrix}\n  \\omega_1 & a_{1}   & b_{1}   & \\cdots & x_{1} & y_{1}\\\\\n  \\omega_2 & a_{2}   & b_{2}   & \\cdots & x_{2} & y_{2}\\\\\n  \\vdots   & \\vdots  & \\vdots  & \\ddots & \\vdots & \\vdots  \\\\\n\\omega_n  & a_{n}   & b_{n}   & \\cdots & x_{n} & y_{n}\n\\end{pmatrix}\n\\]dove, nel caso presente, la prima colonna contiene il\nnome delle unità statistiche, la seconda e la terza colonna si\nriferiscono due mutabili statistiche (variabili categoriali; \\(\\) e\n\\(B\\)) e ne presentano le modalità osservate nel campione mentre le ultime\ndue colonne si riferiscono due variabili statistiche (\\(X\\) e \\(Y\\)) e ne\npresentano le modalità osservate nel campione. Generalmente, tra le\nunità statistiche \\(\\omega_i\\) non esiste un ordine progressivo; l’indice\nattribuito alle unità statistiche nella matrice dei dati si riferisce\nsemplicemente alla riga che esse occupano.","code":""},{"path":"ch-key-notions.html","id":"parametri-e-modelli","chapter":"Capitolo 1 Concetti chiave","heading":"1.3 Parametri e modelli","text":"Ogni variabile casuale ha una distribuzione che descrive la probabilità che la variabile assuma qualsiasi valore un dato intervallo.2 Senza ulteriori specificazioni, una distribuzione può fare riferimento un’intera famiglia di distribuzioni. parametri, tipicamente indicati con lettere greche come \\(\\mu\\) e \\(\\alpha\\), ci permettono di specificare di quale membro della famiglia stiamo parlando. Quindi, si può parlare di una variabile casuale con una distribuzione Normale, ma se viene specificata la media \\(\\mu\\) = 100 e la varianza \\(\\sigma^2\\) = 15, viene individuata una specifica distribuzione Normale – nell’esempio, la distribuzione del quoziente di intelligenza.metodi statistici parametrici specificano la famiglia delle distribuzioni e quindi utilizzano dati per individuare, stimando parametri, una specifica distribuzione ’interno della famiglia di distribuzioni ipotizzata. Se \\(f\\) è la PDF di una variabile casuale \\(Y\\), l’interesse può concentrarsi sulla sua media e varianza. Nell’analisi di regressione, ad esempio, cerchiamo di spiegare come parametri di \\(f\\) dipendano dalle covariate \\(X\\). Nella regressione lineare classica, assumiamo che \\(Y\\) abbia una distribuzione normale con media \\(\\mu = \\mathbb{E}(Y)\\), e stimiamo come \\(\\mathbb{E}(Y)\\) dipenda da \\(X\\). Poiché molti esiti psicologici non seguono una distribuzione normale, verranno introdotte distribuzioni più appropriate per questi risultati. metodi non parametrici, invece, non specificano una famiglia di distribuzioni per \\(f\\). queste dispense faremo riferimento metodi non parametrici quando discuteremo della statistica descrittiva.Il termine modello è onnipresente statistica e nella data science. Il modello statistico include le ipotesi e le specifiche matematiche relative alla distribuzione della variabile casuale di interesse. Il modello dipende dai dati e dalla domanda di ricerca, ma raramente è unico; nella maggior parte dei casi, esiste più di un modello che potrebbe ragionevolmente usato per affrontare la stessa domanda di ricerca e avendo disposizione dati osservati. Nella previsione delle aspettative future dei pazienti depressi che discuteremo seguito (Zetsche, Bürkner, Renneberg 2019), ad esempio, la specifica del modello include l’insieme delle covariate candidate, l’espressione matematica che collega predittori con le aspettative future e qualsiasi ipotesi sulla distribuzione della variabile dipendente. La domanda di cosa costituisca un buon modello è una domanda su cui torneremo ripetutamente questo insegnamento.","code":""},{"path":"ch-key-notions.html","id":"effetto","chapter":"Capitolo 1 Concetti chiave","heading":"1.4 Effetto","text":"L’effetto è una qualche misura dei dati. Dipende dal tipo di dati e dal tipo di test statistico che si vuole utilizzare. Ad esempio, se viene lanciata una moneta 100 volte e esce testa 66 volte, l’effetto sarà 66/100. Diventa poi possibile confrontare l’effetto ottenuto con l’effetto nullo che ci si aspetterebbe da una moneta bilanciata (50/100), o con qualsiasi altro effetto che può essere scelto. La dimensione dell’effetto si riferisce alla differenza tra l’effetto misurato nei dati e l’effetto nullo (di solito un valore che ci si aspetta di ottenere base al caso soltanto).","code":""},{"path":"ch-key-notions.html","id":"stima-e-inferenza","chapter":"Capitolo 1 Concetti chiave","heading":"1.5 Stima e inferenza","text":"La stima è il processo mediante il quale il campione viene utilizzato per conoscere le proprietà di interesse della popolazione. La media campionaria è una stima naturale della media della popolazione e la mediana campionaria è una stima naturale della mediana della popolazione. Quando parliamo di stimare una proprietà della popolazione (volte indicata come parametro della popolazione) o di stimare la distribuzione di una variabile casuale, stiamo parlando dell’utilizzo dei dati osservati per conoscere le proprietà di interesse della popolazione. L’inferenza statistica è il processo mediante il quale le stime campionarie vengono utilizzate per rispondere domande di ricerca e per valutare specifiche ipotesi relative alla popolazione. Discuteremo le procedure bayesiane dell’inferenza nell’ultima parte di queste dispense.","code":""},{"path":"ch-key-notions.html","id":"metodi-e-procedure-della-psicologia","chapter":"Capitolo 1 Concetti chiave","heading":"1.6 Metodi e procedure della psicologia","text":"Un modello psicologico di un qualche aspetto del comportamento umano o della mente ha le seguenti proprietà:descrive le caratteristiche del comportamento questione,formula predizioni sulle caratteristiche future del comportamento,è sostenuto da evidenze empiriche,deve essere falsificabile (ovvero, linea di principio, deve\npotere fare delle predizioni su aspetti del fenomeno considerato che\nnon sono ancora noti e che, se venissero indagati, potrebbero\nportare rigettare il modello, se si dimostrassero incompatibili con\nesso).L’analisi dei dati valuta un modello psicologico utilizzando strumenti statistici.Questa dispensa è strutturata maniera tale da rispecchiare la suddivisione tra temi della misurazione, dell’analisi descrittiva e dell’inferenza. Nel prossimo Capitolo sarà affrontato il tema della misurazione e, nell’ultima parte della dispensa verrà discusso l’argomento più difficile, quello dell’inferenza. Prima di affrontare il secondo tema, l’analisi descrittiva dei dati, sarà necessario introdurre il linguaggio di programmazione statistica R (un’introduzione R è fornita Appendice). Inoltre, prima di potere discutere l’inferenza, dovranno essere introdotti concetti di base della teoria delle probabilità, quanto l’inferenza non è che l’applicazione della teoria delle probabilità ’analisi dei dati.","code":""},{"path":"chapter-misurazione.html","id":"chapter-misurazione","chapter":"Capitolo 2 La misurazione in psicologia","heading":"Capitolo 2 La misurazione in psicologia","text":"Introduco il problema della misurazione psicologia parlando dell’intelligenza. quanto psicologi, siamo abituati pensare alla misurazione dell’intelligenza, ma anche le persone che non sono psicologi sono ben familiari con la misurazione dell’intelligenza: tra le misurazioni delle caratteristiche psicologiche, infatti, la misurazione dell’intelligenza è forse la più conosciuta.test di intelligenza consistono una serie di problemi di carattere verbale, numerico o simbolico. Come ci si può aspettare, alcune persone riescono risolvere correttamente un numero maggiore di problemi di altre. Possiamo contare il numero di risposte corrette e osservare le differenze individuali nei punteggi calcolati. Scopriamo questo modo che le differenze individuali nell’abilità di risolvere tali problemi risultano sorprendentemente stabili nell’età adulta. Inoltre, diversi test di intelligenza tendono ad essere correlati positivamente: le persone che risolvono un maggior numero di problemi verbali, media, tenderanno anche risolvere correttamente un numero più grande di numerici e simbolici. Esiste quindi una notevole coerenza delle differenze osservate tra le persone, sia nel tempo sia considerando diverse procedure di test e valutazione.Avendo stabilito che ci sono differenze individuali tra le persone, è possibile esaminare le associazioni tra punteggi dei test di intelligenza e altre variabili. Possiamo indagare se le persone con punteggi più alti nei test di intelligenza, rispetto persone che ottengono punteggi più bassi, hanno più successo sul lavoro; se guadagnano di più; se votano modo diverso; o se hanno un’aspettativa di vita più alta. Possiamo esaminare le differenze nei punteggi dei test di intelligenza funzione di variabili come il genere, il gruppo etnico-razziale o lo stato socio-economico. Possiamo fare ricerche sull’associazione tra punteggi dei test di intelligenza e l’efficienza dell’elaborazione neuronale, tempi di reazione o la quantità di materia grigia ’interno della scatola cranica. Tutte queste ricerche sono state condotte e gli psicologi hanno scoperto una vasta gamma di associazioni tra le misure dell’intelligenza e altre variabili. Alcune di queste associazioni sono grandi e stabili, altre sono piccole e difficili da replicare. riferimento ’intelligenza, dunque, gli psicologi hanno condotto un enorme numero di ricerche ponendosi domande diverse. quali condizioni si verificano determinati effetti? Quali variabili mediano o moderano le relazioni tra punteggi dei test di intelligenza e altre variabili? Queste relazioni si mantengono stabili diversi gruppi di persone? Le ricerche sull’intelligenza umana sono un campo continuo sviluppo.Tuttavia, tuttavia una domanda sorge spontanea: test di intelligenza misurano davvero qualcosa e, caso affermativo, che cos’è questo qualcosa? Infatti, dopo un secolo di teoria e ricerca sui punteggi dei test di intelligenza e, generale, sui test psicologici, non sappiamo ancora con precisione cosa effettivamente questi test misurano.\nQueste considerazioni relative ai test di intelligenza ci conducono dunque alla domanda che ha motivato le precedenti considerazioni: cosa significa misurare un attributo psicologico? Questa è una domanda cui è difficile rispondere, una domanda cui è dedicata un’intera area di ricerca, quella della teoria della misurazione psicologica.Non possiamo qui entrare nel merito delle complessità formali della teoria della misurazione psicologica – questo argomento verrà approfondito nei successivi insegnamenti sulla testistica psicologica. Ci limiteremo invece presentare alcune nozioni di base su un tema centrale della teoria della misurazione psicologica: il tema delle scale delle misure psicologiche.","code":""},{"path":"chapter-misurazione.html","id":"le-scale-di-misura","chapter":"Capitolo 2 La misurazione in psicologia","heading":"2.1 Le scale di misura","text":"generale possiamo dire che la teoria della misurazione si occupa dello studio delle relazioni esistenti tra due domini: il “mondo fisico” e il “mondo psicologico”. Secondo la teoria della misurazione, la misurazione è un’attività rappresentativa, cioè è un processo di assegnazione di numeri modo tale da preservare, ’interno del dominio numerico, le relazioni qualitative che sono state osservate nel mondo empirico. La teoria della misurazione ha lo scopo di specificare le condizioni necessarie per la costruzione di una rappresentazione adeguata delle relazioni empiriche ’interno di un sistema numerico. Da una prospettiva formale, le operazioni descritte dalla teoria della misurazione possono essere concettualizzate termini di mappatura tra le relazioni esistenti ’interno di due insiemi (quello empirico e quello numerico). Il risultato di questa attività è chiamato “scala di misurazione”.Una famosa teoria delle scale di misura è stata proposta da Stevens (1946). Stevens ci fa notare che, linea di principio, le variabili psicologiche sono grado di rappresentare (preservare) con diversi gradi di accuratezza le relazioni qualitative che sono state osservate nei fenomeni psicologici. Secondo la teoria di Stevens, possiamo distinguere tra quattro scale di misura: le scale nominali (nominal scales), ordinali (ordinal scales), intervalli (interval scales), di rapporti (ratio scales). Tali scale di misura consentono operazioni aritmetiche diverse, come indicato nella tabella successiva, quanto ciasuna di esse è grado di “catturare” soltanto alcune delle proprietà dei fenomeni psicologici che intende misurare.","code":""},{"path":"chapter-misurazione.html","id":"scala-nominale","chapter":"Capitolo 2 La misurazione in psicologia","heading":"2.1.1 Scala nominale","text":"Il livello di misurazione più semplice è quello della scala nominale. Questa scala di misurazione corrisponde ad una tassonomia. simoboli o numeri che costituiscono questa scala non sono altro che nomi delle categorie che utilizziamo per classificare fenomeni psicologici. base alle misure fornite da una scala nominale, l’unica cosa che siamo grado di dire proposito di una caratteristica psicologica è se essa è uguale o ad un’altra caratteristica psicologica.La scala nominale raggruppa dunque dati categorie qualitative mutuamente esclusive (cioè nessun dato si può collocare più di una categoria).\nEsiste la sola relazione di equivalenza tra le misure delle u.s., cioè\nnella scala nominale gli elementi del campione appartenenti classi\ndiverse sono differenti, mentre tutti quelli della stessa classe sono\ntra loro equivalenti: \\(x_i = x_j\\) oppure \\(x_i \\neq x_j\\).L’unica operazione algebrica che possiamo compiere sulle modalità della scala nominale è quella di contare le u.s. che appartengono ad ogni modalità e contare il numero delle modalità (classi di equivalenza). Dunque la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.partire da una scala nominale è possibile costruire altre scale nominali che sono equivalenti alla prima trasformando valori della scala di partenza modo tale\nda cambiare nomi delle modalità, ma lasciando però inalterata la suddivisione u.s. nelle medesime classi di equivalenza. Questo significa che prendendo una variabile misurata su scala nominale e cambiando nomi delle sue categorie otteniamo una nuova variabile esattamente corrispondente alla prima.","code":""},{"path":"chapter-misurazione.html","id":"scala-ordinale","chapter":"Capitolo 2 La misurazione in psicologia","heading":"2.1.2 Scala ordinale","text":"La scala ordinale conserva la proprietà della scala nominale di classificare ciascuna u.s. ’interno di una e una sola categoria, ma alla relazione di equivalenza tra elementi di una stessa classe aggiunge la relazione di ordinamento tra le classi di equivalenza. Essendo basata su una relazione d’ordine, una scala ordinale descrive soltanto l’ordine di rango tra le modalità, ma non ci dà alcuna informazione su quanto una modalità sia più grande di un’altra. Non ci dice, per esempio, se la distanza tra le modalità \\(\\) e \\(b\\) sia uguale, maggiore o minore della distanza tra le modalità \\(b\\) e \\(c\\).Esempio 2.1  Un esempio classico di scala ordinale è quello della scala Mohs per la\ndeterminazione della durezza dei minerali. Per stabilire la durezza dei\nminerali si usa il criterio empirico della scalfittura. Vengono\nstabiliti livelli di durezza crescente da 1 10 con riferimento dieci\nminerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo,\ntopazio, corindone e diamante. Un minerale appartenente ad uno di questi\nlivelli se scalfisce quello di livello inferiore ed è scalfito da quello\ndi livello superiore.","code":""},{"path":"chapter-misurazione.html","id":"scala-ad-intervalli","chapter":"Capitolo 2 La misurazione in psicologia","heading":"2.1.3 Scala ad intervalli","text":"La scala ad intervalli include le proprietà di quella nominale e di\nquella ordinale, e più consente di misurare le distanze tra le coppie\ndi u.s. nei termini di un intervallo costante, chiamato unità di\nmisura, cui viene attribuito il valore “1”. La posizione dell’origine\ndella scala, cioè il punto zero, è scelta arbitrariamente, nel senso che\nnon indica l’assenza della quantità che si sta misurando. Avendo uno\nzero arbitrario, questa scala di misura consente valori negativi. Lo\nzero, infatti, non viene attribuito ’u.s. cui la proprietà\nmisurata risulta assente.La scala intervalli equivalenti ci consente di effettuare operazioni\nalgebriche basate sulla differenza tra numeri associati ai diversi\npunti della scala, operazioni algebriche non era possibile eseguire nel\ncaso di misure livello di scala ordinale o nominale. Il limite della\nscala ad intervalli è quello di non consentire il calcolo del rapporto\ntra coppie di misure. Possiamo dire, per esempio, che la distanza tra\n\\(\\) e \\(b\\) è la metà della distanza tra \\(c\\) e \\(d\\). Oppure che la distanza\ntra \\(\\) e \\(b\\) è uguale alla distanza tra \\(c\\) e \\(d\\). Non possiamo dire,\nperò, che \\(\\) possiede la proprietà misurata quantità doppia rispetto\n\\(b\\). Non possiamo cioè stabilire dei rapporti diretti tra le misure\nottenute. Solo per le differenze tra le modalità sono dunque permesse\ntutte le operazioni aritmetiche: le differenze possono essere tra loro\nsommate, elevate potenza oppure divise, determinando così le quantità\nche stanno alla base della statistica inferenziale.Nelle scale ad intervalli equivalenti, l’unità di misura è arbitraria,\novvero può essere cambiata attraverso una dilatazione, operazione che\nconsiste nel moltiplicare tutti valori della scala per una costante\npositiva. Poiché l’aggiunta di una costante non altera le differenze tra\nvalori della scala, è anche ammessa la traslazione, operazione che\nconsiste nel sommare una costante tutti valori della scala. Essendo\nla scala invariate rispetto alla traslazione e alla dilatazione, le\ntrasformazioni ammissibili sono le trasformazioni lineari:\\[\ny' = + , \\quad b > 0.\n\\]\nL’aspetto che rimane invariante seguito di una trasformazione lineare\nè l’uguaglianza dei rapporti fra intervalli.Esempio 2.2  Esempio di scala ad intervalli è la temperatura misurata gradi\nCelsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è\npossibile stabilire se due modalità sono uguali o diverse: 30\\(^\\circ\\)C\n\\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale è possibile mettere due\nmodalità una relazione d’ordine: 30\\(^\\circ\\)C \\(>\\) 20\\(^\\circ\\)C. \naggiunta ai casi precedenti, però, è possibile definire una unità di\nmisura per cui è possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c’è\nuna differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. valori di\ntemperatura, oltre poter essere ordinati secondo l’intensità del\nfenomeno, godono della proprietà che le differenze tra loro sono\ndirettamente confrontabili e quantificabili.Il limite della scala ad intervalli è quello di non consentire il\ncalcolo del rapporto tra coppie di misure. Ad esempio, una temperatura\ndi 80\\(^\\circ\\)C non è il doppio di una di 40\\(^\\circ\\)C. Se infatti\nesprimiamo le stesse temperature nei termini della scala Fahrenheit,\nallora due valori non saranno rapporto di 1 2 tra loro. Infatti,\n20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa\nche la relazione “il doppio di” che avevamo individuato precedenza si\napplicava ai numeri della scala centigrada, ma non alla proprietà\nmisurata (cioè la temperatura). La decisione di che scala usare\n(Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non\ndeve influenzare le inferenze che traiamo dai dati. Queste inferenze,\ninfatti, devono dirci qualcosa proposito della realtà empirica e non\npossono nessun modo essere condizionate dalle nostre scelte\narbitrarie che ci portano scegliere la scala Centigrada piuttosto che\nquella Fahrenheit.Consideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo esame, ad esempio, tre temperature:\n\\(20^\\circ C = 68^\\circ F\\),\n\\(15^\\circ C = 59^\\circ F\\),\n\\(10^\\circ C = 50 ^\\circ F\\).È facile rendersi conto del fatto che rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]","code":""},{"path":"chapter-misurazione.html","id":"scala-di-rapporti","chapter":"Capitolo 2 La misurazione in psicologia","heading":"2.1.4 Scala di rapporti","text":"Nella scala rapporti equivalenti la posizione dello zero non è\narbitraria, ma corrisponde ’elemento dotato di intensità nulla\nrispetto alla proprietà misurata. Una scala rapporti equivalenti si\ncostruisce associando il numero 0 ’elemento con intensità nulla;\nviene poi scelta un’unità di misura \\(u\\) e, ad ogni elemento, si assegna\nun numero \\(\\) definito come: \\[= \\frac{d}{u}\\] dove \\(d\\) rappresenta la\ndistanza dall’origine. Alle u.s. vengono dunque assegnati dei numeri\ntali per cui le differenze e rapporti tra numeri riflettono le\ndifferenze e rapporti tra le intensità della proprietà misurata.Operazioni aritmetiche sono possibili non solo sulle differenze tra \nvalori della scala (come per la scala intervalli equivalenti), ma\nanche sui valori stessi della scala. L’unica arbitrarietà riguarda\nl’unità di misura che si utilizza. L’unità di misura può cambiare, ma\nqualsiasi unità di misura si scelga, lo zero deve sempre indicare\nl’intensità nulla della proprietà considerata.Le trasformazioni ammissibili questo livello di scala sono dette\ntrasformazioni di similarità: \\[y' = , \\quad b > 0.\\] questo livello\ndi scala, seguito delle trasformazioni ammissibili, rimangono\ninvariati anche rapporti: \\[\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}.\\]","code":""},{"path":"chapter-misurazione.html","id":"gerarchia-dei-livelli-di-scala-di-misura","chapter":"Capitolo 2 La misurazione in psicologia","heading":"2.2 Gerarchia dei livelli di scala di misura","text":"Stevens (1946) parla di livelli di scala poiché quattro tipi di scala di\nmisura stanno una precisa gerarchia: la scala nominale rappresenta il\nlivello più basso della misurazione, la scala rapporti equivalenti è\ninvece il livello più alto.Passando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.Per ciò che riguarda le trasformazioni ammissibili, più il livello di\nscala è basso, più le funzioni sono generali (sono minori cioè vincoli\nper passare da una rappresentazione numerica ad un’altra equivalente).\nSalendo la gerarchia, la natura delle funzioni di trasformazione si fa\npiù restrittiva.","code":""},{"path":"chapter-misurazione.html","id":"variabili-discrete-o-continue","chapter":"Capitolo 2 La misurazione in psicologia","heading":"2.3 Variabili discrete o continue","text":"Le variabili livello di intervalli e di rapporti possono essere\ndiscrete o continue. Le variabili discrete possono assumere alcuni\nvalori ma non altri. Una volta che l’elenco di valori accettabili è\nstato specificato, non ci sono casi che cadono tra questi valori.\nLe variabili discrete di solito assumono valori interi.Quando una variabile può assumere qualsiasi valore entro un intervallo\nspecificato, allora si dice che la variabile è continua. teoria, ciò\nsignifica che frazioni e decimali possono essere utilizzati per\nraggiungere un livello di precisione qualsiasi. pratica, un certo\npunto dobbiamo arrotondare numeri, rendendo tecnicamente la variabile\ndiscreta. variabili veramente discrete, tuttavia, non è possibile\naumentare piacimento il livello di precisione della misurazione.Esempio 2.3  Il numero di biciclette possedute da una persona è una variabile discreta poiché tale variabile può assumere come modalità solo numeri interi non negativi. Frazioni di bicicletta non hanno senso.","code":""},{"path":"chapter-misurazione.html","id":"alcune-misure-sono-migliori-di-altre","chapter":"Capitolo 2 La misurazione in psicologia","heading":"2.4 Alcune misure sono migliori di altre","text":"psicologia, ciò che vogliamo misurare non è una caratteristica fisica, ma invece è un concetto teorico inosservabile, ovvero un costrutto. Un costrutto rappresenta il risultato di una fondata riflessione scientifica, non è per definizione accessibile ’osservazione diretta, ma viene inferito dall’osservazione di opportuni indicatori (Sartori, 2005). Ad esempio, supponiamo che un docente voglia valutare quanto bene uno studente comprenda la distinzione tra le quattro diverse scale di misura che sono state descritte sopra. Il docente potrebbe predisporre un test costituito da un insieme di domande e potrebbe contare quante domande lo studente risponde correttamente. Questo\ntest, però, può o può non essere una buona misura del costrutto relativo\nalla conoscenza effettiva delle quattro scale di misura. Per esempio, se\nil docente scrive le domande del test modo ambiguo o se usa una\nlinguaggio troppo tecnico che lo studente non conosce, allora \nrisultati del test potrebbero suggerire che lo studente non conosce la\nmateria questione anche se realtà questo non è vero. D’altra\nparte, se il docente prepara un test scelta multipla con risposte\nerrate molto ovvie, allora lo studente può ottenere dei buoni risultati\nal test anche senza essere grado di comprendere adeguatamente le\nproprietà delle quattro scale di misura. generale non è possibile misurare un costrutto senza una certa quantità di errore. Poniamoci dunque il problema di determinare che modo una misurazione possa dirsi adeguata.","code":""},{"path":"chapter-misurazione.html","id":"tipologie-di-errori","chapter":"Capitolo 2 La misurazione in psicologia","heading":"2.4.1 Tipologie di errori","text":"L’errore è, per definizione, la differenza tra il valore vero e il\nvalore misurato della grandezza esame. Gli errori sono classificati\ncome sistematici (o determinati) e casuali (o indeterminati). Gli errori\ncasuali sono fluttuazioni, eccesso o difetto rispetto al valore\nreale, delle singole determinazioni e sono dovuti alle molte variabili\nincontrollabili che influenzano ogni misura psicologica. Gli errori\nsistematici, invece, influiscono sulla misurazione sempre nello stesso\nsenso e, solitamente, per una stessa quantità (possono essere additivi o\nproporzionali).Le differenze tra le due tipologie di errori, sistematici e casuali,\nintroducono concetti di accuratezza e di precisione della misura. Una\nmisura viene definita:accurata, quando vi è un accordo tra la misura effettuata ed il\nvalore reale;precisa quando, ripetendo più volte la misura, risultati\nottenuti sono concordanti, cioè differiscono maniera irrilevante\ntra loro.La metafora del tiro bersaglio illustra la relazione tra precisione e accuratezza.\nFIGURA 2.1: Metafora del tiro al bersaglio.\nPer tenere sotto controllo l’incidenza degli errori, sono stati\nintrodotti psicologia concetti di attendibilità e validità.Uno strumento si dice attendibile quando valuta modo coerente e\nstabile la stessa variabile: risultati ottenuti si mantengono costanti\ndopo ripetute somministrazione ed assenza di variazioni psicologiche\ne fisiche dei soggetti sottoposti al test o cambiamenti dell’ambiente \ncui ha luogo la somministrazione.L’attendibilità di uno strumento, però, non è sufficiente: primo luogo uno\nstrumento di misura deve essere valido, laddove la validità rappresenta\nil grado cui uno strumento misura effettivamente ciò che dovrebbe\nmisurare. genere, si fa riferimento ad almeno quattro tipi di\nvalidità.La validità di costrutto riguarda il grado cui un test misura\nciò per cui è stato costruito. Essa si suddivide : validità\nconvergente e validità divergente. La validità convergente fa\nriferimento alla concordanza tra uno strumento e un altro che misura\nlo stesso costrutto. La validità divergente, al contrario, valuta il\ngrado di discriminazione tra strumenti che misurano costrutti\ndifferenti. Senza validità di costrutto le altre forme di validità\nnon hanno senso.base alla validità di contenuto, un test fornisce una misura\nvalida di un attributo psicologico se il dominio dell’attributo è\nrappresentato maniera adeguata dagli item del test. Un requisito\ndi base della validità di contenuto è la rilevanza e la\nrappresentatività del contenuto degli item riferimento\n’attributo che il test intende misurare.La validità di criterio valuta il grado di concordanza tra \nrisultati dello strumento considerato e risultati ottenuti da\naltri strumenti che misurano lo stesso costrutto, o tra risultati\ndello strumento considerato e un criterio esterno. Nella validità\nconcorrente, costrutto e criterio vengono misurati contestualmente,\nconsentendo un confronto immediato. Nella validità predittiva, il\ncostrutto viene misurato prima e il criterio un momento\nsuccessivo, consentendo la valutazione della capacità dello\nstrumento di predire un evento futuro.Infine, la validità di facciata fa riferimento al grado cui il\ntest appare valido ai soggetti cui esso è diretto. La validità di\nfacciata è importante ambiti particolari, quali ad esempio la\nselezione del personale per una determinata occupazione. questo\ncaso è ovviamente importante che chi si sottopone al test ritenga\nche il test vada misurare quegli aspetti che sono importanti per\nle mansioni lavorative che dovranno essere svolte, piuttosto che\naltre cose. generale, la validità di facciata non è utile, tranne\ncasi particolari.","code":""},{"path":"chapter-misurazione.html","id":"commenti-e-considerazioni-finali","chapter":"Capitolo 2 La misurazione in psicologia","heading":"Commenti e considerazioni finali","text":"Una domanda che uno psicologo spesso si pone è: “sulla base delle\nevidenze osservate, possiamo concludere dicendo che l’intervento\npsicologico è efficace nel trattamento e nella cura del disturbo?” Le\nconsiderazioni svolte questo capitolo dovrebbero farci capire che,\nprima di cercare di rispondere questa domanda con l’analisi statistica\ndei dati, devono essere affrontati problemi della validità e\ndell’attendibilità delle misure (oltre stabilire l’appropriato livello\ndi scala di misura delle osservazioni). L’attendibilità è un\nprerequisito della validità. Se gli errori di misurazione sono troppo\ngrandi, dati sono inutili. Inoltre, uno strumento di misurazione può\nessere preciso ma non valido. La validità e l’attendibilità delle\nmisurazioni sono dunque entrambe necessarie.generale, l’attendibilità e la validità delle misure devono essere\nvalutate per capire se dati raccolti da un ricercatore siano adeguati\n(1) per fornire una risposta alla domanda della ricerca, e (2) per\ngiungere alla conclusione proposta dal ricercatore alla luce dei\nrisultati dell’analisi statistica che è stata eseguita. È chiaro che le\ninformazioni fornite questo capitolo si limitano scalfire la\nsuperficie di questi problemi. concetti qui introdotti, però, devono\nsempre essere tenuti mente e costituiscono il fondamento di quanto\nverrà esposto nei capitoli successivi.","code":""},{"path":"ch-eda.html","id":"ch-eda","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"Capitolo 3 Variabili e distribuzioni di frequenza","text":"Le analisi esplorative dei dati e la statistica descrittiva costituiscono la prima fase dell’analisi dei dati psicologici. Consentono di capire come dati sono distribuiti, ci aiutano ad individuare le osservazioni anomale e gli errori di tabulazione. Consentono di riassumere le distribuzioni dei dati mediante indici sintetici. Consentono di visualizzare e di studiare le relazioni tra le variabili. questo Capitolo, dopo avere presentato gli obiettivi dell’analisi esplorative dei dati, discuteremo il problema della descrizione numerica e della rappresentazione grafica delle distribuzioni di frequenza.","code":""},{"path":"ch-eda.html","id":"chapter-descript","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.1 Introduzione all’esplorazione dei dati","text":"Le analisi esplorative dei dati sono indispensabili per condurre modo corretto una qualsiasi analisi statistica, dal livello base quello avanzato. Si parla di analisi descrittiva se l’obiettivo è quello di descrivere le caratteristiche di un campione. Si parla di analisi esplorativa dei dati (Exploratory Data Analysis o EDA) se l’obiettivo è quello di esplorare dati alla ricerca di nuove informazioni e relazioni tra variabili. Questa distinzione, seppur importante livello teorico, nella pratica è più fumosa perché spesso entrambe le situazioni si verificano contemporaneamente nella stessa indagine statistica e le metodologie di analisi che si utilizzano sono molto simili.Né il calcolo delle statistiche descrittive né l’analisi esplorativa dei dati possono essere condotte senza utilizzare un software. Le descrizioni dei concetti di base della EDA saranno dunque fornite di pari passo alla spiegazione di come le quantità discusse possono essere calcolate pratica utilizzando \\(\\mathsf{R}\\).","code":""},{"path":"ch-eda.html","id":"un-excursus-storico","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.2 Un excursus storico","text":"Nel 1907 Francis Galton, cugino di Charles Darwin, matematico e\nstatistico autodidatta, geografo, esploratore, teorico della\ndattiloscopia (ovvero, dell’uso delle impronte digitali fini\nidentificativi) e dell’eugenetica, scrisse una lettera alla rivista\nscientifica Nature sulla sua visita alla Fat Stock Poultry Exhibition di Plymouth. Lì vide alcuni membri del pubblico partecipare\nad un gioco il cui scopo era quello di indovinare il peso della carcassa\ndi un grande bue che era appena stato scuoiato. Galton si procurò 787\ndei biglietti che erano stati compilati dal pubblico e considerò il\nvalore medio di 547 kg come la “scelta democratica” dei partecipanti, \nquanto “ogni altra stima era stata giudicata troppo alta o troppo bassa\ndalla maggioranza dei votanti”. Il punto interessante è che il peso\ncorretto di 543 kg si dimostrò essere molto simile alla “scelta\ndemocratica” basata sulle stime dei 787 partecipanti. Galton intitolò la\nsua lettera Nature Vox Populi (voce del popolo), ma questo processo\ndecisionale è ora meglio conosciuto come la “saggezza delle folle”\n(wisdom crowds). Possiamo dire che, nel suo articolo del 1907,\nGalton effettuò quello che ora chiamiamo un riepilogo dei dati, ovvero\ncalcolò un indice sintetico partire da un insieme di dati. questo\ncapitolo esamineremo le tecniche che sono state sviluppate nel secolo\nsuccessivo per riassumere le grandi masse di dati con cui sempre più\nspesso ci dobbiamo confrontare. Vedremo come calcolare e interpretare\ngli indici di posizione e di dispersione, discuteremo le distribuzioni\ndi frequenze e le relazioni tra variabili. Vedremo inoltre quali sono le\ntecniche di visualizzazione che ci consentono di rappresentare questi\nsommari dei dati mediante dei grafici. Ma prima di entrare nei dettagli, prendiamoci un momento per capire perché abbiamo bisogno della statistica e, per ciò che stiamo discutendo qui, della statistica descrittiva.generale, che cos’è la statistica? Ci sono molte definizioni. Fondamentalmente, la statistica è un insieme di tecniche che ci consentono di dare un senso al mondo attraverso dati. Ciò avviene tramite il processo di analisi statistica. L’analisi statistica traduce le domande che abbiamo proposito del mondo modelli matematici, utilizza dati per scegliere modelli matematici che sono apppropriati per descrivere il mondo e, infine, applica tali modelli per trovare una risposta alle domande che ci siamo posti. La statistica consente quindi di collegare le nostre domande proposito del mondo ai dati, di utilizzare dati per trovare le risposte alle domande che ci siamo posti e di valutare l’impatto delle risposte che abbiamo trovato.","code":""},{"path":"ch-eda.html","id":"riassumere-i-dati","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.3 Riassumere i dati","text":"Iniziamo porci una domanda. Quando riassumiamo dati, necessariamente buttiamo via delle informazioni; ma è una buona idea procedere questo modo? Non sarebbe meglio conservare le informazioni specifiche di ciascun soggetto che partecipa ad un esperimento psicologico, al di là di ciò che viene trasmesso dagli indici riassuntivi della statistica descrittiva? Che dire delle informazioni che descrivono come sono stati raccolti dati, come l’ora del giorno o l’umore del partecipante? Tutte queste informazioni vengono perdute quando riassumiamo dati. La risposta alla domanda che ci siamo posti è che, generale, non è una buona idea conservare tutti dettagli di ciò che sappiamo. È molto più utile riassumere le informazioni perché la semplificazione risultante consente processi di generalizzazione.un contesto letterario, l’importanza della generalizzazione è stata\nsottolineata da Jorge Luis Borges nel suo racconto “Funes o della\nmemoria”, che descrive un individuo che perde la capacità di\ndimenticare. Borges si concentra sulla relazione tra generalizzazione e\npensiero: “Pensare è dimenticare una differenza, generalizzare, astrarre. Nel mondo troppo pieno di Funes, c’erano solo dettagli.”Come possiamo ben capire, la vita di Funes non è facile. Se facciamo\nriferimento alla psicologia possiamo dire che gli psicologi hanno\nstudiato lungo l’utilità della generalizzazione per il pensiero. Un\nesempio è fornito dal fenomeno della formazione dei concetti e lo\npsicologo che viene mente questo proposito è sicuramente Eleanor\nRosch, la quale ha studiato principi di base della categorizzazione. \nconcetti ci forniscono uno strumento potente per organizzare le\nconoscenze. Noi siamo grado di riconoscere facilmente diversi\nesemplare di un concetto – per esempio, “gli uccelli” – anche se \nsingoli esemplari che fanno parte di una categoria sono molto diversi\ntra loro (l’aquila, il gabbiano, il pettirosso). L’uso dei concetti, cioè\nla generalizzazione, è utile perché ci consente di fare previsioni sulle\nproprietà dei singoli esemplari che appartengono ad una categoria, anche\nse non abbiamo mai avuto esperienza diretta con essi – per esempio,\npossiamo fare la predizione che tutti gli uccelli possono volare e\nmangiare vermi, ma non possono guidare un’automobile o parlare \ninglese. Queste previsioni non sono sempre corrette, ma sono utili.Le statistiche descrittive, un certo senso, ci fornisco l’analogo dei\n“prototipi” che, secondo Eleanor Rosch, stanno alla base del processo\npsicologico di creazione dei concetti. Un prototipo è l’esemplare più\nrappresentativo di una categoria. maniera simile, una statistica\ndescrittiva come la media, ad esempio, potrebbe essere intesa come\nl’osservazione “tipica”.La statistica descrittiva ci fornisce gli strumenti per riassumere \ndati che abbiamo disposizione una forma visiva o numerica. Le\nrappresentazioni grafiche più usate della statistica descrittiva sono\ngli istogrammi, diagrammi dispersione o box-plot, e gli indici\nsintetici più comuni sono la media, la mediana, la varianza e la\ndeviazione standard.","code":""},{"path":"ch-eda.html","id":"i-dati-grezzi","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.4 I dati grezzi","text":"Per introdurre principali strumenti della statistica descrittiva considereremo qui dati raccolti da Zetsche, Bürkner, Renneberg (2019). Questi ricercatori hanno studiato le aspettative negative quale meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello studio, Zetsche, Bürkner, Renneberg (2019) si sono chiesti se individui depressi maturino delle aspettative accurate sul loro umore futuro, oppure se tali aspettative sono distorte negativamente.3. uno studio viene esaminato un campione costituito da 30 soggetti con almeno un episodio depressivo maggiore e da 37 controlli sani. Gli autori hanno misurato il livello depressivo con il Beck Depression Inventory (BDI-II). Questi sono dati che considereremo qui.Esercizio 3.1  Qual è la la gravità della depressione riportata dai soggetti nel campione esaminato da Zetsche, Bürkner, Renneberg (2019)?Per rispondere questa domanda, iniziamo leggere \\(\\mathsf{R}\\) dati, assumendo che il file data.mood.csv si trovi nella cartella data contenuta nella working directory.C’è un solo valore BDI-II per ciascun soggetto ma tale valore viene ripetuto tante volte quante volte sono le righe del data.frame associate ad ogni soggetto (ciascuna riga corrispondente ad una prova diversa). È dunque necessario trasformare il data.frame modo tale da avere un’unica riga per ciascun soggetto, ovvero un unico valore BDI-II per soggetto.Ci sono dunque 66 soggetti quali hanno ottenuto valori sulla scala del BDI-II stampati di seguito. Per semplicità, li presentiamo ordinati dal più piccolo al più grande.","code":"\nlibrary(\"rio\")\ndf <- rio::import(\n  here(\"data\", \"data.mood.csv\"),\n  header = TRUE\n)\nbysubj <- df %>%\n  group_by(esm_id) %>%\n  summarise(\n    bdi = mean(bdi)\n  ) %>%\n  na.omit()\nsort(bysubj$bdi)\n#>  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1\n#> [26]  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28 28 30\n#> [51] 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44"},{"path":"ch-eda.html","id":"distribuzioni-di-frequenze","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.5 Distribuzioni di frequenze","text":"È chiaro che dati grezzi sono di difficile lettura. Poniamoci dunque il problema di creare una rappresentazione sintetica e comprensibile di questo insieme di valori. Uno dei modi che ci consentono di effettuare una sintesi dei dati è quello di generare una distribuzione di frequenze.Definizione 3.1  Una distribuzione di frequenze è un riepilogo del conteggio della frequenza con cui le modalità osservate un insieme di dati si verificano un intervallo di valori.altre parole, la distribuzione di frequenze della variabile \\(X\\) corrisponde ’insieme delle frequenze assegnate ciascun possibile valore di \\(X\\).Per creare una distribuzione di frequenze possiamo procedere effettuando una partizione delle modalità della variabile di interesse \\(m\\) classi (denotate con \\(\\Delta_i\\)) tra loro disgiunte. tale partizione, la classe \\(\\)-esima coincide con un intervallo di valori aperto destra \\([a_i, b_i)\\) o aperto sinistra \\((a_i, b_i]\\). Ad ogni classe \\(\\Delta_i\\) avente \\(a_i\\) e \\(b_i\\) come limite inferiore e superiore associamo l’ampiezza \\(b_i - a_i\\) (non necessariamente uguale per ogni\nclasse) e il valore centrale \\(\\bar{x}_i\\). La scelta delle classi è arbitraria, ma è buona norma non definire classi con un numero troppo piccolo (< 5) di osservazioni. Poiché ogni elemento dell’insieme \\(\\{x_i\\}_{=1}^n\\) appartiene ad una ed una sola classe \\(\\Delta_i\\), possiamo calcolare le quantità elencate di seguito.La frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\).\nProprietà: \\(n_1 + n_2 + \\dots + n_m = n\\).\nLa frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\).Proprietà: \\(n_1 + n_2 + \\dots + n_m = n\\).La frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe.\nProprietà: \\(f_1+f_2+\\dots+f_m =1\\).\nLa frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe.Proprietà: \\(f_1+f_2+\\dots+f_m =1\\).La frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(\\)-esima compresa: \\(N_i = \\sum_{=1}^m n_i.\\)La frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(\\)-esima compresa: \\(N_i = \\sum_{=1}^m n_i.\\)La frequenza cumulata relativa \\(F_i\\), ovvero\n\\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{=1}^m f_i.\\)La frequenza cumulata relativa \\(F_i\\), ovvero\n\\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{=1}^m f_i.\\)Esercizio 3.2  Si calcoli la distribuzione di frequenza assoluta e la distribuzione di frequenza relativa per valori del BDI-II del campione clinico di Zetsche, Bürkner, Renneberg (2019).Per costruire una distribuzione di frequenza è innanzitutto necessario scegliere gli intervalli delle classi. Facendo riferimento ai cut-usati per l’interpretazione del BDI-II, definiamo seguenti intervalli aperti destra:depressione minima: [0, 13.5),depressione lieve: [13.5, 19.5),depressione moderata: [19.5, 28.5),depressione severa: [28.5, 63).Esaminando dati, possiamo notare che 36 soggetti cadono nella prima classe, uno nella seconda classe, e così via. La distribuzione di frequenza della variabile bdi2 è riportata nella tabella seguente. Questa distribuzione di frequenza ci aiuta capire meglio cosa sta succedendo. Se consideriamo la frequenza relativa, ad esempio, possiamo notare che ci sono due valori maggiormente ricorrenti e tali valori corrispondono alle due classi più estreme. Questo ha senso nel caso presente, quanto il campione esaminato da Zetsche, Bürkner, Renneberg (2019) includeva due gruppi di soggetti: soggetti sani (con valori BDI-II bassi) e soggetti depressi (con valori BDI-II alti).4 una distribuzione di frequenza tali valori tipici vanno sotto il nome di mode della distribuzione.Poniamoci ora il problema di costruire la tabella precedente utilizzando \\(\\mathsf{R}\\). Usando la funzione cut(), dividiamo il campo di variazione (ovvero, la differenza tra il valore massimo di una distribuzione ed il valore minimo) di una variabile continua x intervalli e codifica ciascun valore x nei termini dell’intervallo cui appartiene. Così facendo otteniamo:\nPossiamo ora usare la funzione table() la quale ritorna un elenco che associa la frequenza assoluta ciascuna modalità della variabile – ovvero, ritorna la distribuzione di frequenza assoluta.\nLa distribuzione di frequenza relativa si ottiene dividendo ciascuna frequenza assoluta per il numero totale di osservazioni:Insiemi di variabili possono anche avere distribuzioni di frequenze, dette distribuzioni congiunte. La distribuzione congiunta di un insieme di variabili \\(V\\) è l’insieme delle frequenze di ogni possibile combinazione di valori delle variabili \\(V\\). Ad esempio, se \\(V\\) è un insieme di due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali può assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) è \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), \\(f(X = 2, Y = 2) = 0.2\\). Proprio come con le distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare 1.","code":"\nbysubj$bdi_level <- cut(\n  bysubj$bdi,\n  breaks = c(0, 13.5, 19.5, 28.5, 63),\n  include.lowest = TRUE,\n  labels = c(\n    \"minimal\", \"mild\", \"moderate\", \"severe\"\n  )\n)\n\nbysubj$bdi_level\n#>  [1] moderate severe   severe   moderate severe   severe   severe   severe  \n#>  [9] moderate severe   moderate mild     severe   minimal  minimal  minimal \n#> [17] severe   moderate minimal  minimal  minimal  minimal  minimal  moderate\n#> [25] minimal  minimal  minimal  minimal  minimal  minimal  minimal  severe  \n#> [33] minimal  minimal  severe   minimal  moderate minimal  minimal  minimal \n#> [41] severe   minimal  minimal  severe   severe   moderate severe   severe  \n#> [49] minimal  moderate minimal  moderate severe   moderate moderate minimal \n#> [57] minimal  minimal  minimal  minimal  minimal  minimal  minimal  minimal \n#> [65] minimal  minimal \n#> Levels: minimal mild moderate severe\ntable(bysubj$bdi_level)\n#> \n#>  minimal     mild moderate   severe \n#>       36        1       12       17\ntable(bysubj$bdi_level) / sum(table(bysubj$bdi_level))\n#> \n#>    minimal       mild   moderate     severe \n#> 0.54545455 0.01515152 0.18181818 0.25757576"},{"path":"ch-eda.html","id":"istogramma","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.6 Istogramma","text":"dati che sono stati sintetizzati una distribuzione di frequenze\npossono essere rappresentati graficamente un istogramma.\nUn istogramma si costruisce riportando sulle ascisse limiti delle\nclassi \\(\\Delta_i\\) e sulle ordinate valori della funzione costante \ntratti\\[\n\\varphi_n(x)= \\frac{f_i}{b_i-a_i}, \\quad x\\\\Delta_i,\\, =1, \\dots, m\n\\]\nche misura la densità della frequenza relativa della variabile \\(X\\)\nnella classe \\(\\Delta_i\\), ovvero il rapporto fra la frequenza relativa\n\\(f_i\\) e l’ampiezza (\\(b_i - a_i\\)) della classe. questo modo il\nrettangolo dell’istogramma associato alla classe \\(\\Delta_i\\) avrà un’area\nproporzionale alla frequenza relativa \\(f_i\\). Si noti che l’area totale\ndell’istogramma delle frequenze relative è data della somma delle aree\ndei singoli rettangoli e quindi vale 1.0.Esercizio 3.3  Si utilizzi \\(\\mathsf{R}\\) per costruire un istogramma per valori BDI-II riportati da Zetsche, Bürkner, Renneberg (2019).Con quattro intervalli individuati dai cut-del BDI-II otteniamo la\nrappresentazione riportata nella figura 3.1. Per chiarezza, precisiamo che ggplot() utilizza intervalli aperti destra. Nel caso della prima barra dell’istogramma, l’ampiezza dell’intervallo è pari 13.5 e l’area della barra (ovvero, la frequenza relativa) è uguale 36/66. Dunque l’altezza della barra è uguale \\((36 / 66) / 13.5 = 0.040\\). Lo stesso procedimento si applica per il calcolo dell’altezza degli altri rettangoli.\nFIGURA 3.1: Istogramma per valori BDI-II riportati da Zetsche et al. (2019).\nAnche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale. Questo è il caso dell’istogramma della figura 3.2.\nFIGURA 3.2: Una rappresentazione più comune per l’istogramma dei valori BDI-II nella quale gli intervalli delle classi hanno ampiezze uguali.\n","code":"\nbysubj %>%\n  ggplot(aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n    breaks = c(0, 13.5, 19.5, 28.5, 44.1)\n    # il valore BDI-II massimo è 44\n  ) +\n  scale_x_continuous(\n    breaks = c(0, 13.5, 19.5, 28.5, 44.1)\n  ) +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densità di frequenza\"\n  )\nbysubj %>%\n  ggplot(aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n    breaks = seq(0, 44.1, length.out = 7)\n  ) +\n  scale_x_continuous(\n    breaks = c(0.00, 7.35, 14.70, 22.05, 29.40, 36.75, 44.10)\n  ) +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densità di frequanza\"\n  )"},{"path":"ch-eda.html","id":"kernel-density-plot","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.7 Kernel density plot","text":"Il confronto tra le figure 3.1 e 3.2 rende chiaro il limite dell’istogramma: il profilo dell’istogramma è arbitrario, quanto dipende dal numero e dall’ampiezza delle classi. Questo rende difficile l’interpretazione.Il problema precedente può essere alleviato utilizzando una rappresentazione alternativa della distribuzione di frequenza, ovvero la stima della densità della frequenza dei dati (detta anche stima kernel di densità). Un modo semplice per pensare tale rappresentazione, che inglese va sotto il nome di kernel density plot (cioè grafici basati sulla stima kernel di densità), è quello di immaginare un grande campione di dati, modo che diventi possibile definire un enorme numero di classi di equivalenza di ampiezza molto piccola, le quali non risultino vuote. tali circostanze, la funzione di densità empirica non è altro che il profilo lisciato dell’istogramma. La stessa idea si applica anche quando il campione è piccolo. tali circostanze, invece di raccogliere le osservazioni barre come negli istogrammi, lo stimatore di densità kernel colloca una piccola “gobba” (bump), determinata da un fattore \\(K\\) (kernel) e da un parametro \\(h\\) di smussamento detto ampiezza di banda (bandwidth), corrispondenza di ogni osservazione, quindi somma le gobbe risultanti generando una curva smussata.L’interpretazione che possiamo attribuire al kernel density plot è simile quella che viene assegnata agli istogrammi: l’area sottesa al kernel density plot un certo intervallo rappresenta la proporzione di casi della distribuzione che hanno valori compresi quell’intervallo.Esercizio 3.4  ’istogramma dei valori BDI-II di Zetsche, Bürkner, Renneberg (2019) si sovrapponga un kernel density plot.\nFIGURA 3.3: Kernel density plot e corrispondente istogramma per valori BDI-II.\n","code":"\nbysubj %>%\n  ggplot(aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n    breaks = seq(0, 44.1, length.out = 7)\n  ) +\n  geom_density(\n    aes(x = bdi),\n    adjust = 0.5,\n    size = 0.8,\n    #fill = colors[2],\n    alpha = 0.5\n  ) +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densità di frequenza\"\n  )"},{"path":"ch-eda.html","id":"forma-di-una-distribuzione","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.8 Forma di una distribuzione","text":"generale, la forma di una distribuzione descrive come dati si distribuiscono intorno ai valori centrali. Distinguiamo tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali o multimodali. Un’illustrazione grafica è fornita nella figura 3.4. Nel pannello 1 la distribuzione è unimodale con asimmetria negativa; nel pannello 2 la distribuzione è unimodale con asimmetria positiva; nel pannello 3 la distribuzione è simmetrica e unimodale; nel pannello 4 la distribuzione è bimodale.\nFIGURA 3.4: 1: Asimmetria negativa. 2: Asimmetria positiva. 3: Distribuzione unimodale. 4: Distribuzione bimodale.\nEsercizio 3.5  Il kernel density plot della figura 3.3 indica che la distribuzione dei valori del BDI-II nel campione di Zetsche, Bürkner, Renneberg (2019) è bimodale. Ciò indica che le osservazioni della distribuzione si addensano due cluster ben distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l’altro gruppo tende ad avere BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche, Bürkner, Renneberg (2019).","code":""},{"path":"ch-eda.html","id":"indici-di-posizione","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.9 Indici di posizione","text":"Nuovamente, se preferite un’introduzione “soft” alla nozione di “tendenza centrale” di una distribuzione statistica, vi rimando nuovamentew al link che ho già suggerito precedenza.","code":""},{"path":"ch-eda.html","id":"quantili","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.9.1 Quantili","text":"La descrizione della distribuzione dei valori BDI-II di\nZetsche, Bürkner, Renneberg (2019) può essere facilitata dalla determinazione di\nalcuni valori caratteristici che sintetizzano le informazioni contenute\nnella distribuzione di frequenze. Si dicono quantili (o frattili)\nquei valori caratteristici che hanno le seguenti proprietà. quartili\nsono quei valori che ripartiscono dati \\(x_i\\) quattro parti\nugualmente numerose (pari ciascuna al 25% del totale). Il primo\nquartile, \\(q_1\\), lascia alla sua sinistra il 25% del campione pensato\ncome una fila ordinata (destra quindi il 75%). Il secondo quartile\n\\(q_2\\) lascia sinistra il 50% del campione (destra quindi il 50%).\nEsso viene anche chiamato mediana. Il terzo quartile lascia sinistra\nil 75% del campione (destra quindi il 25%). Secondo lo stesso\ncriterio, si dicono decili quantili di ordine \\(p\\) multiplo di 0.10 e\npercentili quantili di ordine \\(p\\) multiplo di 0.01.Come si calcolano quantili? Consideriamo la definizione di quantile non interpolato di ordine \\(p\\) \\((0 < p < 1)\\). Si procede innanzitutto\nordinando dati ordine crescente, \\(\\{x_1, x_2, \\dots, x_n\\}\\). Ci\nsono poi due possibilità. Se il valore \\(np\\) non è intero, sia \\(k\\)\nl’intero tale che \\(k < np < k + 1\\) – ovvero, la parte intera di \\(np\\).\nAllora \\(q_p = x_{k+1}.\\) Se \\(np = k\\) con \\(k\\) intero, allora\n\\(q_p = \\frac{1}{2}(x_{k} + x_{k+1}).\\) Se vogliamo calcolare il primo\nquartile \\(q_1\\), ad esempio, utilizziamo \\(p = 0.25\\). Dovendo calcolare\ngli altri quantili basta sostituire \\(p\\) il valore appropriato.Gli indici di posizione, tra le altre cose, hanno un ruolo importante,\novvero vengono utilizzati per creare una rappresentazione grafica di una\ndistribuzione di valori che è molto popolare e può essere usata \nalternativa ad un istogramma (realtà vedremo poi come possa essere\ncombinata con un istogramma). Tale rappresentazione va sotto il nome di\nbox-plot.Esercizio 3.6  Per fare un esempio, consideriamo nove soggetti del campione clinico di Zetsche, Bürkner, Renneberg (2019) che hanno riportato un unico episodio di depressione maggiore. Per tali soggetti valori ordinati del BDI-II (per semplicità li chiameremo \\(x\\)) sono seguenti: 19, 26, 27, 28, 28, 33, 33, 41, 43.\nPer il calcolo del secondo quartile (non interpolato), ovvero per il calcolo della mediana, dobbiamo considerare la quantità \\(np = 9 \\cdot 0.5 = 4.5\\), non intero. Quindi, \\(q_1 = x_{4 + 1} = 27\\).\nPer il calcolo del quantile (non interpolato) di ordine \\(p = 2/3\\) dobbiamo considerare la quantità \\(np = 9 \\cdot 2/3 = 6\\), intero. Quindi, \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).","code":""},{"path":"ch-eda.html","id":"diagramma-a-scatola","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.9.2 Diagramma a scatola","text":"Il diagramma scatola (o box plot) è uno strumento grafico utile al\nfine di ottenere informazioni circa la dispersione e l’eventuale\nsimmetria o asimmetria di una distribuzione. Per costruire un box-plot\nsi rappresenta sul piano cartesiano un rettangolo (cioè la “scatola”) di\naltezza arbitraria la cui base corrisponde alla dist intanza\ninterquartile (IQR = \\(q_{0.75} - q_{0.25}\\)). La linea interna alla\nscatola rappresenta la mediana \\(q_{0.5}\\). Si tracciano poi ai lati della\nscatola due segmenti di retta cui estremi sono detti “valore\nadiacente” inferiore e superiore. Il valore adiacente inferiore è il\nvalore più piccolo tra le osservazioni che risulta maggiore o uguale al\nprimo quartile meno la distanza corrispondente 1.5 volte la distanza\ninterquartile. Il valore adiacente superiore è il valore più grande tra le osservazioni che risulta minore o uguale \\(Q_3+1.5\\) IQR. valori esterni ai valori adiacenti (chiamati valori anomali) vengono rappresentati individualmente nel box-plot per meglio evidenziarne la presenza e la posizione.\nFIGURA 3.5: Box-plot: \\(M\\) è la mediana, \\(\\bar{x}\\) è la media aritmetica e IQR è la distanza interquartile (\\(Q_3 - Q_1\\)).\nEsercizio 3.7  Per dati di Zetsche, Bürkner, Renneberg (2019), si utilizzi un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.Nella figura 3.6 sinistra sono rappresentati dati grezzi. La linea curva che circonda (simmetricamente) le osservazioni è l’istogramma lisciato (kernel density plot) che abbiamo descritto precedenza. Nella figura 3.6 destra sono rappresentanti gli stessi dati: il kernel density plot è lo stesso di prima, ma al suo interno è stato collocato un box-plot. Entrambe le rappresentazioni suggeriscono che la distribuzione dei dati è ’incirca simmetrica nel gruppo clinico. Il gruppo di controllo mostra invece un’asimmetria positiva.\nFIGURA 3.6: Due versioni di un violin plot per valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al. (2019).\n","code":"\nbysubj <- df %>%\n  group_by(esm_id, group) %>%\n  summarise(\n    bdi = mean(bdi),\n    nr_of_episodes = mean(nr_of_episodes, na.rm = TRUE)\n  ) %>%\n  na.omit() %>%\n  ungroup()\n\nbysubj$group <- forcats::fct_recode(\n  bysubj$group,\n  \"Controlli\\n sani\" = \"ctl\",\n  \"Depressione\\n maggiore\" = \"mdd\"\n)\n\np1 <- bysubj %>%\n  ggplot(aes(x = group, y = bdi)) +\n  geom_violin(trim = FALSE) +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\", dotsize = 0.7) +\n  labs(\n    x = \"\",\n    y = \"BDI-II\"\n  )\np2 <- bysubj %>%\n  ggplot(aes(x = group, y = bdi)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.05) +\n  labs(\n    x = \"\",\n    y = \"BDI-II\"\n  )\np1 + p2"},{"path":"ch-eda.html","id":"sina-plot","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.9.3 Sina plot","text":"Si noti che box plot non sono necessariamente la rappresentazione migliore della distribuzione di una variabile. Infatti, richiedono la comprensione di concetti complessi (quali quantili e la differenza interquantile) che non sono necessari se vogliamo presentare maniera grafica la distribuzione della variabile e, generale, non sono compresi da un pubblico di non specialisti. Inoltre, box plot nascondono informazioni che di solito sono cruciali da vedere. È dunque preferibile presentare direttamente dati.Nella figura 3.7 viene presentato un cosiddetto “sina plot”. tale rappresentazione grafica vengono mostrate le singole osservazioni divise classi. Ai punti viene aggiunto un jitter, così da evitare sovrapposizioni. L’ampiezza del jitter lungo l’asse \\(x\\) è determinata dalla distribuzione della densità dei dati ’interno di ciascuna classe; quindi il grafico mostra lo stesso contorno di un violin plot, ma trasmette informazioni sia sul numero di punti dati, sia sulla distribuzione della densità, sui valori anomali e sulla distribuzione dei dati un formato molto semplice, comprensibile e sintetico.Esercizio 3.8  Si generi un sina plot per dati della figura 3.6. Si aggiunga alla figura una rappresentazione della mediana.\nFIGURA 3.7: Sina plot per valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al. (2019) con l’indicazione della mediana per ciascun gruppo.\nPer un esempio una recente pubblicazione, possiamo considerare le figure 3 e 6 di Lazic, Semenova, Williams (2020).","code":"\nzetsche_summary <- bysubj %>%\n  group_by(group) %>%\n  summarize(\n    bdi_mean = mean(bdi),\n    bdi_sd = sd(bdi),\n    bdi_median = median(bdi)\n  ) %>%\n  ungroup()\n\nbysubj %>%\n  ggplot(\n    aes(x = group, y = bdi, color = group)\n  ) +\n  ggforce::geom_sina(aes(color = group, size = 1, alpha = .5)) +\n  geom_errorbar(\n    aes(y = bdi_median, ymin = bdi_median, ymax = bdi_median),\n    data = zetsche_summary, width = 0.3, size = 1\n  ) +\n  labs(\n    x = \"\",\n    y = \"BDI-II\",\n    color = \"Gruppo\"\n  ) +\n  theme(legend.position = \"none\") +\n  scale_colour_grey(start = 0.7, end = 0)"},{"path":"ch-eda.html","id":"leccellenza-grafica","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"3.9.4 L’eccellenza grafica","text":"Non c’è un unico modo “corretto” per la rappresentazione grafica dei dati. Ciascuno dei grafici che abbiamo discusso precedenza ha suoi pregi e suoi difetti. Un ricercatore che ha molto influenzato il modo cui viene realizzata la visualizzazione dei dati scientifici è Edward Tufte, soprannominato dal New York Times il “Leonardo da Vinci dei dati.” Secondo Tufte, “l’eccellenza nella grafica consiste nel comunicare idee complesse modo chiaro, preciso ed efficiente”. Nella visualizzazione delle informazioni, l’“eccellenza grafica” ha l’obiettivo di comunicare al lettore il maggior numero di idee nella maniera più diretta e semplice possibile. Secondo Tufte (2001), le rappresentazioni grafiche dovrebbero:mostrare dati;indurre l’osservatore riflettere sulla sostanza piuttosto che\nsulla progettazione grafica, o qualcos’altro;evitare di distorcere quanto dati stanno comunicando (“integrità\ngrafica”);presentare molte informazioni forma succinta;rivelare la coerenza tra le molte dimensioni dei dati;incoraggiare l’osservatore confrontare differenti sottoinsiemi di dati;rivelare dati diversi livelli di dettaglio, da una visione ampia\nalla struttura di base;servire ad uno scopo preciso (descrizione, esplorazione, o la\nrisposta qualche domanda);essere fortemente integrate con le descrizioni statistiche e verbali\ndei dati fornite nel testo.base questi principi, figura 3.7 sembra fornire la\nrappresentazione migliore dei dati di @zetschefuture2019. Il seguente link fornisce diverse interessanti illustrazioni dei principi elencati sopra.","code":""},{"path":"ch-eda.html","id":"commenti-e-considerazioni-finali-1","chapter":"Capitolo 3 Variabili e distribuzioni di frequenza","heading":"Commenti e considerazioni finali","text":"Una distribuzione è una rappresentazione del modo cui le diverse modalità di una variabile \\(X\\) si distribuiscono nelle unità statistiche che compongono il campione o la popolazione oggetto di studio. Il modo più diretto per trasmettere descrivere le proprietà della distribuzione di una variabile discreta è quello di fornire una rappresentazione grafica della distribuzione di frequenza. seguito vedremo la corrispondente rappresentazione che viene usata nel caso delle variabili continue.","code":""},{"path":"ch-loc-scale.html","id":"ch-loc-scale","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"Capitolo 4 Indici di posizione e di scala","text":"L’analisi grafica, esaminata precedenza, costituisce la base di partenza di qualsivoglia analisi quantitativa dei dati. Tramite opportune rappresentazioni grafiche possiamo individuare alcune caratteristiche importanti di una distribuzione: per esempio, è possibile capire se la distribuzione è simmetrica o asimmetrica; oppure se è unimodale o multimodale. Successivamente, possiamo calcolare degli indici numerici che descrivono modo sintetico le caratteristiche di base dei dati esaminati.","code":""},{"path":"ch-loc-scale.html","id":"indici-di-tendenza-centrale","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.1 Indici di tendenza centrale","text":"Tra le misure di tendenza centrale, ovvero tra gli indici che forniscono un’idea dei valori attorno ai quali sono prevalentemente concentrati dati di un campione, quella più comunemente usata è la media.","code":""},{"path":"ch-loc-scale.html","id":"media","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.1.1 Media","text":"Tutti conosciamo la media aritmetica di \\(\\{x_1, x_2, \\dots, x_n\\}\\), ovvero il numero reale \\(\\bar{x}\\) definito da\\[\\begin{equation}\n\\bar{x}=\\frac{1}{n}\\sum_{=1}^n x_i.\n\\tag{4.1}\n\\end{equation}\\]Nella (4.1) abbiamo usato la notazione delle sommatorie per descrivere una somma di valori. Questa notazione è molto usata statistica e viene descritta Appendice.La media gode della seguente importante proprietà: la somma degli scarti tra ciascuna modalità \\(x_i\\) e la media aritmetica \\(\\bar{x}\\) è nulla, cioè\\[\\begin{equation}\n\\sum_{=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\label{eq:diffmeansumzero}\n\\end{equation}\\]Infatti,\\[\n\\begin{aligned}\n\\sum_{=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]Ciò ci consente di pensare alla media come al baricentro della distribuzione.Un’altra proprietà della media è la seguente. La somma dei quadrati degli scarti tra ciascuna modalità \\(x_i\\) e una costante arbitraria \\(\\), cioè\\[\\begin{equation}\n\\varphi() = \\sum_{=1}^n (x_i - )^2,\\notag\n\\end{equation}\\]è minima per \\(= \\bar{x}\\).Osservazione. Il concetto statistico di media ha suscitato molte battute. Per esempio,\nil fatto che, media, ciascuno di noi ha un numero di gambe circa pari\n1.9999999. Oppure, il fatto che, media, ciascuno di noi ha un\ntesticolo. Ma la media ha altri problemi, oltre al fatto di ispirare\nbattute simili alle precedenti. particolare, dobbiamo notare che la\nmedia non è sempre l’indice che meglio rappresenta la tendenza centrale\ndi una distribuzione. particolare, ciò non accade quando la\ndistribuzione è asimmetrica, o presenza di valori anomali (outlier)\n– si veda il pannello di destra della figura 3.6. tali circostanze, la tendenza centrale della distribuzione è meglio rappresentata dalla mediana o dalla media spuntata.Esercizio 4.1  Si calcoli la media dei valori BDI-II per due gruppi di soggetti di Zetsche, Bürkner, Renneberg (2019).","code":"\ndf <- rio::import(\n  here(\"data\", \"data.mood.csv\"),\n  header = TRUE\n)\nbysubj <- df %>%\n  group_by(group, esm_id) %>%\n  summarise(\n    bdi = mean(bdi)\n  ) %>%\n  na.omit()\nbysubj %>%\n  group_by(group) %>%\n  summarise(\n    avg_bdi = mean(bdi)\n  )\n#> # A tibble: 2 × 2\n#>   group avg_bdi\n#>   <chr>   <dbl>\n#> 1 ctl      1.61\n#> 2 mdd     30.9"},{"path":"ch-loc-scale.html","id":"media-spuntata","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.1.2 Media spuntata","text":"La media spuntata \\(\\bar{x}_t\\) (trimmed mean) non è altro che la\nmedia dei dati calcolata considerando solo il 90% (o altra percentuale)\ndei dati centrali. Per calcolare \\(\\bar{x}_t\\) si ordinando dati secondo\nuna sequenza crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), per\npoi eliminare il primo 5% e l’ultimo 5% dei dati della serie così\nordinata. La media spuntata è data dalla media aritmetica dei dati rimanenti.Esercizio 4.2  Si calcoli la media spuntata dei valori BDI-II per due gruppi di soggetti di Zetsche, Bürkner, Renneberg (2019) escludendo il 10% dei valori più estremi ciascun gruppo.","code":"\nbysubj %>%\n  group_by(group) %>%\n  summarise(\n    avg_trim_bdi = mean(bdi, trim = 0.1)\n  )\n#> # A tibble: 2 × 2\n#>   group avg_trim_bdi\n#>   <chr>        <dbl>\n#> 1 ctl            1  \n#> 2 mdd           30.6"},{"path":"ch-loc-scale.html","id":"moda-e-mediana","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.1.3 Moda e mediana","text":"precedenza abbiamo già incontrato altri due popolari indici di\ntendenza centrale: la moda (Mo), ovvero il valore centrale della\nclasse con la frequenza massima (può succedere che una distribuzione\nabbia più mode; tal caso si dice multimodale e questo operatore\nperde il suo significato di indice di tendenza centrale) e la mediana\n\\(\\tilde{x}\\).Esercizio 4.3  Si calcolino quantili di ordine 0.25, 0.5 e 0.75 dei valori BDI-II per due gruppi di soggetti di Zetsche, Bürkner, Renneberg (2019).Osservazione. Si noti che solitamente software restituiscono un valore interpolato del \\(p\\)-esimo quantile \\(q_p\\) \\((0 < p < 1)\\), il quale viene calcolato mediante specifiche procedure. Il risultato fornito dai software, dunque, non sarà identico quello trovato utilizzando la definizione non interpolata di quantile che abbiamo presentato qui. Se, per qualche ragione, vogliamo conoscere l’algoritmo usato per la determinazione dei quantili interpolati, dobbiamo leggere la documentazione del software.","code":"\nbysubj %>%\n  group_by(group) %>%\n  summarise(\n    q25 = quantile(bdi, probs = 0.25),\n    q50 = quantile(bdi, probs = 0.50),\n    q75 = quantile(bdi, probs = 0.75)\n  )\n#> # A tibble: 2 × 4\n#>   group   q25   q50   q75\n#>   <chr> <dbl> <dbl> <dbl>\n#> 1 ctl       0     1     2\n#> 2 mdd      26    30    35"},{"path":"ch-loc-scale.html","id":"indici-di-dispersione","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.2 Indici di dispersione","text":"Le medie e gli indici di posizione descritti precedenza forniscono\ndelle sintesi dei dati che mettono evidenza la tendenza centrale\ndelle osservazioni. Tali indici, tuttavia, non considerano un aspetto\nimportante della distribuzione dei dati, ovvero la variabilità dei\nvalori numerici della variabile statistica. È dunque necessario\nsintetizzare la distribuzione di una variabile statistica oltre che con\nle misure di posizione anche tramite l’utilizzo di indicatori che\nvalutino la dispersione delle unità statistice.Osservazione. Un’introduzione “soft” al tema degli indici di posizione è fornita nel seguente link.","code":""},{"path":"ch-loc-scale.html","id":"indici-basati-sullordinamento-dei-dati","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.2.1 Indici basati sull’ordinamento dei dati","text":"È possibile calcolare degli indici di variabilità basati\nsull’ordinamento dei dati. L’indice più ovvio è l’intervallo di\nvariazione, ovvero la distanza tra il valore massimo e il valore minimo\ndi una distribuzione di modalità, mentre precedenza abbiamo già\nincontrato la differenza interquartile. Questi due indici, però, hanno\nil limite di essere calcolati sulla base di due soli valori della\ndistribuzione (\\(x_{\\text{max}}\\) e \\(x_{\\text{mini}}\\), oppure \\(x_{0.25}\\) e\n\\(x_{0.75}\\)). Pertanto non utilizzano tutte le informazioni che sono\ndisponibili. Inoltre, l’intervallo di variazione ha il limite di essere\npesantemente influenzato dalla presenza di valori anomali.","code":""},{"path":"ch-loc-scale.html","id":"varianza","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.2.2 Varianza","text":"Dati limiti delle statistiche precedenti è più comune misurare la variabilità di una variabile statistica come la dispersione dei dati attorno ad un indice di tendenza centrale. Infatti, la misura di variabilità di gran lunga più usata per valutare la variabilità di una variabile statistica è senza dubbio la varianza. La varianza\\[\\begin{equation}\ns^2 = \\frac{1}{n} \\sum_{=1}^n (x_i - \\bar{x})^2\n\\tag{4.2}\n\\end{equation}\\]è la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione. La varianza è una misura di dispersione più complessa di quelle esaminate precedenza. È appropriata solo nel caso di distribuzioni simmetriche e, anch’essa, è fortemente influenzata dai valori anomali. Inoltre, è espressa un’unità di misura che è il quadrato dell’unità di misura dei dati originari e quindi ad essa non può essere assegnata un’interpretazione intuitiva.Esercizio 4.4  Si calcoli la varianza dei valori BDI-II per dati di Zetsche, Bürkner, Renneberg (2019).Applicando la formula precedente, per tutto il campione abbiamo","code":"\nvar(bysubj$bdi)\n#> [1] 239.8732"},{"path":"ch-loc-scale.html","id":"precisione","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.2.3 Precisione","text":"Si definisce precisione l’inverso della varianza:\\[\\begin{equation}\n\\tau = \\frac{1}{\\sigma^2}.\n\\tag{4.3}\n\\end{equation}\\]Alcuni ritengono che la precisione sia più “intuitiva” della varianza perché dice quanto sono concentrati valori attorno alla media piuttosto che quanto sono dispersi. altri termini, si potrebbe argomentare che siamo più interessati quanto sia precisa una misurazione piuttosto che quanto sia imprecisa. Più sono dispersi valori attorno alla media (alta varianza), meno sono precisi (poca precisione); minore è la varianza, maggiore è la precisione.La precisione è uno dei due parametri naturali della distribuzione gaussiana. Nei termini della (4.3), la distribuzione gaussiana (si veda il Capitolo ??) può essere espressa nel modo seguente\\[\n{\\displaystyle f(y)=\\sqrt{\\frac{\\tau}{2\\pi}} e^{-{\\frac {1}{2}}\\tau\\left({y-\\mu }\\right)^{2}}},\n\\]\nanziché come\\[\n{\\displaystyle f(y)={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {y-\\mu }{\\sigma }}\\right)^{2}}}.\n\\]","code":""},{"path":"ch-loc-scale.html","id":"scarto-tipo","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.2.4 Scarto tipo","text":"Per le ragioni espresse sopra, la misura più usata della dispersione di una distribuzione di dati è lo scarto quadratico medio (o scarto tipo, o deviazione standard), ovvero la radice quadrata della varianza5. differenza della varianza, dunque, lo scarto tipo è espresso nella stessa unità di misura dei dati. Come nel caso della varianza, anche lo scarto tipo \\(s\\) dovrebbe essere usato soltanto quando la media è adeguata per misurare il centro della distribuzione, ovvero, nel caso di distribuzioni simmetriche. Come nel caso della media \\(\\bar{x}\\), anche lo scarto tipo è fortemente influenzato dai dati anomali (outlier), ovvero dalla presenza di uno o di pochi dati che sono molto più distanti dalla media rispetto agli altri valori della distribuzione. Quando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s > 0\\).Allo scarto tipo può essere assegnata una semplice interpretazione: lo scarto tipo è simile (ma non identico) allo scarto semplice medio campionario, ovvero alla media aritmetica dei valori assoluti degli scarti dalla media. Lo scarto tipo ci dice, dunque, quanto sono distanti, media, le singole osservazioni dal centro della distribuzione. Un’interpretazione più precisa del significato dello scarto tipo è fornita nel Paragrafo successivo.Esercizio 4.5  Si calcoli lo scarto tipo per valori BDI-II di dati di Zetsche, Bürkner, Renneberg (2019).Applicando la formula precedente, per tutto il campione abbiamo","code":"\nsd(bysubj$bdi)\n#> [1] 15.48784"},{"path":"ch-loc-scale.html","id":"deviazione-mediana-assoluta","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.2.5 Deviazione mediana assoluta","text":"Una misura robusta della dispersione statistica di un campione è la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana, ovvero:\\[\n{\\displaystyle \\operatorname {MAD} =\\operatorname {median} \\left(\\ \\left|X_{}-\\operatorname {median} (X)\\right|\\ \\right)}\n\\]\nNel caso di una distribuzione dei dati unimodale simmetrica di forma campanulare (ovvero, normale) si ha che\\[\n{\\displaystyle \\text{deviazione standard} \\approx 1.4826\\ \\operatorname {MAD} .\\,}\n\\]\nPertanto, solitamente software restituiscono il valore MAD moltiplicato per una tale costante.Esercizio 4.6  Si calcoli il valore MAD per valori BDI-II riportati da Zetsche, Bürkner, Renneberg (2019).Applicando la formula precedente, per tutto il campione abbiamoNel caso presente, dati seguono una distribuzione bimodale, dunque \\(1.4826\\ \\operatorname {MAD}\\) produce un valore piuttosto diverso dalla deviazione standard.","code":"\n1.4826 * median(abs(bysubj$bdi - median(bysubj$bdi)))\n#> [1] 8.8956"},{"path":"ch-loc-scale.html","id":"indici-di-variabilità-relativi","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"4.2.6 Indici di variabilità relativi","text":"volte può essere interessante effettuare un confronto fra due misure di variabilità di grandezze incommensurabili, ovvero di caratteri rilevati mediante differenti unità di misura. questi casi, le misure di variabilità precedentemente descritte si rivelano inadeguate quanto dipendono dall’unità di misura adottata. Diventa dunque necessario ricorrere particolari numeri adimensionali detti indici relativi di variabilità. Il più importante di tali indici è il coefficiente di variazione, ovvero il numero puro\\[\nC_v = \\frac{\\sigma}{\\bar{x}}\n\\]\nottenuto dal rapporto tra la deviazione standard e la media dei dati. Un altro indice relativo di variabilità è la differenza interquartile rapportata al primo quartile oppure al terzo quartile oppure alla mediana, cioè:\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]","code":""},{"path":"ch-loc-scale.html","id":"commenti-e-considerazioni-finali-2","chapter":"Capitolo 4 Indici di posizione e di scala","heading":"Commenti e considerazioni finali","text":"Le statistiche descrittive ci forniscono degli indici sintetici che riassumono dati, ovvero le nostre misurazioni dell’intera popolazione o di un campione estratto da una popolazione. Le statistiche descrittive comprendono gli indici di tendenza centrale e gli indici di dispersione. Gli indici di tendenza centrale includono la media, la mediana e la moda, mentre gli indici di dispersione includono lo scarto tipo, la varianza, la curtosi e l’asimmetria.","code":""},{"path":"ch-corr.html","id":"ch-corr","chapter":"Capitolo 5 Le relazioni tra variabili","heading":"Capitolo 5 Le relazioni tra variabili","text":"Nella loro ricerca, Zetsche, Bürkner, Renneberg (2019) hanno misurato il livello di depressione dei soggetti utilizzando due scale psicometriche: il Beck Depression Inventory II (BDI-II) e la Center Epidemiologic Studies Depression Scale (CES-D). Il BDI-II è uno strumento self-report che valutare la presenza e l’intensità di sintomi depressivi pazienti adulti e adolescenti di almeno 13 anni di età con diagnosi psichiatrica\nmentre la CES-D è una scala self-report progettata per misurare \nsintomi depressivi che sono stati vissuti nella settimana precedente\nnella popolazione generale, specialmente quella degli\nadolescenti/giovani adulti. Una domanda ovvia che ci può venire \nmente è: quanto sono simili le misure ottenute mediante queste due\nscale?È chiaro che numeri prodotti dalle scale BDI-II e CES-D non possono\nessere identici, e questo per due motivi: (1) la presenza degli errori\ndi misurazione e (2) l’unità di misura delle due variabili. L’errore di\nmisurazione corrompe sempre, almeno parte, qualunque operazione di\nmisurazione. E questo è vero specialmente psicologia dove\nl’attendibilità degli strumenti di misurazione è minore che altre\ndiscipline (quali la fisica, ad esempio). Il secondo motivo per cui \nvalori delle scale BDI-II e CES-D non possono essere uguali è che\nl’unità di misura delle due scale è arbitraria. Infatti, qual è l’unità\ndi misura della depressione? Chi può dirlo! Ma, al di là delle\ndifferenze derivanti dall’errore di misurazione e dalla differente unità\ndi misura, ci aspettiamo che, se le due scale misurano entrambe lo\nstesso costrutto, allora valori prodotti dalle due scale dovranno\nessere tra loro linearmente associati. Per capire cosa si intende con\n“associazione lineare” iniziamo guardare dati. Per fare questo\nutilizziamo una rappresentazione grafica che va sotto il nome di\ndiagramma dispersione.","code":""},{"path":"ch-corr.html","id":"diagramma-a-dispersione","chapter":"Capitolo 5 Le relazioni tra variabili","heading":"5.1 Diagramma a dispersione","text":"Il diagramma di dispersione è la rappresentazione grafica delle coppie di punti individuati da due variabili \\(X\\) e \\(Y\\).Per fare un esempio concreto, consideriamo le variabili BDI-II e CES-D di Zetsche, Bürkner, Renneberg (2019). Il diagramma di dispersione per tali variabili si ottiene ponendo, ad esempio, valori BDI-II sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate. tale grafico, fornito dalla figura 5.1, cascun punto corrisponde ad un individuo del quale, nel caso presente, conosciamo il livello di depressione misurato dalle due scale psicometriche.Dalla figura 5.1 possiamo vedere che dati mostrano una tendenza disporsi attorno ad una retta – nel gergo statistico, questo fatto viene espresso dicendo che punteggi CES-D tendono ad essere linearmente associati ai punteggi BDI-II. È ovvio, tuttavia, che tale relazione lineare è lungi dall’essere perfetta – se fosse perfetta, tutti punti del diagramma dispersione si disporrebbero esattamente lungo una retta.\nFIGURA 5.1: Associazione tra le variabili BDI-II e CES-D nello studio di Zetsche et al. (2019). grigio sono rappresentate le osservazioni del gruppo di controllo; nero quelle dei pazienti.\n","code":"\ndf <- rio::import(\n  here(\"data\", \"data.mood.csv\"),\n  header = TRUE\n)\nbysubj <- df %>%\n  group_by(esm_id, group) %>%\n  summarise(\n    bdi = mean(bdi),\n    cesd = mean(cesd_sum)\n  ) %>%\n  na.omit() %>%\n  ungroup()\nm_cesd <- bysubj %>%\n  dplyr::pull(cesd) %>%\n  mean()\nm_bdi <- bysubj %>%\n  dplyr::pull(bdi) %>%\n  mean()\nFONT_SIZE <- 9\nbysubj %>%\n  ggplot(\n    aes(x = bdi, y = cesd, color = group)\n  ) +\n  geom_point(size = 3, alpha = .9) +\n  geom_hline(yintercept = m_cesd, linetype = \"dashed\", \n             color = \"gray\") +\n  geom_vline(xintercept = m_bdi, linetype = \"dashed\", \n             color = \"gray\") +\n  geom_text(x = -1, y = 16, label = \"I\", color = \"gray\", \n            size = FONT_SIZE) +\n  geom_text(x = 0, y = 46, label = \"IV\", color = \"gray\", \n            size = FONT_SIZE) +\n  geom_text(x = 18, y = 46, label = \"III\", color = \"gray\", \n            size = FONT_SIZE) +\n  geom_text(x = 18, y = 16, label = \"II\", color = \"gray\", \n            size = FONT_SIZE) +\n  labs(\n    x = \"BDI-II\",\n    y = \"CESD\"\n  ) +\n  theme(legend.position = \"none\") +\n  scale_colour_grey(start = 0.7, end = 0)"},{"path":"ch-corr.html","id":"covarianza","chapter":"Capitolo 5 Le relazioni tra variabili","heading":"5.2 Covarianza","text":"Il problema che ci poniamo ora è quello di trovare un indice numerico che\ndescrive di quanto la nube di punti si discosta da una perfetta\nrelazione lineare tra le due variabili, ovvero che descrive la direzione e la\nforza della relazione lineare tra le due variabili. Ci sono vari indici\nstatistici che possono essere utilizzati questo scopo.Iniziamo considerare il più importante di tali indici, chiamato\ncovarianza. realtà la definizione di questo indice non ci\nsorprenderà più di tanto quanto, una forma solo apparentemente\ndiversa, l’abbiamo già incontrato precedenza. Ci ricordiamo infatti\nche la varianza di una generica variabile \\(X\\) è definita come la media\ndegli scarti quadratici di ciascuna osservazione dalla media:\\[\\begin{equation}\nS_{XX} = \\frac{1}{n} \\sum_{=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\tag{5.1}\n\\end{equation}\\]Infatti, la varianza viene talvolta descritta come la “covarianza di una\nvariabile con sé stessa”.Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di\nuna sola variabile, chiediamoci come due variabili \\(X\\) e \\(Y\\) “variano\ninsieme” (co-variano). È facile capire come una risposta tale domanda\npossa essere fornita da una semplice trasformazione della formula\nprecedente che diventa:\\[\\begin{equation}\nS_{XY} = \\frac{1}{n} \\sum_{=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{5.2}\n\\end{equation}\\]L’eq. (5.2) ci fornisce dunque la definizione della covarianza.Per capire il significato dell’eq. (5.2), supponiamo di dividere il grafico della figura 5.1 quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo quadranti partendo da quello basso sinistra e muovendoci senso antiorario.Se prevalgono punti nel e III quadrante, allora la nuvola di punti\navrà un andamento crescente (per cui valori bassi di \\(X\\) tendono ad\nassociarsi valori bassi di \\(Y\\) e valori elevati di \\(X\\) tendono ad\nassociarsi valori elevati di \\(Y\\)) e la covarianza segno positivo. Mentre\nse prevalgono punti nel II e IV quadrante la nuvola di punti avrà un\nandamento decrescente (per cui valori bassi di \\(X\\) tendono ad\nassociarsi valori elevati di \\(Y\\) e valori elevati di \\(X\\) tendono ad\nassociarsi valori bassi di \\(Y\\)) e la covarianza segno negativo. Dunque,\nil segno della covarianza ci informa sulla direzione della relazione\nlineare tra due variabili: l’associazione lineare si dice positiva se la\ncovarianza è positiva, negativa se la covarianza è negativa.Il segno della covarianza ci informa sulla direzione della relazione, ma\ninvece il valore assoluto della covarianza ci dice ben poco. Esso,\ninfatti, dipende dall’unità di misura delle variabili. Nel caso presente\nquesto concetto è difficile da comprendere, dato che le due variabili \nesame non hanno un’unità di misura (ovvero, hanno un’unità di misura\narbitraria e priva di significato). Ma quest’idea diventa chiara se\npensiamo alla relazione lineare tra l’altezza e il peso delle persone,\nad esempio. La covarianza tra queste due quantità è certamente positiva,\nma il valore assoluto della covarianza diventa più grande se l’altezza\nviene misurata millimetri e il peso grammi, e diventa più piccolo\nl’altezza viene misurata metri e il peso chilogrammi. Dunque, il\nvalore della covarianza cambia al mutare dell’unità di misura delle\nvariabili anche se l’associazione tra le variabili resta costante.","code":""},{"path":"ch-corr.html","id":"correlazione","chapter":"Capitolo 5 Le relazioni tra variabili","heading":"5.3 Correlazione","text":"Dato che il valore assoluto della covarianza è di difficile\ninterpretazione – pratica, non viene mai interpretato – è\nnecessario trasformare la covarianza modo tale da renderla immune\nalle trasformazioni dell’unità di misura delle variabili. Questa\noperazione si dice standardizzazione e corrisponde alla divisione\ndella covarianza per le deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due\nvariabili:\\[\\begin{equation}\nr_{XY} = \\frac{S_{XY}}{s_X s_Y}.\n\\tag{5.3}\n\\end{equation}\\]La quantià che si ottiene questo modo viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, la hanno introdotta).Il coefficiente di correlazione ha le seguenti proprietà:ha lo stesso segno della covarianza, dato che si ottiene dividendo\nla covarianza per due numeri positivi;è un numero puro, cioè non dipende dall’unità di misura delle\nvariabili;assume valori compresi tra -1 e +1.Ad esso possiamo assegnare la seguente interpretazione:\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti \npunti si trovano esattamente su una retta con pendenza negativa (dal\nquadrante alto sinistra al quadrante basso destra);\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti \npunti si trovano esattamente su una retta con pendenza positiva (dal\nquadrante basso sinistra al quadrante alto destra);\\(-1 < r_{XY} < +1\\) \\(\\rightarrow\\) presenza di una relazione lineare\ndi intensità diversa;\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e\n\\(Y\\).Esercizio 5.1  Per dati della figura 5.1, la covarianza è 207.426. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire qual è l’intensità della relazione lineare tra le due variabili calcoliamo la correlazione.\nEssendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali 15.37 e 14.93, la correlazione diventa uguale \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo 1.0, il che vuol dire che punti del diagramma dispersione non si discostano troppo da una retta con una pendenza positiva.","code":""},{"path":"ch-corr.html","id":"correlazione-e-causazione","chapter":"Capitolo 5 Le relazioni tra variabili","heading":"5.4 Correlazione e causazione","text":"Facendo riferimento nuovamente alla figura 5.1, possiamo dire che, molte applicazioni (ma non nel caso presente!) l’asse \\(x\\) rappresenta una quantità nota come variabile indipendente e l’interesse si concentra sulla sua influenza sulla variabile dipendente tracciata sull’asse \\(y\\). Ciò presuppone però che sia nota la direzione cui l’influenza causale potrebbe risiedere. È importante tenere bene mente che la correlazione è soltanto un indice descrittivo della relazione lineare tra due variabili e nessun caso può essere usata per inferire alcunché sulle relazioni causali che legano le variabili. È ben nota l’espressione: “correlazione non significa causazione”.Di opinione diversa era invece Karl Pearson (1911), il quale ha affermato: “Quanto spesso, quando è stato osservato un nuovo fenomeno,\nsentiamo che viene posta la domanda: ‘qual è la sua causa?’. Questa è\nuna domanda cui potrebbe essere assolutamente impossibile rispondere.\nInvece, può essere più facile rispondere alla domanda: ‘che misura\naltri fenomeni sono associati con esso?’. Dalla risposta questa\nseconda domanda possono risultare molte preziose conoscenze.”Che alla seconda domanda posta da Pearson sia facile rispondere è indubbio. Che la nostra comprensione di un fenomeno possa aumentare sulla base delle\ninformazioni fornite unicamente dalle correlazioni, invece, è molto dubbio e quasi certamente falso.","code":""},{"path":"ch-corr.html","id":"usi-della-correlazione","chapter":"Capitolo 5 Le relazioni tra variabili","heading":"5.5 Usi della correlazione","text":"Anche se non può essere usata per studiare le relazioni causali, la\ncorrelazione viene usata per molti altri scopi tra quali, per esempio,\nquello di misurare la validità concorrente di un test psiologico. Se\nun test psicologico misura effettivamente ciò che ci si aspetta che\nmisuri (nel caso dell’esempio presente, la depressione), allora dovremo\naspettarci che fornisca una correlazione alta con risultati di altri\ntest che misurano lo stesso costrutto – come nel caso dei dati di\n(Zetsche, Bürkner, Renneberg 2019). Un’altra proprietà desiderabile di un test\npsicometrico è la validità divergente: risultati di test\npsicometrici che misurano costrutti diversi dovrebbero essere poco\nassociati tra loro. altre parole, questo secondo caso dovremmo\naspettarci che la correlazione sia bassa.","code":""},{"path":"ch-corr.html","id":"correlazione-di-spearman","chapter":"Capitolo 5 Le relazioni tra variabili","heading":"5.6 Correlazione di Spearman","text":"Una misura alternativa della relazione lineare tra due variabili è\nfornita dal coefficiente di correlazione di Spearman e dipende soltanto\ndalla relazione d’ordine dei dati, non dagli specifici valori dei dati.\nTale misura di associazione è appropriata quando, del fenomeno esame,\ngli psicologi sono stati grado di misurare soltanto le relazioni\nd’ordine tra le diverse modalità della risposta dei soggetti, non\nl’intensità della risposta. Le variabili psicologiche che hanno questa\nproprietà si dicono ordinali. Nel caso di variabili ordinali, non è\npossibile sintetizzare dati mediante le statistiche descrittive che\nabbiamo introdotto questo capitolo, quali ad esempio la media e la\nvarianza, ma è invece solo possibile riassumere dati mediante una\ndistribuzione di frequenze per le varie modalità della risposta.","code":""},{"path":"ch-corr.html","id":"correlazione-nulla","chapter":"Capitolo 5 Le relazioni tra variabili","heading":"5.7 Correlazione nulla","text":"Un ultimo aspetto da mettere evidenza proposito della correlazione riguarda il fatto che la correlazione descrive la direzione e l’intensità della relazione lineare tra due variabili. Relazioni non lineari tra le variabili, anche se sono molto forti, non vengono catturate dalla correlazione. È importante rendersi conto che una correlazione pari zero non significa che non c’è relazione tra le due variabili, ma solo che tra esse non c’è una relazione lineare.Esercizio 5.2  La figura 5.2 fornisce un esempio di correlazione nulla presenza di una chiara relazione (non lineare) tra due variabili.\nFIGURA 5.2: Due insiemi di dati (fittizi) per quali coefficienti di correlazione di Pearson sono entrambi 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili.\n","code":""},{"path":"ch-corr.html","id":"commenti-e-considerazioni-finali-3","chapter":"Capitolo 5 Le relazioni tra variabili","heading":"Commenti e considerazioni finali","text":"La prima fase dell’analisi dei dati riassume dati mediante gli strumenti della statistica descrittiva. Le tipiche domande che vengono affrontate questa fase sono: qual è la distribuzione delle variabili di interesse? Quali relazioni coppie si possono osservare nel campione? Ci sono delle osservazioni ‘anomale’, ovvero estremamente discrepanti rispetto alle altre, sia quando si esaminano le statistiche descrittive univariate (ovvero, quelle che riguardano le caratteristiche di una variabile presa singolarmente), sia quando vengono esaminate le statistiche bivariate (ovvero, le statistiche che descrivono l’associazione tra le variabili)? È importante avere ben chiare le idee su questi punti prima di procedere con qualsiasi procedura statistica di tipo inferenziale. Per rispondere alle domande che abbiamo elencato sopra, ed ad altre simili, è molto utile procedere con delle rappresentazioni grafiche dei dati. È chiaro che, quando disponiamo di grandi moli di dati (come è sempre il caso psicologia), l’analisi descrittiva dei dati deve essere svolta mediante un software statistico.","code":""},{"path":"ch-intro-prob-1.html","id":"ch-intro-prob-1","chapter":"Capitolo 6 La logica dell’incerto","heading":"Capitolo 6 La logica dell’incerto","text":"questa parte della dispensa verrà introdotta la teoria delle probabilità. Prima di entrare nei dettagli, cerchiamo di capire perché la probabilità sia cruciale per la ricerca scientifica.La teoria delle probabilità è cruciale per la scienza perché la ricerca procede mediante l’inferenza induttiva. Non siamo mai completamente sicuri della verità di una proposizione (ipotesi, teoria): al valore di verità di una proposizione possiamo solo assegnare un giudizio probabilistico. L’approccio bayesiano è una scuola di pensiero che usa la probabilità per quantificare il grado di fiducia che può essere attribuito ad una proposizione. L’inferenza statistica bayesiana è un tipo di inferenza induttiva che ha lo scopo di quantificare la fiducia che si ha nell’ipotesi \\(H\\) dopo il verificarsi del dato d’evidenza \\(E\\). Per quantificare un tale grado di fiducia l’inferenza statistica bayesiana utilizza la teoria delle probabilità. Una comprensione dell’inferenza statistica bayesiana richiede dunque, preliminarmente, la conoscenze della teoria delle probabilità.","code":""},{"path":"ch-intro-prob-1.html","id":"che-cosè-la-probabilità","chapter":"Capitolo 6 La logica dell’incerto","heading":"6.1 Che cos’è la probabilità?","text":"La definizione della probabilità è un problema estremamente dibattuto ed aperto. Sono state fornite due possibili soluzioni al problema di definire il concetto di probabilità.La natura della probabilità è “ontologica” (ovvero, basata sulla metafisica): la probabilità è una proprietà della della realtà, del mondo, di come sono le cose, indipendentemente dalla nostra esperienza. È una visione che qualcuno chiama “oggettiva”.La natura della probabilità è “ontologica” (ovvero, basata sulla metafisica): la probabilità è una proprietà della della realtà, del mondo, di come sono le cose, indipendentemente dalla nostra esperienza. È una visione che qualcuno chiama “oggettiva”.La natura della probabilità è “epistemica” (ovvero, basata sulla conoscenza): la probabilità si riferisce alla conoscenza che abbiamo del mondo, non al mondo sé. Di conseguenza è detta, contrapposizione alla precedente definizione, “soggettiva”.La natura della probabilità è “epistemica” (ovvero, basata sulla conoscenza): la probabilità si riferisce alla conoscenza che abbiamo del mondo, non al mondo sé. Di conseguenza è detta, contrapposizione alla precedente definizione, “soggettiva”.termini epistemici, la probabilità fornisce una misura della nostra incertezza sul verificarsi di un fenomeno, alla luce delle informazioni disponibili. Potremmo dire che c’è una “scala” naturale che ha per estremi il vero (1: evento certo) da una parte ed il falso (0: evento impossibile) dall’altra. La probabilità è la quantificazione di questa scala: descrive lo stato della nostra incertezza rispetto al contenuto di verità di una proposizione.L’incertezza nelle nostre previsioni può sorgere per due ragioni fondamentalmente diverse. Il primo è dovuto alla nostra ignoranza delle cause nascoste sottostanti o dei meccanismi che generano dati. Questa è appunto un’incertezza epistemica. Il secondo tipo di incertezza deriva dalla variabilità intrinseca dei fenomeni, che non può essere ridotta anche se raccogliamo più dati. Questa seconda forma di incertezza è talvolta chiamata aleatoria. Come esempio concreto, consideriamo il lancio di una moneta equilibrata. Sappiamo con certezza che la probabilità di testa è \\(P = 0.5\\), quindi non c’è incertezza epistemica, ma non questo non è sufficiente per prevedere con certezza il risultato – ovvero, l’incertezza aleatoria persiste anche assenza di incertezza epistemica.Nell’interpretazione frequentista, la probabilità \\(P(E)\\) rappresenta la frequenza relativa lungo termine di un grande numero di ripetizioni di un esperimento casuale sotto le medesime condizioni. Viene stressata qui l’idea che ciò di cui parliamo è qualcosa che emerge nel momento cui è possibile ripetere l’esperimento casuale tante volte sotto le medesime condizioni – sono invece esclusi gli eventi unici e irripetibili.L’interpretazione bayesiana della probabilità fa invece ricorso ad una concezione più ampia, non legata al solo evento sé ma che include anche il soggetto assegnante la funzione di probabilità. pratica l’assegnazione di probabilità bayesiana viene effettuata dal decisore, base alle proprie conoscenze priori integrate con tutto il generico bagaglio culturale personale. questo modo, la probabilità non sarà obbligatoriamente la stessa per tutti soggetti, ma variarierà seconda delle informazioni disposizione, dell’esperienza personale e soprattutto del punto di vista proprio di ogni decisore ed è dunque assimilabile al “grado di fiducia” – inglese degree belief – di un dato soggetto, un dato istante e con un dato insieme d’informazioni, circa l’accadere dell’evento \\(E\\). “[N]essuna scienza ci permetterà di dire: il tale fatto accadrà, andrà così e così, perché ciò è conseguenza di tale legge, e tale legge è una verità assoluta, ma tanto meno ci condurrà concludere scetticamente: la verità assoluta non esiste, e quindi tale fatto può accadere e può non accadere, può andare così e può andare tutt’altro modo, nulla io ne . Quel che si potrà dire è questo: io prevedo che il tale fatto avverrà, e avverrà nel tal modo, perché l’esperienza del passato e l’elaborazione scientifica cui il pensiero dell’uomo l’ha sottoposta mi fanno sembrare ragionevole questa previsione” (Finetti 1931).L’impostazione bayesiana, sviluppata da Ramsey e de Finetti, riconduce l’assegnazione di probabilità allo scommettere sul verificarsi di un evento: la probabilità di un evento \\(E\\) è la quota \\(p(E)\\) che un individuo reputa di dover pagare ad un banco per ricevere “1” ovvero “0” verificandosi o non verificandosi \\(E\\).Secondo De Finetti, le valutazioni di probabilità degli eventi devono rispondere ai principi di equità e coerenza. Una scommessa risponde al principio di equità se il ruolo di banco e giocatore sono scambiabili ogni momento del gioco e sempre alle stesse condizioni. Una scommessa risponde al principio di coerenza se non vi sono combinazioni di scommesse che consentano (sia al banco che al giocatore) di realizzare perdite o vincite certe.L’approccio definettiano dell’impostazione della scommessa si basa dunque sulle assunzioni di razionalità e coerenza del decisore, al quale è fatto esplicito divieto di effettuare scommesse perdita o guadagno certo. Il decisore, proponendo la scommessa, deve essere disposto scambiare il posto dello scommettitore con quello del banco.Il metodo della scommessa, oltre che una definizione, fornisce un mezzo operativo di assegnazione della probabilità. Sulla base di questa definizione operativa, che si può ritenere ragionevolmente soddisfatta dal comportamento di un qualunque individuo che agisca modo razionale condizioni di incertezza, possono essere agevolmente dimostrate tutte le proprietà classiche della probabilità: essa non può assumere valori negativi, né può essere superiore ’unità; se \\(E\\) è un evento certo, la sua probabilità è 1; se invece \\(E\\) è un evento impossibile, la sua probabilità è 0.problemi posti dall’approccio definettiano riguardano l’arbitrarietà dell’assegnazione soggettività di probabilità la quale sembra negare la validità dell’intero costrutto teorico. risposta tale critica, bayesiani sostengono che gli approcci oggettivisti alla probabilità nascondono scelte arbitrarie preliminari e sono basate su assunzioni implausibili. È molto più onesto esplicitare subito tutte le scelte arbitrarie effettuate nel corso dell’analisi modo da controllarne coerenza e razionalità.","code":""},{"path":"ch-intro-prob-1.html","id":"variabili-casuali-e-probabilità-di-un-evento","chapter":"Capitolo 6 La logica dell’incerto","heading":"6.2 Variabili casuali e probabilità di un evento","text":"Esaminiamo qui di seguito alcuni concetti di base della teoria delle probabilità, la quale può essere vista come un’estensione della logica.","code":""},{"path":"ch-intro-prob-1.html","id":"eventi-e-probabilità","chapter":"Capitolo 6 La logica dell’incerto","heading":"6.2.1 Eventi e probabilità","text":"Nella teoria delle probabilità il risultato “testa” nel lancio di una moneta è chiamato evento.6 Un evento, denotato da una variabile binaria, corrisponde ad uno stato del mondo che si verifica oppure . Ad esempio, \\(Y\\) = 1 può denotare l’evento per cui il lancio di una moneta produce il risultato testa. Il funzionale \\(P(Y)\\) denota la probabilità con cui si ritiene che l’evento \\(Y\\) sia vero (o la proporzione di volte che si verifica tale evento osservando lungo termine delle ripetizioni indipendenti di un esperimento casuale). Ad esempio, per il lancio di una moneta equilibrata, la probabilità dell’evento “il risultato del lancio della moneta è testa” è scritta come \\(P(Y = 1) = 0.5.\\)Se la moneta è equilibrata dobbiamo anche avere \\(P(Y = 0) = 0.5\\). due eventi Y = 1 e \\(Y\\) = 0 sono mutuamente esclusivi nel senso che non possono entrambi verificarsi contemporaneamente: \\(P(Y = 1\\; \\land \\; Y = 0) = 0.\\) Gli eventi \\(Y\\) = 1 e \\(Y\\) = 0 di dicono esaustivi, nel senso che almeno uno di essi deve verificarsi e nessun altro tipo di evento è possibile. Nella notazione probabilistica, \\(P(Y = 1\\; \\lor \\; Y = 0) = 1.\\) Il connettivo logico “o” (\\(\\lor\\)) specifica eventi disgiunti, ovvero eventi che non possono verificarsi contemporaneamente (eventi incompatibili) e per quali, perciò, la probabilità della loro congiunzione è \\(P(\\; \\land \\; B) = 0\\). Il connettivo logico “e” (\\(\\land\\)), invece, specifica eventi congiunti, ovvero eventi che possono verificarsi contemporaneamente (eventi compatibili) e per quali, perciò, la probabilità della loro congiunzione è \\(P(\\; \\land \\; B) > 0\\). La probabilità del verificarsi di due eventi congiunti \\(\\) e \\(B\\) si può denotare, maniera equivalente, con la notazione precedente, oppure con \\(P(\\cap B)\\), oppure con \\(P(, B)\\).Si richiede che \\(0 \\leq P() \\leq 1\\), dove \\(P() = 0\\) denota l’evento impossibile e \\(P() = 1\\) denota l’evento certo. Scriviamo \\(P(\\lnot )\\) o \\(P(\\bar{})\\) per denotare la probabilità che l’evento \\(\\) non avvenga; questa probabilità è definita come \\(P(\\bar{}) = 1 − P()\\).","code":""},{"path":"ch-intro-prob-1.html","id":"spazio-campione-e-risultati-possibili","chapter":"Capitolo 6 La logica dell’incerto","heading":"6.2.2 Spazio campione e risultati possibili","text":"Anche se il lancio di una moneta produce sempre uno specifico risultato nel mondo reale, possiamo anche immaginare possibili risultati alternativi che si sarebbero potuti osservare. Quindi, anche se uno specifico lancio la moneta dà testa (\\(Y\\) = 1), possiamo immaginare la possibilità che il lancio possa avere prodotto croce (\\(Y\\) = 0). Tale ragionamento controfattuale è la chiave per comprendere la teoria delle probabilità e l’inferenza statistica.risultati possibili che si possono osservare come conseguenza del lancio di una moneta determinano valori possibili che la variabile casuale può assumere. L’insieme \\(\\Omega\\) di tutti risultati possibili è chiamato spazio campione (sample space). Lo spazio campione può essere concettualizzato come un’urna contenente una pallina per ogni possibile risultato del lancio della moneta. Su ogni pallina è scritto il valore della variabile casuale. Uno specifico lancio di una moneta – ovvero, l’osservazione di uno specifico valore di una variabile casuale – è chiamato esperimento casuale.Il lancio di un dado ci fornisce l’esempio di un altro esperimento casuale. Supponiamo di essere interessati ’evento “il lancio del dado produce un numero dispari”. Un evento seleziona un sottoinsieme dello spazio campione: questo caso, l’insieme dei risultati \\(\\{1, 3, 5\\}\\). Se esce 3, per esempio, diciamo che si è verificato l’evento “dispari” (ma l’evento “dispari” si sarebbe anche verificato anche se fosse uscito 1 o 5).","code":""},{"path":"ch-intro-prob-1.html","id":"variabili-casuali-1","chapter":"Capitolo 6 La logica dell’incerto","heading":"6.3 Variabili casuali","text":"Sia \\(Y\\) il risultato del lancio di moneta equilibrata, non di un generico lancio di una moneta, ma un’istanza specifica del lancio di una specifica moneta un dato momento. Definita questo modo, \\(Y\\) è una variabile casuale, ovvero una variabile cui valori non possono essere previsti con esattezza. Se la moneta è equilibrata, c’è una probabilità del 50% che il lancio della moneta dia come risultato “testa” e una probabilità del 50% che dia come risultato “croce”. Per facilitare la trattazione, le variabili casuali assumono solo valori numerici. Per lo specifico lancio della moneta questione, diciamo, ad esempio, che la variabile casuale \\(Y\\) assume il valore 1 se esce testa e il valore 0 se esce croce.Una variabile casuale può essere discreta o continua. Una variabile casuale discreta può assumere un numero finito di valori \\(x_1, \\dots ,x_n\\), corrispondenza degli eventi \\(E_i, \\dots, E_n\\) che si verificano con le rispettive probabilità \\(p_1, \\dots, p_n\\). Un esempio è il punteggio totale di un test psicometrico costituito da item su scala Likert. Invece un esempio di una variabile casuale continua è la distanza tra due punti, che può assumere infiniti valori ’interno di un certo intervallo. L’insieme \\(S\\) dei valori che la variabile casuale può assumere è detto spazio dei valori o spazio degli stati.La caratteristica fondamentale di una variabile casuale è data dall’insieme delle probabilità dei suoi valori, detta distribuzione di probabilità. Nel seguito useremo la notazione \\(P(\\cdot)\\) per fare riferimento alle distribuzioni di probabilità delle variabili casuali discrete e \\(p(\\cdot)\\) per fare riferimento alla densità di probabilità delle variabili casuali continue. questo contesto, l’insieme dei valori che la variabile casuale può assumere è detto supporto della sua distribuzione di probabilità. Il supporto di una variabile casuale può essere finito (come nel caso di una variabile casuale uniforme di supporto \\([, b]\\)) o infinito (nel caso di una variabile causale gaussiana il cui supporto coincide con la retta reale).","code":""},{"path":"ch-intro-prob-1.html","id":"usare-la-simulazione-per-stimare-le-probabilità","chapter":"Capitolo 6 La logica dell’incerto","heading":"6.4 Usare la simulazione per stimare le probabilità","text":"questa dispensa verrà adottata l’interpretazione bayesiana delle probabilità. Tuttavia, le regole di base della teoria delle probabilità sono le stesse, indipendentemente dall’interpretazione adottata. Pertanto, negli esempi seguenti, possiamo utilizzare la simulazione per stimare le probabilità degli eventi un modo diretto, ovvero mediante la generazione di molteplici osservazioni delle variabili casuali derivate dagli eventi di interesse.Ad esempio, per simulare \\(\\R\\) il lancio di una moneta equilibrata iniziamo con il definire un vettore che contiene risultati possibili del lancio della moneta (ovvero valori possibili della variabile casuale \\(Y\\)):L’estrazione casuale di uno di questi due possibili valori (ovvero, la simulazione di uno specifico lancio di una moneta) si realizza con la funzione sample():maniera equivalente, la stessa operazione si può realizzare mediante l’istruzioneSupponiamo di ripetere questo esperimento casuale 100 volte e di registrare risultati così ottenuti. La stima della probabilità dell’evento \\(P(Y = 1)\\) è data dalla frequenza relativa del numero di volte cui abbiamo osservato l’evento di interesse (\\(Y = 1\\)):Ripetiamo questa procedura 10 volte.Dato che la moneta è equilibrata, la stima delle probabilità dell’evento \\(P(Y = 1)\\) è simile al valore che ci aspettiamo, ovvero \\(P(Y = 1) = 0.5\\), ma il risultato ottenuto nelle simulazioni non è esatto. Proviamo ad aumentare il numero di lanci ciascuna simulazione:questo secondo caso, gli errori tendono ad essere più piccoli che nel caso precedente. Cosa succede se ciascuna simulazione esaminiamo risultati di 10,000 lanci della moneta?Ora le stime ottenute sono molto vicine alla vera probabilità che vogliamo stimare (cioè 0.5, perché la moneta è equilibrata).risultati delle simulazioni precedenti pongono dunque il problema di determinare quale sia il numero di lanci di cui abbiamo bisogno per assicurarci che le stime siano accurate (ovvero, vicine al valore corretto della probabilità)","code":"\ncoin <- c(0, 1)\nsample(coin, size = 1)\n#> [1] 0\nrbinom(1, 1, 0.5)\n#> [1] 1\nM <- 100\ny <- rep(NA, M)\nfor (m in 1:M) {\n  y[m] = rbinom(1, 1, 0.5)\n}\nestimate = sum(y) / M\n\ncat(\"estimated P[Y = 1] =\", estimate)\n#> estimated P[Y = 1] = 0.53\nflip_coin <- function(M) {\n  y <- rep(NA, M)\n  for (m in 1:M) {\n    y[m] = rbinom(1, 1, 0.5)\n  }\n  estimate <- sum(y) / M\n  cat(\"estimated P[Y = 1] =\", estimate, \"\\n\")\n}\nfor(i in 1:10) {\n  flip_coin(100)\n}\n#> estimated P[Y = 1] = 0.44 \n#> estimated P[Y = 1] = 0.52 \n#> estimated P[Y = 1] = 0.46 \n#> estimated P[Y = 1] = 0.57 \n#> estimated P[Y = 1] = 0.47 \n#> estimated P[Y = 1] = 0.46 \n#> estimated P[Y = 1] = 0.48 \n#> estimated P[Y = 1] = 0.49 \n#> estimated P[Y = 1] = 0.47 \n#> estimated P[Y = 1] = 0.62\nfor(i in 1:10) {\n  flip_coin(1000)\n}\n#> estimated P[Y = 1] = 0.497 \n#> estimated P[Y = 1] = 0.529 \n#> estimated P[Y = 1] = 0.493 \n#> estimated P[Y = 1] = 0.511 \n#> estimated P[Y = 1] = 0.506 \n#> estimated P[Y = 1] = 0.52 \n#> estimated P[Y = 1] = 0.49 \n#> estimated P[Y = 1] = 0.495 \n#> estimated P[Y = 1] = 0.489 \n#> estimated P[Y = 1] = 0.496\nfor(i in 1:10) {\n  flip_coin(1e4)\n}\n#> estimated P[Y = 1] = 0.4885 \n#> estimated P[Y = 1] = 0.4957 \n#> estimated P[Y = 1] = 0.4902 \n#> estimated P[Y = 1] = 0.5032 \n#> estimated P[Y = 1] = 0.5048 \n#> estimated P[Y = 1] = 0.4931 \n#> estimated P[Y = 1] = 0.4965 \n#> estimated P[Y = 1] = 0.499 \n#> estimated P[Y = 1] = 0.4979 \n#> estimated P[Y = 1] = 0.4973"},{"path":"ch-intro-prob-1.html","id":"la-legge-dei-grandi-numeri","chapter":"Capitolo 6 La logica dell’incerto","heading":"6.5 La legge dei grandi numeri","text":"La visualizzazione mediante grafici contribuisce alla comprensione dei concetti della statistica e della teoria delle probabilità. Un modo per descrivere ciò che accade ’aumentare del numero \\(M\\) di ripetizioni del lancio della moneta consiste nel registrare la stima della probabilità dell’evento \\(P(Y = 1)\\) funzione del numero di ripetizioni dell’esperimento casuale per ogni \\(m \\1:M\\). Possiamo ottenere un grafico dell’andamento della stima di \\(P(Y = 1)\\) funzione di \\(m\\) nel modo seguente:\nFIGURA 6.1: Stima della probabilità di successo funzione del numero dei lanci di una moneta.\nLa figura 6.1, quando è espressa su una scala lineare, non rivela chiaramente l’andamento della simulazione. Imponiamo dunque una scala logaritmica sull’asse delle ascisse (\\(x\\)). Su scala logaritmica, valori tra 1 e 10 vengono tracciati ’incirca con la stessa ampiezza che si osserva tra valori 50 e 700, eccetera.\nFIGURA 6.2: Stima della probabilità di successo funzione del numero dei lanci di una moneta.\nLa legge dei grandi numeri ci dice che, ’aumentare del numero di ripetizioni dell’esperimento casuale, la media dei risultati ottenuti tende al valore atteso, man mano che vengono eseguite più prove. Nella figura 6.2 vediamo infatti che, ’aumentare del numero M di lanci della moneta, la stima di \\(P(Y = 1)\\) converge al valore 0.5.","code":"\nnrep <- 1e4\nestimate <- rep(NA, nrep)\nflip_coin <- function(m) {\n  y <- rbinom(m, 1, 0.5)\n  phat <- sum(y) / m\n  phat\n}\nfor(i in 1:nrep) {\n  estimate[i] <- flip_coin(i)\n}\nd <- tibble(\n  n = 1:nrep, \n  estimate\n)\nd %>% \n  ggplot(aes(x = n, y = estimate)) +\n  geom_line() +\n  labs(\n    x = \"Numero di lanci della moneta\", \n    y = \"Stima di P(Y = 1)\"\n)\nd %>%\n  ggplot(aes(x = n, y = estimate)) +\n  geom_line() +\n  geom_hline(\n    yintercept = 0.5, color = \"gray\", size = 1\n  ) +\n  scale_x_log10(\n    breaks = c(\n      1, 3, 10, 50, 200,\n      700, 2500, 10000\n    )\n  ) +\n  labs(\n    x = \"Numero dei lanci della moneta (scala logaritmica)\",\n    y = \"Stima di P(Y = 1)\"\n  )"},{"path":"ch-intro-prob-1.html","id":"variabili-casuali-multiple","chapter":"Capitolo 6 La logica dell’incerto","heading":"6.6 Variabili casuali multiple","text":"Le variabili casuali non esistono isolatamente. Abbiamo iniziato con una sola variabile casuale \\(Y\\) che rappresenta il risultato di un singolo, specifico lancio di una moneta equlibrata. Ma supponiamo ora di lanciare la moneta tre volte. risultati di ciascuno dei tre lanci possono essere rappresentati da una diversa variabile casuale, ad esempio, \\(Y_1 , Y_2 , Y_3\\). Possiamo assumere che ogni lancio sia indipendente, ovvero che non dipenda dal risultato degli altri lanci. Per ciascuna di queste variabili \\(Y_n\\), con \\(n \\1:3\\), abbiamo che \\(P(Y_n =1)=0.5\\) e \\(P(Y_n =0)=0.5\\).È possibile combinare più variabili casuali usando le operazioni aritmetiche. Se \\(Y_1 , Y_2, Y_3\\) sono variabili casuali che rappresentano tre lanci di una moneta equilibrata (o un lancio di tre monete equilibrate), possiamo definire la somma di tali variabili casuali come\\[\nZ = Y_1 + Y_2 + Y_3.\n\\]Possiamo simulare valori assunti dalla variabile casuale Z simulando valori di \\(Y_1, Y_2, Y_3\\) per poi sommarli.ovvero,oppure, ancora più semplicemente:Possiamo ripetere questa simulazione \\(M = 1e5\\) volte:e calcolare una stima della probabilità che la variabile casuale \\(Z\\) assuma ciascuno dei possibili valori 0, 1, 2, 3:Nel caso di 4 monete equilibrate, avremo:Una variabile casuale le cui modalità possono essere costituite solo da numeri interi è detta variabile casuale discreta:\\[\n\\mathbb{Z} = \\dots, -2, -1, 0, 1, 2, \\dots\n\\]","code":"\ny1 <- rbinom(1, 1, 0.5)\ny2 <- rbinom(1, 1, 0.5)\ny3 <- rbinom(1, 1, 0.5)\nc(y1, y2, y3)\n#> [1] 1 0 1\nz <- sum(c(y1, y2, y3))\ncat(\"z =\", z, \"\\n\")\n#> z = 2\ny <- rep(NA, 3)\nfor (i in 1:3) {\n  y[i] <- rbinom(1, 1, 0.5)\n}\ny\n#> [1] 0 1 1\nz <- sum(y)\ncat(\"z =\", z, \"\\n\")\n#> z = 2\ny <- rbinom(3, 1, 0.5)\ny\n#> [1] 1 0 1\nz <- sum(y)\ncat(\"z =\", z, \"\\n\")\n#> z = 2\nM <- 1e5\nz <- rep(NA, M)\nfor(i in 1:M) {\n  y <- rbinom(3, 1, 0.5)\n  z[i] <- sum(y)\n}\ntable(z) / M\n#> z\n#>       0       1       2       3 \n#> 0.12585 0.37495 0.37480 0.12440\nM <- 1e5\nz <- rep(NA, M)\nfor(i in 1:M) {\n  y <- rbinom(4, 1, 0.5)\n  z[i] <- sum(y)\n}\ntable(z) / M\n#> z\n#>       0       1       2       3       4 \n#> 0.06340 0.24917 0.37360 0.25022 0.06361"},{"path":"ch-intro-prob-1.html","id":"sec:fun-mass-prob","chapter":"Capitolo 6 La logica dell’incerto","heading":"6.7 Funzione di massa di probabilità","text":"È conveniente avere una funzione che associa una probabilità ciascun possibile valore di una variabile casuale. generale, ciò è possibile se e solo se la variabile casuale è discreta, così com’è stata definita nel Paragrafo precedente. Ad esempio, se consideriamo \\(Z = Y_1 + \\dots + Y_4\\) come, ad esempio, il numero di risultati “testa” 4 lanci della moneta, allora possiamo definire la seguente funzione:\\[\n\\begin{array}{rclll}\np_Z(0) & = & 1/16 & & \\mathrm{TTTT}\n\\\\\np_Z(1) & = & 4/16 & & \\mathrm{HTTT, THTT, TTHT, TTTH}\n\\\\\np_Z(2) & = & 6/16 & & \\mathrm{HHTT, HTHT, HTTH, THHT, THTH, TTTH}\n\\\\\np_Z(3) & = & 4/16 & & \\mathrm{HHHT, HHTH, HTHH, THHH}\n\\\\\np_Z(4) & = & 1/16 & & \\mathrm{HHHH}\n\\end{array}\n\\]Il lancio di quattro monete può produrre 16 risultati possibili. Dato che lanci sono indipendenti, se le monete sono equilibrate ogni possibile risultato è ugualmente probabile. Nella tabella alto, le sequenze dei risultati possibili del lancio delle 4 monete sono riportate nella colonna più destra. Le probabilità si ottengono dividendo il numero di sequenze che producono lo stesso numero di eventi testa per il numero dei risultati possibili.Le sequenze come \\(\\mathrm{TTTT}\\), \\(\\mathrm{HTTT}\\), ecc. sono chiamate “eventi elementari” (corrispondono ad un possibile esito dell’esperimento casuale). L’evento \\(Z = u\\), con \\(u \\0 \\dots, 4\\) è un “evento composto”, il quale può essere costituito da più eventi elementari.La funzione \\(p_Z\\) è stata costruita per associare ciascun valore \\(u\\) della variabile casuale \\(Z\\) la probabilità dell’evento \\(Z = u\\). Convenzionalmente, queste probabilità sono scritte come\\[\nP_Z(z) = P(Z = z).\n\\]La parte destra dell’uguale si può leggere come: “la probabilità che la variabile casuale \\(Z\\) assuma il valore \\(z\\)”. Una funzione definita come sopra è detta funzione di massa di probabilità della variabile casuale \\(Z\\). Ad ogni variabile casuale discreta è associata un’unica funzione di massa di probabilità.Una rappresentazione grafica della stima della funzione di massa di probabilità per l’esperimento casuale del lancio di quattro monete equilibrate è fornita nella figura 6.3.\nFIGURA 6.3: Grafico di \\(M = 100,000\\) simulazioni della funzione di massa di probabilità di una variabile casuale definita come il numero di teste quattro lanci di una moneta equilibrata.\nSe \\(\\) è un sottoinsieme della variabile casuale \\(Z\\), allora denotiamo\ncon \\(P_{z}()\\) la probabilità assegnata ad \\(\\) dalla distribuzione\n\\(P_{z}\\). Mediante una distribuzione di probabilità \\(P_{z}\\) è dunque\npossibile determinare la probabilità di ciascun sottoinsieme\n\\(\\subset Z\\) come\\[\\begin{equation}\nP_{z}() = \\sum_{z \\} P_{z}(Z = z).\n\\end{equation}\\]Una funzione di massa di probabilità soddisfa le proprietà\\(0 \\leq P(X=x) \\leq 1\\),\\(\\sum_{x \\X} P(x) = 1\\).Esempio 6.1  Nel caso dell’esempio discusso nel Paragrafo 6.7, la probabilità che la variabile casuale \\(Z\\) sia un numero dispari è\\[\nP(\\text{Z è un numero dispari}) = P_{z}(Z = 1) + P_{z}(Z = 3) = \\frac{4}{16} + \\frac{4}{16} = \\frac{1}{2}.\n\\]","code":"\nset.seed(1234)\nM <- 1e5\nnflips <- 4\nu <- rbinom(M, nflips, 0.5)\nx <- 0:nflips\ny <- rep(NA, nflips + 1)\nfor (n in 0:nflips) {\n  y[n + 1] <- sum(u == n) / M\n}\nbar_plot <-\n  data.frame(Z = x, count = y) %>%\n  ggplot(aes(x = Z, y = count)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(\n    breaks = 0:4,\n    labels = c(0, 1, 2, 3, 4)\n  ) +\n  labs(\n    y = \"Probabilità stimata P(Z = z)\"\n  )\nbar_plot"},{"path":"ch-intro-prob-1.html","id":"funzione-di-ripartizione","chapter":"Capitolo 6 La logica dell’incerto","heading":"6.7.1 Funzione di ripartizione","text":"Data una variabile casuale discreta \\(X\\) possiamo calcolare la probabilità che \\(X\\) non superi un certo valore \\(x\\), ossia la sua funzione di ripartizione. Poichè \\(X\\) assume valori discreti possiamo cumulare le probabilità mediante una somma:\\[\\begin{equation}\nF(x_k) = P(X \\leq x_k) = \\sum_{x \\leq x_k} P(x).\n\\end{equation}\\]","code":""},{"path":"ch-intro-prob-1.html","id":"commenti-e-considerazioni-finali-4","chapter":"Capitolo 6 La logica dell’incerto","heading":"Commenti e considerazioni finali","text":"questo capitolo abbiamo visto come si costruisce lo spazio campione di un esperimento casuale, quali sono le proprietà di base della probabilità e come si assegnano le probabilità agli eventi definiti sopra uno spazio campione discreto. Abbiamo anche introdotto le nozioni di variabile casuale, ovvero di una variabile che assume suoi valori maniera casuale. Abbiamo descritto il modo di specificare la probabilità con cui sono una variabile casuale assume suoi differenti valori, ovvero la funzione di ripartizione \\(F(X) = P(X < x)\\) e la funzione di massa di probabilità.","code":""},{"path":"ch-prob-cond.html","id":"ch-prob-cond","chapter":"Capitolo 7 Probabilità condizionata","heading":"Capitolo 7 Probabilità condizionata","text":"Il fondamento della statistica bayesiana è il teorema di Bayes e il teorema di Bayes è una semplice ridescrizione della probabilità condizionata. Esaminiamo dunque la nozione di probabilità condizionata.","code":""},{"path":"ch-prob-cond.html","id":"sec:bayes-cancer","chapter":"Capitolo 7 Probabilità condizionata","heading":"7.1 Probabilità condizionata su altri eventi","text":"L’attribuzione di una probabilità ad un evento è sempre condizionata dalle conoscenze che abbiamo disposizione. Per un determinato stato di conoscenze, attribuiamo ad un dato evento una certa probabilità di verificarsi; ma se il nostro stato di conoscenze cambia, allora cambierà anche la probabilità che attribuiremo ’evento questione. Infatti, si può pensare che tutte le probabilità siano probabilità condizionate, anche se l’evento condizionante non è sempre esplicitamente menzionato.Per introdurre la probabilità condizionata, Albert Hu (2019) utilizzando il famoso paradosso delle tre carte. “Ci sono tre carte, delle quali la prima (\\(\\)) è rossa su entrambi lati, la seconda (\\(B\\)) su un lato è rossa e sull’altro è bianca e la terza (\\(C\\)) è bianca su entrambi lati. Ponendo su un tavolo una delle tre carte, scelta caso, ottengo che il lato visibile è di colore rosso. Qual è la probabilità che anche il lato non visibile sia di colore rosso? La risposta intuitiva porta solitamente rispondere che la probabilità ricercata sia pari al 50%, quanto solo due carte (la \\(\\) e la \\(B\\)) possono mostrare il colore rosso e solo una di queste (la \\(\\)) può mostrare anche sull’altro lato il colore rosso; tuttavia si dimostra che la risposta giusta è 2/3.” (da Wikipedia)Albert Hu (2019) propongono di risolvere il problema con una simulazione \\(\\textsf{R}\\): prima di tutto si sceglie una carta caso, e poi si sceglie un lato della carta. Ci sono tre carte possibili, che chiamiamo “c_rossa”, “c_bianca”, e “c_entrambi”. Per la carta rossa, ci sono due lati rossi; per la carta bianca ci sono due lati bianchi e la carta “entrambi” ha un lato rosso e un lato bianco.Estraiamo una carta caso e classifichiamo il risultato ottenuto base al tipo di carta e lato osservato. Ripetiamo l’esperimento 1,000 volte:Se si osserva il colore rosso (seconda colonna nella tabella precedente), questo risultato è dovuto ad una carta \\(\\) (“rossa”) 344 casi e ad una carta \\(B\\) (“entrambi”) 160 casi. Quindi, nella simulazione il risultato per cui è stato osservato un colore rosso (344 + 160) è associato ad una carta \\(\\) (“rossa”) circa 2/3 dei casi – se il lato visibile è di colore rosso, allora c’è una probabilità di 2/3 che anche il lato non visibile sia di colore rosso.Questo esempio dimostra come le nostre intuizioni proposito della probabilità condizionata non sono sempre corrette. Consideriamo un altro problema più articolato.Esercizio 7.1  Supponiamo che lo screening per la diagnosi precoce del tumore mammario si avvalga di un test che è accurato al 90%, nel senso che classifica correttamente il 90% delle donne colpite dal cancro e il 90% delle donne che non hanno il cancro al seno. Supponiamo che l’1% delle donne sottoposte allo screening abbia effettivamente il cancro al seno (e d’altra parte, il 99% non lo ha). Ci chiediamo: (1) qual è la probabilità che una donna scelta caso ottenga una mammografia positiva, e (2) se la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?Per risolvere questo problema, supponiamo che il test questione venga somministrato ad un grande campione di donne, diciamo 1000 donne. Di queste 1000 donne, 10 (ovvero, l’1%) hanno il cancro al seno. Per queste 10 donne, il test darà un risultato positivo 9 casi (ovvero, nel 90% dei casi). Per le rimanenti 990 donne che non hanno il cancro al seno, il test darà un risultato positivo 99 casi (se la probabilità di un vero positivo è del 90%, la probabilità di un falso positivo è del 10%). Questa situazione è rappresentata nella figura 7.1.Combinando due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non ce l’hanno, per un totale di 108 risultati positivi. Dunque, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 11%. Ma delle 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno il cancro al seno. Dunque, la probabilità di essere una donna che ha veramente il cancro al seno, dato un risultato positivo al test (che ha le proprietà descritte sopra), è pari \\(\\frac{9}{108}\\) = 8%.\nFIGURA 7.1: Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia un campione di 1,000 donne.\nNell’esercizio precedente, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, mentre la probabilità dell’evento “avere il cancro al seno, dato che il test ha prodotto un risultato positivo” è una probabilità condizionata.termini generali, la probabilità condizionata \\(P(\\mid B)\\) rappresenta la probabilità che si verifichi l’evento \\(\\) sapendo che si è verificato l’evento \\(B\\). Arriviamo dunque alla seguente definizione.Definizione 7.1  Dato un qualsiasi evento \\(\\), si chiama probabilità condizionata di\n\\(\\) dato \\(B\\) il numero\\[\\begin{equation}\nP(\\mid B) = \\frac{P(\\cap B)}{P(B)}, \\quad \\text{con}\\, P(B) > 0,\n\\tag{7.1}\n\\end{equation}\\]dove \\(P(\\cap B)\\) è la probabilità congiunta dei due eventi, ovvero la probabilità che si verifichino entrambi.Concludiamo con un problema molto semplice per consolidare la nostra comprensione del concetto di probabilità condizionata.Esercizio 7.2  Da un mazzo di 52 carte (13 carte per ciascuno dei 4 semi) ne viene estratta una modo casuale. Qual è la probabilità che esca una figura di cuori? Sapendo che la carta estratta ha il seme di cuori, qual è la probabilità che il valore numerico della carta sia 7, 8 o 9?Ci sono 13 carte di cuori, dunque la risposta alla prima domanda è 1/4. Questa è una probabilità non condizionata, dunque il suo calcolo non presenta alcuna difficoltà. La seconda probabilità cercata è una probabilità condizionata. Anche questo secondo caso dobbiamo solo contare, ma, questo caso, considerando solo un sottoinsieme di carte, ovvero le 13 carte di cuori. questo modo è facile arrivare al risultato cercato, ovvero 3/13. Applicando la formula (7.1), con \\(\\) = 7, 8, o 9, e \\(B\\) = cuori arriviamo allo stesso risulato:\\[\nP(\\mid B) = \\frac{P(\\cap B)}{P(B)} = \\frac{3/52}{13/52} = \\frac{3}{13}.\n\\]","code":"\ndf <- tibble(\n  Carta = c(\n    \"c_rossa\", \"c_rossa\", \"c_bianca\", \"c_bianca\", \"c_entrambi\", \n    \"c_entrambi\"\n  ),\n  Lato = c(\n    \"rosso\", \"rosso\", \"bianco\", \"bianco\", \"rosso\", \"bianco\"\n  )\n)\ndf\n#> # A tibble: 6 × 2\n#>   Carta      Lato  \n#>   <chr>      <chr> \n#> 1 c_rossa    rosso \n#> 2 c_rossa    rosso \n#> 3 c_bianca   bianco\n#> 4 c_bianca   bianco\n#> 5 c_entrambi rosso \n#> 6 c_entrambi bianco\nset.seed(84735)\ncarte <- sample_n(df, 1e3, replace = TRUE)\ntable(carte$Carta, carte$Lato)\n#>             \n#>              bianco rosso\n#>   c_bianca      353     0\n#>   c_entrambi    143   160\n#>   c_rossa         0   344"},{"path":"ch-prob-cond.html","id":"la-regola-moltiplicativa","chapter":"Capitolo 7 Probabilità condizionata","heading":"7.2 La regola moltiplicativa","text":"Dalla definizione di probabilità condizionata è possibile esprimere la probabilità congiunta tramite le condizionate. La regola moltiplicativa (o legge delle probabilità composte, o regola della catena) afferma che la probabilità che si verifichino due eventi \\(\\) e \\(B\\) è pari alla probabilità di uno dei due eventi moltiplicato con la probabilità dell’altro evento condizionato al verificarsi del primo:\\[\\begin{equation}\nP(\\cap B) = P(B)P(\\mid B) = P()P(B \\mid ).\n\\tag{7.2}\n\\end{equation}\\]La (7.2) si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\\[\\begin{equation}\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right)\n\\tag{7.3}\n\\end{equation}\\]Per esempio, nel caso di quattro eventi abbiamo\\[\\begin{equation}\n\\begin{split}\nP(A_1 \\cap A_2 \\cap A_3 \\cap A_4) = {}& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot \\\\\n& P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\end{equation}\\]Esercizio 7.3  Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione\n\\(\\{B_1 \\cap B_2\\}\\) e la sua probabilità vale, per la (7.2)\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava\npertanto:\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]modo analogo si ha che\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]Se l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche vale, per la (7.3):\\[\nP(B_1 \\cap B_2 \\cap B_3)=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2),\n\\]dove la probabilità \\(P(B_3 \\mid B_1 \\cap B_2)\\) si calcola supponendo che si sia verificato l’evento condizionante \\(\\{B_1 \\cap B_2\\}\\). Lo spazio campionario per questa probabilità condizionata è costituito da 4 palline bianche e 4 nere, per cui \\(P(B_3 \\mid B_1 \\cap B_2) = 1/2\\) e quindi:\\[\nP (B_1 \\cap B_2 \\cap B_3) = \\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8}  = \\frac{1}{6}.\n\\]La probabilità dell’estrazione di tre palline nere è invece:\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} = \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]","code":""},{"path":"ch-prob-cond.html","id":"lindipendendenza-stocastica","chapter":"Capitolo 7 Probabilità condizionata","heading":"7.3 L’indipendendenza stocastica","text":"Un concetto molto importante per le applicazioni statistiche della probabilità è quello dell’indipendenza stocastica. La definizione (7.1) consente di esprimere il concetto di indipendenza di un evento da un altro forma intuitiva: se \\(\\) e \\(B\\) sono eventi indipendenti, allora il verificarsi di \\(\\) non influisce sulla probabilità del verificarsi di \\(B\\), ovvero non la condiziona, e il verificarsi di \\(B\\) non influisce sulla probabilità del verificarsi di \\(\\). Infatti, per la (7.1), si ha che, se \\(\\) e \\(B\\) sono due eventi indipendenti, risulta:\\[\nP(\\mid B) = \\frac{P()P(B)}{P(B)} = P(),\n\\]\\[\nP(B \\mid ) = \\frac{P()P(B)}{P()} = P(B).\n\\]Possiamo dunque dire che due eventi \\(\\) e \\(B\\) sono indipendenti se\\[\\begin{equation}\n\\begin{split}\nP(\\mid B) &= P(), \\\\\nP(B \\mid ) &= P(B).\n\\end{split}\n\\end{equation}\\]Esercizio 7.4  Nel lancio di due dadi non truccati, si considerino gli eventi: \\(\\) = {esce un 1 o un 2 nel primo lancio} e \\(B\\) = {il punteggio totale è 8}. Gli eventi \\(\\) e \\(B\\) sono indipendenti?Rappresentiamo qui sotto lo spazio campione dell’esperimento casuale.\nFIGURA 7.2: Rappresentazione dello spazio campionario dei risultati dell’esperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l’evento \\(B\\): ‘il punteggio totale è 8’.\nGli eventi \\(\\) e \\(B\\) non sono statisticamente indipendenti. Infatti, le loro probabilità valgono \\(P() = 12/36\\) e \\(P(B) = 5/36\\) e la probabilità della loro intersezione è\\[\nP(\\cap B) = 1/36 = 3/108 \\neq P()P(B) = 5/108.\n\\]Osservazione. Il concetto di indipendenza è del tutto differente da quello di incompatibilità. Si noti infatti che due eventi e B incompatibili (per quali si ha \\(\\cap B = \\emptyset\\)) sono statisticamente dipendenti, poiché il verificarsi dell’uno esclude il verificarsi dell’altro: \\(P(\\cap B)=0 \\neq P()P(B)\\).","code":""},{"path":"ch-prob-cond.html","id":"il-teorema-della-probabilità-totale","chapter":"Capitolo 7 Probabilità condizionata","heading":"7.4 Il teorema della probabilità totale","text":"Dato un insieme finito \\(A_i\\) di eventi, nel calcolo della probabilità dell’unione di tutti gli eventi, se gli eventi considerati non sono due due incompatibili, si deve tenere conto delle loro intersezioni. particolare, la probabilità dell’unione di due eventi \\(\\) e \\(B\\) è pari alla somma delle singole probabilità \\(P()\\) e \\(P(B)\\) diminuita della probabilità della loro intersezione:\\[\\begin{equation}\nP(\\cup B) = P() + P(B) - P(\\cap B).\n\\tag{7.4}\n\\end{equation}\\]Nel caso di tre eventi, si ha\\[\n\\begin{split}\nP(\\cup B \\cup C) &= P()+P(B)+P(C)-P(\\cap B)-P(\\cap C) - \\\\\n& \\qquad P(B\\cap C) + P(\\cap B\\cap C).\n\\end{split}\n\\]La formula per il caso di \\(n\\) eventi si ricava per induzione.Per il caso di due soli eventi, se \\(\\) e \\(B\\) sono indipendenti, la (7.4) si modifica nella relazione seguente:\\[\\begin{equation}\nP(\\cup B) = P() + P(B) - P()P(B).\n\\end{equation}\\]Nel caso di due eventi \\(\\) e \\(B\\) incompatibili, se cioè \\(P(\\cap B) = \\varnothing\\), si ha che\\[\n\\cap B=\\varnothing \\Rightarrow P(\\cup B)=P()+P(B).\n\\]Si può dimostrare per induzione che ciò vale anche per un insieme finito di eventi \\(A_{n}\\) due due incompatibili, ovvero che:\\[\nA_i\\cap A_j=\\varnothing, \\neq j \\Rightarrow P\\left(\\bigcup_{=1}^n A_i\\right)=\\sum_{=1}^nP(A_i).\n\\]","code":""},{"path":"ch-prob-cond.html","id":"il-teorema-della-probabilità-assoluta","chapter":"Capitolo 7 Probabilità condizionata","heading":"7.5 Il teorema della probabilità assoluta","text":"Il teorema della probabilità assoluta consente di calcolare la probabilità di un evento \\(E\\) di cui sono note le probabilità condizionate rispetto ad altri eventi \\((H_i)_{\\geq 1}\\), condizione che essi costituiscano una partizione dell’evento certo \\(\\Omega\\), ovvero\\(\\bigcup_{=1}^\\infty H_i = \\Omega\\);\\(H_j \\cap H_j = \\emptyset, \\neq j\\);\\(P(H_i) > 0, = 1, \\dots, \\infty\\).Nel caso di una partizione dello spazio campione \\(n\\) sottoinsiemi abbiamo\\[\\begin{equation}\nP(E) = \\sum_{=1}^n P(H_i\\cap E) = \\sum_{=1}^n P(E \\mid H_i) P(H_i).\n\\end{equation}\\]Consideriamo, ad esempio, una partizione dell’evento certo tre sottoinsiemi.\nFIGURA 7.3: Partizione dell’evento certo \\(\\Omega\\) tre sottoinsiemi sui quali viene definito l’evento \\(E\\).\ntali circostanze si ha che\\[\\begin{equation}\nP(E) = P(E \\cap H_1) + P(E \\cap H_2) + P(E \\cap H_3), \\notag\n\\tag{7.5}\n\\end{equation}\\]ovvero\\[\\begin{equation}\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2) + P(E \\mid H_3) P(H_3).\n\\tag{7.6}\n\\end{equation}\\]base al teorema della probabilità assoluta, dunque, se l’evento \\(E\\) è costituito da tutti gli eventi elementari \\(E \\cap H_1\\), \\(E \\cap H_2\\) e \\(E \\cap H_3\\), allora la sua probabilità è data dalla somma delle probabilità condizionate \\(P(E \\mid H_i)\\), ciascuna delle quali pesata per la probabilità dell’evento condizionante \\(H_i\\).Esercizio 7.5  Si considerino tre urne, ciascuna delle quali contiene 100 palline:Urna 1: 75 palline rosse e 25 palline blu,Urna 2: 60 palline rosse e 40 palline blu,Urna 3: 45 palline rosse e 55 palline blu.\nUna pallina viene estratta caso da un’urna anch’essa scelta caso.\nQual è la probabilità che la pallina estratta sia di colore rosso?Sia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che\ncorrisponde alla scelta dell’\\(\\)-esima urna. Sappiamo che\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]Gli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello\nspazio campione quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi\nmutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). base al teorema della probabilità assoluta, la probabilità di estrarre una pallina rossa è dunque\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]","code":""},{"path":"ch-prob-cond.html","id":"indipendenza-condizionale","chapter":"Capitolo 7 Probabilità condizionata","heading":"7.6 Indipendenza condizionale","text":"Aggiungo qui delle considerazioni sul concetto di indipendenza condizionale cui si farà riferimento nell’ultima parte della dispensa. L’indipendenza condizionale descrive situazioni cui un’osservazione è irrilevante o ridondante quando si valuta la certezza di un’ipotesi. L’indipendenza condizionale è solitamente formulata nei termini della probabilità condizionata, come un caso speciale cui la probabilità dell’ipotesi data un’osservazione non informativa è uguale alla probabilità senza tale osservazione non informativa.Se \\(\\) è l’ipotesi e \\(B\\) e \\(C\\) sono osservazioni, l’indipendenza condizionale può essere espressa come l’uguaglianza:\\[\nP(\\mid B,C)=P(\\mid C).\n\\]Dato che \\(P(\\mid B,C)\\) è uguale \\(P(\\mid C)\\), questa uguaglianza corrisponde ’affermazione che \\(B\\) non fornisce alcun contributo alla certezza di \\(\\). questo caso si dice che \\(\\) e \\(B\\) condizionalmente indipendenti dato \\(C\\), scritto simbolicamente come: \\((\\perp\\!\\!\\!\\!\\perp B \\mid C)\\).maniera equivalente, l’indipendenza condizionale \\((\\perp\\!\\!\\!\\!\\perp B \\mid C)\\) si verifica se:\\[\nP(, B \\mid C) = P(\\mid C) P(B \\mid C).\n\\]Un esempio è il seguente (da Wikipedia). Siano due eventi le probabilità che le persone \\(\\) e \\(B\\) tornino casa tempo per la cena, e il terzo evento è il fatto che una tempesta di neve ha colpito la città. Mentre sia \\(\\) che \\(B\\) hanno una probabilità più piccola di tornare casa tempo per la cena di quando non c’è la neve, tali probabilità sono indipendenti l’una dall’altra. Cioè, sapere che \\(\\) è ritardo non ci dice nulla sul fatto che \\(B\\) sia ritardo o meno – \\(\\) e \\(B\\) potrebbero vivere quartieri diversi, percorrere distanze diverse e utilizzare mezzi di trasporto diversi. Tuttavia, se sapessimo che \\(\\) e \\(B\\) vivono nello stesso quartiere, usano lo stesso mezzo di trasporto e lavorano nello stesso luogo, allora due eventi non sarebbero condizionatamente indipendenti.","code":""},{"path":"ch-prob-cond.html","id":"commenti-e-considerazioni-finali-5","chapter":"Capitolo 7 Probabilità condizionata","heading":"Commenti e considerazioni finali","text":"La probabilità condizionata è importante perché ci fornisce uno strumento per precisare il concetto di indipendenza statistica. Una delle domande più importanti delle analisi statistiche è infatti quella che si chiede se due variabili siano associate tra loro oppure . questo Capitolo abbiamo discusso il concetto di indipendenza (come contrapposto al concetto di associazione). seguito vedremo come sia possibile fare inferenza sull’associazione tra variabili.","code":""},{"path":"ch-theorem-bayes.html","id":"ch-theorem-bayes","chapter":"Capitolo 8 Il teorema di Bayes","heading":"Capitolo 8 Il teorema di Bayes","text":"Il teorema di Bayes assume un ruolo fondamentale nell’interpretazione soggettivista della probabilità perché descrive l’aggiornamento della fiducia che si aveva nel verificarsi di una determinata ipotesi \\(H\\) (identificata con la probabilità assegnata ’ipotesi stessa) conseguenza del verificarsi dell’evidenza \\(E\\).","code":""},{"path":"ch-theorem-bayes.html","id":"il-teorema-di-bayes","chapter":"Capitolo 8 Il teorema di Bayes","heading":"8.1 Il teorema di Bayes","text":"Teorema 8.1  Sia \\((H_i)_{\\geq 1}\\) una partizione dell’evento certo \\(\\Omega\\) e sia \\(E \\subseteq \\Omega\\) un evento tale che \\(p(E) > 0\\), allora, per \\(= 1, \\dots, \\infty\\):\\[\\begin{equation}\n{\\mbox{P}}(H_i \\mid E) = \\frac{{\\mbox{P}}(E \\mid H_i){\\mbox{P}}(H_i)}{\\sum_{j=1}^{\\infty}{\\mbox{P}}(H_j)P(E \\mid H_j)}.\n\\tag{8.1}\n\\end{equation}\\]La formula di Bayes contiene tre concetti fondamentali. primi due distinguono il grado di fiducia precedente al verificarsi dell’evidenza \\(E\\) da quello successivo al verificarsi dell’evidenza \\(E\\). Pertanto, dati gli eventi \\(H, E \\subseteq \\Omega\\)si definisce probabilità priori la probabilità che viene attribuita al verificarsi dell’ipotesi \\(H\\) prima di sapere che si è verificato l’evento \\(E\\), tenendo conto delle caratteristiche cognitive del decisore (esperienza, modo di pensare, ecc.);si definisce probabilità posteriori la probabilità assegnata ad \\(H\\) una volta che sia noto \\(E\\), ovvero l’aggiornamento della probabilità priori alla luce della nuova evidenza \\(E\\).Il terzo concetto definisce la probabilità che ha l’evento \\(E\\) di verificarsi quando è vera l’ipotesi \\(H\\), ovvero la probabilità dell’evidenza base ’ipotesi. Pertanto, dati gli eventi \\(H, E \\subseteq \\Omega\\) si definisce verosimiglianza di \\(H\\) dato \\(E\\) la probabilità condizionata che si verifichi \\(E\\), se è vera \\(H\\): \\(P (E \\mid H)\\).Si noti che, per il calcolo della quantità denominatore, si ricorre al teorema della probabilità assoluta.Esercizio 8.1  Per fare un esempio, considerando una partizione dell’evento certo \\(\\Omega\\) due soli eventi che chiamiamo ipotesi \\(H_1\\) e \\(H_2\\). Supponiamo conosciute le probabilità priori \\(P(H_1)\\) e \\(P(H_2)\\). Consideriamo un terzo evento \\(E \\subseteq \\Omega\\) con probabilità non nulla di cui si conosce la verosimiglianza, ovvero si conoscono le probabilità condizionate \\({\\mbox{P}}(E \\mid H_1)\\) e \\(P(E \\mid H_2)\\). Supponendo che si sia verificato l’evento \\(E\\), vogliamo conoscere le probabilità posteriori delle ipotesi, ovvero \\(P(H_1 \\mid E)\\) e \\(P(H_2 \\mid E)\\).Per trovare le probabilità cercate scriviamo:\\[\n\\begin{split}\nP(H_1 \\mid E) &= \\frac{P(E \\cap H_1)}{P(E)}\\notag\\\\\n              &= \\frac{P(E \\mid H_1) P(H_1)}{P(E)}.\n\\end{split}\n\\]Sapendo che \\(E = (E \\cap H_1) \\cup (E \\cap H_2)\\) e che \\(H_1\\) e \\(H_2\\) sono eventi disgiunti, ovvero \\(H_1 \\cap H_2 = \\emptyset\\), ne segue che possiamo calcolare \\({\\mbox{P}}(E)\\) utilizzando il teorema della probabilità assoluta:\\[\n\\begin{split}\nP(E) &= P(E \\cap H_1) + P(E \\cap H_2)\\notag\\\\\n     &= P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2).\n\\end{split}\n\\]\nSostituendo tale risultato nella formula precedente otteniamo:\\[\\begin{equation}\nP(H_1 \\mid E) = \\frac{P(E \\mid H_1)P(H_1)}{P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2)}.\n\\tag{8.2}\n\\end{equation}\\]Un lettore attento si sarà reso conto che, precedenza, abbiamo già applicato il teorema di Bayes quando abbiamo risolto l’esercizio riportato nella Sezione 7.1. quel caso, le due ipotesi erano “malattia”, che possiamo denotare con \\(M\\), e “malattia assente”, \\(M^\\complement\\). L’evidenza \\(E\\) è costituita dal risultato positivo al test, ovvero \\(+\\). Con questa nuova notazione la (8.2) diventa:\\[\\begin{equation}\nP(M \\mid +) = \\frac{P(+ \\mid M) P(M)}{P(+ \\mid M) P(M) + P(+ \\mid M^\\complement) P(M^\\complement)}\\notag\n\\end{equation}\\]Inserendo dati nella formula, otteniamo\\[\\begin{align}\nP(M \\mid +) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\\]","code":""},{"path":"ch-theorem-bayes.html","id":"commenti-e-considerazioni-finali-6","chapter":"Capitolo 8 Il teorema di Bayes","heading":"Commenti e considerazioni finali","text":"Il teorema di Bayes rende esplicito il motivo per cui la probabilità non possa essere pensata come uno stato oggettivo, quanto piuttosto come un’inferenza soggettiva e condizionata. Il denominatore del membro di destra della (8.1) è un semplice fattore di normalizzazione. Nel numeratore compaiono invece due quantità: \\({\\mbox{P}}(H_i\\)) e \\({\\mbox{P}}(E \\mid H_i)\\). La probabilità \\({\\mbox{P}}(H_i\\)) è la probabilità probabilità priori (prior) dell’ipotesi \\(H_i\\) e rappresenta l’informazione che l’agente bayesiano possiede proposito dell’ipotesi \\(H_i\\). Diremo che \\({\\mbox{P}}(H_i)\\) codifica il grado di fiducia che l’agente ripone \\(H_i\\) precedentemente al verificarsi dell’evidenza \\(E\\). Nell’interpretazione bayesiana, \\({\\mbox{P}}(H_i)\\) rappresenta un giudizio personale dell’agente e non esistono criteri esterni che possano determinare se tale giudizio sia coretto o meno. La probabilità condizionata \\({\\mbox{P}}(E \\mid H_i)\\) rappresenta invece la verosimiglianza di \\(H_i\\) dato \\(E\\) e descrive la plausibilità che si verifichi l’evento \\(E\\) se è vera l’ipotesi \\(H_i\\). Il teorema di Bayes descrive la regola che l’agente deve seguire per aggiornare il suo grado di fiducia nell’ipotesi \\(H_i\\) alla luce del verificarsi dell’evento \\(E\\). La \\({\\mbox{P}}(H_i \\mid E)\\) è chiamata probabilità posteriori dato che rappresenta la nuova probabilità che l’agente assegna ’ipotesi \\(H_i\\) affinché rimanga consistente con le nuove informazioni fornitegli da \\(E\\).La probabilità posteriori dipende sia dall’evidenza \\(E\\), sia dalla conoscenza priori dell’agente \\({\\mbox{P}}(H_i)\\). È dunque chiaro come non abbia senso parlare di una probabilità oggettiva: per il teorema di Bayes la probabilità è definita condizionatamente alla probabilità priori, la quale sua volta, per definizione, è un’assegnazione soggettiva. Ne segue pertanto che ogni probabilità deve essere considerata come una rappresentazione del grado di fiducia soggettiva dell’agente. Dato che ogni assegnazione probabilistica rappresenta uno stato di conoscenza e che ciascun particolare stato di conoscenza è arbitrario, un accordo tra agenti diversi non è richiesto. Tuttavia, la teoria delle probabilità ci fornisce uno strumento che, alla luce di nuove evidenze, consente di aggiornare un modo razionale il grado di fiducia che attribuiamo ad un’ipotesi, via via che nuove evidenze vengono raccolte, modo tale da formulare un’ipotesi posteriori la quale non è mai definitiva, ma può sempre essere aggiornata base alle nuove evidenze disponibili. Questo processo si chiama aggiornamento bayesiano. Vedremo nel Capitolo ?? come estendere la (8.1) al caso continuo.","code":""},{"path":"ch-prob-congiunta.html","id":"ch-prob-congiunta","chapter":"Capitolo 9 Probabilità congiunta","heading":"Capitolo 9 Probabilità congiunta","text":"La probabilità congiunta è la probabilità che due o più eventi si verifichino contemporaneamente. questo Capitolo verrà esaminato dettaglio il caso discreto.","code":""},{"path":"ch-prob-congiunta.html","id":"funzione-di-probabilità-congiunta","chapter":"Capitolo 9 Probabilità congiunta","heading":"9.1 Funzione di probabilità congiunta","text":"Dopo aver trattato della distribuzione di probabilità di una variabile casuale, la quale associa ad ogni evento elementare dello spazio campione uno ed un solo numero reale, è naturale estendere questo concetto al caso di due o più variabili casuali.Iniziamo descrivere il caso discreto con un esempio. Consideriamo l’esperimento casuale corrispondente al lancio di tre monete equilibrate. Lo spazio campione è\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\}.\n\\]Dato che tre lanci sono tra loro indipendenti, non c’è ragione di aspettarsi che uno degli otto risultati possibili dell’esperimento sia più probabile degli altri, dunque possiamo associare ciascuno degli otto eventi elementari dello spazio campione la stessa probabilità, ovvero 1/8.Siano \\(X \\\\{0, 1, 2, 3\\}\\) = “numero di realizzazioni con il risultato testa nei tre lanci” e \\(Y \\\\{0, 1\\}\\) = “numero di realizzazioni con il risultato testa nel primo lancio” due variabili casuali definite sullo spazio campione \\(\\Omega\\). Indicando con T = ‘testa’ e C = ‘croce’, si ottiene la situazione riportata nella tabella 9.1.TABELLA 9.1:  Spazio campione dell’esperimento consistente nel lancio di tre monete equilibrate su cui sono state definite le variabili aleatorie \\(X\\) = ‘numero di realizzazioni con il risultato testa nei tre lanci’ e \\(Y\\) = ‘numero di realizzazioni con il risultato testa nel primo lancio’.Ci poniamo il problema di associare un valore di probabilità ad ogni coppia \\((x, y)\\) definita su \\(\\Omega\\). La coppia \\((X = 0, Y = 0)\\) si realizza corrispondenza di un solo evento elementare, ovvero CCC; avrà dunque una probabilità pari \\(P(X=0, Y=0) = P(CCC) = 1/8\\). Nel caso della coppia \\((X = 1, Y = 0)\\) ci sono due eventi elementari che danno luogo al risultato considerato, ovvero, CCT e CTC. La probabilità dell’evento composto \\(P(X=1, Y=0)\\) è uguale alla somma delle probabilità dei due eventi elementari che lo costituiscono, cioé \\(P(X=1, Y=0) = P(\\mbox{CCT}) + P(\\mbox{CTC}) = 1/8 + 1/8 = 1/4\\). Sono riportati qui sotto calcoli per tutti possibili valori di \\(X, Y\\).\\[\\begin{align}\nP(X = 0, Y = 0) &= P(\\omega_8 = CCC) = 1/8; \\notag\\\\\nP(X = 1, Y = 0) &= P(\\omega_5 = CCT) + P(\\omega_6 = CTC) = 2/8; \\notag\\\\\nP(X = 1, Y = 1) &= P(\\omega_7 = TCC) = 1/8; \\notag\\\\\nP(X = 2, Y = 0) &= P(\\omega_4 = CTT) = 1/8; \\notag\\\\\nP(X = 2, Y = 1) &= P(\\omega_3 = TCT) + P(\\omega_2 = TTC) = 2/8; \\notag\\\\\nP(X = 3, Y = 1) &= P(\\omega_1 = TTT) = 1/8; \\notag\n\\end{align}\\]Le probabilità così trovate sono riportate nella tabella 9.2 la quale descrive la distribuzione di probabilità congiunta delle variabili casuali \\(X\\) = “numero di realizzazioni con il risultato testa nei tre lanci” e \\(Y\\) = “numero di realizzazioni con il risultato testa nel primo lancio” per l’esperimento casuale consistente nel lancio di tre monete equilibrate.TABELLA 9.2:  Distribuzione di probabilità congiunta per risultati dell’esperimento consistente nel lancio di tre monete equilibrate.generale, possiamo dire che, dato uno spazio campione discreto \\(\\Omega\\), è possibile associare ad ogni evento elementare \\(\\omega_i\\) dello spazio campione una coppia di numeri reali \\((x, y)\\), essendo \\(x = X(\\omega)\\) e \\(y = Y(\\omega)\\), il che ci conduce alla seguente definizione.Definizione 9.1  Siano \\(X\\) e \\(Y\\) due variabili casuali. La funzione che associa ad ogni coppia \\((x, y)\\) un valore di probabilità prende il nome di funzione di probabilità congiunta:\\[\\begin{equation}\nP(x, y) = P(X = x, Y = y).\n\\end{equation}\\]Il termine “congiunta” deriva dal fatto che questa probabilità è legata al verificarsi di una coppia di valori, il primo associato alla variabile casuale \\(X\\) ed il secondo alla variabile casuale \\(Y\\). Nel caso di due sole variabili casuali si parla di distribuzione bivariata, mentre nel caso di più variabili casuali si parla di distribuzione multivariata.","code":""},{"path":"ch-prob-congiunta.html","id":"proprietà","chapter":"Capitolo 9 Probabilità congiunta","heading":"9.1.1 Proprietà","text":"Una distribuzione di massa di probabilità congiunta bivariata deve soddisfare due proprietà:\\(0 \\leq P(x_i, y_j) \\leq 1\\);\\(0 \\leq P(x_i, y_j) \\leq 1\\);la probabilità totale deve essere uguale \\(1.0\\). Tale proprietà può essere espressa nel modo seguentela probabilità totale deve essere uguale \\(1.0\\). Tale proprietà può essere espressa nel modo seguente\\[\n\\sum_{} \\sum_{j} P(x_i, y_j) = 1.0.\n\\]","code":""},{"path":"ch-prob-congiunta.html","id":"eventi","chapter":"Capitolo 9 Probabilità congiunta","heading":"9.1.2 Eventi","text":"Si noti che dalla probabilità congiunta possiamo calcolare la probabilità di qualsiasi evento definito base alle variabili aleatorie \\(X\\) e \\(Y\\). Per capire come questo possa essere fatto, consideriamo nuovamente l’esperimento casuale discusso precedenza.Esercizio 9.1  Per la distribuzione di massa di probabilità congiunta riportata nella tabella 9.2 si trovi la probabilità dell’evento \\(X+Y \\leq 1\\).Per trovare la probabilità richiesta dobbiamo sommare le probabilità associate tutte le coppie \\((x,y)\\) che soddisfano la condizione \\(X+Y \\leq 1\\), ovvero\\[\\begin{equation}\nP_{XY}(X+Y \\leq 1) = P_{XY}(0, 0)+ P_{XY}(0, 1) + P_{XY}(1, 0) = 3/8.\\notag\n\\end{equation}\\]","code":""},{"path":"ch-prob-congiunta.html","id":"sec:marg-distr-discr","chapter":"Capitolo 9 Probabilità congiunta","heading":"9.1.3 Funzioni di probabilità marginali","text":"Nel caso di due variabili casuali discrete \\(X\\) e \\(Y\\) di cui conosciamo la distribuzione congiunta, la distribuzione marginale di \\(X\\) è calcolata sommando la distribuzione di probabilità congiunta sopra la variabile da “scartare”, questo caso la \\(Y\\). La funzione di massa di probabilità marginale \\(P(X=x)\\) è\\[\\begin{equation}\nP(X = x) = \\sum_y P(X, Y = y) = \\sum_y P(X \\mid Y = y) P(Y = y),\n\\end{equation}\\]dove \\(P(X = x,Y = y)\\) è la distribuzione congiunta di \\(X, Y\\), mentre \\(P(X = x \\mid Y = y)\\) è la distribuzione condizionata di \\(X\\) dato \\(Y\\). Se esaminiamo \\(P(X=x)\\), diciamo che la variabile \\(Y\\) è stata marginalizzata.Le probabilità bivariate marginali e congiunte per variabili casuali discrete sono spesso mostrate come tabelle di contingenza. Si noti che \\(P(X = x)\\) e \\(P(Y = y)\\) sono normalizzate:\\[\n\\sum_x P(X=x) = 1.0, \\quad \\sum_y P(Y=y) = 1.0.\n\\]Nel caso continuo si sostituisce l’integrazione alla somma – si veda la Sezione 9.2.Esercizio 9.2  Per l’esperimento casuale consistente nel lancio di tre monete equilibrate, si calcolino le probabilità marginali di \\(X\\) e \\(Y\\).Nell’ultima colonna destra e nell’ultima riga basso della tabella 9.3 sono riportate le distribuzioni di probabilità marginali di \\(X\\) e \\(Y\\). \\(P_X\\) si ottiene sommando su ciascuna riga fissata la colonna \\(j\\), \\(P_X(X = j) = \\sum_y p_{xy}(x = j, y)\\). \\(P_Y\\) si trova sommando su ciascuna colonna fissata la riga \\(,\\) \\(P_Y (Y = ) = \\sum_x p_{xy}(x, y = )\\).TABELLA 9.3:  Distribuzione di probabilità congiunta \\(p(x,y)\\) per risultati dell’esperimento consistente nel lancio di tre monete equilibrate e probabilità marginali \\(P(x)\\) e \\(P(y)\\).","code":""},{"path":"ch-prob-congiunta.html","id":"sec:margin-vc-cont","chapter":"Capitolo 9 Probabilità congiunta","heading":"9.2 Marginalizzazione di variabili casuali continue","text":"Nella trattazione della statistca bayesiana useremo spesso il concetto di “marginalizzazione” e vedremo equazioni come la seguente:\\[\\begin{equation}\np(y) = \\int_{\\theta} p(y, \\theta) = \\int_{\\theta} p(y \\mid \\theta) p(\\theta),\n\\tag{9.1}\n\\end{equation}\\]laddove \\(y\\) e \\(\\theta\\) sono due variabili casuali continue – nello specifico, con \\(y\\) denoteremo dati e con \\(\\theta\\) parametri di un modello statistico. Per ora, possiamo pensare \\(y\\) e \\(\\theta\\) come due variabili casuali qualsiasi. È possibiile pensare al caso continuo indicato nella (9.1) come ’estensione dell’esempio precedente ad un numero infinito di valori \\(\\theta\\).","code":""},{"path":"ch-prob-congiunta.html","id":"commenti-e-considerazioni-finali-7","chapter":"Capitolo 9 Probabilità congiunta","heading":"Commenti e considerazioni finali","text":"La funzione di probabilità congiunta tiene simultaneamente conto del\ncomportamento di due variabili casuali \\(X\\) e \\(Y\\) e di come esse si\ninfluenzano reciprocamente. particolare, si osserva che se le due\nvariabili discrete \\(X\\) e \\(Y\\) non si influenzano, cioè se sono statisticamente indipendenti, allora la distribuzione di massa di probabilità congiunta si ottiene\ncome prodotto delle funzioni di probabilità marginali di \\(X\\) e \\(Y\\):\n\\(P_{X, Y}(x, y) = P_X(x) P_Y(y)\\).","code":""},{"path":"ch-intro-density-function.html","id":"ch-intro-density-function","chapter":"Capitolo 10 La densità di probabilità","heading":"Capitolo 10 La densità di probabilità","text":"Finora abbiamo considerato solo variabili casuali discrete, cioè variabili che assumono solo valori interi. Ma cosa succede se vogliamo usare variabili casuali per rappresentare lunghezze, o volumi, o distanze, o una qualsiasi delle altre proprietà continue nel mondo fisico (o psicologico)? È necessario generalizzare l’approccio usato finora.Le variabili casuali continue assumono valori reali. L’insieme dei numeri reali è non numerabile perché è più grande dell’insieme degli interi.7 Le leggi della probabilità sono le stessa per le variabili casuali discrete e quelle continue. La nozione di funzione di massa di probabilità, invece, deve essere sostituita dal suo equivalente continuo, ovvero dalla funzione di densità di probabilità. Lo scopo di questo Capitolo è quello di chiarire il significato di questa nozione, usando un approccio basato sulle simulazioni.","code":""},{"path":"ch-intro-density-function.html","id":"spinner-e-variabili-casuali-continue-uniformi","chapter":"Capitolo 10 La densità di probabilità","heading":"10.1 Spinner e variabili casuali continue uniformi","text":"Consideriamo il seguente esperimento casuale. Facciamo ruotare ad alta velocità uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione cui si ferma (individuata dall’angolo acuto con segno tra il suo asse e l’asse orizzontale del goniometro). Chiamiamo \\(\\Theta\\) la variabile casuale “pendenza dello spinner”. Nella trattazione seguente useremo gradi e, di conseguenza, \\(\\Theta \\[0, 360]\\).\nFIGURA 10.1: Uno spinner che riposa 36 gradi, o il dieci percento del percorso intorno al cerchio. La pendenza dello spinner può assumere qualunque valore tra 0 e 360 gradi.\nCosa implica per \\(\\Theta\\) dire che lo spinner è simmetrico? Possiamo dire che, ciascuna prova, la rotazione dello spinner produce un angolo qualunque da 0 360 gradi. altri termini, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilità di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, poiché 36 gradi è un decimo del percorso intorno al cerchio, la probabilità di ottenere un qualsiasi intervallo di 36 gradi sarà sempre uguale al 10%. Ovvero \\(\\mbox{P}(0 \\leq \\Theta \\leq 36) \\ = \\ \\frac{1}{10}\\) e \\(\\mbox{P}(200 \\leq \\Theta \\leq 236) \\ = \\ \\frac{1}{10}\\).È importante notare che le probabilità precedenti non si riferiscono al fatto che \\(\\Theta\\) assume uno specifico valore, ma piuttosto ’evento di osservare \\(\\Theta\\) un intervallo di valori. generale, la probabilità che la pendenza \\(\\Theta\\) dello spinner cada intervallo è la frazione del cerchio rappresentata dall’intervallo, cioè,\\[\n\\mbox{P}(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}, \\qquad 0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360.\n\\]La ragione di questo è che le variabili casuali continue non hanno una massa di probabilità. Invece, una massa di probabilità viene assegnata alla realizzazione della variabile casuale un intervallo di valori.","code":""},{"path":"ch-intro-density-function.html","id":"il-paradosso-delle-variabili-casuali-continue","chapter":"Capitolo 10 La densità di probabilità","heading":"10.1.1 Il paradosso delle variabili casuali continue","text":"Nel nostro esempio, la pendenza dello spinner è esattamente 36 gradi; ma avrebbe anche potuto essere 36.0376531 gradi, o qualunque altro valore quell’intorno. Qual è la probabilità che la pendenza dello spinner sia esattamente 36? Paradossalmente, la risposta è zero:\\[\n\\mbox{P}(\\Theta = 36) = 0.\n\\]Infatti, se la probabilità di un qualunque valore fosse maggiore di zero, ogni altro possibile valore dovrebbe avere la stessa probabilità, dato che abbiamo assunto che tutti valori \\(\\Theta\\) siano egualmente probabili. Ma se poi andiamo sommare tutte queste probabilità il totale diventerà maggiore di uno, il che non è possibile.Nel caso delle variabili casuali continue dobbiamo dunque rinunciare qualcosa, e quel qualcosa è l’idea che, una distribuzione continua, ciascun valore puntuale della variabile casuale possa avere una massa di probabilità maggiore di zero. Il paradosso sorge perché una realizzazione della variabile casuale continua produce sempre un qualche numero, ma ciscuno di tali numeri ha probabilità nulla.","code":""},{"path":"ch-intro-density-function.html","id":"la-funzione-di-ripartizione-per-una-variabile-casuale-continua","chapter":"Capitolo 10 La densità di probabilità","heading":"10.2 La funzione di ripartizione per una variabile casuale continua","text":"Supponiamo che \\(\\Theta \\sim \\mathcal{U}(0, 360)\\) sia la pendenza dello spinner. La funzione di ripartizione (ovvero, la distribuzione cumulativa) è definita esattamente come nel caso delle variabili casuali discrete:\\[\nF_{\\Theta}(\\theta) = \\mbox{P}(\\Theta \\leq \\theta).\n\\]Cioè, è la probabilità che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale \\(\\theta\\). questo caso, poiché si presume che lo spinner sia simmetrico, la funzione di distribuzione cumulativa è\\[\nF_{\\Theta}(\\theta) = \\frac{\\theta}{360}.\n\\]Questa è una funzione lineare di \\(\\theta\\), cioè \\(\\frac{1}{360} \\cdot \\theta\\), come indicato dal grafico della figura 10.2.\nFIGURA 10.2: Funzione di distribuzione cumulativa per l’angolo \\(\\theta\\) (gradi) risultante da una rotazione di uno spinner simmetrico. La linea tratteggiata mostra il valore 180 gradi, che corrisponde ad una probabilità di 0.5, e la linea tratteggiata 270 gradi, che corrisponde ad una probabilità di 0.75.\nPossiamo verificare questo risultato mediante simulazione. Per stimare la funzione di ripartizione, simuliamo \\(M\\) valori \\(\\theta^{(m)}\\) e poi li ordiniamo ordine crescente.\nFIGURA 10.3: Grafico della funzione di ripartizione di una variabile casuale \\(\\Theta\\) che rappresenta il risultato di una rotazione di uno spinner simmetrico. Come previsto, tale funzione è una semplice funzione lineare perché la variabile sottostante \\(\\Theta\\) ha una distribuzione uniforme.\nAnche con M = 1000, tale grafico è praticamente indistinguibile da quello prodotto per via analitica.Come nel caso delle variabili casuali discrete, la funzione di ripartizione può essere utilizzata per calcolare la probabilità che la variabile casuale assuma valori un certo intervallo. Ad esempio\\[\\begin{align}\n\\mbox{P}(180 < \\Theta \\leq 270) &= \\mbox{P}(\\Theta \\leq 270) \\ - \\ \\mbox{P}(\\Theta \\leq 180) \\notag\\\\\n&= F_{\\Theta}(270) - F_{\\Theta}(180)\\notag\\\\\n&= \\frac{3}{4} - \\frac{1}{2} \\notag\\\\\n&= \\frac{1}{4}.\\noindent\n\\end{align}\\]","code":"\nM <- 1000\ntheta <- runif(M, 0, 360)\ntheta_asc <- sort(theta)\nprob <- (1:M) / M\nunif_cdf_df <- data.frame(\n  theta = theta_asc,\n  prob = prob\n)\nunif_cdf_plot <-\n  unif_cdf_df %>%\n  ggplot(aes(x = theta, y = prob)) +\n  geom_line() +\n  scale_x_continuous(breaks = c(0, 90, 180, 270, 360)) +\n  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1.0)) +\n  xlab(expression(theta)) +\n  ylab(expression(F(Theta)(theta)))\nunif_cdf_plot"},{"path":"ch-intro-density-function.html","id":"la-distribuzione-uniforme","chapter":"Capitolo 10 La densità di probabilità","heading":"10.3 La distribuzione uniforme","text":"Dopo avere visto come generare numeri casuali uniformi da 0 360, consideriamo ora una variabile casuale che assume valori nell’intervallo da 0 1. Chiamiamo tale variabile casuale \\(\\Theta\\) e assumiamo che abbia una distribuzione continua uniforme sull’intervallo [0, 1]:\\[\n\\Theta \\sim \\mathcal{U}(0, 1).\n\\]Poiché le probabilità assumono valori nell’intervallo [0, 1], possiamo pensare \\(\\Theta\\) come ad un valore di probabilità preso caso ciascuna realizzazione dell’esperimento casuale.La distribuzione uniforme è la più semplice delle distribuzioni di densità di probabilità. Per chiarire le proprietà di tale distribuzione, iniziamo con una simulazione e generiamo 10,000 valori casuali di \\(\\Theta\\). primi 10 di tali valori sono stampati qui di seguito:Creiamo ora un istogramma che descrive la distribuzione delle 10,000 realizzazioni \\(\\Theta\\) che abbiamo trovato:\nFIGURA 10.4: Istogramma di \\(10\\,000\\) realizzazioni \\(\\Theta \\sim \\mbox{Uniform}(0, 1)\\).\nÈ chiaro che, ’aumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell’istogramma tenderà diventare una linea retta. Ciò significa che la funzione di densità di una variabile casuale uniforme continua è una costante. Cioè, se \\(\\Theta \\sim \\mathcal{U} (, b)\\), allora \\(p_{\\Theta}(\\theta) = c\\), dove \\(c\\) è una costante.\nDal grafico vediamo che l’area sottesa alla funzione di densità è \\((b - )\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - ) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi termini per \\(b - \\),\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - }.\n\\]Ovvero, se \\(\\Theta \\sim \\mathcal{U}(, b)\\), allora\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid , b),\n\\]laddove\\[\n\\mathcal{U}(\\theta \\mid , b) = \\frac{1}{b - }.\n\\]conclusione, la densità di una variabile casuale uniforme continua non dipende da \\(\\theta\\) — è costante e identica per ogni possibile valore \\(\\theta\\).8 Vedremo nel prossimo Paragrafo che, eseguendo una trasformazione su questa variabile casuale uniforme, possiamo creare altre variabili casuali di interesse.Esercizio 10.1  Si consideri una variabile casuale uniforme \\(X\\) definita sull’intervallo [0, 100]. Si trovi la probabilità \\(P(20 < X < 60)\\).Per trovare la soluzione è sufficiente calcolare l’area di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilità cercata è dunque \\(P(20 < X < 60) = 40 \\cdot 0.01 = 0.4\\).","code":"\nset.seed(1234)\nM <- 10000\ntheta <- runif(M)\ntheta[1:10]\n#>  [1] 0.113703411 0.622299405 0.609274733 0.623379442 0.860915384 0.640310605\n#>  [7] 0.009495756 0.232550506 0.666083758 0.514251141\ndf_prob_unif <- data.frame(theta = theta)\nunif_prob_plot <-\n  ggplot(df_prob_unif, aes(theta)) +\n  geom_histogram(\n    binwidth = 1 / 34, center = 1 / 68, color = \"black\",\n    size = 0.25\n  ) +\n  scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +\n  scale_y_continuous(lim = c(0, 1000), breaks = c(500, 1000)) +\n  xlab(expression(paste(Theta, \" ~ Uniform(0, 1)\")))\nunif_prob_plot\nuniform_pdf_df <- data.frame(y = c(0, 1), p_y = c(1, 1))\nuniform_pdf_plot <-\n  ggplot(uniform_pdf_df, aes(x = y, y = p_y)) +\n  geom_line(size = 0.5, color = \"#333333\") +\n  geom_point(size = 1.5, color = \"#333333\") +\n  scale_x_continuous(breaks = c(0, 1), labels = c(\"a\", \"b\")) +\n  scale_y_continuous(\n    lim = c(0, 1), breaks = c(0, 1),\n    labels = c(\"0\", \"c\")\n  ) +\n  xlab(expression(theta)) +\n  ylab(expression(paste(p[Theta], \"(\", theta, \" | a, b)\"))) +\n  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 1),\n    linetype = \"dotted\"\n  ) +\n  geom_segment(aes(x = 1, y = 0, xend = 1, yend = 1),\n    linetype = \"dotted\"\n  ) +\n  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 0),\n    linetype = \"dotted\"\n  ) +\n  geom_segment(aes(x = -0.25, y = 0, xend = 0, yend = 0)) +\n  geom_segment(aes(x = 1, y = 0, xend = 1.25, yend = 0)) +\n  geom_point(aes(x = 0, y = 0),\n    size = 1.5, shape = 21,\n    fill = \"#ffffe6\"\n  ) +\n  geom_point(aes(x = 1, y = 0),\n    size = 1.5, shape = 21,\n    fill = \"#ffffe6\"\n  )\nuniform_pdf_plot"},{"path":"ch-intro-density-function.html","id":"dagli-istogrammi-alle-densità","chapter":"Capitolo 10 La densità di probabilità","heading":"10.4 Dagli istogrammi alle densità","text":"Non esiste l’equivalente di una funzione di massa di probabilità per le variabili casuali continue. Esiste invece una funzione di densità di probabilità la quale, nei termini di una simulazione, può essere concepita nel modo seguente: avendo disposizione un numero enorme di casi, quando l’intervallo \\(\\Delta\\) di ciascuna classe \\(\\rightarrow\\) 0, il profilo dell’istogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende diventare una curva continua. Tale curva continua \\(f(x)\\) è detta funzione di densità di probabilità.Come si trasformano gli istogrammi ’aumentare del numero di osservazioni? Per fare un esempio, considereremo una funzione di una variabile casuale uniforme \\([0, 1]\\). Nello specifico, esamineremo la funzione logit:\\[\n\\alpha = \\log \\left(\\frac{\\theta}{1-\\theta}\\right)\n\\]Alcuni valori \\(\\alpha\\) presi caso sono seguenti:Nei grafici seguenti, la numerosità cresce da \\(10\\) \\(1\\,000\\,000\\).\nFIGURA 10.5: Istogramma di \\(M\\) campioni casuali \\(\\Theta \\sim \\mbox{Uniform}(0, 1)\\) trasformati valori \\(\\Phi = \\mbox{logit}(\\Theta).\\) Il profilo limite dell’istogramma è evidenziato nella figura basso destra che è stata costruita usando \\(1\\,000\\,000\\) di osservazioni.\nun istogramma, l’area di ciascuna barra è proporzionale alla frequenza relativa delle osservazioni quel’intervallo. Perché tutti gli intervalli hanno la stessa ampiezza, anche l’altezza di ciascuna barra sarà proporzionale alla frequenza relativa delle osservazioni quel’intervallo.Nella simulazione, possiamo pensare ’area di ciascuna barra dell’istogramma come alla stima della probabilità che la variabile casuale assuma un valore compreso nell’intervallo considerato. ’aumentare del numero \\(M\\) di osservazioni, le probabilità stimate si avvicinano sempre di più ai veri valori della probabilità. ’aumentare del numero degli intervalli (quando l’ampiezza \\(\\Delta\\) dell’intervallo \\(\\rightarrow\\) 0), il profilo dell’istogramma tende diventare una curva continua. Tale curva continua è la funzione di densità di probabilità della variabile casuale. Per l’esempio presente, con \\(M =1\\,000\\,000\\), otteniamo il grafico riportato nella figura 10.6.\nFIGURA 10.6: Istogramma di \\(M = 1\\,000\\,000\\) campioni casuali \\(\\Theta \\sim \\mbox{Uniform}(0,1)\\) trasformati valori \\(\\Phi = \\mbox{logit}(\\Theta)\\). La spezzata nera congiunge punti centrali superiori delle barre dell’istogramma. Nel limite, quando il numero di osservazioni e di barre tende ’infinito, tale spezzata approssima la funzione di densità di probabilità della variabile casuale.\nNella statistica descrittiva abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un metodo non parametrico per stimare la funzione di densità di probabilità di una variabile casuale.","code":"\nset.seed(1234)\nM <- 10000\nlogit <- function(x) log(x / (1 - x))\ntheta <- runif(M)\nalpha <- logit(theta)\nfor (m in 1:10)\n  print(alpha[m])\n#> [1] -2.053458\n#> [1] 0.4993195\n#> [1] 0.4442646\n#> [1] 0.5039172\n#> [1] 1.822914\n#> [1] 0.5767125\n#> [1] -4.647369\n#> [1] -1.193965\n#> [1] 0.6905252\n#> [1] 0.05702001\ndf_log_odds_growth <- data.frame()\nfor (log10M in 1:6) {\n  M <- 10^log10M\n  alpha <- logit(runif(M))\n  df_log_odds_growth <- rbind(\n    df_log_odds_growth,\n    data.frame(\n      alpha = alpha,\n      M = rep(sprintf(\"M = %d\", M), M)\n    )\n  )\n}\nlog_odds_growth_plot <-\n  df_log_odds_growth %>%\n  ggplot(aes(alpha)) +\n  geom_histogram(color = \"black\", bins = 75) +\n  facet_wrap(~M, scales = \"free\") +\n  scale_x_continuous(\n    lim = c(-8.5, 8.5), breaks = c(-5, 0, 5)\n  ) +\n  xlab(expression(paste(Phi, \" = \", logit(Theta)))) +\n  ylab(\"proportion of draws\") +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.spacing.x = unit(2, \"lines\"),\n    panel.spacing.y = unit(2, \"lines\")\n  )\nlog_odds_growth_plot\nM <- 1e6\nalpha <- logit(runif(M))\ndensity_limit_df <- data.frame(alpha = alpha)\ndensity_limit_plot <-\n  density_limit_df %>%\n  ggplot(aes(alpha)) +\n  geom_histogram(\n    stat = \"density\", n = 75, color = \"black\", size = 0.15\n  ) +\n  stat_function(\n    fun = dlogis,\n    args = list(location = 0, scale = 1),\n    col = \"black\",\n    size = 0.3\n  ) +\n  scale_x_continuous(\n    lim = c(-9, 9),\n    breaks = c(-6, -4, -2, 0, 2, 4, 6)\n  ) +\n  xlab(\n    expression(paste(Phi, \" = \", logit(Theta)))\n  ) +\n  ylab(\"Frequenza relativa\") +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  )\ndensity_limit_plot"},{"path":"ch-intro-density-function.html","id":"funzione-di-densità-di-probabilità","chapter":"Capitolo 10 La densità di probabilità","heading":"10.5 Funzione di densità di probabilità","text":"Per descrivere le probabilità che possono essere associate ad una variabile casuale continua \\(X\\) è necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due proprietà:\\(p(x) \\geq 0, \\forall x\\), ovvero, l’ordinata della funzione di densità è 0 o positiva;\\(p(x) \\geq 0, \\forall x\\), ovvero, l’ordinata della funzione di densità è 0 o positiva;\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l’area sottesa dalla \\(p(x)\\) è unitaria9;\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l’area sottesa dalla \\(p(x)\\) è unitaria9;\\(p(< x < b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(\\leq b\\), ovvero, l’area sottesa dalla \\(p(y)\\) tra due punti \\(\\) e \\(b\\) corrisponde alla probabilità che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\\(p(< x < b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(\\leq b\\), ovvero, l’area sottesa dalla \\(p(y)\\) tra due punti \\(\\) e \\(b\\) corrisponde alla probabilità che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.Interpretazione. È possibile che \\(p(x) > 1\\), quindi una densità di probabilità non può essere interpretata come una probabilità. Piuttosto, la densità \\(p(x)\\) può essere utilizzata per confrontare la fiducia relativa che può essere assegnata diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui è disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) > p(x_l)\\), allora possiamo concludere che è più probabile, termini relativi, osservare realizzazioni \\(X\\) nell’intorno di \\(x_k\\) piuttosto che nell’intorno di \\(x_l\\).","code":""},{"path":"ch-intro-density-function.html","id":"la-funzione-di-ripartizione","chapter":"Capitolo 10 La densità di probabilità","heading":"10.6 La funzione di ripartizione","text":"La funzione di ripartizione \\(F(X)\\) è quella funzione che associa ogni valore di una variabile casuale \\(X\\) la probabilità che la variabile assuma valore minore o uguale un prefissato valore \\(x_k\\). Come nel caso discreto, anche nel caso continuo la funzione di ripartizione è sempre non negativa, monotona non decrescente tra \\(0\\) e \\(1\\), tale che:\\[\n\\lim_{x \\-\\infty} F_x(X) = F_X(-\\infty) = 0, \\quad \\lim_{x \\+\\infty} F_X(X) = F_X(+\\infty) = 1.\n\\]Se \\(X\\) è una variabile aleatoria continua, la funzione di ripartizione è:\\[\nF(x_k) = P(X \\leq x_k) = \\int_{-\\infty}^{x_k} f(x) \\,\\operatorname {d}\\!x .\n\\]","code":""},{"path":"ch-intro-density-function.html","id":"media-e-mediana","chapter":"Capitolo 10 La densità di probabilità","heading":"10.7 Media e mediana","text":"Concludiamo questo capitolo con alcune considerazioni relative al contronto tra la media (valore atteso) e la mediana, nel caso di variabili casuali continue.Per distribuzioni simmetriche, sappiamo che la media e la mediana sono uguali. Chiediamoci ora cosa succede, nel caso di variabili casuali continue, nel caso di distribuzioni asimmetriche.La mediana indica il punto cui la “massa totale” della distribuzione è suddivisa due porzioni uguali. Nel caso della densità di probabilità, ciascuna di queste porzioni rappresenta un’area uguale, \\(A_1 = A_2 = 1/2\\) poiché l’area totale sottesa alla funzione di densità è 1 per definizione.\nFIGURA 10.7: Qual è la differenza tra mediana e media?\nLa figura 10.7 mostra come differiscono due concetti di mediana (indicata dalla linea verticale) e media (indicata dal “punto di equilibrio” triangolare). sinistra, per una densità di probabilità simmetrica, la media e la mediana coincidono. destra, una piccola porzione della distribuzione è stata spostata ’estremo destro. Questa modifica non ha influito sulla posizione della mediana, poiché le aree destra e sinistra della linea verticale sono ancora uguali. altri termini, la mediana, \\(x_m\\), divide l’area sottesa alla funzione di densità due porzioni uguali:\\[\n\\int_{-\\infty}^{x_m} p(x) dx = \\int_{x_m}^{-\\infty} p(x) dx = \\frac{1}{2}.\n\\]Segue da tale definizione che la mediana è il valore \\(x\\) per il quale la distribuzione cumulativa soddisfa\\[\nF(x_m) = \\frac{1}{2}.\n\\]Tuttavia, il fatto che una parte della massa sia stata allontanata verso destra porta uno spostamento della media della distribuzione, per compensare tale cambiamento. altre parole, la media contiene più informazioni sulla distribuzione “spaziale” delle osservazioni, rispetto alla mediana. Ciò deriva dal fatto che la media della distribuzione (il valore atteso) è una “somma” - cioè è un integrale - di termini cha hanno la forma \\(x p(x) \\Delta x\\). Quindi la posizione lungo l’asse \\(x\\), ovvero \\(x\\), e non solo la “massa”, \\(p(x) \\Delta x\\), influenza il contributo che le componenti della distribuzione hanno sulla media.","code":""},{"path":"ch-expval-var-rv.html","id":"ch-expval-var-rv","chapter":"Capitolo 11 Valore atteso e varianza","heading":"Capitolo 11 Valore atteso e varianza","text":"Spesso risulta utile fornire una rappresentazione sintetica della distribuzione di una variabile casuale attraverso degli indicatori caratteristici piuttosto che fare riferimento ad una sua rappresentazione completa mediante la funzione di ripartizione, o la funzione di massa o di densità di probabilità. Una descrizione più sintetica di una variabile casuale, tramite pochi valori, ci consente di cogliere le caratteristiche essenziali della distribuzione, quali: la posizione, cioè il baricentro della distribuzione di probabilità; la variabilità, cioè la dispersione della distribuzione di probabilità attorno ad un centro; la forma della distribuzione di probabilità, considerando la simmetria e la curtosi (pesantezza delle code). questo Capitolo introdurremo quegli indici sintetici che descrivono il centro di una distribuzione di probabilità e la sua variabilità.","code":""},{"path":"ch-expval-var-rv.html","id":"valore-atteso","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.1 Valore atteso","text":"Quando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual è il suo “valore tipico”. La nozione di “valore tipico”, tuttavia, è ambigua. Infatti, essa può essere definita almeno tre modi diversi:la media (somma dei valori divisa per il numero dei valori),la mediana (il valore centrale della distribuzione, quando la variabile è ordinata senso crescente o decrescente),la moda (il valore che ricorre più spesso).Per esempio, la media di \\(\\{3, 1, 4, 1, 5\\}\\) è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è \\(3\\) e la moda è \\(1\\). Tuttavia, la teoria delle probabilità si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per “valore tipico” quando facciamo riferimento alle variabili casuali. Giungiamo così alla seguente definizione.\nDefinizione 11.1  Sia \\(Y\\) è una variabile casuale discreta che assume valori \\(y_1, \\dots, y_n\\) con distribuzione \\(p(y)\\),\nossia\\[\nP(Y = y_i) = p(y_i),\n\\]per definizione il valore atteso di \\(Y\\), \\(\\E(Y)\\), è\\[\\begin{equation}\n\\E(Y) = \\sum_{=1}^n y_i \\cdot p(y_i).\n\\tag{11.1}\n\\end{equation}\\]parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale è definito come la somma di tutti valori che la variabile casuale può prendere, ciascuno pesato dalla probabilità con cui il valore è preso.Esercizio 11.1  Calcoliamo il valore atteso della variabile casuale \\(Y\\) corrispondente al lancio di una moneta equilibrata (testa: Y = 1; croce: Y = 0).\\[\n\\E(Y) = \\sum_{=1}^{2} y_i \\cdot P(y_i) = 0 \\cdot \\frac{1}{5} + 1 \\cdot \\frac{1}{5} = 0.5.\n\\]Esercizio 11.2  Supponiamo ora che Y sia il risultato del lancio di un dado equilibrato. Il valore atteso di Y diventa:\\[\n\\E(Y) = \\sum_{=1}^{6} y_i \\cdot P(y_i) = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + \\dots + 6 \\cdot \\frac{1}{6} = \\frac{21}{6} = 3.5.\n\\]","code":""},{"path":"ch-expval-var-rv.html","id":"interpretazione","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.1.1 Interpretazione","text":"Che interpretazione può essere assegnata alla nozione di valore atteso? Bruno de Finetti adottò lo stesso termine di previsione (e lo stesso simbolo) tanto per la probabilità che per la speranza matematica. Si può pertanto dire che, dal punto di vista bayesiano, la speranza matematica è l’estensione naturale della nozione di probabilità soggettiva.","code":""},{"path":"ch-expval-var-rv.html","id":"proprietà-del-valore-atteso","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.1.2 Proprietà del valore atteso","text":"La proprietà più importante del valore atteso è la linearità: il valore atteso di una somma di variabili casuali è uguale alla somma dei lori rispettivi valori attesi:\\[\\begin{equation}\n\\E(X + Y) = \\E(X) + \\E(Y).\n\\tag{11.2}\n\\end{equation}\\]La (11.2) sembra ragionevole quando \\(X\\) e \\(Y\\) sono indipendenti, ma è anche vera quando \\(X\\) e \\(Y\\) sono associati. Abbiamo anche che\\[\\begin{equation}\n\\E(cY) = c \\E(Y).\n\\tag{11.3}\n\\end{equation}\\]La (11.3) ci dice che possiamo estrarre una costante dall’operatore di valore atteso. Tale proprietà si estende qualunque numero di variabili casuali. Infine, se due variabili casuali \\(X\\) e \\(Y\\) sono indipendenti, abbiamo che\\[\\begin{equation}\n\\E(X Y) = \\E(X) \\E(Y).\n\\tag{11.4}\n\\end{equation}\\]Esercizio 11.3  Si considerino le seguenti variabili casuali: \\(Y\\), ovvero il numero che si ottiene dal lancio di un dado equilibrato, e \\(Y\\), il numero di teste prodotto dal lancio di una moneta equilibrata.\nPoniamoci il problema di trovare il valore atteso di \\(X+Y\\).Per risolvere il problema iniziamo costruire lo spazio campionario dell’esperimento casuale consistente nel lancio di un dado e di una moneta.\novvero\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campionario avrà la stessa probabilità di verificarsi, ovvero \\(Pr(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale :\\[\n\\E(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]Lo stesso risultato si ottiene nel modo seguente:\\[\n\\E(X+Y) = \\E(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]Esercizio 11.4  Si considerino le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso del prodotto delle variabili casuali \\(X\\) e \\(Y\\).La distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\nIl calcolo del valore atteso di \\(XY\\) si riduce \\[\n\\E(XY) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]Si noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare la proprietà ??. Infatti, il valore atteso di \\(X\\) è\\[\n\\E(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]e il valore atteso di \\(Y\\) è\\[\n\\E(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nDunque\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]","code":""},{"path":"ch-expval-var-rv.html","id":"variabili-casuali-continue","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.1.3 Variabili casuali continue","text":"Nel caso di una variabile casuale continua \\(Y\\) il valore atteso diventa:\\[\\begin{equation}\n\\E(Y) = \\int_{-\\infty}^{+\\infty} y p(y) \\,\\operatorname {d}\\!y\n\\tag{11.5}\n\\end{equation}\\]Anche questo caso il valore atteso è una media ponderata della \\(y\\), nella quale ciascun possibile valore \\(y\\) è ponderato per il corrispondente valore della densità \\(p(y)\\). Possiamo leggere l’integrale pensando che \\(y\\) rappresenti l’ampiezza delle barre infinitamente strette di un istogramma, con la densità \\(p(y)\\) che corrisponde ’altezza di tali barre e la notazione \\(\\int_{-\\infty}^{+\\infty}\\) che corrisponde ad una somma.Un’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda della \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\\[\\begin{equation}\n\\Mo(Y) = \\argmax_y p(y).\n\\tag{11.6}\n\\end{equation}\\]","code":""},{"path":"ch-expval-var-rv.html","id":"varianza-1","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.2 Varianza","text":"La seconda più importante proprietà di una variabile casuale, dopo che conosciamo il suo valore atteso, è la varianza.Definizione 11.2  Se \\(Y\\) è una variabile casuale discreta con distribuzione \\(p(y)\\), per definizione la varianza di \\(Y\\), \\(\\mathbb{V}(Y)\\), è\\[\\begin{equation}\n\\mathbb{V}(Y) = \\E\\Big[\\big(Y - \\E(Y)\\big)^2\\Big].\n\\tag{11.7}\n\\end{equation}\\]parole: la varianza è la deviazione media quadratica della variabile dalla sua media.10 Se denotiamo \\(\\E(Y) = \\mu\\), la varianza \\(\\mathbb{V}(Y)\\) diventa il valore atteso di \\((Y - \\mu)^2\\).Esercizio 11.5  Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, poniamoci il problema di calcolare la varianza di \\(S\\).La variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\nEssendo \\(\\E(S) = 7\\), la varianza diventa\\[\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(S- \\mathbb{E}(S)\\right)^2 \\cdot P(S) \\notag\\\\\n&= (2 - 7)^2 \\cdot 0.0278 + (3-7)^2 \\cdot 0.0556 + \\dots + (12 - 7)^2 \\cdot 0.0278 \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\\]","code":""},{"path":"ch-expval-var-rv.html","id":"formula-alternativa-per-la-varianza","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.2.1 Formula alternativa per la varianza","text":"C’è un modo più semplice per calcolare la varianza:\\[\\begin{align}\n\\E\\Big[\\big(X - \\E(Y)\\big)^2\\Big] &= \\E\\big(X^2 - 2X\\E(Y) + \\E(Y)^2\\big)\\notag\\\\\n&= \\E(Y^2) - 2\\E(Y)\\E(Y) + \\E(Y)^2,\\notag\n\\end{align}\\]dato che \\(\\E(Y)\\) è una costante; pertanto\\[\\begin{equation}\n\\mathbb{V}(Y) = \\E(Y^2) - \\big(\\E(Y) \\big)^2.\n\\tag{11.8}\n\\end{equation}\\]parole: la varianza è la media dei quadrati meno il quadrato della media.Esercizio 11.6  Consideriamo la variabile casuale \\(Y\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale 0.8.\nIl valore atteso di \\(Y\\) è\\[\n\\E(Y) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\\[\n\\mathbb{V}(Y) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(Y^2\\) è\\[\n\\E(Y^2) = 0^2 \\cdot 0.2 + 1^2 * 0.8 = 0.8.\n\\]\ne la varianza diventa\\[\n\\mathbb{V}(Y) = \\E(Y^2) - \\big(\\E(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]","code":""},{"path":"ch-expval-var-rv.html","id":"variabili-casuali-continue-1","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.2.2 Variabili casuali continue","text":"Nel caso di una variabile casuale continua \\(Y\\), la varianza diventa:\\[\\begin{equation}\n\\mathbb{V}(Y) = \\int_{-\\infty}^{+\\infty} \\large[y - \\E(Y)\\large]^2 p(y) \\,\\operatorname {d}\\!y\n\\tag{11.9}\n\\end{equation}\\]Come nel caso discreto, la varianza di una v.c. continua \\(y\\) misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori \\(y\\) dalla loro media.","code":""},{"path":"ch-expval-var-rv.html","id":"deviazione-standard","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.3 Deviazione standard","text":"Quando lavoriamo con le varianze, termini sono innalzati al quadrato e quindi numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente valori nell’unità di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato deviazione standard e solitamente è denotato dalla lettera greca \\(\\sigma\\).Definizione 11.3  Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:\\[\\begin{equation}\n\\sigma_Y = \\sqrt{\\mathbb{V}(Y)}.\n\\tag{11.10}\n\\end{equation}\\]Interpretiamo la deviazione standard di una variabile casuale come nella statistica descrittiva: misura approssimativamente la distanza tipica o prevista dei possibili valori \\(y\\) dalla loro media.Esercizio 11.7  Per dadi equilibrati dell’esempio precedente, la deviazione standard della variabile casuale \\(S\\) è uguale \\(\\sqrt{5.833} = 2.415\\).","code":""},{"path":"ch-expval-var-rv.html","id":"standardizzazione","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.4 Standardizzazione","text":"Definizione 11.4  Data una variabile casuale \\(Y\\), si dice variabile standardizzata di \\(Y\\) l’espressione\\[\\begin{equation}\nZ = \\frac{Y - \\E(Y)}{\\sigma_Y}.\n\\tag{11.11}\n\\end{equation}\\]Solitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).","code":""},{"path":"ch-expval-var-rv.html","id":"momenti-di-variabili-casuali","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.5 Momenti di variabili casuali","text":"Definizione 11.5  Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la\nquantità\\[\\begin{equation}\n\\E(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\end{equation}\\]Se \\(X\\) è una v.c. discreta, suoi momenti valgono:\\[\\begin{equation}\n\\E(X^q) = \\sum_i x_i^q p(x_i).\n\\end{equation}\\]momenti sono importanti parametri indicatori di certe proprietà di \\(X\\). più\nnoti sono senza dubbio quelli per \\(q = 1\\) e \\(q = 2\\). Il momento del primo ordine corrisponde al valore atteso di \\(X\\). Spesso momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di \\(X\\), operando una traslazione \\(x_0 = x − \\E(X)\\) che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza.","code":""},{"path":"ch-expval-var-rv.html","id":"covarianza-1","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.6 Covarianza","text":"La covarianza quantifica la tendenza delle variabili aleatorie \\(X\\) e \\(Y\\) ``variare assieme’’. Per esempio, l’altezza e il peso delle giraffe producono una covarianza positiva perché ’aumentare di una di queste due quantità tende ad aumentare anche l’altra. La covarianza misura la forza e la direzione del legame lineare tra due variabili aleatorie \\(X\\) ed \\(Y\\). Si utilizza la notazione \\(\\mbox{Cov}(X,Y)=\\sigma_{xy}\\).Definizione 11.6  Date due variabili aleatorie \\(X\\), \\(Y\\), chiamiamo covarianza tra \\(X\\) ed \\(Y\\) il numero\\[\\begin{equation}\n\\mbox{Cov}(X,Y) = \\mathbb{E}\\Bigl(\\bigl(X - \\mathbb{E}(X)\\bigr) \\bigl(Y - \\mathbb{E}(Y)\\bigr)\\Bigr),\n\\end{equation}\\]dove \\(\\mathbb{E}(X)\\) e \\(\\mathbb{E}(Y)\\) sono valori attesi di \\(X\\) ed \\(Y\\).maniera esplicita,\\[\\begin{equation}\n\\mbox{Cov}(X,Y) = \\sum_{(x,y) \\\\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y).\n\\label{eq:cov_def}\n\\end{equation}\\]La definizione è analoga, algebricamente, quella di varianza e risulta infatti\\[\\begin{equation}\n\\mathbb{V}(x) = cov(X, X)\n\\end{equation}\\]e\\[\\begin{equation}\n\\mbox{Cov}(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X).\n\\label{eq:cov_vc_alt}\n\\end{equation}\\]Dimostrazione. La proprietà precedente si dimostra nel modo seguente:\\[\\begin{align}\n\\mbox{Cov}(X,Y) &= \\mathbb{E}\\Bigl(\\bigl(X-\\mathbb{E}(X)\\bigr) \\bigl(Y-\\mathbb{E}(Y)\\bigr)\\Bigr)\\notag\\\\\n          %&= \\mathbb{E}(XY) - \\mathbb{E}(Y)X -\\mathbb{E}(X)Y + \\mathbb{E}(X)\\mathbb{E}(Y) )\\notag\\\\\n          &= \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X) - \\mathbb{E}(X)\\mathbb{E}(Y) + \\mathbb{E}(X)\\mathbb{E}(Y)\\notag\\\\\n          &= \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X)\\notag.\n\\end{align}\\]Esercizio 11.8  Consideriamo le variabili casuali definite nell’Esercizio 2.4. Si calcoli la covarianza di \\(X\\) e \\(Y\\).Abbiamo che \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). Ne segue che la covarianza di \\(X\\) e \\(Y\\) è:\\[\\begin{equation}\n\\begin{split}\n\\mbox{Cov}(X,Y) &= \\sum_{(x,y) \\\\ \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y)\\\\\n&= (0-1.5)(0-0.5)\\cdot \\frac{1}{8} + (0-1.5)(1-0.5) \\cdot 0 \\\\\n   &\\hskip0.05\\textwidth\\relax + (1-1.5)(0-0.5)\\cdot \\frac{2}{8} + (1-1.5)(1-0.5) \\cdot \\frac{1}{8} \\\\\n    &\\hskip0.05\\textwidth\\relax + (2-1.5)(0-0.5) \\cdot \\frac{1}{8} + (2-1.5)(1-0.5) \\cdot \\frac{2}{8} \\\\\n   &\\hskip0.05\\textwidth\\relax + (3-1.5)(0-0.5) \\cdot 0 +  (3-1.5)(1-0.5)\\cdot\\frac{1}{8} \\\\\n   &= \\frac{1}{4}. \\notag\n\\end{split}\n\\end{equation}\\]Lo stesso risultato può essere trovato nel modo seguente. Iniziamo calcolare il valore atteso del prodotto \\(XY\\):\\[\n\\mathbb{E}(XY) = 0 \\cdot\\frac{4}{8} + 1 \\cdot\\frac{1}{8} + 2 \\cdot\\frac{2}{8} + 3 \\cdot\\frac{1}{8} = 1.0.\n\\]Dunque, la covarianza tra \\(X\\) e \\(Y\\) diventa\\[\\begin{align}\n\\mbox{Cov}(X,Y) &= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\notag\\\\\n&= 1 -  1.5\\cdot 0.5 \\notag\\\\\n&= 0.25.\\notag\n\\end{align}\\]","code":""},{"path":"ch-expval-var-rv.html","id":"correlazione-1","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.7 Correlazione","text":"La covarianza dipende dall’unità di misura delle due variabili e quindi non consente di stabilire l’intensità della relazione.\nUna misura standardizzata della relazione che intercorre fra due variabili è invece rappresentata dalla correlazione. La correlazione si ottiene dividendo la covarianza per le deviazioni standard delle due variabili aleatorie.Il coefficiente di correlazione tra \\(X\\) ed \\(Y\\) è il numero definito da\\[\\begin{equation}\n\\rho(X,Y) =\\frac{\\mbox{Cov}(X,Y)}{\\sqrt{\\mathcal{V}(X)\\mathcal{V}(Y)}}.\n\\end{equation}\\]Si può anche scrivere \\(\\rho_{X,Y}\\) al posto di \\(\\rho(X,Y)\\).Il coefficiente di correlazione \\(\\rho_{xy}\\) è un numero puro, cioè non\ndipende dall’unità di misura delle variabili, e assume valori compresi tra -1 e +1.","code":""},{"path":"ch-expval-var-rv.html","id":"proprietà-1","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.8 Proprietà","text":"La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è nulla:\\[\\begin{equation}\n\\mbox{Cov}(c,X) = 0,\n\\end{equation}\\]la covarianza è simmetrica:\\[\\begin{equation}\n\\mbox{Cov}(X,Y) = \\mbox{Cov}(Y,X),\n\\end{equation}\\]vale\\[\\begin{equation}\n-1 \\leq \\rho(X,Y) \\leq 1,\n\\end{equation}\\]la correlazione non dipende dall’unità di misura:\\[\\begin{equation}\n\\rho(aX, ) = \\rho(X,Y), \\qquad \\forall , b > 0,\n\\end{equation}\\]se \\(Y = + bX\\) è una funzione lineare di \\(X\\) con costanti \\(\\) e \\(b\\), allora \\(\\rho(X,Y) = \\pm 1\\), seconda del segno di \\(b\\),la covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, è uguale al prodotto delle costanti per la covarianza tra \\(X\\) e \\(Y\\):\\[\\begin{equation}\n\\mbox{Cov}(aX,) = ab \\;\\mbox{Cov}(X,Y), \\qquad \\forall ,b \\\\Real,\n\\end{equation}\\]vale\\[\\begin{equation}\n\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2 \\cdot \\mbox{Cov}(X,Y),\n\\end{equation}\\]vale\\[\\begin{equation}\n\\mbox{Cov}(X + Y, Z) = \\mbox{Cov}(X,Z) + \\mbox{Cov}(Y,Z),\n\\end{equation}\\]per una sequenza di variabili aleatorie \\(X_1, \\dots, X_n\\), si ha\\[\\begin{equation}\n\\mathbb{V}\\left( \\sum_{=1}^n X_i\\right) = \\sum_{=1}^n\n\\mathbb{V}(X_i) + 2\\sum_{,j: <j}cov(X_i, X_j),\n\\end{equation}\\]vale\\[\\begin{equation}\n\\mbox{Cov}\\left(\\sum_{=1}^n a_i X_i, \\sum_{j=1}^m b_jY_j\\right) = \\sum_{=1}^n \\sum_{j=1}^m a_j b_j\\mbox{Cov}(X_j, Y_j),\n\\end{equation}\\]se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora\\[\\begin{equation}\n\\mbox{Cov}\\left(\\sum_{=1}^n a_i X_i, \\sum_{j=1}^n b_jX_j\\right) = \\sum_{=1}^n a_i b_i \\mathbb{V}(X_i).\n\\end{equation}\\]","code":""},{"path":"ch-expval-var-rv.html","id":"incorrelazione","chapter":"Capitolo 11 Valore atteso e varianza","heading":"11.8.1 Incorrelazione","text":"Si dice che \\(X\\) ed \\(Y\\) sono incorrelate, o linermente indipendenti, se la loro covarianza è nulla,\\[\\begin{equation}\n\\sigma_{XY} = \\mathbb{E} \\big[(X - \\mu_X) (y-\\mu_u) \\big] = 0,\n\\end{equation}\\]che si può anche scrivere come\\[\\begin{equation}\n\\rho_{XY} = 0, \\quad \\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\end{equation}\\]Si introduce così un secondo tipo di indipendenza, più debole, dopo quello di indipendenza stocastica. Viceversa, però, se \\(\\mbox{Cov}(X, Y) = 0\\), non è detto che \\(X\\) ed \\(Y\\) siano indipendenti.Esercizio 11.9  Siano \\(X\\) e \\(Y\\) due variabili aleatorie discrete avente una distribuzione di massa di probabilità congiunta pari \\[\nf_{XY}(x,y) = \\frac{1}{4} \\quad (x,y) \\\\{(0,0), (1,1), (1, -1), (2,0) \\}\n\\]e zero altrimenti. Si calcoli la covarianza \\(\\rho_{XY}\\). Le due variabili aleatorie \\(X\\) e \\(Y\\) sono mutuamente indipendenti?La distribuzione marginale della \\(X\\) è\\[\n\\begin{cases}\nX = 0, \\quad  P_X = 1/4, \\\\\nX = 1, \\quad P_X = 2/4, \\\\\nX = 2, \\quad P_X = 1/4.\n\\end{cases}\n\\]\\[\n\\mathbb{E}(X) = 0 \\frac{1}{4} + 1 \\frac{2}{4} + 2 \\frac{1}{4} = 1.\n\\]\\[\n\\mathbb{E}(X^2) = 0^2 \\frac{1}{4} + 1^2 \\frac{2}{4} + 2^2 \\frac{1}{4} = \\frac{3}{2}.\n\\]\\[\n\\mathbb{V}(X) = \\frac{3}{2} - 1^2 = \\frac{1}{2}.\n\\]La distribuzione marginale della \\(Y\\) è\\[\n\\begin{cases}\nY = -1, \\quad  P_Y = 1/4, \\\\\nY = 0, \\quad P_Y = 2/4, \\\\\nY = 1, \\quad P_Y = 1/4.\n\\end{cases}\n\\]\\[\n\\mathbb{E}(Y) = 0 \\frac{2}{4} + 1 \\frac{1}{4} + (-1) \\frac{1}{4} = 0.\n\\]\\[\n\\mathbb{E}(Y^2) = 0^2 \\frac{2}{4} + 1^2 \\frac{1}{4} + (-1)^2 \\frac{1}{4} = \\frac{1}{2}.\n\\]\\[\n\\mathbb{V}(X) = \\frac{1}{2} - 0^2 = \\frac{1}{2}.\n\\]Calcoliamo ora la covarianza tra \\(X\\) e \\(Y\\):\\[\n\\mathbb{E}(XY) = \\sum_x\\sum_y xy f_{XY} (x,y) =\n(0\\cdot 0)\\frac{1}{4} +\n(1\\cdot 1)\\frac{1}{4} +\n(1\\cdot -1)\\frac{1}{4} +\n(2\\cdot 0)\\frac{1}{4} = 0.\n\\]\\[\n\\mbox{Cov}(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y) = 0 - 1\\cdot0 = 0.\n\\]Quindi le due variabili aleatorie hanno covarianza pari zero. Tuttavia, esse non sono indipendenti, quanto non è vero che\\[\nf_{XY} (x,y) = f_X(x) f_Y(y)\n\\]per tutti gli \\(x\\) e \\(y\\). conclusione, anche se condizione di indipendenza implica una covarianza nulla, questo esempio mostra come l’inverso non sia necessariamente vero. La covarianza può essere zero anche quando le due variabili aleatorie non sono indipendenti.","code":""},{"path":"ch-expval-var-rv.html","id":"conclusioni","chapter":"Capitolo 11 Valore atteso e varianza","heading":"Conclusioni","text":"La densità di probabilità congiunta bivariata tiene simultaneamente conto del comportamento di due variabili aleatorie \\(X\\) e \\(Y\\) e di come esse si influenzino. Se \\(X\\) e \\(Y\\) sono legate linearmente, allora il coefficiente di correlazione\\[\\begin{equation}\n\\rho = \\frac{\\mbox{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\\notag\n\\end{equation}\\]fornisce l’indice maggiormente utilizzato per descrivere l’intensità e il segno dell’associazione lineare. Nel caso di un’associazione lineare perfetta, \\(Y = + bX\\), avremo \\(\\rho = 1\\) con \\(b\\) positivo ed \\(\\rho = -1\\) con \\(b\\) negativo. Se il coefficiente di correlazione è pari 0 le variabili si dicono incorrelate. Condizione sufficiente (ma non necessaria) affinché \\(\\rho = 0\\) è che le due variabili siano tra loro indipendenti.","code":""},{"path":"ch-distr-rv-discr.html","id":"ch-distr-rv-discr","chapter":"Capitolo 12 Distribuzioni di v.c. discrete","heading":"Capitolo 12 Distribuzioni di v.c. discrete","text":"questo Capitolo verranno esaminate le principali distribuzioni di probabilità delle variabili casuali discrete. Un esperimento casuale che può dare luogo solo due possibili esiti (successo, insuccesso) è modellabile con una variabile casuale di Bernoulli. Una sequenza di prove di Bernoulli costituisce un processo Bernoulliano. Il numero di successi dopo \\(n\\) prove di Bernoulli corrisponde ad una variabile casuale che segue la legge binomiale. La distribuzione binomiale risulta da un insieme di prove di Bernoulli solo se il numero totale \\(n\\) è fisso per disegno. Se il numero di prove è esso stesso una variabile casuale, allora il numero di successi nella corrispondente sequenza di prove bernoulliane segue al distribuzione di Poisson. Concluderemo con la distribuzione discreta uniforme.","code":""},{"path":"ch-distr-rv-discr.html","id":"una-prova-bernoulliana","chapter":"Capitolo 12 Distribuzioni di v.c. discrete","heading":"12.1 Una prova Bernoulliana","text":"Se un esperimento casuale ha solo due esiti possibili, allora le repliche indipendenti di questo esperimento sono chiamate “prove Bernoulliane” (il lancio di una moneta è il tipico esempio).Definizione 12.1  Viene detta variabile di Bernoulli una variabile casuale discreta \\(Y = \\{0, 1\\}\\) con la seguente distribuzione di probabilità:\\[\nP(Y \\mid \\theta) =\n  \\begin{cases}\n    \\theta     & \\text{se $Y = 1$}, \\\\\n    1 - \\theta & \\text{se $Y = 0$},\n  \\end{cases}\n\\]con \\(0 \\leq \\theta \\leq 1\\). Convenzionalmente l’evento \\(\\{Y = 1\\}\\) con probabilità \\(\\theta\\) viene chiamato “successo” mentre l’evento \\(\\{Y = 0\\}\\) con probabilità \\(1-\\theta\\) viene chiamato “insuccesso”.Applicando l’operatore di valore atteso e di varianza, otteniamo\\[\\begin{align}\n\\mathbb{E}(Y) &= 0 \\cdot P(Y=0) + 1 \\cdot P(Y=1) = \\theta, \\\\\n\\mathbb{V}(Y) &= (0 - \\theta)^2 \\cdot P(Y=0) + (1 - \\theta)^2 \\cdot P(Y=1) = \\theta(1-\\theta).\n\\tag{12.1}\n\\end{align}\\]Scriviamo \\(Y \\sim \\mbox{Bernoulli}(\\theta)\\) per indicare che la variabile casuale \\(Y\\) ha una distribuzione Bernoulliana di parametro \\(\\theta\\).Esercizio 12.1  Nel caso del lancio di una moneta equilibrata la variabile casuale di Bernoulli assume valori \\(0\\) e \\(1\\). La distribuzione di massa di probabilità è pari \\(\\frac{1}{2}\\) corrispondenza di entrambi iv valori. La funzione di distribuzione vale \\(\\frac{1}{2}\\) per \\(Y = 0\\) e \\(1\\) per \\(Y = 1\\).","code":""},{"path":"ch-distr-rv-discr.html","id":"una-sequenza-di-prove-bernoulliane","chapter":"Capitolo 12 Distribuzioni di v.c. discrete","heading":"12.2 Una sequenza di prove Bernoulliane","text":"La distribuzione binomiale è rappresentata dall’elenco di tutti \npossibili numeri di successi \\(Y = \\{0, 1, 2, \\dots n\\}\\) che possono\nessere osservati \\(n\\) prove Bernoulliane indipendenti di probabilità\n\\(\\theta\\), ciascuno dei quali è associata la relativa probabilità. Esempi di una distribuzione binomiale sono risultati di una serie di lanci di\nuna stessa moneta o di una serie di estrazioni da un’urna (con\nreintroduzione). La distribuzione binomiale di parametri \\(n\\) e \\(\\theta\\) è realtà una famiglia di distribuzioni: al variare dei parametri \\(\\theta\\) e \\(n\\) variano le probabilità.Definizione 12.2  La probabilità di ottenere \\(y\\) successi e \\(n-y\\) insuccessi \\(n\\) prove\nBernoulliane è data dalla distribuzione binomiale:\\[\\begin{align}\nP(Y=y) &= \\binom{n}{y} \\theta^{y} (1-\\theta)^{n-y} \\notag \\\\\n&= \\frac{n!}{y!(n-y)!} \\theta^{y} (1-\\theta)^{n-y},\n\\tag{12.2}\n\\end{align}\\]dove \\(n\\) = numero di prove Bernoulliane, \\(\\theta\\) = probabilità di successo ciascuna prova e \\(y\\) = numero di successi.Dimostrazione. La (12.2) può essere derivata nel modo seguente. Indichiamo con \\(S\\) il successo e con \\(\\) l’insuccesso di ciascuna prova. Una sequenza di \\(n\\) prove Bernoulliane darà come esito una sequenza di \\(n\\) elementi \\(S\\) e \\(\\). Ad esempio, una sequenza che contiene \\(y\\) successi è la seguente:\\[\n\\overbrace{SS\\dots S}^\\text{$y$ volte} \\overbrace{II\\dots }^\\text{$n-y$ volte}\n\\]\nEssendo \\(\\theta\\) la probabilità di \\(S\\) e \\(1-\\theta\\) la probabilità di \\(\\), la probabilità di ottenere la specifica sequenza riportata sopra è\\[\\begin{equation}\n\\overbrace{\\theta \\theta\\dots \\theta}^\\text{$y$ volte} \\overbrace{(1-\\theta)(1-\\theta)\\dots (1-\\theta)}^\\text{$n-y$ volte} = \\theta^y \\cdot (1-\\theta)^{n-y}.\n\\tag{12.3}\n\\end{equation}\\]Non siamo però interessati alla probabilità di una specifica sequenza di \\(S\\) e \\(\\) ma, bensì, alla probabilità di osservare una qualsiasi sequenza di \\(y\\) successi \\(n\\) prove. altre parole, vogliamo la probabilità dell’unione di tutti gli eventi corrispondenti \\(y\\) successi \\(n\\) prove.È immediato notare che una qualsiasi altra sequenza contenente esattamente \\(y\\) successi avrà sempre come probabilità \\(\\theta^y \\cdot (1-\\theta)^{n-y}\\): il prodotto infatti resta costante anche se cambia l’ordine dei fattori.11 Per trovare il risultato cercato dobbiamo moltiplicare la (12.3) per il numero di sequenze possibili di \\(y\\) successi \\(n\\) prove.Il numero di sequenze che contengono esattamente \\(y\\) successi \\(n\\) prove. La risposta è fornita dal coefficiente binomiale12:\\[\\begin{equation}\n\\binom{n}{y} = \\frac{n!}{y!(n-y)!},\n\\tag{12.4}\n\\end{equation}\\]dove il simbolo \\(n!\\) si legge \\(n\\) fattoriale ed è uguale al prodotto di \\(n\\) numeri interi decrescenti partire da \\(n\\). Per definizione \\(0! = 1\\).Essendo la probabilità dell’unione di \\(K\\) elementi incompatibili uguale alla somma delle loro rispettive probabilità, e dato che le sequenze di \\(y\\) successi \\(n\\) prove hanno tutte la stessa probabilità, per trovare la formula della distributione binomiale (12.2) è sufficiente moltiplicare la (12.3) per la (12.4).La distribuzione di probabilità di alcune distribuzioni binomiali, per due valori di \\(n\\) e \\(\\theta\\), è fornita nella figura 12.1.\nFIGURA 12.1: Alcune distribuzioni binomiali. Nella figura, il parametro \\(\\theta\\) è indicato con \\(p\\).\nEsercizio 12.2  Usando la (12.2), si trovi la probabilità di \\(y = 2\\) successi \\(n = 4\\) prove Bernoulliane indipendenti con \\(\\theta = 0.2\\)\\[\n\\begin{aligned}\nP(Y=2) &= \\frac{4!}{2!(4-2)!} 0.2^{2} (1-0.2)^{4-2} \\notag  \\\\\n&= \\frac{4 \\cdot 3 \\cdot 2 \\cdot 1}{(2 \\cdot 1)(2 \\cdot 1)}\n0.2^{2} 0.8^{2} = 0.1536. \\notag\n\\end{aligned}\n\\]Ripetendo calcoli per valori \\(y = 0, \\dots, 4\\) troviamo la distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):Lo stesso risultato si ottiene usando la sequente istruzione :Esercizio 12.3  Lanciando \\(5\\) volte una moneta onesta, qual è la probabilità che esca testa almeno tre volte?, la soluzione si trova conAlternativamente, possiamo trovare la probabilità dell’evento complementare quello definito dalla funzione di ripartizione calcolata mediante pbinom(), ovvero","code":"\ndbinom(0:4, 4, 0.2)\n#> [1] 0.4096 0.4096 0.1536 0.0256 0.0016\ndbinom(3, 5, 0.5) + dbinom(4, 5, 0.5) + dbinom(5, 5, 0.5)\n#> [1] 0.5\n1 - pbinom(2, 5, 0.5)\n#> [1] 0.5"},{"path":"ch-distr-rv-discr.html","id":"valore-atteso-e-deviazione-standard","chapter":"Capitolo 12 Distribuzioni di v.c. discrete","heading":"12.2.1 Valore atteso e deviazione standard","text":"La media (numero atteso di successi \\(n\\) prove) e la deviazione\nstandard di una distribuzione binomiale sono molto semplici:\\[\\begin{align}\n\\mu    &= n\\theta,  \\notag \\\\\n\\sigma &= \\sqrt{n\\theta(1-\\theta)}.\n\\end{align}\\]Dimostrazione. Essendo \\(Y\\) la somma di \\(n\\) prove Bernoulliane indipendenti \\(Y_i\\), è facile vedere che\\[\\begin{align}\n\\E(Y) &= \\mathbb{E}\\left( \\sum_{=1}^n Y_i \\right) = \\sum_{=1}^n \\E(Y_i) = n\\theta, \\\\\n\\Var(Y) &= \\mathbb{V} \\left( \\sum_{=1}^n Y_i \\right) = \\sum_{=1}^n \\Var(Y_i) = n \\theta (1-\\theta).\n\\end{align}\\]Esercizio 12.4  Si trovino il valore atteso e la varianza del lancio di quattro monete con probabilità di successo pari \\(\\theta = 0.2\\).Il valore atteso è \\(\\mu = n \\theta = 4 \\cdot 0.2 = 0.8.\\) Ciò significa che, se l’esperimento casuale venisse ripetuto infinite volte, l’esito testa verrebbe osservato un numero medio di volte pari 0.8. La varianza è \\(n \\theta (1-\\theta) = 4 \\cdot 0.2 \\cdot (1 - 0.2) = 0.64\\).","code":""},{"path":"ch-distr-rv-discr.html","id":"distribuzione-di-poisson","chapter":"Capitolo 12 Distribuzioni di v.c. discrete","heading":"12.3 Distribuzione di Poisson","text":"La distribuzione di Poisson è una distribuzione di probabilità discreta che esprime le probabilità per il numero di eventi che si verificano successivamente ed indipendentemente un dato intervallo di tempo, sapendo che mediamente se ne verifica un numero \\(\\lambda\\). La distribuzione di Poisson serve dunque per contare il numero di volte cui un evento ha luogo un determinato intervallo di tempo. La stessa distribuzione può essere estesa anche per contare gli eventi che hanno luogo una determinata porzione di spazio.Definizione 12.3  La distribuzione di Poisson può essere intesa come limite della distribuzione binomiale, dove la probabilità di successo \\(\\theta\\) è pari \\(\\frac{\\lambda}{n}\\) con \\(n\\) che tende \\(\\infty\\):\\[\\begin{equation}\n\\lim_{y \\rightarrow \\infty} \\binom{n}{y} \\theta^y (1-\\theta)^{n-y} = \\frac{\\lambda^y}{y!}e^{-\\lambda}.\n\\end{equation}\\]Alcune distribuzioni di Poisson sono riportate nella figura 12.2.\nFIGURA 12.2: Alcune distribuzioni di Poisson.\nEsercizio 12.5  Supponiamo che un evento accada 300 volte ’ora e si vuole determinare la probabilità che un minuto accadano esattamente 3 eventi.Il numero medio di eventi un minuto è pari \nQuindi la probabilità che un minuto si abbiano 3 eventi è pari aEsercizio 12.6  Per dati dell’esempio precedente, si trovi la probabilità che un evento accada almeno 8 volte un minuto.La probabilità cercata è\\[\np(y \\geq 8) = 1 - p (y \\leq 7) = 1- \\sum_{= 0}^7 \\frac{\\lambda^7}{7!}e^{-\\lambda},\n\\]\ncon \\(\\lambda = 5\\).Svolgendo calcoli otteniamo:Esercizio 12.7  Sapendo che un evento avviene media 6 volte al minuto, si calcoli () la probabilità di osservare un numero di eventi uguale o inferiore 3 un minuto, e (b) la probabilità di osservare esattamente 2 eventi 30 secondi.questo caso \\(\\lambda = 6\\) e la probabilità richiesta èIn questo caso \\(\\lambda = 6 / 2\\) e la probabilità richiesta è","code":"\nlambda <- 300 / 60\nlambda\n#> [1] 5\ny <- 3\n(lambda^y / factorial(y)) * exp(-lambda)\n#> [1] 0.1403739\n1 - ppois(q = 7, lambda = 5)\n#> [1] 0.1333717\nppois(q = 7, lambda = 5, lower.tail = FALSE)\n#> [1] 0.1333717\nppois(q = 3, lambda = 6, lower.tail = TRUE)\n#> [1] 0.1512039\ndpois(x = 2, lambda = 3)\n#> [1] 0.2240418"},{"path":"ch-distr-rv-discr.html","id":"alcune-proprietà-della-variabile-di-poisson","chapter":"Capitolo 12 Distribuzioni di v.c. discrete","heading":"12.3.1 Alcune proprietà della variabile di Poisson","text":"Il valore atteso, la moda e la varianza della variabile di Poisson sono uguali \\(\\lambda\\).Il valore atteso, la moda e la varianza della variabile di Poisson sono uguali \\(\\lambda\\).La somma \\(Y_1 + \\dots + Y_n\\) di \\(n\\) variabili casuali indipendenti con distribuzioni di Poisson di parametri \\(\\lambda_{1},\\dots,\\lambda_{n}\\) segue una distribuzione di Poisson di parametro \\(\\lambda = \\lambda_{1}+\\dots+\\lambda_{n}\\).La somma \\(Y_1 + \\dots + Y_n\\) di \\(n\\) variabili casuali indipendenti con distribuzioni di Poisson di parametri \\(\\lambda_{1},\\dots,\\lambda_{n}\\) segue una distribuzione di Poisson di parametro \\(\\lambda = \\lambda_{1}+\\dots+\\lambda_{n}\\).La differenze di due variabili di Poisson non è una variabile di Poisson. Basti infatti pensare che può assumere valori negativi.La differenze di due variabili di Poisson non è una variabile di Poisson. Basti infatti pensare che può assumere valori negativi.","code":""},{"path":"ch-distr-rv-discr.html","id":"distribuzione-discreta-uniforme","chapter":"Capitolo 12 Distribuzioni di v.c. discrete","heading":"12.4 Distribuzione discreta uniforme","text":"Una distribuzione discreta uniforme è una distribuzione di probabilità discreta che è uniforme su un insieme, ovvero che attribuisce ad ogni elemento dell’insieme discreto e finito \\(S\\) su cui è definita la stessa probabilità \\(p\\) di verificarsi.Consideriamo la variabile casuale \\(X\\) con supporto \\(1, 2, \\dots, m\\). Un esperimento casuale cui si verifica questa distribuzione è la scelta casuale di un intero compreso tra 1 e \\(m\\) inclusi. Sia \\(X\\) il numero scelto. Allora\\[\nP(X = x) = \\frac{1}{m}, \\quad x = 1, \\dots, m.\n\\]Il valore atteso è\\[\n\\mathbb{E}(X) = \\sum_{x=1}^m x f_X(x) = \\sum_{x=1}^m x \\frac{1}{m} = \\frac{1}{m} (1 + 2 + \\dots + m) = \\frac{m+1}{2},\n\\]\ndove abbiamo utilizzato l’identità \\(1+2+···+m = m(m+1)/2\\).Per trovare la varianza, prima calcoliamo\\[\n\\mathbb{E}(X^2) = \\frac{1}{m} \\sum_{x=1}^m x^2,\n\\]\ne poi troviamo\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\left[\\mathbb{E}(X)\\right]^2.\n\\]","code":""},{"path":"ch-distr-rv-discr.html","id":"usiamo-textsfr","chapter":"Capitolo 12 Distribuzioni di v.c. discrete","heading":"12.4.1 Usiamo \\(\\textsf{R}\\)","text":"La sintassi generale per simulare una variabile casuale uniforme discreta è sample(x, size, replace = TRUE). L’argomento x identifica numeri da cui campionare casualmente. Se x è un numero, il campionamento viene eseguito da 1 x. L’argomento size indica quanto dovrebbe essere grande la dimensione del campione e replace indica se numeri devono essere reintrodotti o meno nell’urna dopo essere stati estratti. L’opzione di default è replace = FALSE ma per le uniformi discrete valori estratti devono essere sostituiti. Seguono alcuni esempi.Per lanciare un dado equilibrato 3000 volte: sample(6, size = 3000, replace = TRUE);per scegliere 27 numeri casuali da 30 70: sample(30:70, size = 27, replace = TRUE);per lanciare una moneta equa 1000 volte: sample(c(\"H\",\"T\"), size = 1000, replace = TRUE).","code":""},{"path":"ch-distr-rv-discr.html","id":"distribuzione-beta-binomiale","chapter":"Capitolo 12 Distribuzioni di v.c. discrete","heading":"12.5 Distribuzione beta-binomiale","text":"La distribuzione beta-binomiale di parametri \\(N\\), \\(\\alpha\\) e \\(\\beta\\) è una distribuzione discreta con una funzione di massa di probabilità uguale \\[\\begin{equation}\n\\mbox{BetaBinomial}(y \\mid N, \\alpha, \\beta) = \\binom{N}{y} \\frac{B(y + \\alpha, N-y+\\beta)}{B(\\alpha, \\beta)},\n\\end{equation}\\]dove la funzione beta è \\(B(u, v) = \\frac{\\Gamma(u)\\Gamma(v)}{\\Gamma(u+v)}\\).Senza entrare nei dettagli, ci accontentiamo di sapere che tale distribuzione è implementata nella funzione dbbinom() del pacchetto extraDistr.","code":""},{"path":"ch-distr-rv-discr.html","id":"commenti-e-considerazioni-finali-8","chapter":"Capitolo 12 Distribuzioni di v.c. discrete","heading":"Commenti e considerazioni finali","text":"La distribuzione binomiale è una distribuzione di probabilità discreta che descrive il numero di successi un processo di Bernoulli, ovvero la variabile aleatoria \\(Y = Y_1 + \\dots + Y_n\\) che somma \\(n\\) variabili casuali indipendenti di uguale distribuzione di Bernoulli \\(\\mathcal{B}(\\theta)\\), ognuna delle quali può fornire due soli risultati: il successo con probabilità \\(\\theta\\) e il fallimento con probabilità \\(1 - \\theta\\).La distribuzione binomiale è molto importante per le sue molte applicazioni. Nelle presenti dispense, dedicate ’analisi bayesiana, è soprattutto importante perché costituisce il fondamento del caso più semplice del cosiddetto “aggiornamento bayesiano”, ovvero il caso Beta-Binomiale. Il modello Beta-Binomiale ci fornirà infatti un esempio paradigmatico dell’approccio bayesiano ’inferenza e sarà trattato maniera analitica. È dunque importante che le proprietà della distribuzione binomiale risultino ben chiare.","code":""},{"path":"ch-distr-rv-cont.html","id":"ch-distr-rv-cont","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"Capitolo 13 Distribuzioni di v.c. continue","text":"Dopo avere introdotto con una simulazione il concetto di funzione di densità nel Capitolo ??, prendiamo ora esame alcune delle densità di probabilità più note. La più importante di esse è sicuramente la distribuzione Normale.","code":""},{"path":"ch-distr-rv-cont.html","id":"distribuzione-normale","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.1 Distribuzione Normale","text":"Non c’è un’unica distribuzione Normale, ma ce ne sono molte. Tali distribuzioni sono anche dette “gaussiane” onore di Carl Friedrich Gauss (uno dei più grandi matematici della storia il quale, tra le altre cose, scoprì l’utilità di tale funzione di densità per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale densità alle misurazioni dell’uomo. Karl Pearson usò per primo il termine “distribuzione Normale” anche se ammise che questa espressione “ha lo svantaggio di indurre le persone credere che le altre distribuzioni, un senso o nell’altro, non siano normali.”","code":""},{"path":"ch-distr-rv-cont.html","id":"limite-delle-distribuzioni-binomiali","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.1.1 Limite delle distribuzioni binomiali","text":"Iniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre notò che, aumentando il numero di prove una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e forma campanulare. Con 10 prove e una probabilità di successo di 0.9 ciascuna prova, la distribuzione è chiaramente asimmetrica.\nFIGURA 13.1: Probabilità del numero di successi \\(N = 10\\) prove bernoulliane indipendenti, ciascuna con una probabilità di successo di 0.90. Il risultato è una distribuzione \\(\\Bin(y \\mid 10, 0.9)\\). Con solo dieci prove, la distribuzione è fortemente asimmetrica negativa.\nMa se aumentiamo il numero di prove di un fattore di 100 \nN = 1000, senza modificare la probabilità di successo di 0.9, la distribuzione assume una forma campanulare quasi simmetrica. Dunque, de Moivre scoprì che, quando N è grande, la funzione Normale (che introdurremo qui sotto), nonostante sia la densità di v.. continue, fornisce una buona approssimazione alla funzione di massa di probabilità binomiale.\nFIGURA 13.2: Probabilità del numero di successi \\(N = 1000\\) prove bernoulliane indipendenti, ciascuna con una probabilità di successo di 0.90. Il risultato è una distribuzione \\(\\Bin(y \\mid 1000, 0.9)\\). Con mille prove, la distribuzione è quasi simmetrica forma campanulare.\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.","code":"\nN <- 10\nx <- 0:10\ny <- dbinom(x, N, 0.9)\nbinomial_limit_plot <-\n  tibble(x = x, y = y) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_bar(\n    stat = \"identity\", color = \"black\", size = 0.2\n  ) +\n  xlab(\"y\") +\n  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10)) +\n  ylab(\"Binomial(y | 10, 0.9)\")\nbinomial_limit_plot\nN <- 1000\nx <- 0:1000\ny <- dbinom(x, N, 0.9)\nbinomial_limit_plot <-\n  tibble(x = x, y = y) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_bar(stat = \"identity\", color = \"black\", size = 0.2) +\n  xlab(\"y\") +\n  ylab(\"Binomial(y | 1000, 0.9)\") +\n  xlim(850, 950)\nbinomial_limit_plot"},{"path":"ch-distr-rv-cont.html","id":"normal-random-walk","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.2 La Normale prodotta con una simulazione","text":"McElreath (2020) presenta un esempio che illustra come sia possibile giungere alla distribuzione Normale mediante una simulazione. Supponiamo che vi siano mille persone tutte allineate su una linea di partenza. Quando viene dato un segnale, ciascuna persona lancia una moneta e fa un passo avanti oppure ’indietro seconda che sia uscita testa o croce. Supponiamo che la lunghezza di ciascun passo vari da 0 1 metro. Ciascuna persona lancia una moneta 16 volte e dunque compie 16 passi.Alla conclusione di queste passeggiate casuali (random walk) non possiamo sapere con esattezza dove si troverà ciascuna persona, ma possiamo conoscere con certezza le caratteristiche della distribuzione delle mille distanze dall’origine. Per esempio, possiamo predire maniera accurata la proporzione di persone che si sono spostate avanti oppure ’indietro. Oppure, possiamo predire accuratamente la proporzione di persone che si troveranno ad una certa distanza dalla linea di partenza (es., 1.5 m dall’origine).Queste predizioni sono possibili perché tali distanze si distribuiscono secondo la legge Normale. È facile simulare questo processo usando . risultati della simulazione sono riportati nella figura 13.3.\nFIGURA 13.3: Passeggiata casuale di 4, 8 e 16 passi. La spezzata nera indica la media delle distanze dall’origine come funzione del numero di passi.\nUn kernel density plot delle distanze ottenute dopo 4, 8 e 16 passi è riportato nella figura 13.4. Nel pannello di destra, al kernel density plot è stata sovrapposta una densità Normale di opportuni parametri (linea tratteggiata).\nFIGURA 13.4: Kernel density plot dei risultati della passeggiata casuale riportata nella figura precente, dopo 4, 8 e 16 passi. Nel pannello di destra, una densità Normale di opportuni parametri è sovrapposta ’istogramma lisciato.\nQuesta simulazione mostra che qualunque processo nel quale viene sommato un certo numero di valori casuali, tutti provenienti dalla medesima distribuzione, converge ad una distribuzione Normale. Non importa quale sia la forma della distribuzione di partenza: essa può essere uniforme, come nell’esempio presente, o di qualunque altro tipo. La forma della distribuzione da cui viene realizzato il campionamento determina la velocità della convergenza alla Normale. alcuni casi la convergenza è lenta; altri casi la convergenza è molto rapida (come nell’esempio presente).Da un punto di vista formale, diciamo che una variabile casuale continua \\(Y\\) ha una distribuzione Normale se la sua densità è\\[\\begin{equation}\nf(y; \\mu, \\sigma) = {1 \\{\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{13.1}\n\\end{equation}\\]dove \\(\\mu \\\\mathbb{R}\\) e \\(\\sigma > 0\\) sono parametri della distribuzione.La densità normale è unimodale e simmetrica con una caratteristica forma campana e con il punto di massima densità corrispondenza di \\(\\mu\\).Il significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nella (13.1) viene chiarito dalla dimostrazione che\\[\\begin{equation}\n\\mathbb{E}(X) = \\mu, \\qquad \\mathbb{V}(X) = \\sigma^2.\n\\end{equation}\\]La rappresentazione grafica di quattro densità Normali tutte con media 0 e con deviazioni standard 0.25, 0.5, 1 e 2 è fornita nella figura 13.5.\nFIGURA 13.5: Alcune distribuzioni Normali.\n","code":"\npos <-\n  replicate(100, runif(16, -1, 1)) %>%\n  as_tibble() %>%\n  rbind(0, .) %>%\n  mutate(step = 0:16) %>%\n  gather(key, value, -step) %>%\n  mutate(person = rep(1:100, each = 17)) %>%\n  group_by(person) %>%\n  mutate(position = cumsum(value)) %>%\n  ungroup()\n\nggplot(\n  data = pos,\n  aes(x = step, y = position, group = person)\n) +\n  geom_vline(xintercept = c(4, 8, 16), linetype = 2) +\n  geom_line(aes(color = person < 2, alpha = person < 2)) +\n  scale_color_manual(values = c(\"gray\", \"black\")) +\n  scale_alpha_manual(values = c(1 / 5, 1)) +\n  scale_x_continuous(\n    \"Numero di passi\",\n    breaks = c(0, 4, 8, 12, 16)\n  ) +\n  labs(y = \"Posizione\") +\n  theme(legend.position = \"none\")\np1 <-\n  pos %>%\n  filter(step == 4) %>%\n  ggplot(aes(x = position)) +\n  geom_line(stat = \"density\", color = \"black\") +\n  labs(title = \"4 passi\")\n\np2 <-\n  pos %>%\n  filter(step == 8) %>%\n  ggplot(aes(x = position)) +\n  geom_density(color = \"black\", outline.type = \"full\") +\n  labs(title = \"8 passi\")\n\nsd <-\n  pos %>%\n  filter(step == 16) %>%\n  summarise(sd = sd(position)) %>%\n  pull(sd)\n\np3 <-\n  pos %>%\n  filter(step == 16) %>%\n  ggplot(aes(x = position)) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = 0, sd = sd),\n    linetype = 2\n  ) +\n  geom_density(color = \"black\", alpha = 1 / 2) +\n  labs(\n    title = \"16 passi\",\n    y = \"Densità\"\n  )\n\n(p1 | p2 | p3) & coord_cartesian(xlim = c(-6, 6))"},{"path":"ch-distr-rv-cont.html","id":"concentrazione","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.2.1 Concentrazione","text":"È istruttivo osservare il grado di concentrazione della distribuzione\nNormale attorno alla media:\\[\\begin{align}\nP(\\mu - \\sigma < X < \\mu + \\sigma) &= P (-1 < Z < 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma < X < \\mu + 2\\sigma) &= P (-2 < Z < 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma < X < \\mu + 3\\sigma) &= P (-3 < Z < 3) \\simeq 0.997. \\notag\n\\end{align}\\]\nSi noti come un dato la cui distanza dalla media è superiore 3 volte la deviazione standard presenti un carattere di eccezionalità perché meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.Per indicare la distribuzione Normale si usa la notazione\n\\(\\mathcal{N}(\\mu, \\sigma)\\).","code":""},{"path":"ch-distr-rv-cont.html","id":"funzione-di-ripartizione-1","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.2.2 Funzione di ripartizione","text":"Il valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) è l’area sottesa alla curva di densità \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\\[\\begin{equation}\nF(y) = \\int_{-\\infty}^y {1 \\{\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\end{equation}\\]pertanto le probabilità \\(P(Y < y)\\) vengono calcolate mediante integrazione numerica approssimata. valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.Esercizio 13.1  Usiamo per calcolare la funzione di ripartizione della Normale. La funzione pnorm(q, mean, sd) restituisce la funzione di ripartizione della Normale con media mean e deviazione standard sd, ovvero l’area sottesa alla funzione di densità di una Normale con media mean e deviazione standard sd nell’intervallo \\([-\\infty, q]\\).Per esempio, precedenza abbiamo detto che il 68% circa dell’area sottesa ad una Normale è compresa nell’intervallo \\(\\mu \\pm \\sigma\\). Verifichiamo per la distribuzione del QI \\(\\sim \\mathcal{N}(\\mu = 100, \\sigma = 15)\\):Il 95% dell’area è compresa nell’intervallo \\(\\mu \\pm 1.96 \\cdot\\sigma\\):Quasi tutta la distribuzione è compresa nell’intervallo \\(\\mu \\pm 3 \\cdot\\sigma\\):","code":"\npnorm(100+15, 100, 15) - pnorm(100-15, 100, 15)\n#> [1] 0.6826895\npnorm(100 + 1.96 * 15, 100, 15) - pnorm(100 - 1.96 * 15, 100, 15)\n#> [1] 0.9500042\npnorm(100 + 3 * 15, 100, 15) - pnorm(100 - 3 * 15, 100, 15)\n#> [1] 0.9973002"},{"path":"ch-distr-rv-cont.html","id":"distribuzione-normale-standard","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.2.3 Distribuzione Normale standard","text":"La distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale è l’insieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\\[\\begin{equation}\nX = + b Y \\sim \\mathcal{N}(\\mu_X = +b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\end{equation}\\]L’area sottesa alla curva di densità di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) è uguale ’area sottesa alla densità Normale standard nella semiretta \\((-\\infty, z]\\), cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) è il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l’area sottesa nella semiretta \\([1, \\infty)\\) è uguale ’area sottesa nella semiretta \\((-\\infty, 1]\\) e quest’ultima coincide con \\(F(-1)\\). Analogamente, l’area sottesa nell’intervallo \\([y_a, y_b]\\), con \\(y_a < y_b\\), è pari \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono punteggi standard di \\(y_a\\) e \\(y_b\\).Si ha anche il problema inverso rispetto quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema è quello di determinare un numero \\(z \\\\mathbb{R}\\) tale che \\(P(Z < z) = p\\). Il valore \\(z\\) cercato è detto quantile di ordine \\(p\\) della Normale standard e può essere trovato mediante un software.Esercizio 13.2  Supponiamo che l’altezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un’altezza compresa tra \\(1.7\\) e \\(1.8\\) m.Il problema ci chiede di trovare l’area sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell’intervallo \\([1.7, 1.8]\\):\nLa risposta si trova utilizzando la funzione di\nripartizione \\(F(X)\\) della legge \\(\\mathcal{N}(1.7, 0.1)\\) \ncorrispondenza dei due valori forniti dal problema:\n\\(F(X = 1.8) - F(X = 1.7)\\). Utilizzando la seguente istruzioneotteniamo il \\(31.43\\%\\).maniera equivalente, possiamo standardizzare valori che delimitano l’intervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. limiti inferiore e superiore dell’intervallo sono\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]quindi otteniamoIl modo più semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilità richiesta non è altro che la metà dell’area sottesa dalle distribuzioni Normali nell’intervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).","code":"\ndf <- tibble(x = seq(1.4, 2.0, length.out = 100)) %>%\n  mutate(y = dnorm(x, mean = 1.7, sd = 0.1))\n\nggplot(df, aes(x, y)) +\n  geom_area(fill = \"sky blue\") +\n  gghighlight(x < 1.8 & x > 1.7) +\n  labs(\n    x = \"Altezza\",\n    y = \"Densità\"\n  )\npnorm(1.8, 1.7, 0.1) - pnorm(1.7, 1.7, 0.1)\n#> [1] 0.3413447\npnorm(1.0, 0, 1) - pnorm(0, 0, 1)\n#> [1] 0.3413447"},{"path":"ch-distr-rv-cont.html","id":"funzione-di-ripartizione-della-normale-standard-e-funzione-logistica","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.2.3.1 Funzione di ripartizione della normale standard e funzione logistica","text":"Si noti che la funzione logistica (blu), pur essendo del tutto diversa dalla Normale dal punto di vista formale, assomiglia molto alla Normale standard quando le due cdf hanno la stessa varianza.","code":"\ntibble(x = c(-3, 3)) %>%\n  ggplot(aes(x = x)) +\n  stat_function(fun = pnorm) +\n  stat_function(\n    fun = plogis,\n    args = list(scale = 0.56)\n  )"},{"path":"ch-distr-rv-cont.html","id":"teorema-del-limite-centrale","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.3 Teorema del limite centrale","text":"Laplace dimostrò il teorema del limite centrale (TLC) nel 1812. Il TLC ci dice che se prendiamo una sequenza di variabili casuali indipendenti e le sommiamo, tale somma tende distribuirsi come una Normale. Il TLC specifica inoltre, sulla base dei valori attesi e delle varianze delle v.c. che vengono sommate, quali saranno parametri della distribuzione Normale così ottenuta.Teorema 13.1  Si supponga che \\(Y = Y_1, Y_2, \\ldots, Y_N\\) sia una sequenza di v.. ..d. con \\(\\mathbb{E}(Y_n) = \\mu\\) e \\(\\mbox{SD}(Y_n) = \\sigma\\). Si definisca una nuova v.c. come la media di \\(Y\\):\\[\nZ = \\frac{1}{N} \\sum_{n=1}^N Y_n.\n\\]Con \\(N \\rightarrow \\infty\\), \\(Z\\) tenderà ad una Normale con lo stesso valore atteso di \\(Y_n\\) e una deviazione standard che sarà più piccola della deviazione standard originaria di un fattore pari \\(\\sqrt{\\frac{1}{\\sqrt{N}}}\\):\\[\\begin{equation}\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{1}{\\sqrt{N}} \\cdot \\sigma \\right).\n\\end{equation}\\]Il TLC può essere generalizzato variabili che non hanno la stessa distribuzione purché siano indipendenti e abbiano aspettative e varianze finite.Molti fenomeni naturali, come l’altezza dell’uomo adulto di entrambi sessi, sono il risultato di una serie di effetti additivi relativamente piccoli, la cui combinazione porta alla normalità, indipendentemente da come gli effetti additivi sono distribuiti. pratica, questo è il motivo per cui la distribuzione normale ha senso come rappresentazione di molti fenomeni naturali.","code":""},{"path":"ch-distr-rv-cont.html","id":"distribuzione-chi-quadrato","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.4 Distribuzione Chi-quadrato","text":"Dalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà descrive la variabile casuale\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]dove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali ..d. con distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libertà. La densità di probabilità di \\(\\chi^2_{~\\nu}\\) è\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x > 0,\n\\]dove \\(C_{\\nu}\\) è una costante positiva.La figura 13.6 mostra alcune distribuzioni Chi-quadrato variando il parametro \\(\\nu\\).\nFIGURA 13.6: Alcune distribuzioni Chi-quadrato.\n","code":""},{"path":"ch-distr-rv-cont.html","id":"proprietà-2","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.4.1 Proprietà","text":"La distribuzione di densità \\(\\chi^2_{~\\nu}\\) è asimmetrica.La distribuzione di densità \\(\\chi^2_{~\\nu}\\) è asimmetrica.Il valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) è uguale \\(\\nu\\).Il valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) è uguale \\(\\nu\\).La varianza di una variabile \\(\\chi^2_{~\\nu}\\) è uguale \\(2\\nu\\).La varianza di una variabile \\(\\chi^2_{~\\nu}\\) è uguale \\(2\\nu\\).Per \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\).Per \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\).Se \\(X\\) e \\(Y\\) sono due variabili casuali chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libertà, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende qualunque numero finito di variabili casuali chi-quadrato indipendenti.Se \\(X\\) e \\(Y\\) sono due variabili casuali chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libertà, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende qualunque numero finito di variabili casuali chi-quadrato indipendenti.Esercizio 13.3  Usiamo \\(\\mathsf{R}\\) per disegnare la densità chi-quadrato con 3 gradi di libertà dividendo l’area sottesa alla curva di densità due parti uguali.","code":"\ndf <- tibble(x = seq(0, 15.0, length.out = 100)) %>%\n  mutate(y = dchisq(x, 3))\n\nggplot(df, aes(x, y)) +\n  geom_area(fill = \"sky blue\") +\n  gghighlight(x < 3) +\n  labs(\n    x = \"V.a. chi-quadrato con 3 gradi di libertà\",\n    y = \"Densità\"\n  )"},{"path":"ch-distr-rv-cont.html","id":"distribuzione-t-di-student","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.5 Distribuzione \\(t\\) di Student","text":"Dalle distribuzioni Normale e Chi quadrato deriva un’altra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}\\) e \\(W \\sim \\chi^2_{~\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto\\[\\begin{equation}\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\end{equation}\\]definisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si usa scrivere \\(T \\sim t_{\\nu}\\). L’andamento della distribuzione \\(t\\) di Student è simile quello della distribuzione Normale, ma ha una maggiore dispersione (ha le code più pesanti di una Normale, ovvero ha una varianza maggiore di 1).La figura 13.7 mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\).\nFIGURA 13.7: Alcune distribuzioni \\(t\\) di Student.\n","code":""},{"path":"ch-distr-rv-cont.html","id":"proprietà-3","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.5.1 Proprietà","text":"La variabile casuale \\(t\\) di Student soddisfa le seguenti proprietà:Per \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard\n\\(\\mathcal{N}(0, 1)\\).Per \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard\n\\(\\mathcal{N}(0, 1)\\).La densità della \\(t_{\\nu}\\) è una funzione simmetrica con valore\natteso nullo.La densità della \\(t_{\\nu}\\) è una funzione simmetrica con valore\natteso nullo.Per \\(\\nu > 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\);\npertanto è sempre maggiore di 1 e tende 1 per\n\\(\\nu \\rightarrow \\infty\\).Per \\(\\nu > 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\);\npertanto è sempre maggiore di 1 e tende 1 per\n\\(\\nu \\rightarrow \\infty\\).","code":""},{"path":"ch-distr-rv-cont.html","id":"funzione-beta","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.6 Funzione beta","text":"La funzione beta di Eulero è una funzione matematica, non una densità di probabilità. La menzioniamo qui perché viene utilizzata nella distribuzione Beta. La funzione beta si può scrivere molti modi diversi; per nostri scopi la scriveremo così:\\[\\begin{equation}\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\end{equation}\\]dove \\(\\Gamma(x)\\) è la funzione Gamma, ovvero il fattoriale discendente, cioè\\[\\begin{equation}\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\end{equation}\\]Per esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione beta assume il valorePer chiarire, lo stesso risultato si ottiene conovvero","code":"\nalpha <- 3\nbeta <- 9\nbeta(alpha, beta)\n#> [1] 0.002020202\n((2) * (8 * 7 * 6 * 5 * 4 * 3 * 2)) / \n  (11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2)\n#> [1] 0.002020202\ngamma(alpha) * gamma(beta) / gamma(alpha + beta)\n#> [1] 0.002020202"},{"path":"ch-distr-rv-cont.html","id":"distribuzione-beta","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.7 Distribuzione Beta","text":"Una distribuzione che viene usata per modellare percentuali e proporzioni è la distribuzione Beta quanto è definita sull’intervallo \\((0; 1)\\) – ma non include valori 0 o 1. Una definizione formale è la seguente.Definizione 13.1  Sia \\(\\pi\\) una variabile casuale che può assumere qualsiasi valore compreso tra 0 e 1, cioè \\(\\pi \\[0, 1]\\). Diremo che \\(\\pi\\) segue la distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\), \\(\\pi \\sim \\text{Beta}(\\alpha, \\beta)\\), se la sua densità è\\[\\begin{align}\n\\text{Beta}(\\pi \\mid \\alpha, \\beta) &= \\frac{1}{B(\\alpha, \\beta)}\\pi^{\\alpha-1} (1-\\pi)^{\\beta-1}\\notag\\\\\n&=  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\pi^{\\alpha-1} (1-\\pi)^{\\beta-1} \\quad \\text{per } \\pi \\[0, 1]\\,,\n\\tag{13.2}\n\\end{align}\\]laddove \\(B(\\alpha, \\beta)\\) è la funzione beta.termini \\(\\alpha\\) e \\(\\beta\\) sono parametri della distribuzione Beta e devono essere entrambi positivi. Tali parametri possono essere interpretati come l’espressione delle nostre credenze priori relative ad una sequenza di prove Bernoulliane Il parametro \\(\\alpha\\) rappresenta il numero di “successi” e il parametro \\(\\beta\\) il numero di “insuccessi”:\\[\\begin{equation}\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\end{equation}\\]Il rapporto \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha+b)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) è una costante di normalizzazione:\\[\\begin{equation}\n\\int_0^1 \\pi^{\\alpha-1} (1-\\pi)^{\\beta-1} = \\frac{\\Gamma(\\alpha+b)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\,.\n\\end{equation}\\]Ad esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\) abbiamoovveroovveroIl valore atteso, la moda e la varianza di una distribuzione Beta sono dati dalle seguenti equazioni:\\[\\begin{equation}\n\\mathbb{E}(\\pi) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\tag{13.3}\n\\end{equation}\\]\\[\\begin{equation}\n\\mbox{Mo}(\\pi) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\tag{13.4}\n\\end{equation}\\]\\[\\begin{equation}\n\\mathbb{V}(\\pi) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\tag{13.5}\n\\end{equation}\\]Al variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un’illustrazione è fornita dalla seguente GIF animata. Si può ottenere una rappresentazione grafica della distribuzione \\(\\mbox{Beta}(\\pi \\mid \\alpha, \\beta)\\) con la funzione plot_beta() del pacchetto bayesrules. Per esempio:La funzione bayesrules::summarize_beta() ci restituisce la media, moda e varianza della distribuzione Beta. Per esempio:Osservazione. Attenzione alle parole: questo contesto, il termine “beta” viene utilizzato con tre significati diversi:la distribuzione di densità Beta,la funzione matematica beta,il parametro \\(\\beta\\).Esercizio 13.4  Nel disturbo depressivo la recidiva è definita come la comparsa di un nuovo episodio depressivo che si manifesta dopo un prolungato periodo di recupero (6-12 mesi) con stato di eutimia (umore relativamente normale). Supponiamo che una serie di studi mostri una comparsa di recidiva una proporzione che va dal 20% al 60% dei casi, con una media del 40% (per una recente discussione, si veda Nuggerud-Galeas et al. 2020). Sulla base di queste ipotetiche informazioni, è possibile usare la distribuzione Beta per rappresentare le nostre credenze priori relativamente alla probabilità di recidiva. Per fare questo dobbiamo trovare parametri della distribuzione Beta tali per cui la massa della densità sia compresa tra 0.2 e 0.6, con la media corrispondenza di 0.4. Procedendo per tentativi ed errori, ed usando la funzione bayesrules::plot_beta(), un risultato possibile è \\(\\Beta(16, 24)\\).La funzione find_pars() prende input la media e \\(\\alpha + \\beta\\), ritorna valori dei parametri:Verifichiamo il valore della media della distribuzione:La moda èLa deviazione standard della distribuzione è uguale circa 8 punti percentuali:Gli stessi risultati si ottengono usando la funzione bayesrules::summarize_beta():Possiamo concludere dicendo che, se utilizziamo la distribuzione \\(\\mbox{Beta}(16, 24)\\) per rappresentare le nostre credenze (priori) rispetto la possibilità di recidiva, ciò significa che pensiamo che la nostra incertezza sia quantificabile nei termini di una deviazione standard di circa 8 punti percentuali rispetto tutti valori possibili di recidiva, per quali il valore più verosimile (ovvero, la media della distribuzione) è 0.40.Esercizio 13.5  Poniamoci ora il problema di verificare la nostra comprensione delle funzioni \\(\\R\\) che possono essere usate per la funzione Beta. Continuiamo con l’esercizio precedente e utilizziamo seguenti parametri per la distribuzione Beta:La media di una \\(\\mbox{Beta}(16, 24)\\) èIn corrispondenza della media la densità della funzione èovveroUsando la funzione dbeta() possiamo costruire un grafico della funzione \\(\\mbox{Beta}(16, 24)\\) nel modo seguente:","code":"\na <- 3\nb <- 9\nintegrand <- function(p) {p^{a - 1}*(1 - p)^{b - 1}}\nintegrate(integrand, lower = 0, upper = 1)\n#> 0.002020202 with absolute error < 2.2e-17\n1 / (gamma(a + b) / (gamma(a) * gamma(b)))\n#> [1] 0.002020202\nbeta(alpha, beta)\n#> [1] 0.002020202\nbayesrules::plot_beta(alpha = 3, beta = 9)\nbayesrules::summarize_beta(alpha = 3, beta = 9)\n#>   mean mode        var        sd\n#> 1 0.25  0.2 0.01442308 0.1200961\nfind_pars <- function(ev, n) {\n  a <- ev * n\n  b <- n - a\n  return(c(round(a), round(b)))\n}\n\npars <- find_pars(.4, 40)\npars\n#> [1] 16 24\nbayesrules::plot_beta(pars[1], pars[2])\n16 / (16 + 24)\n#> [1] 0.4\n(16 - 1) / (16 + 24 - 2)\n#> [1] 0.3947368\nsqrt((16 * 24) / ((16 + 24)^2 * (16 + 24 + 1)))\n#> [1] 0.07650921\nbayesrules::summarize_beta(alpha = 16, beta = 24)\n#>   mean      mode         var         sd\n#> 1  0.4 0.3947368 0.005853659 0.07650921\nalpha <- 16\nbeta <- 24\nalpha / (alpha + beta)\n#> [1] 0.4\ndbeta(pi, alpha, beta)\n#> [1] 0\ngamma(alpha + beta) / (gamma(alpha) * gamma(beta)) * \n  pi^(alpha - 1) * (1 - pi)^(beta - 1)\n#> [1] -6.99499e+26\nx <- seq(0, 1, length.out = 1e4)\ntibble(x) %>% \n  ggplot(aes(x, dbeta(x, alpha, beta))) +\n  geom_line() +\n  labs(\n    x = \"Probabilità di recidiva\",\n    y = \"Densità Beta(16, 24)\"\n  )"},{"path":"ch-distr-rv-cont.html","id":"distribuzione-di-cauchy","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.8 Distribuzione di Cauchy","text":"La distribuzione di Cauchy è un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libertà. È definita da una densità di probabilità che corrisponde alla funzione, dipendente da due parametri \\(\\theta\\) e \\(d\\) (con la condizione \\(d > 0\\)),\\[\\begin{equation}\nf(x; \\theta, d) = \\frac{1}{\\pi d} \\frac{1}{1 + \\left(\\frac{x - \\theta}{d} \\right)^2},\n\\end{equation}\\]dove \\(\\theta\\) è la mediana della distribuzione e \\(d\\) ne misura la larghezza metà altezza.","code":""},{"path":"ch-distr-rv-cont.html","id":"distribuzione-log-normale","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.9 Distribuzione log-normale","text":"Sia \\(y\\) una variabile casuale avente distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo poi una nuova variabile casuale \\(x\\) attraverso la relazione\\[\nx = e^y \\quad \\Longleftrightarrow \\quad y = \\log x.\n\\]\nIl dominio di definizione della \\(x\\) è il semiasse \\(x > 0\\) e la densità di probabilità \\(f(x)\\) è data da\\[\\begin{equation}\nf(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\frac{1}{x} \\exp \\left\\{-\\frac{(\\log x -  \\mu)^2}{2 \\sigma^2} \\right\\}.\n\\end{equation}\\]Questa funzione di densità si chiama log-normale.Il valore atteso e la varianza di una distribuzione log-normale sono dati dalle seguenti equazioni:\\[\\begin{equation}\n\\mathbb{E}(x) = \\exp \\left\\{\\mu + \\frac{\\sigma^2}{2} \\right\\}.\n\\end{equation}\\]\\[\\begin{equation}\n\\mathbb{V}(x) = \\exp \\left\\{2 \\mu + \\sigma^2 \\right\\} \\left(\\exp \\left\\{\\sigma^2 \\right\\}  -1\\right).\n\\end{equation}\\]Si può dimostrare che il prodotto di variabili casuali log-normali ed indipendenti segue una distribuzione log-normale.","code":""},{"path":"ch-distr-rv-cont.html","id":"distribuzione-di-pareto","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"13.10 Distribuzione di Pareto","text":"La distribuzione paretiana (o distribuzione di Pareto) è una distribuzione di probabilità continua e così chiamata onore di Vilfredo Pareto. La distribuzione di Pareto è una distribuzione di probabilità con legge di potenza utilizzata nella descrizione di fenomeni sociali e molti altri tipi di fenomeni osservabili. Originariamente applicata per descrivere la distribuzione del reddito una società, adattandosi alla tendenza che una grande porzione di ricchezza è detenuta da una piccola frazione della popolazione, la distribuzione di Pareto è diventata colloquialmente nota e indicata come il principio di Pareto, o “regola 80-20”. Questa regola afferma che, ad esempio, l’80% della ricchezza di una società è detenuto dal 20% della sua popolazione. Viene spesso applicata nello studio della distribuzione del reddito, della dimensione dell’impresa, della dimensione di una popolazione e nelle fluttuazioni del prezzo delle azioni.La densità di una distribuzione di Pareto è\\[\nf(x)=(x_m/x)^\\alpha,\n\\]dove \\(x_m\\) (parametro di scala) è il minimo (necessariamente positivo) valore possibile di \\(X\\) e \\(\\alpha\\) è un parametro di forma.\nLa distribuzione di Pareto ha una asimmetria positiva. Il supporto della distribuzione di Pareto è la retta reale positiva. Tutti valori devono essere maggiori del parametro di scala \\(x_m\\), che è realtà un parametro di soglia.","code":""},{"path":"ch-distr-rv-cont.html","id":"commenti-e-considerazioni-finali-9","chapter":"Capitolo 13 Distribuzioni di v.c. continue","heading":"Commenti e considerazioni finali","text":"questa dispensa le densità continue che useremo più spesso sono la distribuzione gaussiana e la distribuzione Beta. Faremo un uso limitato della distribuzione \\(t\\) di Student e della distribuzione di Cauchy. Le altre distribuzioni qui descritte sono stato presentate solo per completezza.","code":""},{"path":"ch-bayes-workflow.html","id":"ch-bayes-workflow","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"Capitolo 14 Flusso di lavoro bayesiano","text":"La moderna statistica bayesiana viene per lo più eseguita utilizzando un linguaggio di programmazione probabilistico implementato su computer. Ciò ha cambiato radicalmente il modo cui venivano eseguite le statistiche bayesiane anche fin pochi decenni fa. La complessità dei modelli che possiamo costruire è aumentata e la barriera delle competenze matematiche e computazionali che sono richieste è diminuita. Inoltre, il processo di modellazione iterativa è diventato, sotto molti aspetti, molto più facile da eseguire. Anche se formulare modelli statistici complessi è diventato più facile che mai, la statistica è un campo pieno di sottigliezze che non scompaiono magicamente utilizzando potenti metodi computazionali. Pertanto, avere una buona preparazione sugli aspetti teorici, specialmente quelli rilevanti per la pratica, è estremamente utile per applicare efficacemente metodi statistici.","code":""},{"path":"ch-bayes-workflow.html","id":"modellizzazione-bayesiana","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.1 Modellizzazione bayesiana","text":"Nell’approccio bayesiano ’inferenza statistica si prende considerazione una variabile casuale \\(Y\\) di cui si conosce la distribuzione meno di un parametro \\(\\theta\\). Secondo l’approccio bayesiano, è possibile modellare l’incertezza sul valore del parametro rappresentandolo con una variabile casuale continua \\(\\Theta\\) avente come supporto l’insieme dei valori ammissibili per il parametro cercato. La funzione di densità \\(p(\\theta)\\) prende il nome di distribuzione priori e rappresenta la sintesi delle opinioni e delle informazioni che si hanno sul parametro prima dell’osservazione dei dati. L’aggiornamento dell’incertezza su \\(\\theta\\) è determinata dal verificarsi dell’evidenza \\(y\\), ovvero dall’osservazione dei risultati di un esperimento casuale. Le informazioni provenienti dal campione osservato \\(y = (y_1, \\dots, y_n)\\) sono contenute nella funzione \\(p(y \\mid \\theta)\\), che, osservata come funzione di \\(\\theta\\) per \\(y\\), prende il nome di funzione di verosimiglianza. L’aggiornamento delle conoscenze priori incorporate nella distribuzione iniziale \\(p(\\theta)\\) seguito al verificarsi di \\(Y = y\\) (evidenza empirica) avviene attraverso il teorema di Bayes cui \\(p(\\theta \\mid y)\\) risulta proporzionale al prodotto della probabilità priori e della verosimiglianza e prende il nome di distribuzione posteriori:\\[\\begin{equation}\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int_{\\Theta}p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\!\\theta} \\quad \\theta \\\\Theta.\n\\tag{14.1}\n\\end{equation}\\]Si noti che l’integrale al denominatore della (14.1) è spesso di difficile risoluzione analitica per cui l’inferenza bayesiana solitamente procede attraverso metodi di ricampionamento e metodi iterativi, quali le Catene di Markov Monte Carlo (MCMC).Martin, Kumar, Lao (2022) descrivono la modellazione bayesiana distinguendo tre passaggi.Dati alcuni dati e alcune ipotesi su come questi dati potrebbero essere stati generati, si progetta un modello statistico combinando e trasformando variabili casuali.Si usa il teorema di Bayes per condizionare il modello ai dati. Questo processo viene chiamato “inferenza” e come risultato si ottiene una distribuzione posteriori.Si critica il modello utilizzando criteri diversi, inclusi dati e la nostra conoscenza del dominio, per verificare se abbia senso. Poiché generale siamo incerti sul modello, volte si confrontano modelli diversi.Questi tre passaggi vengono eseguiti modo iterativo e danno luogo quello che è chiamato “flusso di lavoro bayesiano” (bayesian workflow).","code":""},{"path":"ch-bayes-workflow.html","id":"notazione","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.1.1 Notazione","text":"Per fissare la notazione, nel seguito \\(y\\) rappresenterà dati e \\(\\theta\\) rappresenterà parametri incogniti di un modello statistico. Sia \\(y\\) che \\(\\theta\\) vengono concepiti come variabili casuali. Con \\(x\\) vengono invece denotate le quantità note, come ad esempio predittori del modello lineare. Per rappresentare un modo conciso modelli probabilistici viene usata una notazione particolare. Ad esempio, invece di scrivere \\(p(\\theta) = \\mbox{Beta}(1, 1)\\) scriviamo \\(\\theta \\sim \\mbox{Beta}(1, 1)\\). Il simbolo “\\(\\sim\\)” viene spesso letto “è distribuito come”. Possiamo anche pensare che significhi che \\(\\theta\\) costituisce un campione casuale estratto dalla distribuzione Beta(1, 1). Allo stesso modo, ad esempio, la verosimiglianza del modello binomiale può essere scritta come \\(y \\sim \\text{Bin}(n, \\theta)\\).","code":""},{"path":"ch-bayes-workflow.html","id":"distribuzioni-a-priori","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.2 Distribuzioni a priori","text":"Quando adottiamo un approccio bayesiano, parametri della distribuzione di riferimento non venono considerati come delle costanti incognite ma bensì vengono trattati come variabili casuali; di conseguenza, parametri assumono una particolare distribuzione che nelle statistica bayesiana viene definita “priori”. parametri \\(\\theta\\) possono assumere delle distribuzioni priori differenti: seconda delle informazioni disponibili bisogna selezionare una distribuzione di \\(\\theta\\) modo tale che venga assegnata una probabilità maggiore quei valori del parametro che si ritengono più plausibili. Idealmente, le credenze priori che portano alla specificazione di una distribuzione priori dovrebbero essere supportate da una qualche motivazione, come ad esempio risultati di ricerche precedenti.","code":""},{"path":"ch-bayes-workflow.html","id":"tipologie-di-distribuzioni-a-priori","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.2.1 Tipologie di distribuzioni a priori","text":"Possiamo distinguere tra diverse distribuzioni priori base quanto fortemente impegnano il ricercatore ritenere come plausibile un particolare intervallo di valori dei parametri. Il caso più estremo è quello che rivela una totale assenza di conoscenze priori, il che conduce alle distribuzioni priori non informative, ovvero quelle che assegnano lo stesso livello di fiducia tutti valori dei parametri. Le distribuzioni priori informative, d’altra parte, possono essere debolmente informative o fortemente informative, seconda del modo cui lo sperimentatore distribuisce la sua fiducia nello spazio del parametro. Il caso più estremo di credenza priori è quello che assegna tutta la probabilità ad un singolo valore del parametro. La figura seguente mostra alcuni esempi di distribuzioni priori per il modello Binomiale:distribuzione non informativa: \\(\\theta_c \\sim \\mbox{Beta}(1,1)\\);distribuzione debolmente informativa: \\(\\theta_c \\sim \\mbox{Beta}(5,2)\\);distribuzione fortemente informativa: \\(\\theta_c \\sim \\mbox{Beta}(50,20)\\);valore puntuale: \\(\\theta_c \\sim \\mbox{Beta}(\\alpha, \\beta)\\) con \\(\\alpha, \\beta \\rightarrow \\infty\\) e \\(\\frac{\\alpha}{\\beta} = \\frac{5}{2}\\).\nFIGURA 14.1: Esempi di distribuzioni priori per il parametro \\(\\theta_c\\) nel Modello Binomiale.\n","code":""},{"path":"ch-bayes-workflow.html","id":"selezione-della-distribuzione-a-priori","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.2.2 Selezione della distribuzione a priori","text":"La selezione delle distribuzioni priori è stata spesso vista come una delle scelte più importanti che un ricercatore fa quando implementa un modello bayesiano quanto può avere un impatto sostanziale sui risultati finali. La soggettività delle distribuzioni priori è evidenziata dai critici come un potenziale svantaggio dei metodi bayesiani. questa critica, Schoot et al. (2021) rispondono dicendo che, al di là della scelta delle distribuzioni priori, ci sono molti elementi del processo di inferenza statistica che sono soggettivi, ovvero la scelta del modello statistico e le ipotesi sulla distribuzione degli errori. secondo luogo, Schoot et al. (2021) notano come le distribuzioni priori svolgono due importanti ruoli statistici: quello della “regolarizzazione della stima”, ovvero, il processo che porta ad indebolire l’influenza indebita di osservazioni estreme, e quello del miglioramento dell’efficienza della stima, ovvero, la facilitazione dei processi di calcolo numerico di stima della distribuzione posteriori. L’effetto della distribuzione priori sulla distribuzione posteriori verrà discusso dettaglio nel Capitolo ??.","code":""},{"path":"ch-bayes-workflow.html","id":"unapplicazione-empirica","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.2.3 Un’applicazione empirica","text":"Per introdurre la modelizzazione bayesiana useremo qui dati riportati da Zetsche, Bürkner, Renneberg (2019) (si veda l’appendice E). Tali dati corrispondono 23 “successi” 30 prove e possono dunque essere considerati la manifestazione di una variabile casuale Bernoulliana.Se non abbiamo alcuna informazione priori su \\(\\theta\\) (ovvero, la probabilità che l’aspettativa dell’umore futuro del partecipante sia distorta negativamente), potremmo pensare di usare una distribuzione priori uniforme, ovvero una Beta di parametri \\(\\alpha=1\\) e \\(\\beta=1\\). Una tale scelta, tuttavia, è sconsigliata quanto è più vantaggioso usare una distribuzione debolmente informativa, come ad esempio \\(\\mbox{Beta}(2, 2)\\), che ha come scopo la regolarizzazione, cioè quello di mantenere le inferenze un intervallo ragionevole. Qui useremo una \\(\\mbox{Beta}(2, 10)\\).\\[\np(\\theta) = \\frac{\\Gamma(12)}{\\Gamma(2)\\Gamma(10)}\\theta^{2-1} (1-\\theta)^{10-1}.\n\\]La \\(\\mbox{Beta}(2, 10)\\) esprime la credenza che \\(\\theta\\) assume valori \\(< 0.5\\), con il valore più plausibile pari circa 0.1. Questo è assolutamente implausibile per il caso dell’esempio discussione: la \\(\\mbox{Beta}(2, 10)\\) verrà usata solo per scopi didattici, ovvero, per esplorare le conseguenze di tale scelta sulla distribuzione posteriori.","code":"\nbayesrules::plot_beta(alpha = 2, beta = 10, mean = TRUE, mode = TRUE)"},{"path":"ch-bayes-workflow.html","id":"la-funzione-di-verosimiglianza","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.3 La funzione di verosimiglianza","text":"Iniziamo con una definizione.Definizione 14.1  La funzione di verosimiglianza \\(\\mathcal{L}(\\theta \\mid y) = f(y \\mid \\theta), \\theta \\\\Theta,\\) è la funzione di massa o di densità di probabilità dei dati \\(y\\) vista come una funzione del parametro sconosciuto (o dei parametri sconosciuti) \\(\\theta\\).Detto altre parole, le funzioni di verosimiglianza e di (massa o densità di) probabilità sono formalmente identiche, ma è completamente diversa la loro interpretazione. Nel caso della funzione di massa o di densità di probabilità la distribuzione del vettore casuale delle osservazioni campionarie \\(y\\) dipende dai valori assunti dal parametro (o dai parametri) \\(\\theta\\); nel caso della la funzione di verosimiglianza la credibilità assegnata ciascun possibile valore \\(\\theta\\) viene determinata avendo acquisita l’informazione campionaria \\(y\\) che rappresenta l’elemento condizionante. altri termini, la funzione di verosimiglianza descrive termini relativi il sostegno empirico che \\(\\theta \\\\Theta\\) riceve da \\(y\\). Infatti, la funzione di verosimiglianza assume forme diverse al variare di \\(y\\). Possiamo dunque pensare alla funzione di verosimiglianza come alla risposta alla seguente domanda: avendo osservato dati \\(y\\), quanto risultano (relativamente) credibili diversi valori del parametro \\(\\theta\\)? termini più formali possiamo dire: sulla base dei dati, \\(\\theta_1 \\\\Theta\\) risulta più credibile di \\(\\theta_2 \\\\Theta\\) quale indice del modello probabilistico generatore dei dati se \\(\\mathcal{L}(\\theta_1) > \\mathcal{L}(\\theta_1)\\).Notiamo un punto importante: la funzione \\(\\mathcal{L}(\\theta \\mid y)\\) non è una funzione di densità. Infatti, essa non racchiude un’area unitaria.","code":""},{"path":"ch-bayes-workflow.html","id":"notazione-1","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.3.1 Notazione","text":"Seguendo una pratica comune, questa dispensa spesso useremo la notazione \\(p(\\cdot)\\) per rappresentare due quantità differenti, ovvero la funzione di verosimiglianza e la distribuzione priori. Questo piccolo abuso di notazione riflette il seguente punto di vista: anche se la verosimiglianza non è una funzione di densità di probabilità, noi non vogliamo stressare questo aspetto, ma vogliamo piuttosto pensare alla verosimiglianza e alla distribuzione priori come due elementi che sono egualmente necessari per calcolare la distribuzione posteriori. altri termini, per così dire, questa notazione assegna lo stesso status epistemologico alle due diverse quantità che si trovano al numeratore della regola di Bayes.","code":""},{"path":"ch-bayes-workflow.html","id":"la-log-verosimiglianza","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.3.2 La log-verosimiglianza","text":"Dal punto di vista pratico risulta più conveniente utilizzare, al posto della funzione di verosimiglianza, il suo logaritmo naturale, ovvero la funzione di log-verosimiglianza:\\[\\begin{equation}\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta).\n\\end{equation}\\]Poiché il logaritmo è una funzione strettamente crescente (usualmente si considera il logaritmo naturale), allora \\(\\mathcal{L}(\\theta)\\) e \\(\\ell(\\theta)\\) assumono il massimo (o punti di massimo) corrispondenza degli stessi valori di \\(\\theta\\) (per un approfondimento, si veda l’Appendice ??):\\[\n\\hat{\\theta} = \\argmax_{\\theta \\\\Theta} \\ell(\\theta) = \\argmax_{\\theta \\\\Theta} \\mathcal{L}(\\theta).\n\\]Per le proprietà del logaritmo, si ha\\[\\begin{equation}\n\\ell(\\theta) = \\log \\left( \\prod_{= 1}^n f(y \\mid \\theta) \\right) = \\sum_{= 1}^n \\log f(y \\mid \\theta).\n\\end{equation}\\]Si noti che non è necessario lavorare con logaritmi, ma è fortemente consigliato. Il motivo è che valori della verosimiglianza, cui si moltiplicano valori di probabilità molto piccoli, possono diventare estremamente piccoli – qualcosa come \\(10^{-34}\\). tali circostanze, non è sorprendente che programmi dei computer mostrino problemi di arrotondamento numerico. Le trasformazioni logaritmiche risolvono questo problema.","code":""},{"path":"ch-bayes-workflow.html","id":"unapplicazione-empirica-1","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.3.3 Un’applicazione empirica","text":"Se dati di Zetsche, Bürkner, Renneberg (2019) possono essere riassunti da una proporzione allora è sensato adottare un modello probabilistico binomiale quale meccanismo generatore dei dati:\\[\\begin{equation}\ny  \\sim \\mbox{Bin}(n, \\theta),\n\\tag{14.2}\n\\end{equation}\\]laddove \\(\\theta\\) è la probabiltà che una prova Bernoulliana assuma il valore 1 e \\(n\\) corrisponde al numero di prove Bernoulliane. Questo modello assume che le prove Bernoulliane \\(y_i\\) che costituiscono il campione \\(y\\) siano tra loro indipendenti e che ciascuna abbia la stessa probabilità \\(\\theta \\[0, 1]\\) di essere un “successo” (valore 1). altre parole, il modello generatore dei dati avrà una funzione di massa di probabilità\\[\np(y \\mid \\theta)\n\\ = \\\n\\mbox{Bin}(y \\mid n, \\theta).\n\\]Nei capitoli precedenti è stato mostrato come, sulla base del modello binomiale, sia possibile assegnare una probabilità ciascun possibile valore \\(y \\\\{0, 1, \\dots, n\\}\\) assumendo noto il valore del parametro \\(\\theta\\). Ma ora abbiamo il problema inverso, ovvero quello di fare inferenza su \\(\\theta\\) alla luce dei dati campionari \\(y\\). altre parole, riteniamo di conoscere il modello probabilistico che ha generato dati, ma di tale modello non conosciamo parametri: vogliamo dunque ottenere informazioni su \\(\\theta\\) avendo osservato dati \\(y\\).Per dati di Zetsche, Bürkner, Renneberg (2019) la funzione di verosimiglianza corrisponde alla funzione binomiale di parametro \\(\\theta \\[0, 1]\\) sconosciuto. Abbiamo osservato un “successo” 23 volte 30 “prove”, dunque, \\(y = 23\\) e \\(n = 30\\). La funzione di verosimiglianza diventa\\[\\begin{equation}\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} \\theta^{23} + (1-\\theta)^7.\n\\tag{14.3}\n\\end{equation}\\]Per costruire la funzione di verosimiglianza dobbiamo applicare la (14.3) tante volte, cambiando ogni volta il valore \\(\\theta\\) ma tenendo sempre costante il valore dei dati. Per esempio, se poniamo \\(\\theta = 0.1\\)\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.1^{23} + (1-0.1)^7\n\\]otteniamoSe poniamo \\(\\theta = 0.2\\)\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.2^{23} + (1-0.2)^7\n\\]otteniamoe così via. La figura 14.2 — costruita utilizzando 100 valori equispaziati \\(\\theta \\[0, 1]\\) — fornisce una rappresentazione grafica della funzione di verosimiglianza.\nFIGURA 14.2: Funzione di verosimiglianza nel caso di 23 successi 30 prove.\nCome possiamo interpretare la curva che abbiamo ottenuto? Per alcuni valori \\(\\theta\\) la funzione di verosimiglianza assume valori piccoli; per altri valori \\(\\theta\\) la funzione di verosimiglianza assume valori più grandi. Questi ultimi sono valori di \\(\\theta\\) più credibili e il valore 23/30 (la moda della funzione di verosimiglianza) è il valore più credibile di tutti.","code":"\ndbinom(23, 30, 0.1)\n#> [1] 9.737168e-18\ndbinom(23, 30, 0.2)\n#> [1] 3.581417e-11\nn <- 30\ny <- 23\ntheta <- seq(0, 1, length.out = 100)\nlike <- choose(n, y) * theta^y * (1 - theta)^(n - y)\ntibble(theta, like) %>%\n  ggplot(aes(x = theta, y = like)) +\n  geom_line() +\n  labs(\n    y = expression(L(theta)),\n    x = expression(\"Valori possibili di\" ~ theta)\n  )"},{"path":"ch-bayes-workflow.html","id":"sec:const-normaliz-bino23","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.4 La verosimiglianza marginale","text":"Per il calcolo di \\(p(\\theta \\mid y)\\) è necessario dividere il prodotto tra la distribuzione priori e la verosimiglianza per una costante di normalizzazione. Tale costante di normalizzazione, detta verosimiglianza marginale, ha lo scopo di fare modo che \\(p(\\theta \\mid y)\\) abbia area unitaria.Si noti che, nel caso di variabili continue, la verosimiglianza marginale è espressa nei termini di un integrale. Tranne pochi casi particolari, tale integrale non ha una soluzione analitica. Per questa ragione, l’inferenza bayesiana procede calcolando una approssimazione della distribuzione posteriori mediante metodi numerici.","code":""},{"path":"ch-bayes-workflow.html","id":"unapplicazione-empirica-2","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.4.1 Un’applicazione empirica","text":"Consideriamo nuovamente dati di Zetsche, Bürkner, Renneberg (2019). Supponiamo che nel numeratore bayesiano la verosimiglianza sia moltiplicata per una distribuzione uniforme, ovvero \\(\\mbox{Beta}(1, 1)\\). tali circostanze, il prodotto si riduce alla funzione di verosimiglianza. Per dati di Zetsche, Bürkner, Renneberg (2019), dunque, la costante di normalizzazione si ottiene marginalizzando la funzione di verosimiglianza \\(p(y = 23, n = 30 \\mid \\theta)\\) sopra \\(\\theta\\), ovvero risolvendo l’integrale:\\[\\begin{equation}\np(y = 23, n = 30) = \\int_0^1 \\binom{30}{23} \\theta^{23} (1-\\theta)^{7} \\,\\operatorname {d}\\!\\theta.\n\\tag{14.4}\n\\end{equation}\\]Una soluzione numerica si trova facilmente usando \\(\\R\\):La derivazione analitica è fornita nell’Appendice G.","code":"\nlike_bin <- function(theta) {\n  choose(30, 23) * theta^23 * (1 - theta)^7\n}\nintegrate(like_bin, lower = 0, upper = 1)$value\n#> [1] 0.03225806"},{"path":"ch-bayes-workflow.html","id":"distribuzione-a-posteriori","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.5 Distribuzione a posteriori","text":"La distribuzione postreriori si trova applicando il teorema di Bayes:\\[\n\\text{probabilità posteriori} = \\frac{\\text{probabilità priori} \\cdot \\text{verosimiglianza}}{\\text{costante di normalizzazione}}\n\\]Una volta trovata la distribuzione posteriori, possiamo usarla per derivare altre quantità di interesse. Questo viene generalmente ottenuto calcolando il seguente valore atteso:\\[\nJ = \\int f(\\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!y\n\\]Se \\(f(\\cdot)\\) è la funzione identità, ad esempio, \\(J\\) risulta essere la media di \\(\\theta\\):\\[\n\\bar{\\theta} = \\int_{\\Theta} \\theta p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta .\n\\]Ripeto qui quanto detto sopra: le quantità di interesse della statistica bayesiana(costante di normalizzazione, valore atteso della distribuzione posteriori, ecc.) contengono integrali che risultano, nella maggior parte dei casi, impossibili da risolvere analiticamente. Per questo motivo, si ricorre metodi di stima numerici, particolare quei metodi Monte Carlo basati sulle proprietà delle catene di Markov (MCMC). Questo argomento verrà discusso nel Capitolo ??.","code":""},{"path":"ch-bayes-workflow.html","id":"distribuzione-predittiva-a-priori","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.6 Distribuzione predittiva a priori","text":"La distribuzione posteriori è l’oggetto centrale nella statistica bayesiana, ma non è l’unico. Oltre fare inferenze sui valori dei parametri, potremmo voler fare inferenze sui dati. Questo può essere fatto calcolando la distribuzione predittiva priori:\\[\\begin{equation}\np(y^*) = \\int_\\Theta p(y^* \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\!\\theta .\n\\tag{14.5}\n\\end{equation}\\]La (14.5) descrive la distribuzione prevista dei dati base al modello (che include la distribuzione priori e la verosimiglianza), ovvero descrive dati \\(y^*\\) che ci aspettiamo di osservare, dato il modello, prima di avere osservato dati del campione.È possibile utilizzare campioni dalla distribuzione predittiva priori per valutare e calibrare modelli utilizzando le nostre conoscenze dominio-specifiche. Ad esempio, ci possiamo chiedere: “È sensato che un modello dell’altezza umana preveda che un essere umano sia alto -1.5 metri?”. Già prima di misurare una singola persona, possiamo renderci conto dell’assurdità di questa domanda. Se la distribuzione prevista dei dati consente domande di questo tipo (ovvero, prevede di osservare dati che risultano insensati alla luce delle nostre conoscenze dominio-specifiche), è chiaro che il modello deve essere riformulato.","code":""},{"path":"ch-bayes-workflow.html","id":"distribuzione-predittiva-a-posteriori","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"14.7 Distribuzione predittiva a posteriori","text":"Un’altra quantità utile da calcolare è la distribuzione predittiva posteriori:\\[\\begin{equation}\np(\\tilde{y} \\mid y) = \\int_\\Theta p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta .\n\\tag{14.6}\n\\end{equation}\\]Questa è la distribuzione dei dati attesi futuri \\(\\tilde{y}\\) alla luce della distribuzione posteriori \\(p(\\theta \\mid y)\\), che sua volta è una conseguenza del modello adottato (distribuzione priori e verosimiglianza) e dei dati osservati. altre parole, questi sono dati che il modello si aspetta dopo aver osservato dati de campione. Dalla (14.6) possiamo vedere che le previsioni sui dati attesi futuri sono calcolate integrando (o marginalizzando) sulla distribuzione posteriori dei parametri. Di conseguenza, le previsioni calcolate questo modo incorporano l’incertezza relativa alla stima dei parametri del modello.","code":""},{"path":"ch-bayes-workflow.html","id":"commenti-e-considerazioni-finali-10","chapter":"Capitolo 14 Flusso di lavoro bayesiano","heading":"Commenti e considerazioni finali","text":"Questo Capitolo ha brevemente passato rassegna concetti di base dell’inferenza statistica bayesiana. base ’approccio bayesiano, invece di dire che il parametro di interesse di un modello statistico ha un valore vero ma sconosciuto, diciamo che, prima di eseguire l’esperimento, è possibile assegnare una distribuzione di probabilità, che chiamano stato di credenza, quello che è il vero valore del parametro. Questa distribuzione priori può essere nota (per esempio, sappiamo che la distribuzione dei punteggi del QI è normale con media 100 e deviazione standard 15) o può essere del tutto arbitraria. L’inferenza bayesiana procede poi nel modo seguente: si raccolgono alcuni dati e si calcola la probabilità dei possibili valori del parametro alla luce dei dati osservati e delle credenze priori. Questa nuova distribuzione di probabilità è chiamata “distribuzione posteriori” e riassume l’incertezza dell’inferenza.","code":""},{"path":"ch-subj-think-prop.html","id":"ch-subj-think-prop","chapter":"Capitolo 15 Pensare ad una proporzione in termini soggettivi","heading":"Capitolo 15 Pensare ad una proporzione in termini soggettivi","text":"Obiettivo di questo Capitolo è introdurre l’inferenza bayesiana considerando il caso della verosimiglianza binomiale. Esamineremo prima il caso di una distribuzione priori è discreta; poi considereremo una distribuzione priori continua. Il materiale qui presentato segue molto da vicino il capitolo 7 del testo di Albert Hu (2019).","code":""},{"path":"ch-subj-think-prop.html","id":"ch-prior-discr-binom","chapter":"Capitolo 15 Pensare ad una proporzione in termini soggettivi","heading":"15.1 Inferenza bayesiana con una distribuzione a priori discreta","text":"Nei problemi tradizionali di teoria delle probabilità ci sono molti esempi che riguardano l’estrazione di palline colorate da un’urna. questi esempi, ci viene fornito il numero di palline di vari colori presenti nell’urna e ci viene chiesto di calcolare le probabilità di vari eventi. Ad esempio, un’urna ci sono 40 palline bianche e 20 rosse. Se estrai due palline caso, qual è la probabilità che entrambe siano bianche?L’approccio bayesiano considera uno scenario diverso, ovvero quello cui non conosciamo le proporzioni delle palline colorate presenti nell’urna. Cioè, nell’esempio precedente, sappiamo solo che nell’urna ci sono due tipi di palline colorate, ma non sappiamo che 40 sono bianche (proporzione di bianco = \\(2/3\\)) e 20 sono rosse (proporzione di rosso = \\(1/3\\)). Ci poniamo la seguente domanda: è possibile inferire le proporzioni di palline nell’urna estraendo un campione di palline dall’urna e osservando colori delle palline nel campione? Espresso questo modo, questo diventa un problema di inferenza statistica, perché stiamo cercando di inferire la proporzione \\(\\theta\\) della popolazione sulla base di un campione casuale. Per continuare con l’esempio precedente, quello che vogliamo fare è inferire \\(\\theta\\), la proporzione di palline rosse nell’urna, base al numero di palline rosse e bianche che osserviamo nel campione.Le proporzioni assomigliano alle probabilità. Ricordiamo che sono state proposte tre diverse interpretazioni del concetto di una probabilità.Il punto di vista classico: è necessario enumerare tutti gli eventi elementari dello spazio campionario cui ogni risultato è ugualmente probabile.Il punto di vista frequentista: è necessario ripetere l’esperimento esperimento casuale (cioè l’estrazione del campione) molte volte condizioni identiche.La visione soggettiva: è necessario esprimere la propria opinione sulla probabilità di un evento unico e irripetibile.La visione classica non sembra potere funzionare qui, perché sappiamo solo che ci sono due tipi di palline colorate e il numero totale di palline è 60. Anche se estraiamo un campione di 10 palline, possiamo solo osservare la proporzione di palline rosse palline nel campione. Non c’è modo per stabilire quali sono le proprietà dello spazio campionario cui ogni risultato è ugualmente probabile.La visione frequentista potrebbe funzionare nel caso presente. Possiamo considerare il processo del campionamento (cioè l’estrazione di un campione casuale di 10 palline dall’urna) come un esperimento casuale che produce una proporzione campionaria \\(p\\). Potremmo quindi pensare di ripetere l’esperimento molte volte nelle stesse condizioni, ottenere molte proporzioni campionarie \\(p\\) e riassumere poi qualche modo questa distribuzione di statistiche campionarie. Ripetendo l’esperimento casuale tante volte è possibile ottenere una stima abbastanza accurata della proporzione \\(\\theta\\) di palline rosse nell’urna. Questo processo è fattibile, ma è però noioso, dispendioso termini di tempo e soggetto ad errori.La visione soggettivista concepisce invece la probabilità sconosciuta \\(\\theta\\) come un’opinione soggettiva di cui possiamo essere più o meno sicuri. Abbiamo visto precedenza come questa opinione soggettiva dipenda da due tipi di evidenze: le nostre credenze iniziali e le nuove informazioni fornite dai dati che abbiamo osservato. Vedremo questo capitolo come sia possibile combinare le credenze iniziali rispetto al possibile valore \\(\\theta\\) con le evidenza fornite dai dati per giungere ad una credenza posteriori su \\(\\theta\\). particolare, vedremo come si possa pensare termini soggetti delle quantità sconosciute (questo caso, \\(\\theta\\)) usando le distribuzioni di probabilità.Sappiamo che, essendo una proporzione, \\(\\theta\\) può assumere valori compresi tra 0 e 1. Potremmo pensare che \\(\\theta\\) sia uguale, ad esempio, 0.5. Ciò significa assegnare ’evento \\(\\theta = 1\\) la probabilità 1 – altri termini, significa dire che siamo assolutamente certi che la quantità sconosciuta \\(\\theta\\) ha il valore di 0.5. Questa posizione, però, è troppo estrema: non possiamo essere assolutamente certi che una quantità sconosciuta abbia uno specifico valore; altrimenti non sarebbe una quantità sconosciuta. Invece, sembra più sensato pensare che \\(\\theta\\) può, linea di principio, assumere valori diversi e, questi valori, vengono attribuiti diversi livelli di certezza soggettiva. Consideriamo, ad esempio, 10 possibili valori per \\(\\theta\\):Se non abbiamo alcun motivo di pensare diversamente, potremmo pensare di assegnare ciascuno di questi valori lo stesso livello di plausibilità:Oppure, per qualche ragione, potremmo pensare che valori centrali della distribuzione di \\(\\theta\\) siamo più plausibili dei valori estremi. Tale opinione soggettiva potrebbe corrispondere alla seguente distribuzione di massa di probabilità:La prima distribuzione di probabilità è chiamata distribuzione discreta uniforme perché attribuisce la stessa probabilità (ovvero, 1/10) ad ogni elemento dell’insieme discreto su cui è definita (ovvero, \\(0.1, 0.2, \\dots, 1.0\\)). Anche la seconda distribuzione è discreta, ma non è uniforme: viene ritenuto più plausibile che \\(\\theta\\) assuma un valore nell’insieme \\(\\{0.4, 0.5, 0.6, 0.7\\}\\) piuttosto che nell’insieme \\(\\{0.1, 0.2, 0.3, 0.8, 0.9, 1.0\\}\\).Le credenze relative alla plausibilità dei possibili valori che \\(\\theta\\) possono assumere forme diverse e corrispondono quella che viene chiamata la distribuzione priori, ovvero descrivono le credenze che possediamo relativamente alla quantità sconosciuta di interesse.La procedura di inferenza bayesiana non fa altro che “aggiornare” tali credenze priori utilizzando le informazioni fornite da un campione di dati. Usando il teorema di Bayes, le informazioni dei dati vengono combinate con le nostre precedenti credenze relative alla quantità sconosciuta \\(\\theta\\) per giungere ad una credenza detta “posteriori”.Supponendo che dati corrispondano ’osservazione di 12 palline rosse 20 estrazioni con rimessa dall’urna, usiamo ora la seconda delle distribuzioni priori descritte precedenza per ottenere la distribuzione posteriori. Il teorema di Bayes specifica la distribuzione posteriori come il prodotto della verosimiglianza e la distribuzione priori, diviso per una costante di normalizzazione:\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)}.\n\\]Per definire la funzione di verosimiglianza, \\(p(y \\mid \\theta)\\), è necessario pensare come abbiamo ottenuto dati. Abbiamo estratto 20 palline dall’una, con rimessa. Dunque, se l’estrazione è stata casuale con reinserimento, allora dati (12 successi 20 prove) possono essere intesi come il risultato di un esperimento casuale binomiale. Usando \\(\\textsf{R}\\), la funzione di verosimiglianza è dunque data da:Per calcolare la distribuzione posteriori dobbiamo dunque fare il prodotto (elemento per elemento) del vettore che contiene valori della distribuzione priori per il vettore che contiene valori di verosimiglianza. Tale prodotto andrà poi diviso per una costante di normalizzazione, \\(p(y)\\).Per la legge della probabilità totale, il denominatore corrisponde alla probabilità marginale dei dati \\(y\\) ed è uguale alla somma dei prodotti tra la distribuzione priori e la verosimiglianza calcolata corrispondenza di ciascun valore possibile di \\(\\theta\\).\nNel nostro caso discreto, la probabilità marginale dei dati ci calcola utilizzando la distribuzione priorie la verosimiglianzaDopo avere fatto il prodottodobbiamo sommare:Una volta calcolata la verosimiglianza marginale dei dati, possiamo trovare la distribuzione posteriori di \\(\\theta\\):Conoscendo la distribuzione posteriori di \\(\\theta\\) diventa possibile calcolare altre quantità di interesse. Per esempio, la moda posteriori di \\(\\theta\\) si ricava direttamente dal grafico precedente, e corrisponde 0.6. La media posteriori è data da:La varianza della distribuzione posteriori èIl calcolo della distribuzione posteriori, nel caso di una distribuzione priori discreta, è implementata nella funzione bayesian_crank() del pacchetto ProbBayes. Dato che ProbBayes non è su CRAN, può essere installato nel modo seguente:Una volta installato, il pacchetto può essere caricato come facciamo normalmente:Per usare bayesian_crank() procediamo come indicato di seguito:Verifichiamo il risultato trovato calcolando, ad esempio, la media posteriori (come abbiamo fatto sopra):questo modo possiamo dunque trovare la distribuzione posteriori per \\(\\theta\\), nel caso di qualunque distribuzione priori discreta.","code":"\ntheta = seq(0.1, 1, length.out = 10)\ntheta\n#>  [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\np1 <- rep(0.1, 10)\np1\n#>  [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\ntibble(theta, p1) %>% \n  ggplot(aes(theta, p1)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), size = 10, lineend = \"butt\"\n  )\np2 <- c(\n  0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05\n)\np2\n#>  [1] 0.050 0.050 0.050 0.175 0.175 0.175 0.175 0.050 0.050 0.050\ntibble(theta, p2) %>% \n  ggplot(aes(theta, p2)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), size = 10, lineend = \"butt\"\n  )\nlike <- dbinom(12, 20, theta)\nlike\n#>  [1] 5.422595e-08 8.656592e-05 3.859282e-03 3.549744e-02 1.201344e-01\n#>  [6] 1.797058e-01 1.143967e-01 2.216088e-02 3.557765e-04 0.000000e+00\ntibble(theta, like) %>% \n  ggplot(aes(theta, like)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), size = 10, lineend = \"butt\"\n  )\np2\n#>  [1] 0.050 0.050 0.050 0.175 0.175 0.175 0.175 0.050 0.050 0.050\nlike\n#>  [1] 5.422595e-08 8.656592e-05 3.859282e-03 3.549744e-02 1.201344e-01\n#>  [6] 1.797058e-01 1.143967e-01 2.216088e-02 3.557765e-04 0.000000e+00\np2 * like\n#>  [1] 2.711298e-09 4.328296e-06 1.929641e-04 6.212052e-03 2.102351e-02\n#>  [6] 3.144851e-02 2.001943e-02 1.108044e-03 1.778882e-05 0.000000e+00\nsum(p2 * like)\n#> [1] 0.08002663\npost <- (p2 * like) / sum(p2 * like)\npost\n#>  [1] 3.387994e-08 5.408570e-05 2.411248e-03 7.762481e-02 2.627064e-01\n#>  [6] 3.929756e-01 2.501596e-01 1.384594e-02 2.222863e-04 0.000000e+00\ntibble(theta, post) %>% \n  ggplot(aes(theta, post)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), size = 10, lineend = \"butt\"\n  )\nsum(pi * post)\n#> [1] 3.141593\nsum(theta^2 * post) - (sum(theta * post))^2\n#> [1] 0.008817409\nlibrary(\"devtools\")\ninstall_github(\"bayesball/ProbBayes\")\nlibrary(\"ProbBayes\")\ndf <- tibble(p = theta, Prior = p2)\ny <- 12\nn <- 20\ndf$Likelihood <- dbinom(y, prob = df$p, size = n)\ndf <- bayesian_crank(df)\ndf\n#> # A tibble: 10 × 5\n#>       p Prior   Likelihood       Product    Posterior\n#>   <dbl> <dbl>        <dbl>         <dbl>        <dbl>\n#> 1   0.1 0.05  0.0000000542 0.00000000271 0.0000000339\n#> 2   0.2 0.05  0.0000866    0.00000433    0.0000541   \n#> 3   0.3 0.05  0.00386      0.000193      0.00241     \n#> 4   0.4 0.175 0.0355       0.00621       0.0776      \n#> 5   0.5 0.175 0.120        0.0210        0.263       \n#> 6   0.6 0.175 0.180        0.0314        0.393       \n#> 7   0.7 0.175 0.114        0.0200        0.250       \n#> 8   0.8 0.05  0.0222       0.00111       0.0138      \n#> # … with 2 more rows\nsum(pi * df$Posterior)\n#> [1] 3.141593"},{"path":"ch-subj-think-prop.html","id":"ch-prior-cont-binom","chapter":"Capitolo 15 Pensare ad una proporzione in termini soggettivi","heading":"15.2 Inferenza bayesiana con una distribuzione a priori continua","text":"Il caso di una distribuzione priori discreta è stato discusso solo per scopi didattici. generale, però, l’uso di una distribuzione priori discreta non è una buona scelta per rappresentare le nostre credenze priori sul parametro sconosciuto. Infatti, per definizione, una distribuzione priori discreta può rappresentare solo alcuni dei possibili valori del parametro – nel caso dell’esempio precedente, non abbiamo considerato il valore 0.55, per esempio. Sembra molto più sensato descrivere le nostre credenze priori sul parametro utilizzando una distribuzione continua.Cerchiamo una funzione di densità con supporto \\([0, 1]\\). Il candidato naturale è ovviamente fornito dalla funzione Beta (si veda il Capitolo ??). Come per le altre funzioni di densità, abbiamo disposizione quattro funzioni \\(\\textsf{r}\\) che ci consentono di manipolare facilmente questa densità.Ad esempio, possiao valutare la funzione di densità \\(\\mbox{Beta}(1, 1)\\) corrispondenza dei valori \\(p = 0.5\\) e \\(p = 0.8\\), che dovrebbe essere entrambi uguali 1, e corrispondenza di \\(p = 1.2\\), che dovrebbe essere ugualea 0 poiché questo valore è al di fuori dell’intervallo \\([ 0, 1]\\).Oppure possiamo valutare la funzione distribuzione \\(\\mbox{Beta}(1, 1)\\) corrispondenza dei punti 0.5 e 0.8:Oppure possiamo calcolare la probabilità \\(P(0.5 < p < 0.8)\\)Possiamo trovare quntili della distribuzione \\(\\mbox{Beta}(1, 1)\\) di ordine 0.5 e 0.8:Infine, è possibile simulare dei valori casuali dalla distribuzione \\(\\mbox{Beta}(1, 1)\\). Se vogliamo 5 valori, scriviamo:Se vogliamo 5 valori da una \\(\\mbox{Beta}(2, 10)\\), scriviamo:Il pacchetto ProbBayes offre la funzione beta_area() per visualizzare la probabilità di una distribuzione Beta un certo intrvallo di valori. Per esempio, se vogliamo la probabilità dell’evento per cui la variabile casuale \\(p\\) è contenuta nell’intervallo \\([0.1, 0.3]\\) nel caso di una \\(\\mbox{Beta}(2, 10)\\), scriviamo:","code":"\ndbeta(c(0.5, 0.8, 1.2), 1, 1)\n#> [1] 1 1 0\npbeta(c(0.5, 0.8), 1, 1)\n#> [1] 0.5 0.8\npbeta(0.8, 1, 1) - pbeta(0.5, 1, 1) \n#> [1] 0.3\nqbeta(c(0.5, 0.8), 1, 1)\n#> [1] 0.5 0.8\nrbeta(5, 1, 1)\n#> [1] 0.2523117 0.5492791 0.2174402 0.4063601 0.2128675\nrbeta(5, 2, 10)\n#> [1] 0.17364773 0.21332530 0.24430864 0.15817644 0.04897118\nbeta_area(0.1, 0.3, c(2, 10))"},{"path":"ch-subj-think-prop.html","id":"quali-parametri-per-la-distribuzione-beta","chapter":"Capitolo 15 Pensare ad una proporzione in termini soggettivi","heading":"15.2.1 Quali parametri per la distribuzione Beta?","text":"Se usiamo una distribuzione Beta per rappresentare le nostre credenze priori sul parametro \\(\\theta\\) (probabilità di successo), allora dobbiamo porci il problema di scegliere parametri che definiscono la distribuzione Beta che meglio rappresenta le nostre opinioni priori. Il modo più ovvio per ottenere questo risultato è per prove ed errori. Oppure, possiamo individuare parametri \\(\\alpha\\) e \\(\\beta\\) della distribuzione interpretando \\(\\alpha\\) come la nostra stima priori del numero di “successi”, \\(\\beta\\) come nostra stima priori del numero di “insuccessi” e \\(\\alpha + \\beta\\) come il numero di prove del campione. Quindi, per esempio, se pensiamo che, su 30 prove, verranno osservati 10 successi, otteniamo una \\(\\mbox{Beta}(10, 20)\\):alternativa, potremmo specificare la distribuzione priori definendo la mediana e un quantile della distribuzione. Per esempio, le nostre opinioni priori sul parametro potrebbero essere tali per cui pensiamo che la mediana della distribuzione sia 0.25 e il quantile della distribuzione di ordine 0.9 sia 0.5. Usando la Shiny App ProbBayes::ChooseBeta() troviamo parametri \\(\\alpha = 1.84\\) e \\(\\beta = 4.89\\).","code":"\nbayesrules::plot_beta(10, 20, mean = TRUE, mode = TRUE)"},{"path":"ch-subj-think-prop.html","id":"commenti-e-considerazioni-finali-11","chapter":"Capitolo 15 Pensare ad una proporzione in termini soggettivi","heading":"Commenti e considerazioni finali","text":"Abbiamo qui introdotto la procedura dell’aggiornamento bayesiano nel caso cui la distribuzione priori sia discreta. Abbiamo anche fornito alcune informazioni che sono utili per affrontare il problema nel caso cui viene utilizzata una distribuzione priori continua. Se viene utilizzata una distribuzione priori continua, al denominatore del rapporto di Bayes troviamo un integrale che, generale, non si può risolvere per via analitica. Il caso dell’inferenza di una proporzione, cui la distribuzione priori è una distribuzione Beta e la verosimiglianza è binoniale, rappresenta però un’eccezione, ovvero consente di derivare le proprietà della distribuzione posteriori per via analitica. Il prossimo capitolo ha lo scopo di mostrare come questo possa essere fatto.","code":""},{"path":"ch-distr-coniugate.html","id":"ch-distr-coniugate","chapter":"Capitolo 16 Distribuzioni coniugate","heading":"Capitolo 16 Distribuzioni coniugate","text":"Obiettivo di questo Capitolo è fornire un esempio di derivazione della distribuzione posteriori scegliendo quale distribuzione priori una distribuzione coniugata. Esamineremo qui il lo schema beta-binomiale.","code":""},{"path":"ch-distr-coniugate.html","id":"lo-schema-beta-binomiale","chapter":"Capitolo 16 Distribuzioni coniugate","heading":"16.1 Lo schema beta-binomiale","text":"Esiste una particolare classe di distribuzioni priori, dette distribuzioni priori coniugate al modello, che godono di un’importante proprietà: se la distribuzione iniziale appartiene tale classe, anche la distribuzione finale vi appartiene, cioé ha la stessa forma funzionale, e l’aggiornamento della fiducia si riduce alla modifica dei parametri della distribuzione priori. Ad esempio, se la distribuzione priori è una Beta e la verosimiglianza è binomiale, allora la distribuzione posteriori sarà anch’essa una distribuzione Beta.Da un punto di vista matematico, le distribuzioni priori coniugate sono la scelta più conveniente quanto consentono di calcolare analiticamente la distribuzione posteriori con “carta e penna”, senza la necessità di ricorrere calcoli complessi. Da una prospettiva computazionale moderna, però, le distribuzioni priori coniugate generalmente non sono migliori delle alternative, dato che moderni metodi computazionali consentono di eseguire l’inferenza praticamente con qualsiasi scelta delle distribuzioni priori, e non solo con le distribuzioni priori che risultano matematicamente convenienti. Tuttavia, le famiglie coniugate offronto un utile ausilio didattico nello studio dell’inferenza bayesiana. Questo è il motivo per cui le esamineremo qui. Nello specifico, esamineremo quello che viene chiamato lo schema beta-binomiale.Per fare un esempio concreto, consideriamo nuovamente dati di Zetsche, Bürkner, Renneberg (2019): nel campione di 30 partecipanti clinici le aspettative future di 23 partecipanti risultano negativamente distorte mentre quelle di 7 partecipanti risultano positivamente distorte. Nel seguito, indicheremo con \\(\\theta\\) la probabilità che le aspettative di un paziente clinico siano distorte negativamente. Ci poniamo il problema di ottenere una stima posteriori di \\(\\theta\\) avendo osservato 23 “successi” 30 prove. dati osservati (\\(y = 23\\)) possono essere considerati la manifestazione di una variabile casuale Bernoulliana, dunque la verosimiglianza è binomiale. tali circostanze, se viene scelta una distribuzione priori Beta, allora anche la distribuzione posteriori sarà una Beta.","code":""},{"path":"ch-distr-coniugate.html","id":"la-specificazione-della-distribuzione-a-priori","chapter":"Capitolo 16 Distribuzioni coniugate","heading":"16.1.1 La specificazione della distribuzione a priori","text":"È possibile esprimere diverse credenze iniziali rispetto \\(\\theta\\) mediante la distribuzione Beta. Ad esempio, la scelta di una \\(\\mbox{Beta}(\\alpha = 4, \\beta = 4)\\) quale distribuzione priori per il parametro \\(\\theta\\) corrisponde alla credenza priori che associa ’evento “presenza di una aspettativa futura distorta negativamente” una grande incertezza: il valore 0.5 è il valore di \\(\\theta\\) più plausibile, ma anche gli altri valori del parametro (tranne gli estremi) sono ritenuti piuttosto plausibili. Questa distribuzione priori esprime la credenza che sia egualmente probabile per un’aspettativa futura essere distorta negativamente o positivamente.Possiamo quantificare la nostra incertezza calcolando, con un grado di fiducia del 95%, la regione nella quale, base tale credenza priori, si trova il valore del parametro. Per ottenere tale intervallo di credibilità priori, usiamo la funzione qbeta() di \\(\\R\\). qbeta() parametri \\(\\alpha\\) e \\(\\beta\\) sono chiamati shape1 e shape2:Se poniamo \\(\\alpha=10\\) e \\(\\beta=10\\), questo corrisponde ad una credenza priori che sia egualmente probabile per un’aspettativa futura essere distorta negativamente o positivamente,ma ora la nostra certezza priori sul valore del parametro è maggiore, come indicato dall’intervallo al 95%:Quale distribuzione priori dobbiamo scegliere? un problema concreto di analisi dei dati, la scelta della distribuzione priori dipende dalle credenze priori che vogliamo includere nell’analisi dei dati. Se non abbiamo alcuna informazione priori, potremmo usare \\(\\alpha=1\\) e \\(\\beta=1\\), che produce una distribuzione priori uniforme. Ma l’uso di distribuzioni priori uniformi è sconsigliato per vari motivi, inclusa l’instabilità numerica della stima dei parametri. È meglio invece usare una distribuzione priori debolmente informativa, come \\(\\mbox{Beta}(2, 2)\\).Nella discussione presente, solo per fare un esempio, useremo quale distribuzione priori una \\(\\mbox{Beta}(2, 10)\\), ovvero:\\[\np(\\theta) = \\frac{\\Gamma(12)}{\\Gamma(2)\\Gamma(10)}\\theta^{2-1} (1-\\theta)^{10-1}.\n\\]La \\(\\mbox{Beta}(2, 10)\\) esprime la credenza che \\(\\theta < 0.5\\), con il valore più plausibile pari cicrca 0.1.","code":"\nlibrary(\"bayesrules\")\nplot_beta(alpha = 4, beta = 4, mean = TRUE, mode = TRUE)\nqbeta(c(0.025, 0.975), shape1 = 4, shape2 = 4)\n#> [1] 0.1840516 0.8159484\nplot_beta(alpha = 10, beta = 10, mean = TRUE, mode = TRUE)\nqbeta(c(0.025, 0.975), shape1 = 10, shape2 = 10)\n#> [1] 0.2886432 0.7113568\nplot_beta(alpha = 2, beta = 10, mean = TRUE, mode = TRUE)"},{"path":"ch-distr-coniugate.html","id":"la-specificazione-della-distribuzione-a-posteriori","chapter":"Capitolo 16 Distribuzioni coniugate","heading":"16.1.2 La specificazione della distribuzione a posteriori","text":"Una volta scelta una distribuzione priori di tipo Beta, cui parametri rispecchiano le nostre credenze iniziali su \\(\\theta\\), la distribuzione posteriori viene specificata dalla formula di Bayes:\\[\n\\text{distribuzione posteriori} = \\frac{\\text{verosimiglianza}\\cdot\\text{distribuzione priori}}{\\text{verosimiglianza marginale}}.\n\\]Nel caso presente abbiamo\\[\np(\\theta \\mid n=30, y=23) = \\frac{\\Big[\\binom{30}{23}\\theta^{23}(1-\\theta)^{30-23}\\Big]\\Big[\\frac{\\Gamma(12)}{\\Gamma(2)\\Gamma(10)}\\theta^{2-1} (1-\\theta)^{10-1}\\Big]}{p(y = 23)},\n\\]laddove \\(p(y = 23)\\), ovvero la verosimiglianza marginale, è una costante di normalizzazione.Riscriviamo l’equazione precedente termini più generali:\\[\np(\\theta \\mid n, y) = \\frac{\\Big[\\binom{n}{y}\\theta^{y}(1-\\theta)^{n-y}\\Big]\\Big[\\frac{\\Gamma(+b)}{\\Gamma()\\Gamma(b)}\\theta^{-1} (1-\\theta)^{b-1}\\Big]}{p(y)}\n\\]Raccogliendo tutte le costanti otteniamo:\\[\np(\\theta \\mid n, y) =\\left[\\frac{\\binom{n}{y}\\frac{\\Gamma(+b)}{\\Gamma()\\Gamma(b)}}{p(y)}\\right] \\theta^{y}(1-\\theta)^{n-y}\\theta^{-1} (1-\\theta)^{b-1}.\n\\]Se ignoriamo il termine costante ’interno della parentesi quadra\\[\\begin{align}\np(\\theta \\mid n, y) &\\propto \\theta^{y}(1-\\theta)^{n-y}\\theta^{-1} (1-\\theta)^{b-1},\\notag\\\\\n&\\propto \\theta^{+y-1}(1-\\theta)^{b+n-y-1},\\notag\n\\end{align}\\]il termine di destra dell’equazione precedente identifica il kernel della distribuzione posteriori e corrisponde ad una Beta non normalizzata di parametri \\(+ y\\) e \\(b + n - y\\).Per ottenere una distribuzione di densità, dobbiamo aggiungere una costante di normalizzazione al kernel della distribuzione posteriori. base alla definizione della distribuzione Beta, ed essendo \\(' = +y\\) e \\(b' = b+n-y\\), tale costante di normalizzazione sarà uguale \\[\n\\frac{\\Gamma('+b')}{\\Gamma(')\\Gamma(b')} = \\frac{\\Gamma(+b+n)}{\\Gamma(+y)\\Gamma(b+n-y)}.\n\\]altri termini, nel caso dello schema beta-binomiale, la distribuzione posteriori è una \\(\\mbox{Beta}(+y, b+n-y)\\):\\[\n\\mbox{Beta}(+y, b+n-y) = \\frac{\\Gamma(+b+n)}{\\Gamma(+y)\\Gamma(b+n-y)} \\theta^{+y-1}(1-\\theta)^{b+n-y-1}.\n\\]sintesi, moltiplicando verosimiglianza \\(\\mbox{Bin}(n = 30, y = 23 \\mid \\theta)\\) per la la distribuzione priori \\(\\theta \\sim \\mbox{Beta}(2, 10)\\) e dividendo per la costante di normalizzazione, abbiamo ottenuto la distribuzione posteriori \\(p(\\theta \\mid n, y) \\sim \\mbox{Beta}(25, 17)\\). Questo è un esempio di analisi coniugata. La presente combinazione di verosimiglianza e distribuzione priori è chiamata caso coniugato beta-binomiale ed è descritta dal seguente teorema.Teorema 16.1  Sia data la funzione di verosimiglianza \\(\\mbox{Bin}(n, y \\mid \\theta)\\) e sia \\(\\mbox{Beta}(\\alpha, \\beta)\\) una distribuzione priori. tali circostanze, la distribuzione posteriori del parametro \\(\\theta\\) sarà una distribuzione \\(\\mbox{Beta}(\\alpha + y, \\beta + n - y)\\).È facile calcolare il valore atteso posteriori di \\(\\theta\\). Essendo \\(\\E[\\mbox{Beta}(\\alpha, \\beta)] = \\frac{\\alpha}{\\alpha + \\beta}\\), il risultato cercato diventa\\[\\begin{equation}\n\\E_{\\text{post}} [\\mathrm{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta +n}.\n\\tag{16.1}\n\\end{equation}\\]Esercizio 16.1  Si rappresenti maniera grafica e si descriva forma numerica l’aggiornamento bayesiano beta-binomiale per dati di Zetsche, Bürkner, Renneberg (2019). Si assuma una distribuzione priori \\(\\mbox{Beta}(2, 10)\\).Per dati questione, l’aggiornamento bayesiano può essere rappresentato forma grafica usando la funzione plot_beta_binomial() del pacchetto bayesrules:Oppure, possiamo scrivere noi stessi una funzione, come ad esempio la funzione plot_beta_binom() riportata Appendice F. Mediante tale la funzione otteniamoUn sommario delle distribuzioni priori e posteriori può essere ottenuto, ad esempio, usando la funzione summarize_beta_binomial() del pacchetto bayesrules:Esercizio 16.2  Per dati di Zetsche, Bürkner, Renneberg (2019), si trovino la media, la moda, la deviazione standard della distribuzione posteriori di \\(\\theta\\). Si trovi inoltre l’intervallo di credibilità posteriori del 95% per il parametro \\(\\theta\\).Usando il Teorema 16.1, l’intervallo di credibilità posteriori del 95% per il parametro \\(\\theta\\) è:Usando la (16.1), la media della distribuzione posteriori èPer le proprietà della distribuzione Beta, la moda della distribuzione posteriori èe la deviazione standard della distribuzione priori èEsercizio 16.3  Si trovino parametri e le proprietà della distribuzione posteriori del parametro \\(\\theta\\) per dati dell’esempio relativo alla ricerca di Stanley Milgram discussa da Johnson, Ott, Dogucu (2022).Nel 1963, Stanley Milgram presentò una ricerca sulla propensione delle persone obbedire agli ordini di figure di autorità, anche quando tali ordini possono danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come “consist[ing] ordering naive subject administer electric shock victim. simulated shock generator used, 30 clearly marked voltage levels range 450 volts. instrument bears verbal designations range Slight Shock Danger: Severe Shock. responses victim, trained confederate experimenter, standardized. orders administer shocks given naive subject context `learning experiment’ ostensibly set study effects punishment memory. experiment proceeds naive subject commanded administer increasingly intense shocks victim, even point reaching level marked Danger: Severe Shock.”’insaputa del partecipante, gli shock elettrici erano falsi e l’attore stava solo fingendo di provare il dolore dello shock.Johnson, Ott, Dogucu (2022) fanno inferenza sui risultati dello studio di Milgram mediante il modello Beta-Binomiale. Il parametro di interesse è \\(\\theta\\), la probabiltà che una persona obbedisca ’autorità (questo caso, somministrando lo shock più severo), anche se ciò significa recare danno ad altri. Johnson, Ott, Dogucu (2022) ipotizzano che, prima di raccogliere dati, le credenze di Milgram relative \\(\\theta\\) possano essere rappresentate mediante una \\(\\mbox{Beta}(1, 10)\\). Sia \\(y = 26\\) il numero di soggetti che, sui 40 partecipanti allo studio, aveva accettato di infliggere lo shock più severo. Assumendo che ogni partecipante si comporti indipendentemente dagli altri, possiamo modellare la dipendenza di \\(y\\) da \\(\\theta\\) usando la distribuzione binomiale. Giungiamo dunque al seguente modello bayesiano Beta-Binomiale:\\[\\begin{align}\ny \\mid \\theta & \\sim \\mbox{Bin}(n = 40, \\theta) \\notag\\\\\n\\theta & \\sim \\text{Beta}(1, 10) \\; . \\notag\n\\end{align}\\]Usando le funzioni di bayesrules possiamo facilmente calcolare parametri e le proprietà della distribuzione posteriori:Il processo di aggiornamento bayesiano è descritto dalla figura seguente:","code":"\nbayesrules::plot_beta_binomial(\n  alpha = 2, beta = 10, y = 23, n = 30\n  ) \nplot_beta_bin(2, 10, 23, 30)\nbayesrules:::summarize_beta_binomial(\n  alpha = 2, beta = 10, y = 23, n = 30\n)\n#>       model alpha beta      mean mode         var        sd\n#> 1     prior     2   10 0.1666667  0.1 0.010683761 0.1033623\n#> 2 posterior    25   17 0.5952381  0.6 0.005603016 0.0748533\nqbeta(c(0.025, 0.975), shape1 = 25, shape2 = 17)\n#> [1] 0.4450478 0.7368320\n25 / (25 + 17)\n#> [1] 0.5952381\n(25 - 1) / (25 + 17 - 2)\n#> [1] 0.6\nsqrt((25 * 17) / ((25 + 17)^2 * (25 + 17 + 1)))\n#> [1] 0.0748533\nbayesrules:::summarize_beta_binomial(\n  alpha = 1, beta = 10, y = 26, n = 40\n)\n#>       model alpha beta       mean      mode         var         sd\n#> 1     prior     1   10 0.09090909 0.0000000 0.006887052 0.08298827\n#> 2 posterior    27   24 0.52941176 0.5306122 0.004791057 0.06921746\nplot_beta_bin(1, 10, 26, 40)"},{"path":"ch-distr-coniugate.html","id":"inferenza-bayesiana-con-distribuzioni-a-priori-continue","chapter":"Capitolo 16 Distribuzioni coniugate","heading":"16.2 Inferenza bayesiana con distribuzioni a priori continue","text":"L’inferenza bayesiane sulla proporzione \\(\\theta\\) si basa su vari riepiloghi della distribuzione posteriori Beta. Il riepilogo che si calcola dalla distribuzione posteriori dipende dal tipo di inferenza. Consideriamo qui su due tipi di inferenza: (1) problemi cui si è interessati valutare la plausibilità che il parametro assuma valori contenuti un dato intervallo di valori, (2) stime dell’intervallo che contiene il parametro ad un dato livello di probabilità soggettiva.","code":""},{"path":"ch-distr-coniugate.html","id":"approccio-bayesiano-alla-verifica-di-ipotesi","chapter":"Capitolo 16 Distribuzioni coniugate","heading":"16.2.1 Approccio bayesiano alla verifica di ipotesi","text":"Nell’esempio precedente sui dati di Zetsche, Bürkner, Renneberg (2019), la nostra credenza posteriori relativa \\(\\theta\\) (ovvero, la probabilità che l’aspettativa dell’umore futuro sia distorta negativamente) è descritta da una distribuzione Beta(25,17). Una volta definita la distribuzione posteriori, ci possiamo porre altre domande. Per esempio: qual è la probabilità che \\(\\theta\\) sia maggiore di 0.5?Una risposta questa domanda si trova conoppure, maniera equivalente, conQuesto calcolo può essere svolto mediante simulazione. Dato che conosciamo la distribuzione target, è possibile ricavare un campione casuale di osservazioni da una tale distribuzione e poi riassumere il campione modo da calcolare \\(\\theta > 0.5\\).Il risultato della simulazione è molto simile quello ottenuto precedenza.","code":"\n1 - pbeta(0.5, 25, 17)\n#> [1] 0.8944882\nProbBayes::beta_area(lo = 0.5, hi = 1.0, shape_par = c(25, 17))\nnsim <- 1e6\ntheta_samples <- rbeta(nsim, 25, 17)\nsum(theta_samples > 0.5) / nsim\n#> [1] 0.894317"},{"path":"ch-distr-coniugate.html","id":"intervalli-di-credibilità","chapter":"Capitolo 16 Distribuzioni coniugate","heading":"16.2.2 Intervalli di credibilità","text":"Un secondo tipo di inferenza bayesiana è quella che ci porta formulare gli intervalli di credibilità. Un intervallo di credibilità di ordine \\(\\[0, 1]\\) è l’intervallo di valori che contiene una proporzione della distribuzione posteriori pari ad \\(\\).La funzione ProbBayes::beta_interval() consente di calcolare l’intervallo di credibilità che lascia la stessa probabilità nelle due code. Per esempio, l’intervallo di credibilità ’89% per la distribuzione posteriori dell’esempio relativo ai dati di Zetsche, Bürkner, Renneberg (2019) èPer dati di Zetsche, Bürkner, Renneberg (2019), l’intervallo di credibilità ’50% per la distribuzione posteriori è","code":"\nProbBayes::beta_interval(0.89, c(25, 17))\nProbBayes::beta_interval(0.5, c(25, 17))"},{"path":"ch-distr-coniugate.html","id":"principali-distribuzioni-coniugate","chapter":"Capitolo 16 Distribuzioni coniugate","heading":"16.3 Principali distribuzioni coniugate","text":"Esistono molte altre combinazioni simili di verosimiglianza e distribuzione priori le quali producono una distribuzione posteriori che ha la stessa densità della distribuzione priori. Sono elencate qui sotto le più note coniugazioni tra modelli statistici e distribuzioni priori.Per il modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribizione iniziale è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione finale è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).Per il modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribizione iniziale è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione finale è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).Per il modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribizione iniziale è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione finale è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).Per il modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribizione iniziale è \\(\\mbox{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione finale è \\(\\mbox{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).","code":""},{"path":"ch-distr-coniugate.html","id":"commenti-e-considerazioni-finali-12","chapter":"Capitolo 16 Distribuzioni coniugate","heading":"Commenti e considerazioni finali","text":"Lo scopo di questa discussione è mostrare come sia possibile combinare le nostre conoscenze priori (espresse nei termini di una densità di probabilità) con le evidenze fornite dai dati (espresse nei termini della funzione di verosimiglianza), così da determinare, mediante il teorema di Bayes, una distribuzione posteriori, la quale condensa l’incertezza che abbiamo sul parametro \\(\\theta\\). Per illustrare tale problema, abbiamo considerato una situazione nella quale \\(\\theta\\) corrisponde alla probabilità di successo una sequenza di prove Bernoulliane. tali circostanze è ragionevole esprimere le nostre credenze priori mediante la densità Beta, con opportuni parametri. L’inferenza rispetto \\(\\theta\\) può essere svolta utilizzando una distribuzione priori Beta e una verosimiglianza binomiale. Così facendo, la distribuzione posteriori diventa essa stessa una distribuzione Beta – questo è il cosiddetto schema beta-binomiale. Dato che utilizza una distribuzione priori coniugata, lo schema beta-binomiale rende possibile la determinazione analitica dei parametri della distribuzione posteriori.","code":""},{"path":"ch-prior-influence.html","id":"ch-prior-influence","chapter":"Capitolo 17 L’influenza della distribuzione a priori","heading":"Capitolo 17 L’influenza della distribuzione a priori","text":"La notazione \\(p(\\theta \\mid y) \\propto p(\\theta) \\ p(y \\mid \\theta)\\) rende particolarmente chiaro che la distribuzione posteriori è un “miscuglio” della distribuzione priori e della verosimiglianza. Prima di preoccuparci di come calcolare la distribuzione posteriori, cerchiamo di capire meglio cosa significa “mescolare” la distribuzione priori e la verosimiglianza. Considereremo qui un esempio discusso da Johnson, Ott, Dogucu (2022).","code":""},{"path":"ch-prior-influence.html","id":"il-test-di-benchdel","chapter":"Capitolo 17 L’influenza della distribuzione a priori","heading":"17.1 Il test di Benchdel","text":"Nel fumetto di Alison Bechdel Rule, un personaggio afferma di guardare un film solo se soddisfa le seguenti tre regole (Bechdel 1986):almeno due caratteri nel film devono essere donne;queste due donne si parlano;parlano di qualcosa altro oltre parlare di qualche uomo.Questi criteri costituiscono il test di Bechdel per la rappresentazione delle donne nei film. Johnson, Ott, Dogucu (2022) pongono la seguente domanda “Quale percentuale dei film che avete visto supera il test di Bechdel?”.Sia \\(\\pi \\[0, 1]\\) una variabile casuale che indica la proporzione sconosciuta di film che superano il test di Bechdel. Tre amiche — la femminista, l’ignara e l’ottimista — hanno opionioni diverse su \\(\\pi\\). Riflettendo sui film che ha visto, la femminista capisce che nella maggioranza dei film mancano personaggi femminili forti. L’ignara non ricorda bene film che ha visto, quindi non sa quanti film superano il test di Bechdel. Infine, l’ottimista pensa che, generale, le donne sono ben rappresentate ’interno dei film: secondo lei quasi tutti film superano il test di Bechdel. Le tre amiche hanno dunque tre modelli priori diversi di \\(\\pi\\).Abbiamo visto precedenza come sia possibile usare la distribuzione Beta per rappresentare le credenze priori. Ponendo la gran parte della massa della probabilità priori su valori \\(\\pi < 0.5\\), la distribuzione priori \\(\\text{Beta}(5, 11)\\) riflette il punto di vista femminista secondo il quale la maggioranza dei film non supera il test di Bechdel. Al contrario, la \\(\\text{Beta}(14,1)\\) pone la gran parte della massa della distribuzione priori su valori \\(\\pi\\) prossimi 1, e corrisponde quindi alle credenze priori dell’amica ottimista. Infine, una \\(\\text{Beta}(1 ,1)\\) o \\(Unif(0, 1)\\), assegna lo stesso livello di plausibilità tutti valori \\(\\pi \\[0, 1]\\), e corrisponde ’incertezza priori dell’ignara.Nell’esempio di Johnson, Ott, Dogucu (2022), le tre amiche decidono di rivedere un campione di \\(n\\) film e di registrare \\(y\\), ovvero il numero di film che superano il test di Bechdel. Se \\(y\\) corrisponde al numero di “successi” un numero fisso di \\(n\\) prove Bernoulliane ..d., allora la dipendenza di \\(y\\) da \\(\\pi\\) viene specificata nei termini di un modello binomiale. Quindi, per ciascuna delle tre amiche è possibile scrivere un modello beta-binomiale\\[\\begin{align}\nY \\mid \\pi & \\sim \\mbox{Bin}(n, \\pi)  \\notag\\\\\n\\pi & \\sim \\mbox{Beta}(\\alpha, \\beta) \\notag\n\\end{align}\\]che utilizza diversi parametri \\(\\alpha\\) e \\(\\beta\\) per la distribuzione priori e che conduce tre diverse distribuzioni posteriori per il parametro sconosciuto \\(\\pi\\):\\[\\begin{equation}\n\\pi \\mid (Y = y) \\sim \\mbox{Beta}(\\alpha + y, \\beta + n - y).\n\\end{equation}\\]Johnson, Ott, Dogucu (2022) si chiedono come le credenze priori delle tre amiche influenzano le conclusioni posteriori cui esse giungono, dopo avere osservato dati. Si chiedono inoltre che modo la dimensione del campione moduli l’influenza della distribuzione priori sulla distribuzione posteriori. Per rispondere queste domande, Johnson, Ott, Dogucu (2022) consideriamo tre diversi scenari:gli stessi dati osservati, ma distribuzioni priori diverse;dati diversi, ma la stessa distribuzione priori;dati diversi e distribuzioni priori diverse.","code":""},{"path":"ch-prior-influence.html","id":"stessi-dati-ma-diverse-distribuzioni-a-priori","chapter":"Capitolo 17 L’influenza della distribuzione a priori","heading":"17.2 Stessi dati ma diverse distribuzioni a priori","text":"Iniziamo con lo scenario che descrive il caso cui abbiamo gli stessi dati ma diverse distribuzioni priori. Supponiamo che le tre amiche decidano di guardare insieme 20 film selezionati caso:\nDi questi 20 film, solo il 45% (\\(y\\) = 9) passa il test di Bechdel:Esaminiamo ora le tre distribuzioni posteriori. Per la femminista abbiamo:Per l’ottimista abbiamo:Infine, per l’ignara troviamoPer calcolare la distribuzione posteriori, ho qui usato le funzioni del pacchetto bayesrules. Ma per lo schema beta-binomiale è facile trovare parametri della distribuzione posteriori. Per esempio, nel caso dell’amica femminista, la distribuzione posteriori è una Beta di parametri\\[\n\\alpha_{post} = \\alpha_{prior} + y = 5+9 = 14\n\\]\ne\\[\n\\beta_{post} = \\beta_{prior} + n - y = 11 + 20 - 9 = 22.\n\\]L’aggiornamento bayesiano indica che le tre amiche ottengono valori per la media (o la moda) posteriori per \\(\\pi\\) molto diversi. Dunque, anche dopo avere visto 20 film, le tre amiche non si trovano d’accordo su quale sia la proporzione di film che passano il test di Bechdel.Questo non dovrebbe sorprenderci. L’amica ottimista aveva opinioni molto forti sul valore di \\(\\pi\\) e pochi nuovi dati che le sono stati forniti non sono riusciti convincerla cambiare idea: crede ancora che valori \\(\\pi > 0.5\\) siano più plausibili. Lo stesso si può dire, ’estremo opposto, dell’amica femminista: anche lei continua credere che valori \\(\\pi < =.5\\) siano più plausibili. Infine, l’ignara non aveva nessuna opinione priori su \\(\\pi\\) e, anche dopo avere visto 20 film, continua credere che il valore \\(\\pi\\) più plausibile sia quello intermedio, nell’intorno di 0.5.","code":"\ndata(bechdel, package = \"bayesrules\")\nset.seed(84735)\nbechdel_20 <- bechdel %>% \n  sample_n(20)\nbechdel_20 %>% \n  head(3)\n#> # A tibble: 3 × 3\n#>    year title      binary\n#>   <dbl> <chr>      <chr> \n#> 1  2005 King Kong  FAIL  \n#> 2  1983 Flashdance PASS  \n#> 3  2013 The Purge  FAIL\nbechdel_20 %>% \n  janitor::tabyl(binary) %>% \n  janitor::adorn_totals(\"row\")\n#>  binary  n percent\n#>    FAIL 11    0.55\n#>    PASS  9    0.45\n#>   Total 20    1.00\nbayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 9, n = 20\n  ) \nbayesrules:::summarize_beta_binomial(\n  alpha = 5, beta = 11, y = 9, n = 20\n)\n#>       model alpha beta      mean      mode        var         sd\n#> 1     prior     5   11 0.3125000 0.2857143 0.01263787 0.11241827\n#> 2 posterior    14   22 0.3888889 0.3823529 0.00642309 0.08014418\nbayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 9, n = 20\n) \nbayesrules:::summarize_beta_binomial(\n  alpha = 14, beta = 1, y = 9, n = 20\n)\n#>       model alpha beta      mean      mode         var         sd\n#> 1     prior    14    1 0.9333333 1.0000000 0.003888889 0.06236096\n#> 2 posterior    23   12 0.6571429 0.6666667 0.006258503 0.07911070\nbayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 9, n = 20\n)\nbayesrules:::summarize_beta_binomial(\n  alpha = 1, beta = 1, y = 9, n = 20\n)\n#>       model alpha beta      mean mode        var        sd\n#> 1     prior     1    1 0.5000000  NaN 0.08333333 0.2886751\n#> 2 posterior    10   12 0.4545455 0.45 0.01077973 0.1038255"},{"path":"ch-prior-influence.html","id":"dati-diversi-ma-la-stessa-distribuzione-a-priori","chapter":"Capitolo 17 L’influenza della distribuzione a priori","heading":"17.3 Dati diversi ma la stessa distribuzione a priori","text":"Supponiamo ora che l’amica ottimista abbia tre amiche, Maria, Anna e Sara, tutte ottimiste come lei. L’ottimista chiede Maria, Anna e Sara di fare loro stesse l’esperimento descritto precedenza. Maria guarda 13 film; di questi 6 passano il test di Bechdel. Anna guarda 63 film; di questi 29 passano il test di Bechdel. Sara guarda 99 film; di questi 46 passano il test di Bechdel.Supponiamo che Maria, Anna e Sara condividano la stessa credenza priori su \\(\\pi\\): ovvero, Beta(14, 1). tali circostanze e, alla luce dei dati osservati, cosa possiamo dire delle tre distribuzioni posteriori?\nFIGURA 17.1: Aggiornamento bayesiano per le credenze di Maria, Anna e Sara.\nNotiamo due cose. ’aumentare delle informazioni disponibili (ovvero, ’aumentare dell’ampiezza del campione), la distribuzione posteriori si allontana sempre di più dalla distribuzione priori, e si avvicina sempre di più alla verosimiglianza. secondo luogo, ’aumentare dell’ampiezza del campione la varianza della distribuzione posteriori diminuisce sempre di più — ovvero, diminuisce l’incertezza su quelli che sono valori \\(\\pi\\) più plausibili.","code":"\np1 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 6, n = 13\n  ) + \n  theme(legend.position = \"none\") \np2 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 29, n = 63\n  ) + \n  theme(legend.position = \"none\") \np3 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \np1 + p2 + p3"},{"path":"ch-prior-influence.html","id":"dati-diversi-e-diverse-distribuzioni-a-priori","chapter":"Capitolo 17 L’influenza della distribuzione a priori","heading":"17.4 Dati diversi e diverse distribuzioni a priori","text":"Nella figura successiva esaminiamo le distribuzioni posteriori che si ottengono incrociando tre diversi set di dati (\\(y\\) = 6, \\(n\\) = 13;, \\(y\\) = 29, \\(n\\) = 63; \\(y\\) = 66, \\(n\\) = 99) con tre diverse distribuzioni priori [Beta(14, 1), Beta(5, 11), Beta(1, 1)].\nFIGURA 17.2: Sulle colonne (partire da sinistra) dati utilizzati sono, rispettivamente, (y = 6, n = 13), (y = 29, n = 63) e (y = 66, n = 99). Sulle righe (partire dall’alto), le distribuzioni priori usate sono: Beta(14, 1), Beta(5, 11) e Beta(1, 1).\nLa figura indica che, se il campione è grande, una distribuzione priori debolmente informativa ha uno scarso effetto sulla distribuzione posteriori. Invece, se il campione è piccolo, anche una distribuzione priori debolmente informativa ha un grande effetto sulla distribuzione posteriori.","code":"\np1 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 6, n = 13\n  ) +\n  theme(legend.position = \"none\") \np2 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 29, n = 63\n  ) +\n  theme(legend.position = \"none\") \np3 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \np4 <- bayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 6, n = 13\n  ) +\n  theme(legend.position = \"none\") \np5 <- bayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 29, n = 63\n  ) +\n  theme(legend.position = \"none\") \np6 <- bayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \np7 <- bayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 6, n = 13\n  ) +\n  theme(legend.position = \"none\") \np8 <- bayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 29, n = 63\n  ) +\n  theme(legend.position = \"none\") \np9 <- bayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \n(p1 + p2 + p3) / (p4 + p5 + p6) / (p7 + p8 + p9)"},{"path":"ch-prior-influence.html","id":"collegare-le-intuizioni-alla-teoria","chapter":"Capitolo 17 L’influenza della distribuzione a priori","heading":"17.5 Collegare le intuizioni alla teoria","text":"Il compromesso che abbiamo osservato nell’esempio precedente, che combina la distribuzione priori con le evidenze fornite dai dati, è molto vicino alle nostre intuizioni. Ma è anche il frutto di una necessità matematica. È infatti possibile riscrivere la (16.1) nel modo seguente\\[\\begin{align}\n\\E_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta +n}\\notag\\\\\n&= \\frac{+b}{+b+n} \\cdot \\frac{}{+b} + \\frac{n}{+b+n} \\cdot \\frac{y}{n}.\n\\tag{17.1}\n\\end{align}\\]Ciò indica che il valore atteso posteriori è una media pesata fra il valore atteso priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la frequenze di successi osservata \\(\\left(\\frac{y}{n}\\right)\\). pesi sono \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Quindi, quando \\(n\\) è grande rispetto ad \\(\\alpha + \\beta\\), conta molto quanto abbiamo osservato e conta poco la credenza priori. Viceversa, quando \\(n\\) è piccolo rispetto \\(\\alpha + \\beta\\), le osservazioni contano poco rispetto alla credenza priori.Queste osservazioni ci fanno capire come scegliere parametri \\(\\alpha\\) e \\(\\beta\\): se vogliamo assumere una totale ignoranza rispetto al fenomeno esame, la scelta coerente è \\(\\alpha = \\beta = 1\\) (ogni valore di \\(\\theta\\) è ugualmente probabile); se invece abbiamo delle credenze priori, allora possiamo scegliere \\(\\alpha\\) così che sia uguale al valore atteso priori, mentre \\(\\alpha + \\beta\\) esprime l’importanza che diamo ’informazione priori: maggiore è il valore di \\(\\alpha + \\beta\\), tanti più dati serviranno per allontanare la distribuzione posteriori dalla distribuzione priori. Se \\(n\\) è grande, infine, la distribuzione posteriori sarà scarsamente influenzata dalla distribuzione priori, meno di scelte estreme.","code":""},{"path":"ch-prior-influence.html","id":"commenti-e-considerazioni-finali-13","chapter":"Capitolo 17 L’influenza della distribuzione a priori","heading":"Commenti e considerazioni finali","text":"La conclusione che possiamo trarre dall’esempio di Johnson, Ott, Dogucu (2022) è molto chiara: l’aggiornamento bayesiano può essere paragonato ai processi di ragionamento del senso comune. Quando le nuove evidenze (dati) sono deboli, non c’è ragione di cambiare idea (le nostre credenze “posteriori” sono molto simili ciò che pensavamo prima di avere osservato dati). Quando le nuove evidenze sono irrefutabili, invece, è necessario modificare le nostre credenze sulla base di ciò che ci dicono dati, quali che siano le nostre credenze pregresse — non farlo significherebbe vivere un mondo di fantasia e avere scarse possibilità di sopravvivere nel mondo empirico. L’aggiornamento bayesiano esprime maniera quantitativa e precisa ciò che ci dicono le nostre intuizioni.Incredibilmente, però, l’approccio frequentista nega questa logica. test frequentisti non tengono conto delle conoscenze pregresse. Dunque, se un test frequentista, calcolato su un piccolo campione (ovvero, quando dati sono molto deboli), suggerisce che dovremmo farci un’opinione di un certo tipo sul fenomeno esame, l’indicazione è di prendere seriamente il risultato del test quali siano le evidenze precedenti — le quali, possibilmente, mostrano che il risultato del test non ha alcun senso. È sorprendente che un tale modo di pensare possa essere preso sul serio nella comunità scientifica, ma vi sono alcuni ricercatori che continuano seguire questo modo di (s)ragionare. Dato che questo Capitolo paliamo di fumetti, concluderei dicendo che la presente discussione è catturata nella maniera più chiara possibile questa famosa striscia.","code":""},{"path":"ch-post-approx.html","id":"ch-post-approx","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"Capitolo 18 Approssimazione della distribuzione a posteriori","text":"generale, un problema bayesiano dati \\(y\\) provengono da una densità \\(p(y \\mid \\theta)\\) e al parametro \\(\\theta\\) viene assegnata una densità priori \\(p(\\theta)\\). Dopo avere osservato dati \\(Y = y\\), la funzione di verosimiglianza è uguale \\(\\mathcal{L}(\\theta) = p(y \\mid \\theta)\\) e la densità posteriori diventa\\[\\begin{equation}\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\! \\theta}. \\notag\n\\end{equation}\\]Se vogliamo trovare la distribuzione posteriori con metodi analitici è necessario ricorrere ’impiego di distribuzioni priori coniugate, come nello schema beta-binomiale. Per quanto “semplice” termini formali, la scelta di distribuzioni priori coniugate limita di molto le possibili scelte del ricercatore. Inoltre, non è sempre sensato, dal punto di vista teorico, utilizzare tali distribuzioni per la stima dei parametri di interesse. Il mancato ricorso ’impiego delle distribuzioni priori coniugate richiede necessariamente il computo dell’espressione denominatore della formula di Bayes che solo rare occasioni può essere ottenuta per via analitica. altre parole, è possibile ottenere analiticamenre la distribuzione posteriori solo per alcune specifiche combinazioni di distribuzioni priori e verosimiglianza, il che limita considerevolmente la flessibilità della modellizzazione. Inoltre, sommari della distribuzione posteriori sono espressi come rapporto di integrali. Ad esempio, la media posteriori di \\(\\theta\\) è data da\\[\\begin{equation}\n\\mathbb{E}(\\theta \\mid y) = \\frac{\\int \\theta p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\! \\theta}{\\int p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\! \\theta}.\\notag\n\\end{equation}\\]Il calcolo del valore atteso posteriori richiede dunque il computo di due integrali, quello denominatore e quello numeratore dell’espressione, ciascuno dei quali non esprimibile forma chiusa. Per questa ragione, la strada principale che viene seguita nella modellistica bayesiana è quella che porta determinare la distribuzione posteriori non per via analitica, ma bensì mediante metodi numerici. La simulazione fornisce dunque la strategia generale del calcolo bayesiano. questo fine vengono principalmente usati metodi di campionamento Monte Carlo basati su Catena di Markov (MCMC). Tali metodi costituiscono una potente e praticabile alternativa per la costruzione della distribuzione posteriori per modelli complessi e consentono di decidere quali distribuzioni priori e quali distribuzioni di verosimiglianza usare sulla base di considerazioni teoriche soltanto, senza dovere preoccuparsi di altri vincoli.Dato che è basata su metodi computazionalmente intensivi, la stima numerica della funzione posteriori può essere svolta soltanto mediante software. anni recenti metodi Bayesiani di analisi dei dati sono diventati sempre più popolari proprio perché la potenza di calcolo necessaria per svolgere tali calcoli è ora alla portata di tutti. Questo non era vero solo pochi decenni fa.questo Capitolo verranno presentati due metodi di simulazione iterativa13 che consentono di generare dalle distribuzioni posteriori campioni dei parametri del modello:metodi basati su griglia: dove, sebbene non sia disponibile alcuna formula algebrica forma chiusa, le proprietà della distribuzione posteriori possono essere calcolate con una precisione arbitraria;metodi Monte Carlo: dove, utilizzando appropriate funzioni di numeri casuali, viene generato un ampio campione di casi della variabile casuale per poi stimare empiricamente la proprietà di interesse base al campione così otttenuto.","code":""},{"path":"ch-post-approx.html","id":"metodo-basato-su-griglia","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.1 Metodo basato su griglia","text":"Il metodo basato su griglia (grid-based) è un metodo numerico esatto basato su una griglia di punti uniformemente spaziati. Anche se la maggior parte dei parametri è continua (ovvero, linea di principio ciascun parametro può assumere un numero infinito di valori), possiamo ottenere un’eccellente approssimazione della distribuzione posteriori considerando solo una griglia finita di valori dei parametri. un tale metodo, la densità di probabilità posteriori può dunque essere approssimata tramite le densità di probabilità calcolate ciascuna cella della griglia.Il metodo basato su griglia si sviluppa quattro fasi:fissare una griglia discreta di possibili valori \\(\\theta\\);valutare la distribuzione priori \\(p(\\theta)\\) e la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) corrispondenza di ciascun valore \\(\\theta\\) della griglia;ottenere un’approssimazione discreta della densità posteriori:\nper ciascun valore \\(\\theta\\) della griglia, calcolare il prodotto \\(p(\\theta) p(y \\mid \\theta)\\);\nnormalizzare prodotti così ottenuti modo tale che la loro somma sia 1;\nper ciascun valore \\(\\theta\\) della griglia, calcolare il prodotto \\(p(\\theta) p(y \\mid \\theta)\\);normalizzare prodotti così ottenuti modo tale che la loro somma sia 1;selezionare \\(N\\) valori casuali della griglia modo tale da ottenere un campione casuale delle densità posteriori normalizzate.Possiamo migliorare l’approssimazione aumentando il numero di punti della griglia. Infatti utilizzando un numero infinito di punti si otterrebbe la descrizione esatta della distribuzione posteriori, dovendo però pagare il costo dell’utilizzo di infinite risorse di calcolo. Il limite maggiore dell’approccio basato su griglia è che, al crescere della dimensionalità \\(N\\) dello spazio dei parametri, punti della griglia necessari per avere una buona stima crescerebbero esponenzialmente con \\(N\\), rendendo questo metodo inattuabile.","code":""},{"path":"ch-post-approx.html","id":"modello-beta-binomiale","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.1.1 Modello Beta-Binomiale","text":"Per fare un esempio, consideriamo lo schema beta-binomiale di cui conosciamo la soluzione esatta. Utilizziamo nuovamente dati di Zetsche, Bürkner, Renneberg (2019): 23 “successi” 30 prove Bernoulliane indipendenti.14 Imponiamo alla distribuzione priori su \\(\\theta\\) (probabilità di successo una singola prova, laddove per “successo” si intende una aspettativa distorta negativamente dell’umore futuro) una \\(\\mbox{Beta}(2, 10)\\) per descrivere la nostra incertezza sul parametro prima di avere osservato dati. Dunque, il modello diventa:\\[\\begin{align}\nY \\mid \\theta & \\sim \\mbox{Bin}(n = 30, \\theta), \\notag\\\\\n\\theta & \\sim \\mbox{Beta}(2, 10).\\notag\n\\end{align}\\]queste circostanze, l’aggiornamento bayesiano produce una distribuzione posteriori Beta di parametri 25 (\\(y + \\alpha\\) = 23 + 2) e 17 (\\(n - y + \\beta\\) = 30 - 23 + 10):\\[\\begin{equation}\n\\theta \\mid (y = 23) \\sim \\mbox{Beta}(25, 17).\\notag\n\\end{equation}\\]Per approssimare la distribuzione posteriori, fissiamo una griglia di \\(n = 11\\) valori equispaziati: \\(\\theta \\\\{0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1\\}\\):corrispondenza di ciascun valore della griglia, valutiamo la distribuzione priori \\(\\mbox{Beta}(2, 10)\\) e la verosimiglianza \\(\\mbox{Bin}(y = 23, n = 30)\\).ciascuna cella della griglia calcoliamo poi il prodotto della verosimiglianza e della distribuzione priori. Troviamo così un’approssimazione discreta e non normalizzata della distribuzione posteriori (unnormalized). Normalizziamo questa approssimazione dividendo ciascun valore unnormalized per la somma di tutti valori del vettore:Verifichiamo:Abbiamo dunque ottenuto la seguente distribuzione posteriori discretizzata \\(p(\\theta \\mid y)\\):La figura 18.1 mostra un grafico della distribuzione posteriori discretizzata così ottenuta:\nFIGURA 18.1: Distribuzione posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi 30 prove Bernoulliane, con distribuzione priori \\(\\mbox{Beta}(2, 10)\\). È stata utilizzata una griglia di solo \\(n\\) = 11 punti.\nL’ultimo passo della simulazione è il campionamento dalla distribuzione posteriori discretizzata:La figura 18.2 mostra che, con una griglia così sparsa abbiamo ottenuto una versione approssimata della vera distribuzione posteriori (’istogramma è stata sovrapposta l’esatta distribuzione posteriori \\(\\mbox{Beta}(25, 17)\\)).\nFIGURA 18.2: Campionamento dalla distribuzione posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi 30 prove Bernoulliane, con distribuzione priori \\(\\mbox{Beta}(2, 10)\\). È stata utilizzata una griglia di solo \\(n\\) = 11 punti.\nPossiamo ottenere un risultato migliore con una griglia più fine, come indicato nella figura 18.3:\nFIGURA 18.3: Distribuzione posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi 30 prove Bernoulliane, con distribuzione priori \\(\\mbox{Beta}(2, 10)\\). È stata utilizzata una griglia di \\(n\\) = 100 punti.\nCampioniamo ora 10000 punti:Con il campionamento dalla distribuzione posteriori discretizzata costruita mediante una griglia più densa (\\(n = 100\\)) otteniamo un risultato soddisfacente (figura 18.4): ora la distribuzione dei valori prodotti dalla simulazione approssima molto bene la corretta distribuzione posteriori \\(p(\\theta \\mid y) = \\mbox{Beta}(25, 17)\\).\nFIGURA 18.4: Campionamento dalla distribuzione posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi 30 prove Bernoulliane, con distribuzione priori \\(\\mbox{Beta}(2, 10)\\). È stata utilizzata una griglia di \\(n\\) = 100 punti. ’istogramma è stata sovrapposta la corretta distribuzione posteriori, ovvero la densità \\(\\mbox{Beta}(25, 17)\\).\nconclusione, il metodo basato su griglia è molto intuitivo e non richiede particolari competenze di programmazione per essere implementato. Inoltre, fornisce un risultato che, per tutti gli scopi pratici, può essere considerato come un campione casuale estratto da \\(p(\\theta \\mid y)\\). Tuttavia, anche se tale metodo fornisce risultati accuratissimi, esso ha un uso limitato. causa della maledizione della dimensionalità15, tale metodo può solo essere solo nel caso di semplici modelli statistici, con non più di due parametri. Nella pratica concreta tale metodo viene dunque sostituito da altre tecniche più efficienti quanto, anche nei più comuni modelli utilizzati psicologia, vengono solitamente stimati centinaia se non migliaia di parametri.","code":"\ngrid_data <- tibble(\n  theta_grid = seq(from = 0, to = 1, length.out = 11)\n)\ngrid_data\n#> # A tibble: 11 × 1\n#>   theta_grid\n#>        <dbl>\n#> 1        0  \n#> 2        0.1\n#> 3        0.2\n#> 4        0.3\n#> 5        0.4\n#> 6        0.5\n#> 7        0.6\n#> 8        0.7\n#> # … with 3 more rows\ngrid_data <- grid_data %>%\n  mutate(\n    prior = dbeta(theta_grid, 2, 10),\n    likelihood = dbinom(23, 30, theta_grid)\n  )\ngrid_data <- grid_data %>%\n  mutate(\n    unnormalized = likelihood * prior,\n    posterior = unnormalized / sum(unnormalized)\n  )\ngrid_data %>%\n  summarize(\n    sum(unnormalized),\n    sum(posterior)\n  )\n#> # A tibble: 1 × 2\n#>   `sum(unnormalized)` `sum(posterior)`\n#>                 <dbl>            <dbl>\n#> 1            0.000869                1\nround(grid_data, 2)\n#> # A tibble: 11 × 5\n#>   theta_grid prior likelihood unnormalized posterior\n#>        <dbl> <dbl>      <dbl>        <dbl>     <dbl>\n#> 1        0    0          0               0      0   \n#> 2        0.1  4.26       0               0      0   \n#> 3        0.2  2.95       0               0      0   \n#> 4        0.3  1.33       0               0      0   \n#> 5        0.4  0.44       0               0      0.02\n#> 6        0.5  0.11       0               0      0.23\n#> 7        0.6  0.02       0.03            0      0.52\n#> 8        0.7  0          0.12            0      0.21\n#> # … with 3 more rows\ngrid_data %>% \n  ggplot(\n    aes(x = theta_grid, y = posterior)\n  ) +\n  geom_point() +\n  geom_segment(\n    aes(\n      x = theta_grid, \n      xend = theta_grid, \n      y = 0, \n      yend = posterior)\n  )\nset.seed(84735)\npost_sample <- sample_n(\n  grid_data,\n  size = 1e5,\n  weight = posterior,\n  replace = TRUE\n)\nggplot(post_sample, aes(x = theta_grid)) +\n  geom_histogram(aes(y = ..density..), color = \"white\") +\n  stat_function(fun = dbeta, args = list(25, 17)) +\n  lims(x = c(0, 1))\ngrid_data <- tibble(\n  theta_grid = seq(from = 0, to = 1, length.out = 100)\n)\ngrid_data <- grid_data %>%\n  mutate(\n    prior = dbeta(theta_grid, 2, 10),\n    likelihood = dbinom(23, 30, theta_grid)\n  )\ngrid_data <- grid_data %>%\n  mutate(\n    unnormalized = likelihood * prior,\n    posterior = unnormalized / sum(unnormalized)\n  )\ngrid_data %>%\n  ggplot(\n    aes(x = theta_grid, y = posterior)\n  ) +\n  geom_point() +\n  geom_segment(\n    aes(\n      x = theta_grid,\n      xend = theta_grid,\n      y = 0,\n      yend = posterior\n    )\n  )\n# Set the seed\nset.seed(84735)\npost_sample <- sample_n(\n  grid_data,\n  size = 1e4,\n  weight = posterior,\n  replace = TRUE\n)\npost_sample %>%\n  ggplot(aes(x = theta_grid)) +\n  geom_histogram(\n    aes(y = ..density..),\n    color = \"white\",\n    bins=50\n  ) +\n  stat_function(fun = dbeta, args = list(25, 17)) +\n  lims(x = c(0, 1))"},{"path":"ch-post-approx.html","id":"chapter-simulazioneMC","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2 Metodo Monte Carlo","text":"metodi più ampiamente adottati nell’analisi bayesiana per la costruzione della distribuzione posteriori per modelli complessi sono metodi di campionamento MCMC. Tali metodi consentono al ricercatore di decidere quali distribuzioni priori e quali distribuzioni di verosimiglianza usare sulla base di considerazioni teoriche soltanto, senza doversi preoccupare di altri vincoli. Dato che è basata su metodi computazionalmente intensivi, la stima numerica MCMC della funzione posteriori può essere svolta soltanto mediante software. anni recenti metodi Bayesiani di analisi dei dati sono diventati sempre più popolari proprio perché la potenza di calcolo necessaria per svolgere tali calcoli è ora alla portata di tutti. Questo non era vero solo pochi decenni fa.","code":""},{"path":"ch-post-approx.html","id":"integration-mc","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.1 Integrazione di Monte Carlo","text":"Il termine Monte Carlo si riferisce al fatto che la computazione fa ricorso ad un ripetuto campionamento casuale attraverso la generazione di sequenze di numeri casuali. Una delle sue applicazioni più potenti è il calcolo degli integrali mediante simulazione numerica. Supponiamo di essere grado di estrarre campioni casuali dalla distribuzione continua \\(p(\\theta \\mid y)\\) di media \\(\\mu\\). Se possiamo ottenere una sequenza di realizzazioni indipendenti\\[\n\\theta^{(1)}, \\theta^{(2)},\\dots, \\theta^{(T)} \\overset{\\text{iid}}{\\sim} p(\\theta \\mid y)\n\\]allora diventa possibile calcolare\\[\n\\mathbb{E}(\\theta \\mid y) = \\int \\theta p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta \\approx \\frac{1}{T} \\sum_{=1}^T \\theta^{(t)}.\n\\]altre parole, l’aspettazione teorica di \\(\\theta\\) può essere approssimata dalla media campionaria di un insieme di realizzazioni indipendenti ricavate da \\(p(\\theta \\mid y)\\). Per la Legge Forte dei Grandi Numeri, l’approssimazione diventa arbitrariamente esatta per \\(T \\rightarrow \\infty\\).16Quello che è stato detto sopra non è altro che un modo sofisticato per dire che, se vogliamo calcolare un’approssimazione del valore atteso di una variabile casuale, non dobbiamo fare altro che la media aritmetica di un grande numero di realizzazioni indipendenti della variabile casuale. Come è facile intuire, l’approssimazione migliora al crescere del numero di dati che abbiamo disposizione.Un’altra importante funzione di \\(\\theta\\) è la funzione indicatore, \\((l < \\theta < u)\\), che assume valore 1 se \\(\\theta\\) giace nell’intervallo \\((l, u)\\) e 0 altrimenti. Il valore di aspettazione di \\((l < \\theta < u)\\) rispetto \\(p(\\theta)\\) dà la probabilità che \\(\\theta\\) rientri nell’intervallo specificato, \\(Pr(l < \\theta < u)\\), e può essere approssimato usando l’integrazione Monte Carlo, ovvero prendendo la media campionaria del valore della funzione indicatore per ogni realizzazione \\(\\theta^{(t)}\\). È semplice vedere come\\[\nPr(l < \\theta < u) \\approx \\frac{\\text{numero di realizzazioni } \\theta^{(t)} \\(l, u)}{T}.\n\\]Presentiamo qui l’integrazione di Monte Carlo perché, nell’analisi bayesiana, il metodo Monte Carlo viene usato per ottenere un’approssimazione della distribuzione posteriori, quando tale distribuzione non può essere calcolata con metodi analitici. altre parole, il metodo Monte Carlo consente di ottenere un gran numero di valori \\(\\theta\\) che, nelle circostanze ideali, avrà una distribuzione identica alla distribuzione posteriori \\(p(\\theta \\mid y)\\).","code":""},{"path":"ch-post-approx.html","id":"descrizione-intuitiva","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.2 Descrizione intuitiva","text":"Se la funzione di densità \\(p(\\theta \\mid y)\\) è conosciuta, è facile ottenere una sequenza di realizzazioni iid della variabile casuale, per esempio, usando \\(\\textsf{R}\\). Ma ora supponiamo di non conoscere \\(p(\\theta \\mid y)\\). Quello che vogliamo fare è ottenere comunque una sequenza di valori \\(\\theta\\). Anche se tali valori non saranno iid, per qualunque coppia di valori \\(\\theta_a\\) e \\(\\theta_b\\) nella sequenza vogliamo che sia soddisfatto il seguente vincolo:\\[\n\\frac{\\#\\theta'\\text{ nella sequenza} = \\theta_a}{\\#\\theta'\\text{ nella sequenza} = \\theta_b} \\approx \\frac{p(\\theta_a \\mid y)}{p(\\theta_b \\mid y)}.\n\\]L’algoritmo di Metropolis ci consente di ottenere una tale sequenza di valori, la cui distribuzione sarà dunque uguale \\(p(\\theta \\mid y)\\). forma intuitiva, l’algoritmo di Metropolis può essere descritto come indicato di seguito.Data una sequenza di valori \\(\\{\\theta^{(1)}, \\theta^{(2)},\\dots, \\theta^{(t)}\\}\\), ci poniamo il problema di aggiungere un nuovo valore \\(\\theta^{t+1}\\) alla sequenza.Data una sequenza di valori \\(\\{\\theta^{(1)}, \\theta^{(2)},\\dots, \\theta^{(t)}\\}\\), ci poniamo il problema di aggiungere un nuovo valore \\(\\theta^{t+1}\\) alla sequenza.Consideriamo un valore \\(\\theta^*\\) simile \\(\\theta^{(t)}\\); ci chiediamo se dobbiamo inserire un tale valore nella sequenza oppure .Consideriamo un valore \\(\\theta^*\\) simile \\(\\theta^{(t)}\\); ci chiediamo se dobbiamo inserire un tale valore nella sequenza oppure .Se \\(p(\\theta^* \\mid y) > p(\\theta^{(t)} \\mid y)\\), allora sicuramente lo dobbiamo aggiungere alla sequenza perché, nella sequenza, il numero di valori \\(\\theta^*\\) deve essere maggiore del numero dei valori \\(\\theta^{(t)}\\).Se \\(p(\\theta^* \\mid y) > p(\\theta^{(t)} \\mid y)\\), allora sicuramente lo dobbiamo aggiungere alla sequenza perché, nella sequenza, il numero di valori \\(\\theta^*\\) deve essere maggiore del numero dei valori \\(\\theta^{(t)}\\).Se invece \\(p(\\theta^* \\mid y) < p(\\theta^{(t)} \\mid y)\\), allora non dobbiamo necessariamente aggiungere \\(\\theta^*\\) alla sequenza.Se invece \\(p(\\theta^* \\mid y) < p(\\theta^{(t)} \\mid y)\\), allora non dobbiamo necessariamente aggiungere \\(\\theta^*\\) alla sequenza.La decisione di aggiungere o \\(\\theta^*\\) alla sequenza dipenderà dal confronto tra \\(p(\\theta^* \\mid y)\\) e \\(p(\\theta^{(t)} \\mid y)\\).La decisione di aggiungere o \\(\\theta^*\\) alla sequenza dipenderà dal confronto tra \\(p(\\theta^* \\mid y)\\) e \\(p(\\theta^{(t)} \\mid y)\\).Calcoliamo il rapportoCalcoliamo il rapporto\\[\n  r = \\frac{p(\\theta^* \\mid y)}{p(\\theta^{(t)} \\mid y)} = \\frac{p(y \\mid \\theta^*) p(\\theta^*)}{p(y \\mid p(\\theta^{(t)}) p(p(\\theta^{(t)})}.\n\\]Se \\(r > 1\\), accettiamo \\(\\theta^*\\) e lo aggiungiamo alla sequenza: \\(\\theta^{(t+1)} = \\theta^*\\), quanto \\(\\theta^{(t)}\\) è già presente nella sequenza e \\(\\theta^*\\) ha una probabilità maggiore di \\(\\theta^{(t)}\\).Se \\(r < 1\\), per ciasuna istanza di \\(\\theta^{(t)}\\), accettiamo \\(\\theta^*\\) solo una frazione di volte uguale \\[\n\\frac{p(\\theta^* \\mid y)}{p(\\theta^{(t)} \\mid y)}\n\\]quanto la frequenza relativa dei valori \\(\\theta^{(t)}\\) e \\(\\theta^*\\) nella sequenza deve essere uguale al rapporto precedente. Per ottenere questo risultato, poniamo \\(\\theta^{(t+1)}\\) uguale \\(\\theta^*\\) o \\(\\theta^{(t)}\\) con probabilità rispettivamente uguali \\(r\\) o \\(1 - r\\).Questa è l’intuizione che sta alla base dell’algoritmo di Metropolis et al. (1953).","code":""},{"path":"ch-post-approx.html","id":"unapplicazione-empirica-3","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.3 Un’applicazione empirica","text":"Poniamoci ora il problema di usare l’algoritmo di Metropolis per calcolare la distribuzione posteriori di una proporzione \\(\\theta\\). Usiamo nuovamente dati di Zetsche, Bürkner, Renneberg (2019) (ovvero, 23 “successi” 30 prove Bernoulliane) e, per rendere il problema più interessante, assumiamo per \\(\\theta\\) una distribuzione priori \\(\\mbox{Beta}(2, 10)\\). Sappiamo che, tali circostanze, la distribuzione posteriori può essere ottenuta analiticamente tramite lo schema beta-binomiale ed è una \\(\\mbox{Beta}(25, 17)\\). Se vogliamo il valore della media posteriori di \\(\\theta\\), il risultato esatto è dunque\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 17} \\approx 0.5952.\n\\]È anche possibile ottenere il valore della media posteriori per via numerica. Sapendo che la distribuzione posteriori è una \\(\\mbox{Beta}(25, 17)\\), possiamo estrarre un campione di osservazioni da una tale distribuzione e calcolare la media. Con poche osservazioni (diciamo 10) otteniamo un risultato molto approssimatoma, per la legge dei grandi numeri, l’approssimazione migliora ’aumentare del numero di osservazioni:Lo stesso si può dire delle altre statistiche descrittive: moda, varianza, eccetera. Nel presente esempio, la simulazione Monte Carlo produce il risultato desiderato perchésappiamo che la distribuzione posteriori è una \\(\\mbox{Beta}(25, 17)\\),è possibile usare le funzioni \\(\\textsf{R}\\) per estrarre campioni casuali da una tale distribuzione.Tuttavia, capita raramente di usare una distribuzione priori coniugata alla verosimiglianza. Quindi, generale, le due condizioni descritte sopra non si applicano. Ad esempio, nel caso di una verosimiglianza binomiale e di una distribuzione priori gaussiana, la distribuzione posteriori di \\(\\theta\\) è\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}.\n\\]Una tale distribuzione non è implementata \\(\\textsf{R}\\) e dunque non possiamo ottenere dei campioni casuali da una tale distribuzione.tali circostanze, però, è ancora possibile ottenere ottenere un campione causale dalla distribuzione posteriori un altro modo. Questo risultato si ottiene utilizzando metodi Monte Carlo basati su Catena di Markov (MCMC). metodi MCMC, di cui l’algoritmo di Metropolis è un caso particolare e ne rappresenta il primo esempio, sono una classe di algoritmi che consentono di ottenere campioni casuali da una distribuzione posteriori senza dovere conoscere la rappresentazione analitica di una tale distribuzione.17 Le tecniche MCMC sono il metodo computazionale maggiormente usato per risolvere problemi dell’inferenza bayesiana.","code":"\nset.seed(84735)\nprint(mean(rbeta(1e2, shape1 = 25, shape2 = 17)), 6)\n#> [1] 0.584251\nprint(mean(rbeta(1e4, shape1 = 25, shape2 = 17)), 6)\n#> [1] 0.595492\nprint(mean(rbeta(1e6, shape1 = 25, shape2 = 17)), 6)\n#> [1] 0.595192"},{"path":"ch-post-approx.html","id":"una-passeggiata-casuale-sui-numeri-naturali","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.4 Una passeggiata casuale sui numeri naturali","text":"Prima di applicare l’algoritmo di Metropolis ai dati di Zetsche, Bürkner, Renneberg (2019), consideriamo un caso più semplice. questo esempio preliminare useremo l’algoritmo di Metropolis per ottenere un campione casuale da una distribuzione di massa di probabilità; esamineremo il caso continuo seguito.18Definiamo la distribuzione di probabilità discreta della variabile casuale \\(X\\) che assume valori nell’insieme dei numeri naturali \\(1, 2, \\dots, K\\). Scriviamo \\(\\textsf{R}\\) la funzione pd() che assegna \\(X = \\{1, 2, \\dots, 8\\}\\) valori di probabilità proporzionali agli interi 5, 10, 4, 4, 20, 20, 12 e 5:La figura 18.5 illustra la distribuzione di massa di probabilità che è stata generata questo modo.\nFIGURA 18.5: Distribuzione di massa di probabilità della variabile casuale discreta \\(X\\) avente supporto \\(\\{1, 2, ..., 8\\}\\).\nPer dati di questo esempio, l’algoritmo di Metropolis corrisponde alla seguente passeggiata aleatoria.19L’algoritmo inizia con un valore iniziale qualsiasi da 1 \\(K=8\\) della variabile casuale.Per simulare il valore successivo della sequenza, lanciamo una moneta equilibrata. Se esce testa, consideriamo come valore candidato il valore immediatamente precedente al valore corrente nella sequenza; se esce croce, il candidato è il valore nella sequenza immediatamente successivo quello corrente.Si calcola il rapporto \\(r\\) tra la probabilità del valore candidato e la probabilità del valore corrente:\\[\nr = \\frac{pd(\\text{valore candidato})}{pd(\\text{valore corrente})}.\n\\]Si estrae un numero caso \\(\\[0, 1]\\). Se tale valore è minore di \\(r\\) si accetta il valore candidato come valore successivo della catena markoviana; altrimenti il valore successivo della catena rimane il valore corrente.termini tecnici (si veda l’Appendice H), passi da 1 4 definiscono una catena di Markov irriducibile e aperiodica sui valori di stato \\(\\{1, 2,\\dots, 8\\}\\), dove il passo 1 fornisce il valore iniziale della catena e passi da 2 4 definiscono la matrice di transizione \\(P\\). Il campionamento dalla distribuzione di massa pd corrisponde ad una passeggiata aleatoria che inizia da una posizione qualsiasi e che ripete le fasi 2, 3 e 4 dell’algoritmo di Metropolis. Dopo un gran numero di passi, la distribuzione dei valori della catena markoviana approssimerà la distribuzione di probabilità pd.La funzione random_walk() implementa l’algoritmo di Metropolis. Tale funzione prende input la distribuzione di probabilità pd, la posizione di partenza start e il numero di passi dell’algoritmo num_steps.Implementiamo ora l’algoritmo di Metropolis utilizzando, quale valore iniziale, \\(X=4\\). Ripetiamo la simulazione 10,000 volte.\nFIGURA 18.6: L’istogramma confronta valori prodotti dall’algoritmo di Metropolis con valori corretti della distribuzione di massa di probabilità.\nLa figura 18.6 confronta l’istogramma dei valori simulati dalla passeggiata aleatoria con l’effettiva distribuzione di probabilità pd. Si noti che le due distribuzioni sono molto simili.","code":"\npd <- function(x){\n  values <- c(5, 10, 4, 4, 20, 20, 12, 5)\n  ifelse(\n    x %in% 1:length(values),\n    values[x] / sum(values),\n    0\n  )\n}\nprob_dist <- tibble(\n  x = 1:8,\n  prob = pd(1:8)\n)\nx <- 1:8\nprob_dist %>%\n  ggplot(aes(x = x, y = prob)) +\n  geom_bar(stat = \"identity\", width = 0.06) +\n  scale_x_continuous(\"x\", labels = as.character(x), breaks = x) +\n  labs(\n    y = \"Probabilità\",\n    x = \"X\"\n  )\nrandom_walk <- function(pd, start, num_steps){\n  y <- rep(0, num_steps)\n  current <- start\n  for (j in 1:num_steps){\n    candidate <- current + sample(c(-1, 1), 1)\n    prob <- pd(candidate) / pd(current)\n    if (runif(1) < prob)\n      current <- candidate\n    y[j] <- current\n  }\n  return(y)\n}\nout <- random_walk(pd, 4, 1e4)\n\nS <- tibble(out) %>%\n  group_by(out) %>%\n  summarize(\n    N = n(),\n    Prob = N / 10000\n  )\n\nprob_dist2 <- rbind(\n  prob_dist,\n  tibble(\n    x = S$out,\n    prob = S$Prob\n  )\n)\nprob_dist2$Type <- rep(\n  c(\"Prob. corrette\", \"Prob. simulate\"),\n  each = 8\n)\nx <- 1:8\nprob_dist2 %>%\n  ggplot(aes(x = x, y = prob, fill = Type)) +\n  geom_bar(\n    stat = \"identity\",\n    width = 0.1,\n    position = position_dodge(0.3)\n  ) +\n  scale_x_continuous(\n    \"x\",\n    labels = as.character(x),\n    breaks = x\n  ) +\n  scale_fill_manual(values = c(\"black\", \"gray80\")) +\n  theme(legend.title = element_blank()) +\n  labs(\n    y = \"Probabilità\",\n    x = \"X\"\n  )"},{"path":"ch-post-approx.html","id":"lalgoritmo-di-metropolis","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.5 L’algoritmo di Metropolis","text":"Dopo avere introdotto l’algoritmo di Metropolis con l’esempio proposto da Albert Hu (2019), consideriamo ora l’algoritmo nella sua forma più generale.20 Nelle iterazioni dell’algoritmo di Metropolis possiamo distinguere le seguenti fasi.Si inizia con un punto arbitrario \\(\\theta^{(1)}\\); quindi il primo valore della catena di Markov \\(\\theta^{(1)}\\) può corrispondere semplicemente ad un valore caso tra valori possibili del parametro.Per ogni passo successivo della catena, \\(m + 1\\), si estrae un valore candidato \\(\\theta'\\) da una distribuzione proposta: \\(\\theta' \\sim \\Pi(\\theta)\\). La distribuzione proposta può essere qualunque distribuzione, anche se, idealmente, è meglio che sia simile alla distribuzione posteriori. pratica, però, la distribuzione posteriori è sconosciuta e quindi il valore \\(\\theta'\\) viene estratto caso da una qualche distribuzione simmetrica centrata sul valore corrente \\(\\theta^{(m)}\\) del parametro. Nell’esempio presente useremo la gaussiana quale distribuzione proposta. La distribuzione proposta (gaussiana) sarà centrata sul valore corrente della catena e avrà una deviazione standard appropriata: \\(\\theta' \\sim \\mathcal{N}(\\theta^{(m)}, \\sigma)\\). pratica, questo significa che, se \\(\\sigma\\) è piccola, il valore candidato \\(\\theta'\\) sarà simile al valore corrente \\(\\theta^{(m)}\\).Per ogni passo successivo della catena, \\(m + 1\\), si estrae un valore candidato \\(\\theta'\\) da una distribuzione proposta: \\(\\theta' \\sim \\Pi(\\theta)\\). La distribuzione proposta può essere qualunque distribuzione, anche se, idealmente, è meglio che sia simile alla distribuzione posteriori. pratica, però, la distribuzione posteriori è sconosciuta e quindi il valore \\(\\theta'\\) viene estratto caso da una qualche distribuzione simmetrica centrata sul valore corrente \\(\\theta^{(m)}\\) del parametro. Nell’esempio presente useremo la gaussiana quale distribuzione proposta. La distribuzione proposta (gaussiana) sarà centrata sul valore corrente della catena e avrà una deviazione standard appropriata: \\(\\theta' \\sim \\mathcal{N}(\\theta^{(m)}, \\sigma)\\). pratica, questo significa che, se \\(\\sigma\\) è piccola, il valore candidato \\(\\theta'\\) sarà simile al valore corrente \\(\\theta^{(m)}\\).Si calcola il rapporto \\(r\\) tra la densità della distribuzione posteriori non normalizzata calcolata nel punto \\(\\theta'\\) e la densità nel punto \\(\\theta^{(m)}\\):Si calcola il rapporto \\(r\\) tra la densità della distribuzione posteriori non normalizzata calcolata nel punto \\(\\theta'\\) e la densità nel punto \\(\\theta^{(m)}\\):\\[\\begin{equation}\nr = \\frac{p(y \\mid \\theta') p(\\theta')}{p(y \\mid \\theta^{(m)}) p(\\theta^{(m)})}.\n\\tag{18.1}\n\\end{equation}\\]Il numeratore della (18.1) contiene il prodotto tra la verosimiglianza \\(p(y \\mid \\theta')\\) e la densità priori di \\(\\theta\\), entrambe calcolate nel punto \\(\\theta'\\). Il denominatore contiene il prodotto tra la verosimiglianza \\(p(y \\mid \\theta^{(m)})\\) e la densità priori di \\(\\theta\\), entrambe calcolate nel punto \\(\\theta^{(m)}\\). Si noti che, essendo un rapporto, la (18.1) cancella la costante di normalizzazione.Si decide se accettare il candidato \\(\\theta'\\) oppure se rigettarlo e estrarre un nuovo valore dalla distribuzione proposta. Possiamo pensare al rapporto \\(r\\) come alla risposta alla seguente domanda: alla luce dei dati, quale stima di \\(\\theta\\) è più plausibile il valore candidato o il valore corrente? Se \\(r\\) è maggiore di 1, ciò significa che il candidato è più plausibile del valore corrente; dunque il candidato viene sempre accettato. Altrimenti, si decide di accettare il candidato con una probabilità minore di 1, ovvero non sempre, ma soltanto con una probabilità uguale ad \\(r\\). Se \\(r\\) è uguale 0.10, ad esempio, questo significa che la credibilità posteriori del valore candidato è 10 volte più piccola della credibilità posteriori del valore corrente. Dunque, il valore candidato verrà accettato solo nel 10% dei casi. Come conseguenza di questa strategia di scelta, l’algoritmo di Metropolis ottiene un campione casuale dalla distribuzione posteriori, dato che la probabilità di accettare il valore candidato è proporzionale alla densità del candidato nella distribuzione posteriori. Dal punto di vista algoritmico, la procedura descritta sopra viene implementata confrontando il rapporto \\(r\\) con un valore estratto caso da una distribuzione uniforme \\(\\mbox{Unif}(0, 1)\\). Se \\(r > u \\sim \\mbox{Unif}(0, 1)\\), allora il candidato \\(\\theta'\\) viene accettato e la catena si muove quella nuova posizione, ovvero \\(\\theta^{(m+1)} = \\theta'\\). Altrimenti \\(\\theta^{(m+1)} = \\theta^{(m)}\\) e si estrae un nuovo candidato dalla distribuzione proposta.Si decide se accettare il candidato \\(\\theta'\\) oppure se rigettarlo e estrarre un nuovo valore dalla distribuzione proposta. Possiamo pensare al rapporto \\(r\\) come alla risposta alla seguente domanda: alla luce dei dati, quale stima di \\(\\theta\\) è più plausibile il valore candidato o il valore corrente? Se \\(r\\) è maggiore di 1, ciò significa che il candidato è più plausibile del valore corrente; dunque il candidato viene sempre accettato. Altrimenti, si decide di accettare il candidato con una probabilità minore di 1, ovvero non sempre, ma soltanto con una probabilità uguale ad \\(r\\). Se \\(r\\) è uguale 0.10, ad esempio, questo significa che la credibilità posteriori del valore candidato è 10 volte più piccola della credibilità posteriori del valore corrente. Dunque, il valore candidato verrà accettato solo nel 10% dei casi. Come conseguenza di questa strategia di scelta, l’algoritmo di Metropolis ottiene un campione casuale dalla distribuzione posteriori, dato che la probabilità di accettare il valore candidato è proporzionale alla densità del candidato nella distribuzione posteriori. Dal punto di vista algoritmico, la procedura descritta sopra viene implementata confrontando il rapporto \\(r\\) con un valore estratto caso da una distribuzione uniforme \\(\\mbox{Unif}(0, 1)\\). Se \\(r > u \\sim \\mbox{Unif}(0, 1)\\), allora il candidato \\(\\theta'\\) viene accettato e la catena si muove quella nuova posizione, ovvero \\(\\theta^{(m+1)} = \\theta'\\). Altrimenti \\(\\theta^{(m+1)} = \\theta^{(m)}\\) e si estrae un nuovo candidato dalla distribuzione proposta.Il passaggio finale dell’algoritmo calcola l’accettanza una specifica esecuzione dell’algoritmo, ovvero la proporzione di candidati \\(\\theta'\\) che sono stati accettati quali valori successivi della catena.Il passaggio finale dell’algoritmo calcola l’accettanza una specifica esecuzione dell’algoritmo, ovvero la proporzione di candidati \\(\\theta'\\) che sono stati accettati quali valori successivi della catena.L’algoritmo di Metropolis prende come input il numero \\(T\\) di passi da simulare, la deviazione standard \\(\\sigma\\) della distribuzione proposta e la densità priori, e ritorna come output la sequenza \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\). La chiave del successo dell’algoritmo di Metropolis è il numero di passi fino che la catena approssima la stazionarietà. Tipicamente primi da 1000 5000 elementi sono scartati. Dopo un certo periodo \\(k\\) (detto di burn-), la catena di Markov converge ad una variabile casuale che è distribuita secondo la distribuzione posteriori. altre parole, campioni del vettore \\(\\left(\\theta^{(k+1)}, \\theta^{(k+2)}, \\dots, \\theta^{(T)}\\right)\\) diventano campioni di \\(p(\\theta \\mid y)\\).","code":""},{"path":"ch-post-approx.html","id":"unapplicazione-empirica-4","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.6 Un’applicazione empirica","text":"Possiamo ora utilizzare l’algoritmo di Metropolis per trovare, nel caso dei pazienti clinici depressi di Zetsche, Bürkner, Renneberg (2019), la distribuzione posteriori di \\(\\theta\\), ovvero la probabilità che l’umore futuro atteso sia negativo. dati di Zetsche, Bürkner, Renneberg (2019) ci dicono che, nel caso dei 30 pazienti che sono stati esaminati, 23 hanno manifestato aspettative distorte negativamente circa il loro stato d’animo futuro. priori, abbiamo deciso di imporre su \\(\\theta\\) una \\(\\mbox{Beta}(2, 10)\\).21","code":""},{"path":"ch-post-approx.html","id":"funzioni","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.6.1 Funzioni","text":"Definiamo la funzione likelihood(), considerati come fissi dati di Zetsche, Bürkner, Renneberg (2019), ritorna l’ordinata della verosimiglianza binomiale per ciascun valore param input:La funzione prior() ritorna l’ordinata della distribuzione priori \\(\\mbox{Beta}(2, 10)\\) per ciascun valore param input:La funzione posterior() ritorna, per ciascun valore param input, il prodotto della densità priori e della verosimiglianza:","code":"\nlikelihood <- function(param, x = 23, N = 30) {\n  dbinom(x, N, param)\n}\nprior <- function(param, alpha = 2, beta = 10) {\n  dbeta(param, alpha, beta) \n}\nposterior <- function(param) {\n  likelihood(param) * prior(param)\n}"},{"path":"ch-post-approx.html","id":"implementazione","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.6.2 Implementazione","text":"Per implementare l’algoritmo di Metropolis utilizzeremo una distribuzione proposta gaussiana. Il valore candidato sarà dunque un valore selezionato caso da una gaussiana di parametri \\(\\mu\\) uguale al valore corrente nella catena e \\(\\sigma = 0.9\\). questo esempio, la deviazione standard \\(\\sigma\\) è stata scelta empiricamente modo tale da ottenere una accettanza adeguata. L’accettanza ottimale èpari circa 0.20/0.30 — se l’accettanza è troppo grande, l’algoritmo esplora uno spazio troppo ristretto della distribuzione posteriori.22Ho inserito un controllo che impone al valore candidato di essere incluso nell’intervallo [0, 1], com’è necessario per il valore di una proporzione.23L’algoritmo di Metropolis viene implementato nella seguente funzione:Mediante la funzione precedente, generiamo una catena di valori \\(\\theta\\):questo modo, abbiamo ottenuto una catena di Markov costituita da 10,001 valori. Escludiamo primi 5,000 valori considerati come burn-. Consideriamo restanti 5,001 valori come un campione casuale estratto dalla distribuzione posteriori \\(p(\\theta \\mid y)\\).L’accettanza è pari \nil che conferma la bontà della deviazione standard (\\(\\sigma\\) = 0.9) scelta per la distribuzione proposta.Mediante valori della catena così ottenuta è facile trovare una stima posteriori del parametro \\(\\theta\\). Per esempio, la stima della media posteriori è:Una figura che mostra l’approssimazione di \\(p(\\theta \\mid y)\\) ottenuta con l’algoritmo di Metropolis, insieme ad un trace plot dei valori della catena di Markov, è prodotta nel modo seguente:\nFIGURA 18.7: Sinistra. Stima della distribuzione posteriori della probabilità di una aspettativa futura distorta negativamente per dati di Zetsche et al. (2019). Destra. Trace plot dei valori della catena di Markov escludendo il periodo di burn-.\n","code":"\nproposal_distribution <- function(param) {\n  while(1) {\n    res = rnorm(1, mean = param, sd = 0.9)\n    if (res > 0 & res < 1)\n      break\n  }\n  res\n}\nmetropolis <- function(startvalue, iterations) {\n  chain <- vector(length = iterations + 1)\n  chain[1] <- startvalue\n  for (i in 1:iterations) {\n    proposal <- proposal_distribution(chain[i])\n    r <- posterior(proposal) / posterior(chain[i])\n    if (runif(1) < r) {\n      chain[i + 1] <- proposal\n    } else {\n      chain[i + 1] <- chain[i]\n    }\n  }\n  chain\n}\nset.seed(84735)\nstartvalue <- runif(1, 0, 1)\nniter <- 1e4\nchain <- metropolis(startvalue, niter)\nburnin <- niter / 2\nacceptance <- 1 - mean(duplicated(chain[-(1:burnin)]))\nacceptance\n#> [1] 0.2585483\nmean(chain[-(1:burnin)])\n#> [1] 0.5956983\np1 <- tibble(\n  x = chain[-(1:burnin)]\n) %>%\n  ggplot(aes(x)) +\n  geom_histogram(fill = \"darkgray\") +\n  labs(\n    x = expression(theta),\n    y = \"Frequenza\",\n    title = \"Distribuzione a posteriori\"\n  ) +\n  geom_vline(\n    xintercept = mean(chain[-(1:burnin)])\n  ) +\n  xlim(c(0.3, 0.85)) +\n  coord_flip()\n\np2 <- tibble(\n  x = 1:length(chain[-(1:burnin)]),\n  y = chain[-(1:burnin)]\n) %>%\n  ggplot(aes(x, y)) +\n  geom_line(color = \"darkgray\") +\n  labs(\n    x = \"Numero di passi\",\n    y = expression(theta),\n    title = \"Valori della catena\"\n  ) +\n  geom_hline(\n    yintercept = mean(chain[-(1:burnin)]),\n    colour = \"black\"\n  ) +\n  ylim(c(0.3, 0.85)) \n\np1 + p2"},{"path":"ch-post-approx.html","id":"funzione-metropolis","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.6.3 Funzione metropolis()","text":"calcoli precedenti possono essere svolti anche mediante la funzione metropolis() del pacchetto ProbBayes. Per fare un esempio, consideriamo dati corrispondenti 23 successi 30 prove, con una distribuzione priori \\(\\mbox{Beta}(2, 10)\\). Le istruzioni sono le seguenti:Utilizzando un burn-piuttosto lungo, la stima posteriori di \\(\\theta\\) diventa:L’accettanza però non è ottimale:","code":"\nset.seed(123)\nlpost <- function(theta, s){\n  dbeta(theta, 2, 10,log = TRUE) +\n  dbinom(23, 30, theta, log = TRUE)\n}\npost <- ProbBayes::metropolis(lpost, 0.5, 0.2, 8000)\n\ntibble(\n  x = post$S[4001:8000]\n) %>%\n  ggplot(aes(x)) +\n  geom_histogram(fill = \"darkgray\") +\n  labs(\n    x = expression(theta),\n    y = \"Frequenza\",\n    title = \"Distribuzione a posteriori\"\n  )\nmean(post$S[4001:8000])\n#> [1] 0.594834\npost$accept_rate\n#> [1] 0.546375"},{"path":"ch-post-approx.html","id":"gibbs-sampling","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.7 Gibb’s sampling","text":"Il campionamento di Gibbs è un algoritmo MCMC per ottenere una sequenza di campioni casuali da una distribuzione di probabilità congiunta di due o più variabili casuali quando il campionamento diretto si dimostra difficoltoso. Questa sequenza può essere usata per approssimare la distribuzione congiunta.Consideriamo, quale esempio, la seguente distribuzione di probabilità congiunta \\(p(x, y)\\) delle due variabili casuali \\(X\\) e \\(Y\\) (lo script \\(\\textsf{R}\\) è ricavato da Albert Hu 2019):Supponiamo che sia difficile campionare direttamente da \\(p(x, y)\\); supponiamo, tuttavia, di poter facilmente campionare dalle distribuzioni condizionate \\(p(x \\mid y)\\) e \\(p(y \\mid x)\\). Poniamo che l’algoritmo inizi con il valore \\(X = 1\\).Passo 1. Si simula \\(Y\\) dalla distribuzione condizionata \\(f(y \\mid X = 1)\\). Questa distribuzione condizionata è contenuta nella prima colonna della matrice \\(p(x, y)\\), ovveroSupponiamo di avere ottenuto il valore \\(Y = 2\\).Passo 2. Ora estraiamo un valore caso \\(X\\) dalla distribuzione condizionata \\(f(x \\mid Y = 2)\\). Questa distribuzione condizionata è contenuta nella seconda riga della matrice \\(p(x, y)\\), ovveroSupponiamo di avere ottenuto il valore \\(X = 3\\).Implementando passi 1 e 2, si ottiene un’iterazione del campionamento di Gibbs, ovvero la coppia simulata \\((X, Y) = (3, 2)\\). Il campionamento di Gibbs si realizza ripetendo passaggi 1 e 2 molte volte, laddove ogni passo condizioniamo valori simulati ai valori \\(X\\) o \\(Y\\) più recenti.Le seguenti istruzioni generano 100,000 iterazioni dell’algorimo di Gibbs per l’esempio considerazione:Esaminando risultati ottenuti, notiamo che il campionamento di Gibbs produce una buona approssimazione della distribuzione di probabilità congiunta di partenza:","code":"\np <- matrix(c(\n  4, 3, 2, 1,\n  3, 4, 3, 2,\n  2, 3, 4, 3,\n  1, 2, 3, 4\n) / 40, 4, 4, byrow = TRUE)\ndimnames(p)[[1]] <- 1:4\ndimnames(p)[[2]] <- 1:4\np\n#>       1     2     3     4\n#> 1 0.100 0.075 0.050 0.025\n#> 2 0.075 0.100 0.075 0.050\n#> 3 0.050 0.075 0.100 0.075\n#> 4 0.025 0.050 0.075 0.100\np[, 1]\n#>     1     2     3     4 \n#> 0.100 0.075 0.050 0.025\np[2, ]\n#>     1     2     3     4 \n#> 0.075 0.100 0.075 0.050\nn_iter <- 1e5\ngibbs_discrete <- function(p, i = 1, iter = n_iter){\n  x <- matrix(0, iter, 2)\n  n_x <- dim(p)[1]\n  n_y <- dim(p)[2]\n  for(k in 1:n_iter){\n    j <- sample(1:n_y, 1, prob = p[i, ])\n    i <- sample(1:n_x, 1, prob = p[, j])\n    x[k, ] <- c(i, j)\n  }\n  x\n}\nsp <- data.frame(gibbs_discrete(p))\nnames(sp) <- c(\"X\", \"Y\")\nround(table(sp) / n_iter, 3)\n#>    Y\n#> X       1     2     3     4\n#>   1 0.090 0.068 0.046 0.023\n#>   2 0.067 0.090 0.068 0.046\n#>   3 0.045 0.069 0.091 0.069\n#>   4 0.023 0.045 0.068 0.093"},{"path":"ch-post-approx.html","id":"campionamento-beta-binomiale","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.7.1 Campionamento beta-binomiale","text":"L’esempio precedente ha dimostrato il campionamento di Gibbs per una distribuzione discreta due parametri, ma il campionamento di Gibbs funziona per qualsiasi distribuzione due parametri. Per illustrare questo, consideriamo nuovamente lo schema beta-binomiale.\\[\n\\begin{split}\nY \\mid p &\\sim \\mbox{Binom}(n, p),\\\\\np &\\sim \\mbox{Beta}(, b).\n\\end{split}\n\\]Per implementare il campionamento Gibbs per questa situazione, è necessario identificare le due distribuzioni condizionate \\(Y \\mid P\\) e \\(p \\mid Y\\). questo fine, calcoliamo prima la distribuzione congiunta \\(f(Y, p)\\):\\[\n\\begin{split}\nf(Y, p) &= f(p) f(y \\mid p)\\\\\n&= \\left[ \\frac{1}{B(, b)}p^{-1} (1-p)^{b-1} \\right] \\left[ \\binom{n}{y}p^y (1-p)^{n-y}\\right].\n\\end{split}\n\\]Per trovare le distribuzioni marginali, sopprimiamo la dipendenza di \\(f(Y, p)\\) dalle costanti irrilevanti. Se teniamo fisso \\(p\\), l’unica variabile casuale è \\(y\\). Dunque, tutto il contenuto della prima parentesi quadra diventa una costante che può essere ignorata. Per cui \\(f(y \\mid p)\\) è \\(\\mbox{Binom}(n, p)\\). D’altra parte, se teniamo fisso \\(y\\), ignorando le costanti, la densità congiunta risulta proporzionale \\[\np^{y+-1} (1-p)^{n-y+b-1}\n\\]che è il kernel della distribuzione Beta con parametri di forma \\(y+\\) e \\(n-y+b\\). Quindi abbiamo \\(f(p \\mid y) = \\mbox{Beta}(y+, n-y+b)\\).Una volta trovate le due distribuzioni condizionate è facile modificare l’algoritmo di Gibbs visto sopra per adattarlo alla situazione presente:Di seguito eseguiamo il campionamento Gibbs per questo modello Beta-Binomiale con \\(n=20\\), \\(= 5\\) e \\(b=5\\). Dopo aver eseguito 100,000 iterazioni, possiamo considerare la matrice \\(sp\\) come un campione casuale tratto dalla distribuzione congiunta \\(f(Y, p)\\).Se dalla sequenza di coppie \\((Y, p)\\) generate dall’algoritmo di Gibbs consideriamo solo valori \\(Y\\), possiamo ottenere un’approssimazione della distribuzione marginale \\(f(y)\\) di \\(Y\\).La figura seguente mostra invece l’approssimazione della distribuzione congiunta \\(f(Y, p)\\) che è stata ottenuta:","code":"\ngibbs_betabin <- function(n, a, b, p = 0.5, iter = n_iter){\n  x <- matrix(0, iter, 2)\n  for(k in 1:iter){\n    y <- rbinom(1, size = n, prob = p)\n    p <- rbeta(1, y + a, n - y + b)\n    x[k, ] <- c(y, p)\n  }\n  x\n}\nset.seed(123)\nsp <- data.frame(gibbs_betabin(20, 5, 5))\nggplot(data.frame(Y = sp$X1), aes(Y)) +\n  geom_bar(width = 0.5, fill = \"darkgray\") +\n  ylab(\"Frequency\") \nggplot(sp, aes(X1, X2)) +\n  geom_point(size = 0.5, color = \"black\", alpha = 0.05) +\n  xlab(\"Y\") +\n  ylab(\"p\")"},{"path":"ch-post-approx.html","id":"input","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.8 Input","text":"Negli esempi discussi questo Capitolo abbiamo illustrato l’esecuzione di una singola catena cui si parte un unico valore iniziale e si raccolgono valori simulati da molte iterazioni. È possibile però che valori di una catena siano influenzati dalla scelta del valore iniziale. Quindi una raccomandazione generale è di eseguire l’algoritmo di Metropolis più volte utilizzando diversi valori di partenza. questo caso, si avranno più catene di Markov. Confrontando le proprietà delle diverse catene si esplora la sensibilità dell’inferenza alla scelta del valore di partenza. software MCMC consentono sempre ’utente di specificare diversi valori di partenza e di generare molteplici catene di Markov.","code":""},{"path":"ch-post-approx.html","id":"stazionarietà","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.9 Stazionarietà","text":"Un punto importante da verificare è se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta “mixing”.","code":""},{"path":"ch-post-approx.html","id":"approx-post-autocor","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.9.1 Autocorrelazione","text":"Informazioni sul “mixing” della catena di Markov sono fornite dall’autocorrelazione. L’autocorrelazione misura la correlazione tra valori successivi di una catena di Markov. Il valore \\(m\\)-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantità \\(k\\) (dove \\(k\\) è l’entità del ritardo) per verificare quanto si correli al variare di \\(k\\). L’autocorrelazione di ordine 1 (lag 1) misura la correlazione tra valori successivi della catena di Markow (cioè, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-1)}\\)); l’autocorrelazione di ordine 2 (lag 2) misura la correlazione tra valori della catena di Markow separati da due “passi” (cioè, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-2)}\\)); e così via.L’autocorrelazione di ordine \\(k\\) è data da \\(\\rho_k\\) e può essere stimata come:\\[\\begin{align}\n\\rho_k &= \\frac{\\mbox{Cov}(\\theta_m, \\theta_{m+k})}{\\mbox{Var}(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\tag{18.2}\n\\end{align}\\]Per fare un esempio pratico, simuliamo dei dati autocorrelati con la funzione \\(\\textsf{R}\\) colorednoise::colored_noise():L’autocorrelazione di ordine 1 è semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza. Nell’esempio, il vettore rednoise è una sequenza temporale di 30 elementi. Il vettore rednoise[-length(rednoise)] include gli elementi con gli indici da 1 29 nella sequenza originaria, mentre il vettore rednoise[-1] include gli elementi 2:30. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici \\((1, 2), (2, 3), \\dots (29, 30)\\) degli elementi della sequenza originaria. La correlazione di Pearson tra vettori rednoise[-length(rednoise)] e rednoise[-1] corrisponde ’autocorrelazione di ordine 1 della serie temporale.Il Correlogramma è uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce partire dall’autocorrelazione \\(\\rho_k\\) di una catena di Markov funzione del ritardo (lag) \\(k\\) con cui l’autocorrelazione è calcolata: nel grafico ogni barretta verticale riporta il valore dell’autocorrelazione (sull’asse delle ordinate) funzione del ritardo (sull’asse delle ascisse). \\(\\textsf{R}\\), il correlogramma può essere prodotto con una chiamata acf():Nel correlogramma precedente vediamo che l’autocorrelazione di ordine 1 è circa pari 0.4 e diminuisce per lag maggiori; per lag di 4, l’autocorrelazione diventa negativa e aumenta progressivamente fino ad un lag di 8; eccetera.situazioni ottimali l’autocorrelazione diminuisce rapidamente ed è effettivamente pari 0 per piccoli lag. Ciò indica che valori della catena di Markov che si trovano più di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del “mixing” della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l’autocorrelazione è quella di assottigliare l’output immagazzinando solo ogni \\(m\\)-esimo punto dopo il periodo di burn-. Una tale strategia va sotto il nome di thinning.","code":"\nsuppressPackageStartupMessages(library(\"colorednoise\"))\nset.seed(34783859)\nrednoise <- colored_noise(\n  timesteps = 30, mean = 0.5, sd = 0.05, phi = 0.3\n)\ncor(rednoise[-length(rednoise)], rednoise[-1])\n#> [1] 0.3967366\nacf(rednoise)"},{"path":"ch-post-approx.html","id":"test-di-convergenza","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"18.2.10 Test di convergenza","text":"Un test di convergenza può essere svolto maniera grafica mediante le tracce delle serie temporali (trace plot), cioè il grafico dei valori simulati rispetto al numero di iterazioni. Se la catena è uno stato stazionario le tracce mostrano assenza di periodicità nel tempo e ampiezza costante, senza tendenze visibili o andamenti degni di nota. Un esempio di trace plot è fornito nella figura 18.7 (destra).Ci sono inoltre alcuni test che permettono di verificare la stazionarietà del campionatore dopo un dato punto. Uno è il test di Geweke che suddivide il campione, dopo aver rimosso un periodo di burn , due parti. Se la catena è uno stato stazionario, le medie dei due campioni dovrebbero essere uguali. Un test modificato, chiamato Geweke z-score, utilizza un test \\(z\\) per confrontare due subcampioni ed il risultante test statistico, se ad esempio è più alto di 2, indica che la media della serie sta ancora muovendosi da un punto ad un altro e quindi è necessario un periodo di burn-più lungo.","code":""},{"path":"ch-post-approx.html","id":"commenti-e-considerazioni-finali-14","chapter":"Capitolo 18 Approssimazione della distribuzione a posteriori","heading":"Commenti e considerazioni finali","text":"generale, la distribuzione posteriori dei parametri di un modello statistico non può essere determinata per via analitica. Tale problema viene invece affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilità che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre più semplice l’uso dei metodi MCMC, insieme ’incremento della potenza di calcolo dei computer, ha contribuito rendere sempre più popolare il metodo dell’inferenza bayesiana che, questo modo, può essere estesa problemi di qualunque grado di complessità.","code":""},{"path":"ch-stan-beta-binom.html","id":"ch-stan-beta-binom","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","text":"questo Capitolo introdurremo un linguaggio di programmazione probabilistica chiamato Stan (Carpenter et al. 2017). Stan consente di generare campioni da distribuzioni di probabilità basati sulla costruzione di una catena di Markov avente come distribuzione di equilibrio (o stazionaria) la distribuzione desiderata. Prende il nome da uno dei creatori del metodo Monte Carlo, Stanislaw Ulam (Eckhardt 1987). Un’introduzione al linguaggio Stan è fornita nell’Appendice ??. questo Capitolo useremo Stan per fare inferenza su una proporzione.","code":""},{"path":"ch-stan-beta-binom.html","id":"il-presidente-trump-e-lidrossiclorochina","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"19.1 Il presidente Trump e l’idrossiclorochina","text":"Per fare un esempio concreto, consideriamo un set di dati reali. Cito dal Washington Post del 7 aprile 2020: “One bizarre disturbing aspects President Trump’s nightly press briefings coronavirus pandemic turns drug salesman. Like cable TV pitchman hawking ‘male enhancement’ pills, Trump regularly extols virtues taking hydroxychloroquine, drug used treat malaria lupus, potential ‘game changer’ just might cure Covid-19.” Tralasciamo qui il fatto che il Donald Trump non sia un esperto questo campo. Esaminiamo invece le evidenze iniziali supporto dell’ipotesi che l’idrossiclorochina possa essere utile per la cura del Covid-19, ovvero le evidenze che erano disponibili nel momento cui il Donald Trump ha fatto le affermazioni riportate sopra (seguito, quest’idea è stata screditata). Tali evidenze sono state fornite da uno studio di Gautret et al. (2020). Il disegno sperimentale di Gautret et al. (2020) comprende, tra le altre cose, il confronto tra una condizione sperimentale e una condizione di controllo. Il confronto importante è tra la proporzione di paziente positivi al virus SARS-CoV-2 nel gruppo sperimentale (cui è stata somministrata l’idrossiclorochina; 6 su 14) e la proporzione di paziente positivi nel gruppo di controllo (cui non è stata somministrata l’idrossiclorochina; ovvero 14 su 16). Obiettivo di questo Capitolo è mostrare come si possa fare inferenza sui dati di Gautret et al. (2020) usando il linguaggio Stan. Per semplicità, iniziamo considerando solo il gruppo di controllo.","code":""},{"path":"ch-stan-beta-binom.html","id":"una-proporzione","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"19.2 Una proporzione","text":"Sulla base di ciò che è stato detto nel Capitolo ??, sappiamo che, quando dati sono rappresentati da una proporzione \\(\\theta\\), e quando utilizziamo una distribuzione priori Beta per \\(\\theta\\), la distribuzione posteriori di \\(\\theta\\) è specificata dallo schema beta-binomiale. Se scegliamo, ad esempio, una \\(\\mbox{Beta}(2, 2)\\) quale distribuzione priori per \\(\\theta\\), il modello diventa:\\[\\begin{align}\ny &\\sim \\mbox{Bin}(n, \\theta) \\notag\\\\\n\\theta &\\sim \\mbox{Beta}(2, 2)\n\\tag{19.1}\n\\end{align}\\]dove la prima riga definisce la funzione di verosimiglianza e la seconda riga definisce la distribuzione priori. Vediamo ora come specificare il modello beta-binomiale linguaggio Stan.","code":""},{"path":"ch-stan-beta-binom.html","id":"cmdstanr-gautret","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"19.3 Interfaccia cmdstanr","text":"modelli presentati questo capitolo sono discussi da Gelman et al. (1995) mentre il codice è stato ricavato dalla seguente pagina web. questo e nei successivi capitoli useremo Stan mediante l’interfaccia cmdstanr di CmdStan.Iniziamo con il caricare pacchetti necessari:Per svolgere l’analisi mediante cmdstanr è necessario prima specificare la struttura del modello bayesiano nella notazione Stan e, poi, eseguire il campionamento dalla distribuzione posteriori. Esaminiamo questi due passaggi per il caso dell’esempio presente.","code":"\nlibrary(\"cmdstanr\")\nlibrary(\"posterior\")\n# rstan_options(auto_write = TRUE) # avoid recompilation of models\n# parallelize across all CPUs\noptions(mc.cores = parallel::detectCores()) \n# improve execution time\nSys.setenv(LOCAL_CPPFLAGS = '-march=native') \nSEED <- 374237 # set random seed for reproducibility"},{"path":"ch-stan-beta-binom.html","id":"fase-1","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"19.3.1 Fase 1","text":"Nella prima fase dell’analisi dobbiamo definire dati, parametri e il modello. dati devono essere contenuti un oggetto di classe list. Per l’esempio presente abbiamo:Il modello è \\(\\mbox{Bin}(n, \\theta)\\) e, linguaggio Stan, può essere specificato comeIl modello dipende dal parametro theta. Stan, dobbiamo specificare che theta può essere un qualsiasi numero reale compreso tra 0 e 1. Inoltre, dobbiamo specificare la distribuzione priori di \\(\\theta\\). Per questo parametro abbiamo scelto una \\(\\mbox{Beta}(2, 2)\\) e, linguaggio Stan, scriviamoMemorizziamo ora il modello beta-binomiale specificato linguaggio Stan come stringa di caratteri nel file oneprop.stan:","code":"\ndata1_list <- list(\n  N = 16,\n  y = c(rep(1, 14), rep(0, 2))\n)\ny ~ bernoulli(theta);\ntheta ~ beta(2, 2);\nmodelString = \"\ndata {\n  int<lower=0> N;\n  int<lower=0, upper=1> y[N];\n}\nparameters {\n  real<lower=0, upper=1> theta;\n}\nmodel {\n  theta ~ beta(2, 2);\n  y ~ bernoulli(theta);\n}\n\"\nwriteLines(modelString, con = \"code/oneprop.stan\")"},{"path":"ch-stan-beta-binom.html","id":"fase-2","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"19.3.2 Fase 2","text":"Per utilizzare il modello specificato, leggiamo l’indirizzo del file che contiene il codice Stan:Compiliamo il codiceed eseguiamo il campionamento MCMC con la chiamataAvendo assunto una distribuzione priori per il parametro \\(\\theta\\), l’algoritmo procede maniera ciclica, correggendo la distribuzione priori di \\(\\theta\\) condizionandola ai valori già generati. Dopo un certo numero di cicli, necessari per portare l’algoritmo convergenza, valori estratti possono essere assunti come campionati dalla distribuzione posteriori di \\(\\theta\\).Si noti che $sample() richiede due tipi di informazioni. Innanzitutto, dobbiamo specificare le informazioni sul modello base :mod = la stringa di caratteri che definisce il modello (qui oneprop.stan),data = dati formato lista (data1_list).Dobbiamo inoltre specificare le informazioni sul campionamento MCMC utilizzando alcuni argomenti aggiuntivi:L’argomento chains specifica quante catene di Markov parallele eseguire. Eseguiamo qui quattro catene, quindi otteniamo quattro campioni distinti di valori \\(\\pi\\).L’argomento iter specifica il numero desiderato di iterazioni o la lunghezza di ciascuna catena di Markov. Per impostazione predefinita, la prima metà di queste iterazioni è costituita da campioni “burn-” o “warm-” che verranno ignorati. La seconda metà è conservata e costituisce un campione della distribuzione posteriori.L’argomento seed per impostare il numero casuale che genera il seme per una simulazione cmdstanr.","code":"\nfile <- file.path(\"code\", \"oneprop.stan\")\nmod <- cmdstan_model(file)\nfit1 <- mod$sample(\n  data = data1_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = 84735,\n  chains = 4L,\n  parallel_chains = 4L,\n  refresh = 0,\n  thin = 1\n)"},{"path":"ch-stan-beta-binom.html","id":"burn-in","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"19.3.3 Burn-in","text":"Al crescere del numero di passi della catena, la distribuzione di target viene sempre meglio approssimata. ’inizio del campionamento, però, la distribuzione può essere significativamente lontana da quella stazionaria, e ci vuole un certo tempo prima di raggiungere la distribuzione stazionaria di equilibrio, detto, appunto, periodo di burn-. campioni provenienti da tale parte iniziale della catena vanno tipicamente scartati perché possono non rappresentare accuratamente la distribuzione posteriori.","code":""},{"path":"ch-stan-beta-binom.html","id":"inferenza","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"19.3.4 Inferenza","text":"Un sommario della distribuzione posteriori si ottiene con:Creiamo un oggetto di classe stanfitdi dimensioniI primi 10 valori sono presentati qui di seguitoLa matrice precedente include valori assunti dalla catena di Markov, ovvero un insieme di valori plausibili \\(\\theta\\) estratti dalla distribuzione posteriori.\nUn tracciato della catena di Markov illustra questa esplorazione rappresentando il valore \\(\\theta\\) sulle ordinate e l’indice progressivo di ogni iterazione sull’ascissa. Usiamo la funzione mcmc_trace() del pacchetto bayesplot per costruire il grafico che include tutte e quattro le catene di Markov:\nFIGURA 19.1: Trace-plot per il parametro \\(\\theta\\) nel modello Beta-Binomiale.\nLa figura 19.1 mostra che le catene esplorano uno spazio compreso approssimativamenre tra 0.5 e 0.95; questa figura descrive il comportamento longitudinale delle catene di Markov.Possiamo anche esaminare la distribuzione degli stati della catena di Markov, ovvero, dei valori che queste catene visitano lungo il loro percorso, ignorando l’ordine di queste visite. L’istogramma della figura 19.2 fornisce una rappresentazione grafica di questa distribuzione per 16000 valori complessivi delle quattro catene, ovvero per 4000 valori provienienti da ciascuna catena.\nFIGURA 19.2: Istogramma che illustra l’approssimazione della distribuzione posteriori per il parametro \\(\\theta\\) nel modello Beta-Binomiale.\nNello schema beta-binomiale cui la verosimiglianza è binomiale con 14 successi su 16 prove e cui assumiamo una distribuzione priori \\(\\mbox{Beta}(2, 2)\\) sul parametro \\(\\theta\\), la distribuzione posteriori è una distribuzione Beta di parametri \\(\\alpha\\) = 2 + 14 e \\(\\beta\\) = 2 + 16 - 14. La figura 19.3 riporta un kernel density plot per valori delle quattro catene di Markov con sovrapposta nero la densità \\(\\mbox{Beta}(16, 4)\\). Si noti come la distribuzione dei valori delle catene di Markov produca un’eccellente approssimazione alla distribuzione bersaglio.24\nFIGURA 19.3: Istogramma che illustra l’approssimazione della distribuzione posteriori per il parametro \\(\\theta\\) nel modello Beta-Binomiale. La curva nera rappresenta la corretta distribuzione posteriori Beta(16, 4).\nUn intervallo di credibilità al 95% per \\(\\theta\\) si ottiene con la seguente chiamata:Svolgendo un’analisi bayesiana simile questa, Gautret et al. (2020) hanno trovato che gli intervalli di credibilità del gruppo di controllo e del gruppo sperimentale non si sovrappongono. Questo fatto viene interpretato dicendo che il parametro \\(\\theta\\) è diverso nei due gruppi. Sulla base di queste evidenza, Gautret et al. (2020) hanno concluso, con un grado di certezza soggettiva del 95%, che nel gruppo sperimentale vi è una probabilità più bassa di risultare positivi al SARS-CoV-2 rispetto al gruppo di controllo. altri termini, l’analisi statistica condotta da Gautret et al. (2020) suggerisce che l’idrossiclorochina è una terapia efficace per il Covid-19.","code":"\nfit1$summary(c(\"theta\"))\n#> # A tibble: 1 × 10\n#>   variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 theta    0.798  0.808 0.0876 0.0872 0.638 0.924  1.00    5769.    6359.\nstanfit1 <- rstan::read_stan_csv(fit1$output_files())\ndim(as.matrix(stanfit1, pars = \"theta\"))\n#> [1] 16000     1\nas.matrix(stanfit1, pars = \"theta\") %>% \n  head(10)\n#>           parameters\n#> iterations    theta\n#>       [1,] 0.852111\n#>       [2,] 0.784496\n#>       [3,] 0.784496\n#>       [4,] 0.755076\n#>       [5,] 0.725578\n#>       [6,] 0.774385\n#>       [7,] 0.774385\n#>       [8,] 0.806225\n#>       [9,] 0.826550\n#>      [10,] 0.849894\nstanfit1 %>% \n  mcmc_trace(pars = c(\"theta\"), size = 0.1)\nmcmc_hist(stanfit1, pars = \"theta\") + \n  yaxis_text(TRUE) + \n  ylab(\"count\")\nmcmc_dens(stanfit1, pars = \"theta\") + \n  yaxis_text(TRUE) + \n  ylab(\"density\") +\n  stat_function(fun = dbeta, args = list(shape1 = 16, shape2=4))\nposterior1 <- extract(stanfit1)\nrstantools::posterior_interval(as.matrix(stanfit1), prob = 0.95)\n#>              2.5%       97.5%\n#> theta   0.5990419   0.9376123\n#> lp__  -12.5817650 -10.0086000"},{"path":"ch-stan-beta-binom.html","id":"la-critica-di-hulme_2020","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"19.4 La critica di Hulme et al. (2020)","text":"Un articolo pubblicato da Hulme et al. (2020) si è posto il problema di rianalizzare dati di Gautret et al. (2020).25 Tra gli autori di questo articolo figura anche Eric-Jan Wagenmakers, uno psicologo molto conosciuto per suoi contributi metodologici. Hulme et al. (2020) osservano che, nelle loro analisi statistiche, Gautret et al. (2020) hanno escluso alcuni dati. Nel gruppo sperimentale, infatti, vi erano alcuni pazienti quali, anziché migliorare, sono realtà peggiorati. L’analisi statistica di Gautret et al. (2020) ha escluso dati di questi pazienti. Se consideriamo tutti pazienti — non solo quelli selezionati da Gautret et al. (2020) — la situazione diventa la seguente:gruppo sperimentale: 10 positivi su 18;gruppo di controllo: 14 positivi su 16.L’analisi dei dati proposta da Hulme et al. (2020) richiede l’uso di alcuni strumenti statistici che, queste dispense, non verranno discussi. Ma possiamo giungere alle stesse conclusioni raggiunte da questi ricercatori anche usando le procedure statistiche descritte nel Paragrafo successivo.","code":""},{"path":"ch-stan-beta-binom.html","id":"due-proporzioni","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"19.5 Due proporzioni","text":"Svolgiamo ora l’analisi statistica considerando tutti dati, come suggerito da Hulme et al. (2020). Per fare questo verrà creato un modello bayesiano per fare inferenza sulla differenza tra due proporzioni. Dopo avere generato le distribuzioni posteriori per le proporzioni di “successi” nei due gruppi, calcoleremo la quantità\\[\n\\omega = \\frac{\\theta_2 / (1-\\theta_2)}{\\theta_1 / (1-\\theta_1)},\n\\]ovvero il rapporto tra gli Odds di positività tra pazienti del gruppo di controllo e gli Odds di positività tra pazienti del gruppo sperimentale. Se il valore dell’è uguale 1, significa che l’Odds di positività nel gruppo di controllo è uguale ’Odds di positività nel gruppo sperimentale, cioè il fattore esame (somministrazione dell’idrossiclorochina) è ininfluente sulla comparsa della malattia. L’inferenza statistica sull’efficacia dell’idrossiclorochina come terapia per il Covid-19 può dunque essere effettuata esaminando l’intervallo di credibilità al 95% per l’: se tale intervallo include il valore 1, allora non vi è evidenza che l’idrossiclorochina sia efficace come terapia per il Covid-19.Nell’implementazione di questo modello, la quantità di interesse è dunque l’odds ratio; tale quantità viene calcolata nel blocco generated quantities del programma Stan. Per parametri \\(\\theta_1\\) e \\(\\theta_2\\) useremo delle distribuzioni priori debolmente informative il cui unico scopo è la regolarizzazione dei dati.L’intervallo di credibilità del 95% per l’include il valore di 1.0 (ovvero, il valore che indica che gli Odds di positività sono uguali nei due gruppi). base agli standard correnti, un risultato di questo tipo non viene considerato come evidenza sufficiente per potere concludere che il parametro \\(\\theta\\) assume un valore diverso nei due gruppi. conclusione, se consideriamo tutti dati, e non solo quelli selezionati da Gautret et al. (2020), non vi sono evidenze sull’efficacia dell’idrossiclorochina come terapia per casi di Covid-19.","code":"\ndata_list <- list(\n  N1 = 18, \n  y1 = 10, \n  N2 = 16, \n  y2 = 14\n)\nmodelString <- \"\n//  Comparison of two groups with Binomial\ndata {\n  int<lower=0> N1;              // number of experiments in group 1\n  int<lower=0> y1;              // number of deaths in group 1\n  int<lower=0> N2;              // number of experiments in group 2\n  int<lower=0> y2;              // number of deaths in group 2\n}\nparameters {\n  real<lower=0,upper=1> theta1; // probability of death in group 1\n  real<lower=0,upper=1> theta2; // probability of death in group 2\n}\nmodel {\n  theta1 ~ beta(2, 2);          // prior\n  theta2 ~ beta(2, 2);          // prior\n  y1 ~ binomial(N1, theta1);    // observation model / likelihood\n  y2 ~ binomial(N2, theta2);    // observation model / likelihood\n}\ngenerated quantities {\n  // generated quantities are computed after sampling\n  real oddsratio = (theta2/(1-theta2))/(theta1/(1-theta1));\n}\n\"\nwriteLines(modelString, con = \"code/twoprop1.stan\")\nfile <- file.path(\"code\", \"twoprop1.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 4L,\n  refresh = 0,\n  thin = 1\n)\nstanfit <- rstan::read_stan_csv(fit$output_files())\nprint(\n  stanfit,\n  pars = c(\"theta1\", \"theta2\", \"oddsratio\"),\n  digits_summary = 3L\n)\n#> Inference for Stan model: twoprop1-202204241012-1-5c0ef5.\n#> 4 chains, each with iter=6000; warmup=2000; thin=1; \n#> post-warmup draws per chain=4000, total post-warmup draws=16000.\n#> \n#>            mean se_mean    sd  2.5%   25%   50%   75%  97.5% n_eff Rhat\n#> theta1    0.546   0.001 0.103 0.344 0.475 0.546 0.620  0.740 12795    1\n#> theta2    0.798   0.001 0.087 0.601 0.744 0.808 0.862  0.937 14193    1\n#> oddsratio 4.721   0.043 4.411 0.906 2.166 3.514 5.698 15.558 10400    1\n#> \n#> Samples were drawn using NUTS(diag_e) at Dom Apr 24 10:12:27 2022.\n#> For each parameter, n_eff is a crude measure of effective sample size,\n#> and Rhat is the potential scale reduction factor on split chains (at \n#> convergence, Rhat=1)."},{"path":"ch-stan-beta-binom.html","id":"commenti-e-considerazioni-finali-15","chapter":"Capitolo 19 Il modello beta-binomiale in linguaggio Stan","heading":"Commenti e considerazioni finali","text":"Ciò che è stato presentato questo capitolo è un esercizio didattico: la ricerca di Gautret et al. (2020) include altre informazioni e altre analisi statistiche che non sono state qui considerate. Tuttavia, notiamo che la semplice analisi statistica che abbiamo qui descritto è stata grado di replicare le conclusioni cui sono giunti (per altra via) Hulme et al. (2020).","code":""},{"path":"ch-diagn-markov-chains.html","id":"ch-diagn-markov-chains","chapter":"Capitolo 20 Diagnostica delle catene markoviane","heading":"Capitolo 20 Diagnostica delle catene markoviane","text":"Come discusso nel Paragrafo 19.3, le catene di Markov forniscono un’approssimazione che tende convergere alla distribuzione posteriori. “Approssimazione” e “convergenza” sono le parole chiave qui: il punto è che il campionamento MCMC non è perfetto. Questo solleva le seguenti domande:cosa corrisponde, dal punto di vista grafico, una “buona” catena di Markov?Come possiamo sapere se il campione prodotto dalla catena di Markov costituisce un’approssimazione adeguata della distribuzione posteriori?Quanto deve essere grande la dimensione del campione casuale prodotto dalla catena Markov?Rispondere queste ed altre domande di questo tipo fa parte di quell’insieme di pratiche che vano sotto il nome di diagnostica delle catene Markoviane.La diagnostica delle catene Markoviane non è “una scienza esatta”. Ovvero, non sono disponibili procedure che risultano valide tutti casi possibili e non sempre siamo grado di rispondere tutte le domande precedenti. È piuttosto l’esperienza del ricercatore che consente di riconoscere una “buona” catena di Markov e suggerire cosa si può fare per riparare una “cattiva” catena di Markov. questo Capitolo ci concentreremo su alcuni strumenti diagnostici grafici e numerici che possono essere utilizzati per la diagnostica delle catene markoviane. L’utilizzo di questi strumenti diagnostici deve essere eseguito modo olistico. Nessuna singola diagnostica visiva o numerica è sufficiente: un quadro completo della qualità della catena di Markov si può solo ottenere considerando tutti gli strumenti descritti di seguito.","code":""},{"path":"ch-diagn-markov-chains.html","id":"esame-dei-trace-plot","chapter":"Capitolo 20 Diagnostica delle catene markoviane","heading":"20.1 Esame dei trace plot","text":"La convergenza e il “mixing” possono essere controllate mediante il trace plot che mostra l’andamento delle simulazioni e ci dice se stiamo effettivamente utilizzando una distribuzione limite. Consideriamo nuovamente il trace plot del simulazione Beta-Binomiale della figura 20.1:\nFIGURA 20.1: Trace plot per il modello Beta-Binomiale dei dati di Gautret et al.(2020).\nLa figura 20.1 fornisce un esempio perfetto di come dovrebbero apparire trace plot. Quando le catene markoviane raggiungono uno stato stazionario e sono stabili ciò significa che hanno raggiunto la distribuzione stazionaria e il trace plot rivela un’assenza di struttura e diventa simile alla rappresentazione del rumore bianco, come nella figura 20.1.Una mancanza di convergenza è invece indicata dalla figura 20.226.\nFIGURA 20.2: Trace plots (sinistra) e corrispondenti grafici di densità (destra) di due ipotetiche catene di Markov. Queste figure forniscono due esempi di come potrebbero apparire delle catene di Markov non stazionarie. Le linee nere sovrapposte alle densità empiriche (destra) rappresentano una ipotetica distribuzione target Beta(11,3).\nNel trace-plot della figura 20.2, la tendenza verso il basso indica che la catena non è stazionaria, ovvero non si mantiene costante ’evolversi nel tempo. La tendenza verso il basso suggerisce inoltre la presenza di una forte correlazione tra valori della catena: il trace-plot non fornisce una rappresentazione di rumore indipendente. Tutto questo significa che la catena “si sta mescolando lentamente”. Sebbene le catene di Markov siano intrinsecamente dipendenti, più si comportano come se fossero dei campioni casuali (rumorosi), minore è l’errore dell’approssimazione alla distribuzione posteriori.La catena B presenta un problema diverso. Come evidenziato dalle due linee completamente piatte nel tracciato, essa tende bloccarsi quando visita valori bassi di \\(\\theta\\).Gli istogrammi lisciati della figura 20.2 (destra) confermano che entrambe queste catene sono problematiche: infatti producono approssimazioni scadenti della distribuzione posteriori che, nell’esempio di Johnson, Ott, Dogucu (2022), è una \\(\\mbox{Beta}(11, 3)\\) (la curva nera nella figura). Consideriamo la catena . Dal momento che si sta mescolando lentamente, nelle iterazioni eseguite ha esplorato unicamente valori \\(\\theta\\) nell’intervallo da 0.6 0.9. Di conseguenza, la sua approssimazione della distribuzione posteriori sopravvaluta la plausibilità dei valori \\(\\theta\\) questo intervallo e, nel contempo, sottovaluta la plausibilità dei valori \\(\\theta\\) esterni questo intervallo. Consideriamo ora la catena B. Rimanendo bloccata, la catena B campiona maniera eccessiva alcuni valori nella coda sinistra della distribuzione posteriori di \\(\\theta\\). Questo fenomeno produce picchi che sono presenti nell’approssimazione alla distribuzione posteriori.pratica, al di là dei presenti esempi “scolastici” (cui disponiamo di una formulazione analitica della distribuzione posteriori), non abbiamo mai il privilegio di poter confrontare risultati del campionamento MCMC con la corretta distribuzione posteriori. Ecco perché la diagnostica delle catene di Markov è così importante: se vediamo trace-plots come quelli della figura 20.2, sappiamo che non abbiamo ottenuto una adeguata approssimazione della distribuzione posteriori.tali circostanze possiamo ricorrere ad alcuni rimedi.Controllare il modello. Siamo sicuri che le distribuzioni priori e la verosimiglianza siano appropriate per dati osservati?Utilizzare un numero maggiore di iterazioni. Alcune tendenze indesiderate breve termine della catena possono appianarsi nel lungo termine.","code":""},{"path":"ch-diagn-markov-chains.html","id":"confronto-delle-catene-parallele","chapter":"Capitolo 20 Diagnostica delle catene markoviane","heading":"20.2 Confronto delle catene parallele","text":"Nella simulazione cmdstanr() per il modello beta-binomiale dei dati di Gautret et al. (2020) abbiamo utilizzato quattro catene di Markov parallele. Non solo è necessario che ogni singola catena sia stazionaria (come discusso sopra), ma è anche necessario che le quattro catene siano coerenti tra loro. Sebbene le catene esplorino percorsi diversi nello spazio dei parametri, quando convergono ad uno stato di equilibrio dovrebbero presentare caratteristiche simili e dovrebbero produrre approssimazioni simili alla distribuzione posteriori. Per il caso beta-binomiale dei dati di Gautret et al. (2020), gli istogrammi lisciati della figura seguente indicano che le quattro catene producono approssimazioni della distribuzione posteriori quasi indistinguibili tra loro. Ciò prova che la simulazione è stabile e contiene un nunero sufficiente di valori: l’esecuzione delle catene per un numero maggiore di iterazioni non porterebbe ad un miglioramento della stima della distribuzione posteriori.Per fare un confronto, per lo stesso modello, consideriamo la simulazione di una catena di Markov più corta. La chiamata seguente richiede quattro catene parallele per sole 100 iterazioni ciascuna:Di seguito sono riportati trace-plot e corrispondenti istogrammi lisciati.Anche se trace plot sembrano tutti mostrare un andamento casuale, gli istogrammi lisciati sono piuttosto diversi tra loro e producono approssimazioni diverse della distribuzione posteriori. Di fronte tale instabilità è chiaro che sarebbe un errore interrompere la simulazione dopo solo 100 iterazioni.","code":"\nmcmc_dens_overlay(stanfit1, pars = \"theta\") + \n  ylab(\"density\")bb_short <- mod$sample(\n  data = data1_list,\n  iter_sampling = 50*2L,\n  seed = 84735,\n  chains = 4L,\n  parallel_chains = 4L,\n  refresh = 0,\n  thin = 1\n)\nFALSE Running MCMC with 4 parallel chains...\nFALSE \nFALSE Chain 1 finished in 0.0 seconds.\nFALSE Chain 2 finished in 0.0 seconds.\nFALSE Chain 3 finished in 0.0 seconds.\nFALSE Chain 4 finished in 0.0 seconds.\nFALSE \nFALSE All 4 chains finished successfully.\nFALSE Mean chain execution time: 0.0 seconds.\nFALSE Total execution time: 0.3 seconds.\n\nstanfit_bb_short <- rstan::read_stan_csv(bb_short$output_files())\nmcmc_trace(stanfit_bb_short, pars = \"theta\")\nmcmc_dens_overlay(stanfit_bb_short, pars = \"theta\")"},{"path":"ch-diagn-markov-chains.html","id":"numerosita-campionaria-effettiva","chapter":"Capitolo 20 Diagnostica delle catene markoviane","heading":"20.3 Numerosità campionaria effettiva","text":"Nella simulazione del modello beta-binomiale per dati di Gautret et al. (2020) abbiamo utilizzato quattro catene di Markov parallele che producono un totale di \\(N\\) = 16000 campioni dipendenti di \\(\\theta\\). Sapendo che l’errore dell’approssimazione alla distribuzione posteriori è probabilmente più grande di quello che si otterrebbe usando 16000 campioni indipendenti, ci possiamo porre la seguente domanda: quanti campioni indipendenti sarebbero necessari per produrre un’approssimazione della distribuzione posteriori equivalentemente quella che abbiamo ottenuto? La numerosità campionaria effettiva (effective sample size, \\(N_{eff}\\)) fornisce una risposta questa domanda.Tipicamente, \\(N_{eff} < N\\), per cui il rapporto campionario effettivo (effective sample size ratio) \\(\\frac{N_{eff}}{N}\\) è minore di 1. Come regola euristica, viene considerato problematico un rapporto campionario effettivo minore del 10% del numero totale di campioni ottenuti nella simulazione (più basso è il rapporto campionario effettivo peggiore è il “mixing” della catena). La funzione bayesplot::neff_ratio() consente di calcolare il rapporto campionario effettivo. Per il modello Beta-Binomiale dei dati di Gautret et al. (2020), questo rapporto è di circa 0.34:Ciò indica che l’accuratezza dell’approssimazione della distribuzione posteriori di \\(\\theta\\) ottenuta mediante 16000 campioni dipendenti è approssimativamente simile quella che si potrebbe ottenere concampioni indipendenti. questo esempio, il rapporto campionario effettivo è maggiore di 0.1; dunque non ci sono problemi.","code":"\nbayesplot::neff_ratio(stanfit1, pars = c(\"theta\"))\n#> [1] 0.3629411\nbayesplot::neff_ratio(\n  stanfit1, pars = c(\"theta\")\n) * 16000\n#> [1] 5807.058"},{"path":"ch-diagn-markov-chains.html","id":"autocorrelazione","chapter":"Capitolo 20 Diagnostica delle catene markoviane","heading":"20.4 Autocorrelazione","text":"Normalmente un algoritmo MCMC genera catene di Markov di campioni, ognuno dei quali è autocorrelato quelli generati immediatamente prima e dopo di lui. Conseguentemente campioni successivi non sono indipendenti ma formano una catena di Markov con un certo grado di correlazione. Il valore \\(\\theta^{()}\\) tende ad essere più simile al valore \\(\\theta^{(-1)}\\) che al valore \\(\\theta^{(-2)}\\), o al valore \\(\\theta^{(-3)}\\), eccetera. Una misura di ciò è fornita dall’autocorrelazione tra valori consecutivi della catena.Il correlogramma per ciascuna delle quattro catene dell’esempio si produce con la seguente chiamata:Il correlogramma mostra l’autocorrelazione funzione di ritardi da 0 20. L’autocorrelazione di lag 0 è naturalmente 1 – misura la correlazione tra un valore della catena di Markov e se stesso. L’autocorrelazione di lag 1 è di circa 0.5, indicando una correlazione moderata tra valori della catena che distano di solo 1 passo l’uno dall’altro. Successivamente, l’autocorrelazione diminuisce rapidamente ed è effettivamente pari 0 per un lag di 5. Questo risultato fornisce una conferma del fatto che la catena di Markov costituisce una buona approssimazione di un campione casuale di \\(p(\\theta \\mid y)\\).\nFIGURA 20.3: Trace plot (sinistra) e correlogramma (destra) di una catena di Markow cui il mixing è lento – figura riprodotta da Johnson, Ott, Dogucu (2022).\nQuesta osservazione è confermata nell’correlogramma (destra). La lenta diminuzione della curva di autocorrelazione indica che la dipendenza tra valori della catena non svanisce rapidamente. Con un lag di 20 la correlazione è addirittura pari 0.9. Poiché valori della catena sono fortemente associati tra loro, il “mixing” è lento: la simulazione richiede un numero molto grande di iterazioni per esplorare adeguatamente l’intera gamma di valori della distribuzione posteriori.27In presenza di catene di Markov non rapidly mixing sono possibili due rimedi.Aumentare il numero di iterazioni. Anche una catena non rapidly mixing può produrre eventualmente una buona approssimazione della distribuzione posteriori se il numero di iterazioni è sufficientemente grande.Thinning. Per esempio, se la catena di Markov è costituita da 16000 valori di \\(\\theta\\), potremmo decidere di conservare solo ogni secondo valore e ignorare gli altri valori: \\(\\{\\theta^{(2)}, \\theta^{(4)}, \\theta^{(6)}, \\dots, \\theta^{(16000)}\\}\\). Oppure, potremmo decidere di conservare ogni decimo valore: \\(\\{\\theta^{(10)}, \\theta^{(20)}, \\theta^{(30)}, \\dots, \\theta^{(16000)}\\}\\). Scartando campioni intermedi, è possibile rimuovere le forti correlazioni che sono presenti nel caso di lag più piccoli.Vediamo ora come sia possibile estrarre valodi di una catena dall’oggetto stanfit1.La prima catena può essere isolata nel modo seguente:Una serie temporale della catena si ottiene con la funzione ggmcmc::ggs_running:Il grafico precedente mostra che, per il modello bayesiano che stiamo discutendo, una condizione di equilibrio della catena di Markov richiederebbe un numero maggiore di iterazioni di quelle che sono state effettivamente simulate.L’autocorrelazione di ordine 1 si ottiene nel modo seguente (si veda il Paragrafo 18.2.9.1):Questo valore corrisponde ciò che è riportato nel correlogramma mostrato sopra.","code":"\nbayesplot::mcmc_acf(stanfit1, pars = \"theta\")\n# valori delle 4 catene\nS <- ggmcmc::ggs(stanfit1)\nhead(S)\n#> # A tibble: 6 × 4\n#>   Iteration Chain Parameter value\n#>       <dbl> <int> <fct>     <dbl>\n#> 1         1     1 theta     0.628\n#> 2         2     1 theta     0.758\n#> 3         3     1 theta     0.719\n#> 4         4     1 theta     0.715\n#> 5         5     1 theta     0.856\n#> 6         6     1 theta     0.870\nS1 <- S %>% \n  dplyr::filter(\n    Chain == 1,\n    Parameter == \"theta\"\n  )\nggmcmc::ggs_running(S1)\ncor(S1$value[-length(S1$value)], S1$value[-1])\n#> [1] 0.3819515"},{"path":"ch-diagn-markov-chains.html","id":"statistica-hatr","chapter":"Capitolo 20 Diagnostica delle catene markoviane","heading":"20.5 Statistica \\(\\hat{R}\\)","text":"precedenza abbiamo detto che non solo è necessario che ogni singola catena sia stazionaria, è anche necessario che le diverse catene siano coerenti tra loro. La statistica \\(\\hat{R}\\) affronta questo problema calcolando il rapporto tra la varianza tra le catene markoviane e la varianza entro le catene. una situazione ottimale \\(\\hat{R} = 1\\); se \\(\\hat{R}\\) è lontano da 1 questo vuol dire che non è ancora stata raggiunta la convergenza.È possibile calcolare \\(\\hat{R}\\) mediante la chiamata alla funzione bayesplot::rhat(). Per il modello Beta-Binomiale applicato ai dati di Gautret et al. (2020) abbiamo:il che indica che il valore \\(\\hat{R}\\) ottenuto è molto simile al valore ottimale.maniera euristica, si può affermare che se \\(\\hat{R}\\) supera la soglia di 1.05 questo viene interpretato come evidenza che le diverse catene parallele non producono approssimazioni coerenti della distribuzione posteriori, quindi la simulazione è instabile.Una rappresentazione grafica dei valori \\(\\hat{R}\\) per tutti parametri del modello si ottiene con la seguente chiamata:","code":"\nbayesplot::rhat(stanfit1, pars = \"theta\")\n#> [1] 1.00039\nggmcmc::ggs_Rhat(S) + xlab(\"R_hat\") + xlim(0.95, 1.05)"},{"path":"ch-diagn-markov-chains.html","id":"diagnostica-di-convergenza-di-geweke","chapter":"Capitolo 20 Diagnostica delle catene markoviane","heading":"20.6 Diagnostica di convergenza di Geweke","text":"La statistica diagnostica di convergenza di Geweke è basata su un test per l’uguaglianza delle medie della prima e dell’ultima parte di una catena di Markov (di default il primo 10% e l’ultimo 50% della catena). Se due campioni sono estratti dalla distribuzione stazionaria della catena, le due medie sono statisticamente uguali e la statistica di Geweke ha una distribuzione asintotica Normale standardizzata.Utilizzando l’oggetto stanfit1, possiamo recuperare la statistica di Geweke nel modo seguente:Per interpretare questi valori ricordiamo che la statistica di Geweke è uguale zero quando le medie delle due porzioni della catena di Markov sono uguali. Valori maggiori di \\(\\mid 2 \\mid\\) suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria.","code":"\nfit_mcmc <- As.mcmc.list(\n  stanfit1,\n  pars = c(\"theta\")\n)\ncoda::geweke.diag(fit_mcmc, frac1 = .1, frac2 = .5) \n#> [[1]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#>  theta \n#> -0.017 \n#> \n#> \n#> [[2]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#>  theta \n#> 0.6504 \n#> \n#> \n#> [[3]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#>    theta \n#> -0.04024 \n#> \n#> \n#> [[4]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#> theta \n#> 1.315"},{"path":"ch-sintesi-distr-post.html","id":"ch-sintesi-distr-post","chapter":"Capitolo 21 Sintesi a posteriori","heading":"Capitolo 21 Sintesi a posteriori","text":"La distribuzione posteriori è un modo per descrivere il nostro grado di incertezza rispetto al parametro incognito (o rispetto ai parametri incogniti) oggetto dell’inferenza. La distribuzione posteriori contiene tutte le informazioni disponibili sui possibili valori del parametro. Se il parametro esaminato è monodimensionale (o bidimensionale) è possibile fornire un grafico di tutta la distribuzione posteriori \\(p(\\theta \\mid y)\\). Tuttavia, spesso vogliamo anche giungere ad una sintesi numerica della distribuzione posteriori, soprattutto se il vettore dei parametri ha più di due dimensioni. questo proposito è possibile utilizzare le consuete statistiche descrittive, come media, mediana, moda, varianza, deviazione standard e quantili. alcuni casi, queste statistiche descrittive sono più facili da presentare e interpretare rispetto alla rappresentazione grafica della distribuzione posteriori.La stima puntuale della tendenza centrale della distribuzione posteriori fornisce informazioni su quello che può essere considerato come il “valore più plausibile” del parametro. L’intervallo di credibilità fornisce invece un’indicazione dell’ampiezza dell’intervallo che contiene una determinata quota della massa della distribuzione posteriori del parametro.","code":""},{"path":"ch-sintesi-distr-post.html","id":"stima-puntuale","chapter":"Capitolo 21 Sintesi a posteriori","heading":"21.1 Stima puntuale","text":"Per sintetizzare la distribuzione posteriori modo da giungere ad\nuna stima puntuale di \\(\\theta\\) si è soliti scegliere tra moda, mediana o media seconda del tipo di distribuzione con cui si ha che fare e\ndella sua forma. Ogni stima puntuale ha una sua interpretazione.La media è il valore atteso posteriori del parametro.La moda può essere interpretata come il singolo valore più credibile (“più plausibile”) del parametro, alla luce dei dati, ovvero il valore per il parametro \\(\\theta\\) che massimizza la distribuzione posteriori. Per questa ragione la moda viene detta massimo posteriori, MAP. Il limite della moda quale statistica riassuntiva della distribuzione posteriori è che, talvolta, tale distribuzione è multimodale e il MAP non è necessariamente il valore “più credibile”.La mediana è il valore del parametro tale per cui, su entrambi lati di essa, giace il 50% della massa di probabilità posteriori.La misura di variabilità del parametro è la varianza posteriori\nla quale, nel caso di una distribuzione posteriori ottenuta per via\nnumerica, si calcola con la formula della varianza che conosciamo\nrispetto alla tendenza centrale data dalla media posteriori. La radice quadrata della varianza posteriori è la deviazione standard posteriori che descrive l’incertezza posteriori circa il parametro di interesse nella stessa unità di misura dei dati.Le procedure bayesiane basate sui metodi MCMC utilizzano un numero finito di campioni dalla distribuzione stazionaria, e una tale caratteristica della simulazione introduce un ulteriore livello di incertezza nella stima del parametro. L’errore standard della stima (inglese Monte Carlo standard error, MCSE) misura l’accuratezza della simulazione. La deviazione standard posteriori e l’errore standard della stima sono due concetti completamente diversi. La deviazione standard posteriori descrive l’incertezza circa il parametro (l’ampiezza della distribuzione posteriori) ed è una funzione della dimensione del campione; il MCSE descrive invece l’incertezza nella stima del parametro dovuta alla simulazione MCMC ed è una funzione del numero di iterazioni nella simulazione.","code":""},{"path":"ch-sintesi-distr-post.html","id":"intervallo-di-credibilità","chapter":"Capitolo 21 Sintesi a posteriori","heading":"21.2 Intervallo di credibilità","text":"Molto spesso la stima puntuale è accompagnata da una stima intervallare (abbiamo già incontrato questo aspetto nel Capitolo 16 discutendo lo schema beta-binomiale). Nella statistica bayesiana, se il parametro \\(\\theta \\\\Theta\\) è monodimensionale, si dice intervallo di credibilità un intervallo di valori \\(I_{\\alpha}\\) che contiene la proporzione \\(1 - \\alpha\\) della massa di probabilità della funzione posteriori:\\[\\begin{equation}\np(\\Theta \\I_{\\alpha} \\mid y) = 1 - \\alpha.\n\\tag{21.1}\n\\end{equation}\\]L’intervallo di credibilità ha lo scopo di esprimere il nostro grado di incertezza riguardo la stima del parametro. Se il parametro \\(\\theta\\) è multidimensionale, si parla invece di “regione di credibilità”.La condizione (21.1) non determina un unico intervallo di\ncredibilità al \\((1 - \\alpha) \\cdot 100\\%\\). realtà esiste un numero\ninfinito di tali intervalli. Ciò significa che dobbiamo definire alcune\ncondizioni aggiuntive per la scelta dell’intervallo di credibilità.\nEsaminiamo due delle condizioni aggiuntive più comuni.","code":""},{"path":"ch-sintesi-distr-post.html","id":"intervallo-di-credibilità-a-code-uguali","chapter":"Capitolo 21 Sintesi a posteriori","heading":"21.2.1 Intervallo di credibilità a code uguali","text":"Un intervallo di credibilità code uguali livello \\(\\alpha\\) è un intervallo\\[\nI_{\\alpha} = [q_{\\alpha/2}, 1 - q_{\\alpha/2}],\n\\]dove \\(q_z\\) è un quantile \\(z\\) della distribuzione posteriori. Per esempio, l’intervallo di credibilità code uguali al 95% è un intervallo\\[\nI_{0.05} = [q_{0.025}, q_{0.975}]\n\\]che lascia il 2.5% della massa di densità posteriori ciascuna coda.","code":""},{"path":"ch-sintesi-distr-post.html","id":"intervallo-di-credibilità-a-densità-a-posteriori-più-alta","chapter":"Capitolo 21 Sintesi a posteriori","heading":"21.2.2 Intervallo di credibilità a densità a posteriori più alta","text":"Nell’intervallo di credibilità code uguali alcuni valori del parametro che sono inclusi nell’intervallo possono avere una credibilità posteriori più bassa rispetto quelli esterni ’intervallo. L’intrevallo di credibilità densità posteriori più alta (inglese High Posterior Density Interval, HPD) è invece costruito modo tale da assicurare di includere nell’intervallo tutti valori \\(\\theta\\) che sono posteriori maggiormente credibili. Graficamente questo intervallo può essere ricavato tracciando una linea orizzontale sulla rappresentazione della distribuzione posteriori e regolando l’altezza della linea modo tale che l’area sottesa alla curva sia pari \\(1 - \\alpha\\). Questo tipo di intervallo è il più stretto possibile, tra tutti possibili intervalli di credibilità allo stesso livello di fiducia. Se la distribuzione posteriori è simmetrica unimodale, l’intervallo di credibilità densità posteriori più alta corrisponde ’intervallo di credibilità code uguali.","code":""},{"path":"ch-sintesi-distr-post.html","id":"interpretazione-1","chapter":"Capitolo 21 Sintesi a posteriori","heading":"21.2.3 Interpretazione","text":"L’interpretazione dell’intervallo di credibilità è molto intuitiva:\nl’intervallo di credibilità è un intervallo di valori ’interno del\nquale cade il valore del parametro incognito con un particolare livello\ndi probabilità soggettiva. Possiamo dire che, dopo aver visto dati\ncrediamo, con un determinato livello di probabilità soggettiva, che il\nvalore del parametro (ad esempio, la dimensione dell’effetto di un\ntrattamento) abbia un valore compreso ’interno dell’intervallo che è\nstato calcolato, laddove per probabilità soggettiva intendiamo “il grado di fiducia che lo sperimentatore ripone nel verificarsi di un evento”. Gli intervalli di credibilità si calcolano con un software.","code":""},{"path":"ch-sintesi-distr-post.html","id":"un-esempio-concreto","chapter":"Capitolo 21 Sintesi a posteriori","heading":"21.3 Un esempio concreto","text":"Per fare un esempio pratico, consideriamo nuovamente valori del BDI-II dei 30 soggetti clinici di Zetsche, Bürkner, Renneberg (2019):Un valore BDI-II \\(\\geq 30\\) indica la presenza di un livello “grave” di depressione. Nel campione clinico di Zetsche, Bürkner, Renneberg (2019),17 pazienti su 30 manifestano un livello grave di depressione.Supponiamo di volere stimare la distribuzione posteriori della probabilità \\(\\theta\\) di depressione “grave” nei pazienti clinici, così come viene misurata dal test BDI-II, imponendo su \\(\\theta\\) una distribuzione priori \\(\\mbox{Beta}(8, 2)\\).Sappiamo che il modello Beta-Binomiale può essere espresso nella forma seguente:\\[\\begin{align}\nY | \\theta & \\sim \\mbox{Bin}(30, \\theta) \\notag\\\\\n\\theta & \\sim \\mbox{Beta}(8, 2) \\notag\n\\end{align}\\]con una corrispondente distribuzione posteriori \\(\\mbox{Beta}(25, 15)\\):\\[\\begin{equation}\nf(\\theta | y = 17) = \\frac{\\Gamma(25 + 15)}{\\Gamma(25)\\Gamma(15)}\\theta^{25-1} (1-\\theta)^{15-1} \\;\\; \\text{ } \\theta \\[0,1] \\; .\n\\tag{21.2}\n\\end{equation}\\]","code":"\nsuppressPackageStartupMessages(library(\"bayesrules\")) \n\ndf <- tibble(\n  y = c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n        24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n        41, 36, 26, 35, 33, 28, 27, 34, 27, 22)\n)\nsum(df$y > 29)\n#> [1] 17\nplot_beta_binomial(alpha = 8, beta = 2, y = 17, n = 30)"},{"path":"ch-sintesi-distr-post.html","id":"stime-puntuali-della-distribuzione-a-posteriori","chapter":"Capitolo 21 Sintesi a posteriori","heading":"21.3.1 Stime puntuali della distribuzione a posteriori","text":"Una volta trovata l’intera distribuzione posteriori, quale valore di\nsintesi è necessario riportare? Questa sembra una domanda innocente, ma\nrealtà è una domanda cui è difficile rispondere. La stima bayesiana dei parametri è fornita dall’intera distribuzione posteriori, che non è un singolo numero, ma una funzione che mappa ciascun valore del parametro ad un valore di plausibilità. Quindi non è necessario scegliere una stima puntuale. linea di principio, una stima puntuale non è quasi mai necessaria ed è spesso dannosa quanto comporta una perdita di informazioni.Tuttavia talvolta una tale sintesi è richiesta. Diverse risposte sono allora possibili. La media della distribuzione posteriori per \\(\\theta\\) è\\[\n\\E(\\pi \\mid y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25+15} = 0.625.\n\\]Una stima del massimo della probabilità posteriori, o brevemente massimo posteriori, MAP (da maximum posteriori probability), è la moda della distribuzione posteriori. Nel caso presente, una stima del MAP può essere ottenuta nel modo seguente:\\[\n\\Mo(\\pi \\mid y = 17) = \\frac{\\alpha-1}{\\alpha + \\beta-2} = \\frac{25-1}{25+15-2} = 0.6316.\n\\]Gli stessi risultati si ottiengono usando la chiamata bayesrules::summarize_beta_binomial():La mediana si ottiene con","code":"\nsummarize_beta_binomial(alpha = 8, beta = 2, y = 17, n = 30)\n#>       model alpha beta  mean      mode         var        sd\n#> 1     prior     8    2 0.800 0.8750000 0.014545455 0.1206045\n#> 2 posterior    25   15 0.625 0.6315789 0.005716463 0.0756073\nqbeta(.5, shape1 = 25, shape2 = 15)\n#> [1] 0.6271031"},{"path":"ch-sintesi-distr-post.html","id":"intervallo-di-credibilità-1","chapter":"Capitolo 21 Sintesi a posteriori","heading":"21.3.2 Intervallo di credibilità","text":"È più comune sintetizzare la distribuzione posteriori mediante l’intervallo di credibilità. Per esempio, l’intervallo di credibilità code uguali al 95%è dato dalla chiamataIl calcolo precedente evidenzia l’interpretazione intuitiva dell’intervallo di credibilità. Tale intervallo, infatti, può essere interpretato come la probabilità che \\(\\theta\\) assuma valori compresi tra 0.472 e 0.766:\\[\nP(\\theta \\(0.472, 0.766) | Y = 17) = \\int_{0.472}^{0.766} f(\\theta \\mid y=17) d\\theta = 0.95,\n\\]ovveroPossiamo costruire diversi intervalli di credibilità code equivalenti. Ad esempio, l’intervallo di credibilità compreso tra il 25-esimo e il 75-esimo percentile èovvero, abbiamo una certezza posteriori del 50% che la probabilità di depressione grave tra pazienti clinici sia un valore compreso tra 0.57 e 0.68.Non esiste un livello credibile “corretto”. ricercatori, utilizzano vari livelli, ad esempio 50%, 80% o 95%, seconda del contesto dell’analisi. Ciascuno di questi intervalli fornisce un’immagine diversa della nostra comprensione della distribuzione posteriori del parametro di interesse.Non è inoltre necessario riportare l’intervallo di credibilità code uguali. Se la distribuzione posteriori è fortemente asimmetrica è più sensato riportare l’intervallo di credibilità densità posteriori più alta.\nL’intervallo HPD risulta più semplice da determinare quando la distribuzione posteriori viene approssimata con il metodo MCMC.","code":"\nplot_beta_ci(alpha = 25, beta = 15, ci_level = 0.95)\nqbeta(c(0.025, 0.975), 25, 15)\n#> [1] 0.4717951 0.7663607\npostFun <- function(theta) {\n  gamma(25 + 15) / \n    (gamma(25) * gamma(15)) * theta^24 * (1 - theta)^14\n}\nintegrate(\n  postFun, \n  lower = 0.4717951, \n  upper = 0.7663607\n)$value\n#> [1] 0.95\nqbeta(c(0.25, 0.75), 25, 15)\n#> [1] 0.5743878 0.6778673"},{"path":"ch-sintesi-distr-post.html","id":"probabilità-della-distribuzione-a-posteriori","chapter":"Capitolo 21 Sintesi a posteriori","heading":"21.3.3 Probabilità della distribuzione a posteriori","text":"Il test di ipotesi è un compito comune dell’analisi della distribuzione posteriori (si veda anche il Capitolo 16). Supponiamo che si voglia conoscere la probabilità posteriori che \\(\\theta\\) sia superiore 0.5. Per sapere quanto credibile sia l’evento \\(\\theta > 0.5\\) possiamo calcolare il seguente integrale:\\[\nP(\\theta > 0.5 \\; \\mid \\; y = 17) = \\int_{0.5}^{1}f(\\theta \\mid y=17)d\\theta \\;,\n\\]dove \\(f(\\cdot)\\) è la distribuzione \\(\\mbox{\\Beta}(25, 15)\\):il che è equivalente :È anche possibile formulare un test di ipotesi contrastando due ipotesi contrapposte. Per esempio, \\(H_1: \\theta \\geq 0.5\\) e \\(H_2: \\theta < 0.5\\). Ciò consente di calcolare l’odds posteriori di \\(\\theta > 0.5\\):\\[\\begin{equation}\n\\text{poterior odds} = \\frac{H_1 \\mid y = 17}{H_2 \\mid y = 17}\n\\end{equation}\\]ovveroL’odds posteriori rappresenta l’aggiornamento delle nostre credenze dopo avere osservato \\(y = 17\\) \\(n = 30\\). L’odds priori di \\(\\theta > 0.5\\) era:Il fattore di Bayes (Bayes Factor; BF) confronta gli odds posteriori con gli odds priori e quindi fornisce informazioni su quanto sia mutata la nostra comprensione relativa \\(\\theta\\) dopo avere osservato nostri dati del campione:\\[\n\\text{BF} = \\frac{\\text{odds posteriori}}{\\text{odds priori}}.\n\\]Nel caso presente abbiamoQuindi, dopo avere osservato dati, gli odds posteriori della nostra ipotesi proposito di \\(\\theta\\) sono pari solo il 34% degli odds priori.Per fare un altro esempio, consideriamo invece il caso cui le credenze priori rivelano una credenza diametralmente opposta rispetto \\(\\theta\\) che nel caso considerato precedenza, ovvero \\(\\mbox{Beta}(2, 8)\\). questo secondo caso, la distribuzione posteriori diventae il BF èIn alre parole, questo secondo esempio gli odds posteriori della nostra ipotesi proposito di \\(\\theta\\) sono aumentati di 30 volte rispetto agli odds priori.generale, un test di ipotesi che contrappone un’ipotesi sostantiva \\(H_a\\) ad un’ipotesi nulla \\(H_0\\) il BF è un rapporto di odds per l’ipotesi sostantiva:\\[\n\\text{Bayes Factor}\n= \\frac{\\text{posterior odds}}{\\text{prior odds}}\n= \\frac{P(H_a \\mid Y) / P(H_0 \\mid Y)}{P(H_a) / P(H_0)}\n\\; .\n\\]Essendo un rapporto, il BF deve esere valutato rispetto al valore di 1. Ci sono tre possibilità:BF = 1: La credibilità di \\(H_a\\) non è cambiata dopo avere osservato dati.BF > 1: La credibilità di \\(H_a\\) è aumentata dopo avere osservato dati. Quindi maggiore è BF, più convincente risulta l’evidenza per \\(H_a\\).BF < 1: La credibilità di \\(H_a\\) è diminuita dopo avere osservato dati.Non ci sono delle soglie universalmente riconosciute per interpretare il BF. Per esempio, Lee Wagenmakers (2014) propongono il seguente schema:Tuttavia, è importante notare che l’opinione maggiormente diffusa nella comunità scientifica sia quella che incoraggia non trarre conclusioni rigide dai dati utilizzando dei criteri fissati una volta per tutte. Pertanto, non esiste una soglia univoca per il BF che consente di classificare le ipotesi dei ricercatori nelle due categorie “vero” o “falso”. Invece, è più utile adottare una pratica più flessibile capace di tenere considerazione il contesto e le potenziali implicazioni di ogni singolo test di ipotesi. Inoltre, è stato molte volte ripetuto che la distribuzione posteriori è molto più informativa di una decisione binaria: la rappresentazione di tutta la distribuzione posteriori fornisce una misura olistica del nostro livello di incertezza riguardo ’affermazione (il parametro, ovvero l’ipotesi) che viene valutata.","code":"\npbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = FALSE)\n#> [1] 0.9459355\npostFun <- function(theta) {\n  gamma(25 + 15) / (gamma(25) * gamma(15)) * theta^24 * (1 - theta)^14\n}\nintegrate(\n  postFun, \n  lower = 0.5, \n  upper = 1\n)$value\n#> [1] 0.9459355\nposterior_odds <- \n  pbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = TRUE)\nposterior_odds\n#> [1] 17.49642\nprior_odds <- \n  pbeta(0.5, shape1 = 8, shape2 = 2, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 8, shape2 = 2, lower.tail = TRUE)\nprior_odds\n#> [1] 50.2\nBF <- posterior_odds / prior_odds\nBF\n#> [1] 0.3485343\nsummarize_beta_binomial(alpha = 2, beta = 8, y = 17, n = 30)\n#>       model alpha beta  mean      mode         var         sd\n#> 1     prior     2    8 0.200 0.1250000 0.014545455 0.12060454\n#> 2 posterior    19   21 0.475 0.4736842 0.006082317 0.07798921\nposterior_odds <- \n  pbeta(0.5, shape1 = 19, shape2 = 21, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 19, shape2 = 21, lower.tail = TRUE)\n\nprior_odds <- \n  pbeta(0.5, shape1 = 2, shape2 = 8, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 2, shape2 = 8, lower.tail = TRUE)\n\nBF <- posterior_odds / prior_odds\nBF\n#> [1] 30.07239"},{"path":"ch-sintesi-distr-post.html","id":"la-funzione-di-perdita-attesa","chapter":"Capitolo 21 Sintesi a posteriori","heading":"21.4 La funzione di perdita attesa","text":"Un modo razionale per giungere ad una decisione statistica utilizzando l’intera distribuzione posteriori è quello di usare la funzione di perdita (loss function). La funzione di perdita è concetto nella teoria delle decisioni statistiche che consente di quantificare il costo derivante dalla decisione di scegliere quale stima del parametro il valore \\(\\theta_0\\) quando esso realtà ha il valore \\(\\theta\\).Per chiarire che cosa si intende per funzione di perdita, esaminiamo qui un semplice esempio nel quale vengono considerati due soli valori di probabilità per l’evento target, anziché l’intera distribuzione posteriori (il codice è ricavato da Schmettow 2021).Si consideri la scelta di prendere o meno l’ombrello nell’uscire di casa. Le previsioni del tempo sono le seguenti:Le azioni possibili sono: prendo / non prendo l’ombrello:Assegniamo un costo massimo (4) alla conseguenza peggiore (“non prendo l’ombrello e piove”) e uno minimo (0) alla conseguenza migliore (“non prendo l’ombrello e non piove”):Calcoliamo ora il costo atteso delle due azioni tenuto conto delle probabilità che si verifichi l’uno o l’altro stato del mondo (ricordiamo che piove/non piove hanno una probabilità rispettivamente del 40% e del 60%), ovvero ponderiamo il costo di ogni azione con la probabilità che si verifichi l’evento corrispondente:La regola di minimizzazione dei costi induce scegliere l’alternativa che comporta il valore più basso: nel nostro esempio “prendere l’ombrello”.La stessa logica dell’esempio può essere usata anche nel momento cui, anziché avere solo due valori per la probabilità dello stato del mondo questione (per esempio, pioverà / non pioverà), utilizziamo l’intera distribuzione posteriori (per esempio, quella relativa alla previsione di pioggia). Concludiamo questi brevi accenni relativi alla funzione di perdita con una considerazione di McElreath (2020) il quale nota che, anche se gli statistici e teorici dei giochi sono da tempo interessati alle funzioni di perdita e alle relazioni che intercorrono tra esse e l’inferenza bayesiana, ricercatori non le usano quasi mai modo esplicito.","code":"\nRisultato <-\n  tibble(\n    risultato = c(\"piove\", \"non piove\"),\n    prob = c(0.6, 0.4)\n  )\nRisultato\n#> # A tibble: 2 × 2\n#>   risultato  prob\n#>   <chr>     <dbl>\n#> 1 piove       0.6\n#> 2 non piove   0.4\nAzione <-\n  tibble(azione = c(\"prendo l'ombrello\", \"non prendo l'ombrello\"))\nAzione\n#> # A tibble: 2 × 1\n#>   azione               \n#>   <chr>                \n#> 1 prendo l'ombrello    \n#> 2 non prendo l'ombrello\nCosti <-\n  expand.grid(\n    azione = Azione$azione,\n    risultato = Risultato$risultato\n  ) %>%\n  inner_join(Risultato) %>%\n  mutate(costo = c(2, 4, 2, 0))\nCosti\n#>                  azione risultato prob costo\n#> 1     prendo l'ombrello     piove  0.6     2\n#> 2 non prendo l'ombrello     piove  0.6     4\n#> 3     prendo l'ombrello non piove  0.4     2\n#> 4 non prendo l'ombrello non piove  0.4     0\nUtil <-\n  Costi %>%\n  mutate(costo_condizionato = prob * costo) %>%\n  group_by(azione) %>%\n  summarise(costo_atteso = sum(costo_condizionato))\nUtil\n#> # A tibble: 2 × 2\n#>   azione                costo_atteso\n#>   <fct>                        <dbl>\n#> 1 prendo l'ombrello              2  \n#> 2 non prendo l'ombrello          2.4"},{"path":"ch-sintesi-distr-post.html","id":"commenti-e-considerazioni-finali-16","chapter":"Capitolo 21 Sintesi a posteriori","heading":"Commenti e considerazioni finali","text":"Questo capitolo introduce le procedure di base per la manipolazione\ndella distribuzione posteriori. Lo strumento fondamentale che è stato\nutilizzato è quello fornito dai campioni di valori del parametro che vengono estratti dalla distribuzione posteriori. Lavorare con campioni di valori del parametro estratti dalla distribuzione posteriori trasforma un problema di calcolo integrale un problema di riepilogo dei dati. Abbiamo visto le procedure maggiormente usate che consentono di utilizzare campioni \nposteriori per produrre indici di sintesi della distribuzione \nposteriori: gli intervalli di credibilità e le stime puntuali.","code":""},{"path":"ch-prediction.html","id":"ch-prediction","chapter":"Capitolo 22 La predizione bayesiana","heading":"Capitolo 22 La predizione bayesiana","text":"Oltre ad una sintesi della distribuzione posteriori attraverso il computo di indici caratteristici e alla verifica di ipotesi, un altro compito dell’analisi bayesiana è la predizione di nuovi dati futuri. Dopo aver osservato dati di un campione e dopo avere ricavato le distribuzioni posteriori dei parametri, è infatti possibile ottenere delle indicazioni sulle proprietà di dati futuri. L’uso più immediato della stima della distribuzione dei possibili valori futuri della variabile di esito è la verifica del modello. Infatti, il modo più diretto per testare un modello è quello di utilizzare il modello per fare previsioni sui possibili dati futuri per poi confrontare dati predetti con dati effettivi. Questa pratica va sotto il nome di controllo predittivo posteriori. questo capitolo ci focalizzeremo sul problema della predizione bayesiana esaminando il caso più semplice, ovvero lo schema beta-binomiale. seguito estenderemo questa discussione al caso generale.","code":""},{"path":"ch-prediction.html","id":"la-distribuzione-predittiva","chapter":"Capitolo 22 La predizione bayesiana","heading":"22.1 La distribuzione predittiva","text":"Una volta costruita la distribuzione posteriori del parametro \\(\\theta\\), potremmo essere interessati utilizzare il nostro modello statistico allo scopo di prevedere la probabilità di risultati futuri basandosi sui dati storici. L’obiettivo è andare oltre la comprensione di cosa è successo per arrivare una migliore valutazione di quello che accadrà futuro. Questo tipo di analisi inferenziale va sotto il nome di analisi predittiva. L’analisi predittiva utilizza dati che sono già disponibili per sviluppare un modello che può essere usato per prevedere valori di dati diversi o nuovi.L’esempio che considereremo nei dettagli riguarda il caso beta-binomiale, nel quale la distribuzione priori per il parametro \\(\\theta\\) (probabilità di successo) è una distribuzione Beta, la verosimiglianza è binomiale e dati sono costituiti dal numero \\(y\\) di successi \\(n\\) prove Bernoulliane indipendenti. Nell’esempio che discuteremo useremo un’altra volta dati del campione di pazienti clinici depressi di Zetsche, Bürkner, Renneberg (2019) – si veda l’Appendice ??. Supponendo di volere esaminare futuro altri \\(m\\) pazienti clinici, ci chiediamo: quanti di essi manifesteranno una depressione grave?Siamo interessati predire risultati che si potrebbero osservare nuovi campioni di \\(m\\) osservazioni. Denotiamo con \\(\\tilde{y}\\) la manifestazione della variabile casuale \\(\\tilde{Y}\\). un nuovo campione di \\(m\\) osservazioni, \\(\\tilde{y}\\) potrà assumere il valore \\(\\tilde{y}_1\\), un altro campione potrà assumere il valore \\(\\tilde{y}_2\\), e così via. Siamo interessati descrivere la distribuzione predittiva posteriori \\(p(\\tilde{Y} = \\tilde{y} \\mid Y = y)\\), ovvero, siamo interessati descrivere la verosimiglianza relativa di ciascuno di questi possibili valori.Nel caso dell’esempio discussione, la distribuzione di \\(\\tilde{Y}\\) dipende da \\(\\theta\\) e ciò che sappiamo di \\(\\theta\\) è sintetizzato nella distribuzione posteriori. Usando la regola della catena, possiamo scrivere la distribuzione congiunta di \\(\\tilde{Y}\\) e \\(\\theta\\) nel modo seguente\\[\\begin{equation}\np(\\tilde{Y} = \\tilde{y}, \\theta \\mid Y = y) = p(\\tilde{Y} = \\tilde{y} \\mid \\theta) p(\\theta \\mid Y = y).\n\\end{equation}\\]La distribuzione predittiva posteriori può essere ottenuta integrando rispetto \\(\\theta\\) la distribuzione congiunta:\\[\\begin{equation}\np(\\tilde{y} \\mid y) = \\int_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta.\n\\tag{14.6}\n\\end{equation}\\]Nel caso dello schema beta-binomiale, la funzione \\(p(\\tilde{y} \\mid \\theta)\\) è binomiale di parametri \\(m\\) e \\(\\theta\\), e la distribuzione posteriori \\(p(\\theta \\mid y)\\) è \\(\\mbox{Beta}(\\alpha + y, \\beta + n - y)\\). Risolvendo l’integrale otteniamo:\\[\\begin{align}\np(\\tilde{y} \\mid y) &= \\int_0^1 p(\\tilde{y} \\mid \\theta)\np(\\theta \\mid y)\\,\\operatorname {d}\\!\\theta \\notag\\\\\n&= \\int_0^1 \\begin{pmatrix}m\\\\\\tilde{y}\\end{pmatrix}\n\\theta^{\\tilde{y}}\n(1-\\theta)^{m-\\tilde{y}} \\, \\mbox{Beta}(+y,b+n-y) \\, d\\theta \\notag\\\\\n&= \\begin{pmatrix}{m}\\\\\\tilde{y}\\end{pmatrix} \\int_0^1 \\theta^{\\tilde{y}}\n(1-\\theta)^{m-\\tilde{y}} \\frac{1}{B(+y, b+n-y)}\\theta^{+y-1}(1-\\theta)^{b+n-y-1}\\notag\\\\\n&= \\begin{pmatrix}{ m }\\\\\\tilde{y}\\end{pmatrix} \\frac{1}{B(+y, b+n-y)}\\int_0^1 \\theta^{\\tilde{y}++y-1}(1-\\theta)^{m-\\tilde{y}+b+n-y-1}\\notag\\\\\n&= \\begin{pmatrix}{ m }\\\\\\tilde{y}\\end{pmatrix} \\frac{B(\\tilde{y}++y,b+n-y+m-\\tilde{y})}{B(+y, b+n-y)} \\; .\n\\tag{22.1}\n\\end{align}\\]conclusione, per lo schema beta-binomiale, la distribuzione predittiva posteriori è\\[\\begin{equation}\nf(\\tilde{y} \\mid y) = \\binom{m}{\\tilde{y}} \\frac{B(+ y + \\tilde{y}, b + n - y + m - \\tilde{y})}{B(+y, b+n-y)},\n\\tag{22.2}\n\\end{equation}\\]ovvero, corrisponde ad una distribuzione di probabilità discreta chiamata distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha+y\\) e \\(\\beta+n-y\\).Nell’esempio che stiamo discutendo, relativo allo studio di Zetsche, Bürkner, Renneberg (2019), la verosimiglianza è binomiale, dati sono costituiti da 23 successi su 30 prove e la distribuzione priori su \\(\\theta\\) è \\(\\mbox{Beta}(2, 10)\\). Di conseguenza, la distribuzione posteriori è \\(\\mbox{Beta}(25, 17)\\). Vogliamo calcolare la distribuzione predittiva posteriori per un nuovo campione, poniamo, di \\(m = 20\\) osservazioni.base alla (22.2) sappiamo che la distribuzione predittiva posteriori è una distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha+y\\) e \\(\\beta+n-y\\), dove \\(m\\) è il numero di prove nel nuovo campione, \\(\\alpha\\) e \\(\\beta\\) sono parametri della distribuzione priori, e \\(y\\) e \\(n\\) sono le proprietà del campione corrente. Nel caso dell’esempio discussione, \\(m = 20\\), \\(\\alpha = 2 + 23 = 25\\), \\(\\beta = 10 + 30 - 23 = 17\\). Possiamo svolgere calcoli con le funzioni del pacchetto extraDistr. Un grafico della distribuzione predittiva posteriori si ottiene nel modo seguente:La distribuzione predittiva posteriori illustrata nella figura precedente ci dice qual è la plausibilità relativa di osservare \\(0, 1, \\dots, 20\\) successi su \\(m = 20\\) prove un futuro campione di osservazioni, considerati dati che abbiamo osservato nel campione corrente (23 successi 30 prove), e tenuto conto delle nostre opinioni precedenti sul valore \\(\\theta\\) (ovvero, \\(\\mbox{Beta}(2, 10)\\)).Esaminando la distribuzione predittiva notiamo che, nei possibili campioni futuri di 20 osservazioni, il valore \\(\\tilde{y}\\) più plausibile è 12. Tuttavia, \\(\\tilde{y}\\) può assumere anche altri valori e la distribuzione predittiva ci informa sulla plausibilità relativa di ciascuno dei possibili valori futuri \\(\\tilde{y}\\) – nel caso dell’esempio, \\(\\tilde{y}\\) corrisponde al numero di pazienti clinici (su 20) che manifestano una depressione grave.È desiderabile costruire un intervallo che contiene le realizzazioni della \\(\\tilde{Y}\\) ad un livello specificato di probabilità. Supponiamo che il livello di probabilità richiesto sia 0.89. L’intervallo si costruisce aggiungendo valori \\(\\tilde{y}\\) ’intervallo fino che il contenuto di probabilità dell’insieme eccede la soglia di 0.89. La procedura è implementata nella funzione discint() del pacchetto LearnBayes. Per dati dell’esempio otteniamoda cui\\[\nP(8 \\leq \\tilde{Y} \\leq 16) = 0.9145.\n\\]","code":"\nprob <- extraDistr::dbbinom(0:20, 20, 25, 17)\ntibble(Y=0:20, Probability = prob) %>% \n  ProbBayes::prob_plot(Color = \"black\")\nLearnBayes::discint(cbind(0:20, prob), 0.89)\n#> $prob\n#> [1] 0.9144721\n#> \n#> $set\n#> [1]  8  9 10 11 12 13 14 15 16"},{"path":"ch-prediction.html","id":"la-distribuzione-predittiva-a-posteriori-mediante-simulazione","chapter":"Capitolo 22 La predizione bayesiana","heading":"22.2 La distribuzione predittiva a posteriori mediante simulazione","text":"situazioni dove è difficile derivare l’esatta distribuzione predittiva posteriori è possibile simulare valori estratti da tale distribuzione. Consideriamo un esempio riferito ’esempio che stiamo discutendo. È possibile implementare una simulazione predittiva estraendo prima valori del parametro (questo caso, \\(\\theta\\)) dalla distribuzione posteriori. Con valori del parametro così determinati, poi, si possono generare valori delle possibili osservazioni future (nel caso presente, usando la distribuzione binomiale).Per l’esempio che stiamo discutendo, la distribuzione posteriori è una Beta(25, 17). Estaiamo 100,000 valori da tale distribuzione:Confrontiamo valori prodotti dalla simulazione con valori esatti della distribuzione predittiva posteriori:La distribuzione predittiva posteriori esatta èUna rappresentazione della distribuzione posteriori ottenuta mediante simulazione èSi noti la somiglianza tra le due distribuzioni.conclusione, per il caso che abbiamo discusso, la predizione bayesiana di una nuova osservazione è una distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha + y\\), e \\(\\beta + n - y\\), dove \\(m\\) è il numero di prove nel nuovo campione, \\(\\alpha\\) e \\(\\beta\\) sono parametri della distribuzione priori, e \\(y\\) e \\(n\\) sono le quantità della verosimiglianza. Ricordiamo che, nello schema beta-binomiale, la distribuzione posteriori è una Beta di parametri \\(\\alpha + y\\) e \\(\\beta + n - y\\). Quindi, detto un altro modo, nello schema beta-binomiale la distribuzione predittiva posteriori è una distribuzione beta-binomiale cui tre parametri sono \\(m\\) (la numerosità del nuovo campione) e due parametri di forma della distribuzione Beta che descrive la distribuzione posteriori.","code":"\nset.seed(12345)\na <- 2\nb <- 10\nn <- 30\ny <- 23\npred_p_sim <- rbeta(1e5, a + y, b + n - y)\npred_y_sim <- rbinom(1e5, n, pred_p_sim)\nppd <- table(pred_y_sim) / 1e5\nppd\n#> pred_y_sim\n#>       3       4       5       6       7       8       9      10      11      12 \n#> 0.00002 0.00004 0.00011 0.00036 0.00096 0.00241 0.00533 0.01000 0.01753 0.02882 \n#>      13      14      15      16      17      18      19      20      21      22 \n#> 0.04290 0.06110 0.07812 0.09476 0.10763 0.11311 0.10821 0.09765 0.07982 0.06185 \n#>      23      24      25      26      27      28      29      30 \n#> 0.04156 0.02536 0.01299 0.00630 0.00224 0.00064 0.00016 0.00002\nLearnBayes::discint(cbind(3:30, ppd), 0.89)\n#> $prob\n#>      12 \n#> 0.91553 \n#> \n#> $set\n#> 12 13 14 15 16 17 18 19 20 21 22 23 \n#> 12 13 14 15 16 17 18 19 20 21 22 23\nprob30 <- extraDistr::dbbinom(0:30, 30, 25, 17)\nLearnBayes::discint(cbind(0:30, prob30), 0.89)\n#> $prob\n#> [1] 0.9152885\n#> \n#> $set\n#>  [1] 12 13 14 15 16 17 18 19 20 21 22 23\ntibble(Y=0:30, Probability = prob30) %>% \n  ProbBayes::prob_plot(Color = \"black\")\ntibble(Y=0:30, Probability = c(0, 0, 0, ppd)) %>% \n  ProbBayes::prob_plot(Color = \"black\")"},{"path":"ch-prediction.html","id":"la-distribuzione-predittiva-a-posteriori-mediante-mcmc","chapter":"Capitolo 22 La predizione bayesiana","heading":"22.3 La distribuzione predittiva a posteriori mediante MCMC","text":"Il metodo basato su simulazione che abbiamo discusso nel paragrafo precedente viene utilizzato per ottenere un’approssimazione della distribuzione predittiva posteriori quando l’inferenza bayesiana viene svolta mediante metodi MCMC. Le stime delle possibili osservazioni future \\(p(\\tilde{y} \\mid y)\\), chiamate \\(p(y^{rep} \\mid y)\\), si ottengono nel modo seguente:campionare \\(\\theta_i \\sim p(\\theta \\mid y)\\), ovvero campionare un valore del parametro dalla distribuzione posteriori;campionare \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\), ovvero campionare il valore di un’osservazione dalla funzione di verosimiglianza condizionata al valore del parametro definito nel passo precedente.Se due passaggi descritti sopra vengono ripetuti un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva posteriori che, teoria (ma non pratica) potrebbe essere ottenuta per via analitica.Esercizio 22.1  Riportiamo qui sotto il codice Stan per generare \\(p(y^{rep} \\mid y)\\) nel caso dell’inferenza su una proporzione.\nSi noti che nel nel blocco generated quantities sono state aggiunte le istruzioni necessarie per simulare \\(y^{rep}\\), ovvero, y_rep[n] = bernoulli_rng(theta). dati dell’esempio sono:\nCompiliamo il codice Stan\ned eseguiamo il campionamento MCMC:\nPer comodità, trasformiamo l’oggetto fit un oggetto di classe stanfit:\nIl contenuto dell’oggetto stanfit può essere esaminato nel modo seguente:\nDall’oggetto list_of_draws recuperiamo y_rep:Dato che il codice Stan definisce un modello per dati grezzi (ovvero, per ciascuna singola prova Bernoulliana del campione), ogni riga di y_bern include 30 colonne, ciascuna delle quali corrisponde ad un campione (\\(n\\) = 16000 questa simulazione) di possibili valori futuri \\(y_i \\\\{0, 1\\}\\). Per ottenere una stima della distribuzione predittiva posteriori p(y_rep), ovvero, una stima della probabilità associata ciascuno dei possibili numeri di “successi” \\(m = 30\\) nuove prove future, è sufficiente calcolare la proporzione di valori 1 ciascuna riga:Si noti che questo istogramma non può essere confrontato con quello ottenuto nella simulazione precedente dato che \\(m\\) assume un valore diverso nelle due simulazioni.","code":"\nmodelString = \"\ndata {\n  int<lower=0> N;\n  int<lower=0, upper=1> y[N];\n}\nparameters {\n  real<lower=0, upper=1> theta;\n}\nmodel {\n  theta ~ beta(2, 10);\n  y ~ bernoulli(theta);\n}\ngenerated quantities {\n  int y_rep[N];\n  real log_lik[N];\n  for (n in 1:N) {\n    y_rep[n] = bernoulli_rng(theta);\n    log_lik[n] = bernoulli_lpmf(y[n] | theta);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/betabin23-30-2-10.stan\")\ndata_list <- list(\n  N = 30,\n  y = c(rep(1, 23), rep(0, 7))\n)\nfile <- file.path(\"code\", \"betabin23-30-2-10.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  cores = 4L,\n  chains = 4L,\n  parallel_chains = 4L,\n  refresh = 0,\n  thin = 1\n)\nstanfit <- rstan::read_stan_csv(fit$output_files())\nlist_of_draws <- extract(stanfit)\nprint(names(list_of_draws))\n#> [1] \"theta\"   \"y_rep\"   \"log_lik\" \"lp__\"\ny_bern <- list_of_draws$y_rep\ndim(y_bern)\n#> [1] 16000    30\nhead(y_bern)\n#>           \n#> iterations [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n#>       [1,]    1    1    1    1    0    1    1    1    1     1     1     1     1\n#>       [2,]    0    1    0    1    1    1    0    0    1     0     0     0     0\n#>       [3,]    0    1    0    1    1    1    0    0    1     1     1     0     1\n#>       [4,]    1    0    0    1    1    0    0    1    0     1     1     1     0\n#>       [5,]    0    0    0    1    1    0    1    1    0     1     0     0     1\n#>       [6,]    1    1    1    1    1    1    0    1    0     1     1     1     0\n#>           \n#> iterations [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24]\n#>       [1,]     0     1     1     1     1     1     0     0     1     0     1\n#>       [2,]     1     0     0     1     0     1     1     1     0     0     0\n#>       [3,]     0     0     1     0     1     1     0     1     0     0     1\n#>       [4,]     0     1     0     1     0     1     0     0     1     0     1\n#>       [5,]     0     0     1     1     1     1     1     0     1     0     1\n#>       [6,]     1     1     0     1     0     1     1     0     0     1     0\n#>           \n#> iterations [,25] [,26] [,27] [,28] [,29] [,30]\n#>       [1,]     1     1     1     1     1     1\n#>       [2,]     0     1     1     0     1     1\n#>       [3,]     1     1     1     1     1     0\n#>       [4,]     0     1     1     0     0     1\n#>       [5,]     0     0     0     0     1     0\n#>       [6,]     0     0     1     0     1     1\ntibble(y_rep = rowSums(y_bern)) %>%\n  ggplot(aes(x = y_rep, after_stat(density))) +\n  geom_histogram(binwidth = 1)"},{"path":"ch-prediction.html","id":"i-metodi-per-la-valutazione-del-modello","chapter":"Capitolo 22 La predizione bayesiana","heading":"22.4 I metodi per la valutazione del modello","text":"","code":""},{"path":"ch-prediction.html","id":"posterior-predictive-checks","chapter":"Capitolo 22 La predizione bayesiana","heading":"22.4.1 Posterior predictive checks","text":"La distribuzione predittiva posteriori viene utilizzata per eseguire cosiddetti controlli predittivi posteriori (Posterior Predictive Checks, PPC). Nella distribuzione predittiva posteriori, viene generato un campione di dati possibili futuri utilizzando le proprietà del modello adattato. È ovvio che tali dati possibili futuri devono almento essere coerenti con dati del campione presente. PPC eseguono un confronto grafico tra \\(p(y^{rep} \\mid y)\\) e dati osservati \\(y\\): confrontando visivamente gli aspetti chiave dei dati previsti futuri \\(y^{rep}\\) e dei dati osservati \\(y\\) è possibile determinare se il modello è adeguato.Oltre al confronto visivo tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\) è anche possibile un confronto tra la distribuzione di varie statistiche descrittive, cui valori sono calcolati su diversi campioni \\(y^{rep}\\), e le corrispondenti statistiche calcolate sui dati osservati. Vengono solitamente considerate statistiche descrittive quali la media, la varianza, la deviazione standard, il minimo o il massimo, ma confronti di questo tipo sono possibili per qualunque altra statistica.Esercizio 22.2  Esaminiamo ora un set di dati che non seguono la distribuzione normale (Gelman, Hill, Vehtari 2020). dati corrispondono ad una serie di misurazioni prese da Simon Newcomb nel 1882 come parte di un esperimento per stimare la velocità della luce. questi dati verrà (inappropriatamente) adattata una distribuzione normale. L’obiettivo dell’esempio è quello di mostrare come PPC possono rivelare la mancanza di adattamento di un modello ai dati.PPC mostrano che il modo più semplice per verificare l’adattamento del modello è quello di visualizzare \\(y^{rep}\\) insieme ai dati effettivi. Iniziamo caricare dati:Visualizziamo la distribuzione dei dati con un istogramma:Creiamo un oggetto di tipo list dove inserire dati:Il codice Stan per il modello normale è il seguente:Adattando il modello ai datiotteniamo le seguenti stime dei parametri \\(\\mu\\) e \\(\\sigma\\):Trasformiamo fit un oggetto stanfit:La distribuzione posteriori di \\(\\mu\\) èConfrontiamo \\(\\mu\\) con la media di \\(y\\):Anche se trova la media giusta, il modello non è comunque adeguato prevedere le altre proprietà della \\(y\\). Estraiamo \\(y^{rep}\\) dall’oggetto stanfit:valori y_rep sono dati della distribuzione predittiva posteriori che sono stati simulati usando gli stessi valori \\(X\\) dei predittori utilizzati per adattare il modello. Il confronto tra l’istogramma della \\(y\\) e gli istogrammi di diversi campioni \\(y^{rep}\\) mostra una scarsa corrispondenza tra due:Alla stessa conclusione si giunge tramite un confronto tra la funzione di densità empirica della \\(y\\) e quella di diversi campioni \\(y^{rep}\\):Generiamo ora PPC per la media e il minimo della distribuzione:Mentre la media viene riprodotta accuratamente dal modello (come abbiamo visto sopra), ciò non è vero per il minimo dela distribuzione. L’origine di questa mancanza di adattamento è il fatto che la distribuzione delle misurazioni della velocità della luce è asimmetrica negativa. Dato che ci sono poche osservazioni nella coda negativa della distribuzione, solo per fare un esempio, utilizzeremo ora un secondo modello che ipotizza una distribuzione \\(t\\) di Student:Adattiamo questo secondo modello ai dati.Per questo secondo modello il confronto tra la funzione di densità empirica della \\(y\\) e quella di diversi campioni \\(y^{rep}\\) risulta adeguato:Inoltre, anche la statistica “minimo della distribuzione” viene ben predetta dal modello.conclusione, per le misurazioni della velocità della luce di Newcomb l’accuratezza predittiva del modello basato sulla distribuzione \\(t\\) di Student è chiaramente migliore di quella del modello normale.","code":"\nlibrary(\"MASS\")\ndata(\"newcomb\")\ntibble(newcomb) %>%\n  ggplot(aes(x = newcomb, after_stat(density))) +\n  geom_histogram(binwidth = 1)\ndata_list <- list(\n  y = newcomb,\n  N = length(newcomb)\n)\nmodelString <- \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  mu ~ normal(25, 10);\n  sigma ~ cauchy(0, 10);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/newcomb.stan\")\nfile <- file.path(\"code\", \"newcomb.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  cores = 4L,\n  refresh = 0,\n  thin = 1\n)\nfit$summary(c(\"mu\", \"sigma\"))\n#> # A tibble: 2 × 10\n#>   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu        26.2   26.2 1.33  1.30  24.0   28.4  1.00   13305.   11189.\n#> 2 sigma     10.9   10.8 0.958 0.943  9.40  12.5  1.00   12614.   10352.\nstanfit <- rstan::read_stan_csv(fit$output_files())\nmu_draws <- as.matrix(stanfit, pars = \"mu\")\nmcmc_areas(mu_draws, prob = 0.95) # color 95% interval\nmean(newcomb)\n#> [1] 26.21212\ny_rep <- as.matrix(stanfit, pars = \"y_rep\")\ndim(y_rep)\n#> [1] 16000    66\nppc_hist(data_list$y, y_rep[1:8, ], binwidth = 1)\nppc_dens_overlay(data_list$y, y_rep[1:50, ])\nppc_stat_2d(data_list$y, y_rep, stat = c(\"mean\", \"min\"))\nmodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n  real<lower=0> nu;\n}\nmodel {\n  mu ~ normal(25, 10);\n  sigma ~ cauchy(0, 10);\n  nu ~ cauchy(0, 10);\n  y ~ student_t(nu, mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (n in 1:N) {\n    y_rep[n] = student_t_rng(nu, mu, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/newcomb2.stan\")\nfile <- file.path(\"code\", \"newcomb2.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  cores = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\n#> Running MCMC with 4 parallel chains...\n#> \n#> Chain 1 finished in 0.3 seconds.\n#> Chain 2 finished in 0.3 seconds.\n#> Chain 3 finished in 0.3 seconds.\n#> Chain 4 finished in 0.3 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.3 seconds.\n#> Total execution time: 0.4 seconds.\nstanfit <- rstan::read_stan_csv(fit$output_files())\ny_rep <- as.matrix(stanfit, pars = \"y_rep\")\nppc_dens_overlay(data_list$y, y_rep[1:50, ])\nppc_stat_2d(data_list$y, y_rep, stat = c(\"mean\", \"min\"))"},{"path":"ch-prediction.html","id":"distribuzione-predittiva-a-priori-1","chapter":"Capitolo 22 La predizione bayesiana","heading":"22.5 Distribuzione predittiva a priori","text":"Nella sezione precedente abbiamo visto come la distribuzione predittiva è stata usata per generare nuovi dati previsti futuri. Più precisamente, mediante la (14.6)\\[\\begin{equation}\np(\\tilde{y} \\mid y) = \\int_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta\\notag\n\\end{equation}\\]abbiamo descritto la nostra incertezza sulla distribuzione di future osservazioni di dati, data la distribuzione posteriori di \\(\\theta\\), ovvero tenendo conto della scelta del modello e della stima dei parametri mediante dati osservati. Si noti che, nella (14.6), \\(\\tilde{y}\\) è condizionato da \\(y\\) ma non da ciò che è incognito, ovvero \\(\\theta\\). La distribuzione predittiva posteriori è ottenuta mediante marginalizzazione sopra parametri incogniti \\(\\theta\\).un modello bayesiano dove \\(\\theta\\) ha una distribuzione priori \\(p(\\theta)\\) e per \\(y\\) possiamo definire la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) possiamo scrivere la distribuzione congiunta \\(p(y, \\theta)\\) come il prodotto della verosimiglianza e della distribuzione priori:\\[\np(y, \\theta) = p(y \\mid \\theta)p(\\theta).\n\\]Una rappresentazione alternativa della distribuzione congiunta \\(p(y, \\theta)\\) è\\[\np(y, \\theta) = p(\\theta \\mid y)p(y)\n\\]Il primo termine questo prodotto, la densità \\(p(\\theta \\mid y)\\), è la densità posteriori di \\(\\theta\\) date le osservazioni \\(y\\). Il secondo termine questo prodotto, \\(p(y)\\), è la distribuzione predittiva priori che rappresenta la distribuzione dei dati futuri previsti dal modello prima di avere osservato il campione \\(y\\). Se risulta che dati \\(y\\) non sono coerenti con distribuzione predittiva priori, questa è evidenza che il modello bayesiano non è specificato correttamente. altre parole, questo ci dice che, base al modello bayesiano così come è stato formulato, è improbabile che si verifichino dati che sono stati effettivamente osservati. Ovviamente, questo vuol dire che, per dati del campione, il modello è inadeguato.seguito vedremo come la distribuzione predittiva priori possa essere facilmente ricavata se l’inferenza bayesiana viene svolta mediante metodi MCMC. Qui consideriamo un esempio relativo ai dati di Zetsche, Bürkner, Renneberg (2019) senza approfondire dettagli computazionali. Lo scopo è solo quello di interpretare il risultato ottenuto.Nel campione di Albert Hu (2019) abbiamo osservato 23 successi 30 prove. Nella discussione precedente abbiamo svolto l’aggiornamento bayesiano imponendo su \\(\\theta\\) una distribuzione priori \\(\\mbox{Beta}(2, 10)\\). Ci poniamo il problema di costruire la distribuzione predittiva priori per questo modello.Nel caso di una verosimiglianza binomiale e di una distribuzione priori Beta, la distribuzione predittiva priori può essere costruita mediante la funzione LearnBayes::pbetap(). Con dati dell’esempio, otteniamoLa distribuzione predittiva priori assegna livelli diversi di plausibilità ciascuno dei possibili risultati del nostro esperimento casuale, ovvero ’osservazione di \\(0, 1, \\dots, 30\\) successi 30 prove Bernoulliane. Nella distribuzione predittiva priori assegna ho evidenziato il punto \\(y = 23\\), ovvero il numero di successi che sono stati effettivamente osservati nel campione. Il grafico mostra che la distribuzione predittiva priori assegna una plausibilità quasi nulla ’evento \\(y = 23\\), ovvero ai dati che sono stati effettivamente osservati. Questo indica chiaramente che la distribuzione priori \\(\\mbox{Beta}(2, 10)\\) non è adeguata per dati che stiamo analizzando. Se viene invece utilizzata una distribuzione priori debolmente informativa, come \\(\\mbox{Beta}(2, 2)\\), la distribuzione predittiva priori diventa:questo secondo caso al valore \\(y\\) osservato nel campione viene assegnata una plausibilità piuttosto alta. Ciò significa che una \\(\\mbox{Beta}(2, 2)\\) è adeguata quale distribuzione priori.Ricordo che, nell’analisi dei dati di Zetsche, Bürkner, Renneberg (2019), la \\(\\mbox{Beta}(2, 10)\\) è stata utilizzata quale distribuzione priori solo per scopi didattici, ovvero per evidenziare le proprietà dell’aggiornamento bayesiano (la differenza tra la distribuzione priori e la distribuzione posteriori). La discussione presente mette però chiaramente evidenza il fatto che la \\(\\mbox{Beta}(2, 10)\\) non è una buona scelta per la distribuzione priori: sarebbe invece più opportuno usare una \\(\\mbox{Beta}(2, 2)\\).","code":"\ndf <- tibble(\n  y = 0:30,\n  Probability = LearnBayes::pbetap(c(2, 10), 30, 0:30)\n)\ndf %>% \n  ProbBayes::prob_plot(Color = \"gray\", Size = 3) + \n  geom_point(data = tibble(y = 23, Probability = 0), size = 3) \ndf <- tibble(\n  y = 0:30,\n  Probability = LearnBayes::pbetap(c(2, 2), 30, 0:30)\n)\ndf %>% \n  ProbBayes::prob_plot(Color = \"gray\", Size = 3) + \n  geom_point(data = tibble(y = 23, Probability = 0), size = 3) "},{"path":"ch-prediction.html","id":"commenti-e-considerazioni-finali-17","chapter":"Capitolo 22 La predizione bayesiana","heading":"Commenti e considerazioni finali","text":"Questo capitolo discute la predizione bayesiana e ne mostra un’applicazione nel caso dei\ncontrolli predittivi posteriori. questo proposito è necessario notare un punto importante: un buona corrispondenza tra \\(y\\) e \\(y^{rep}\\) costituisce una condizione necessaria ma non sufficiente per la validità del modello. Infatti, PPC non sono grado di garantire la generalizzabilità del modello nuovi campioni di dati. D’altra parte, invece, se PPC mostrano un cattivo adattamento del modello ai dati previsti futuri, questo ci dice chiaramente che il modello è specificato manera errata.","code":""},{"path":"ch-normal-normal-mod-stan.html","id":"ch-normal-normal-mod-stan","chapter":"Capitolo 23 Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)","heading":"Capitolo 23 Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)","text":"Estendiamo ora la discussione precedente considerano un altro caso comune: quello cui disponiamo di un campione di dati livello di scala intervalli o rapporti e vogliamo fare inferenza sulla media della popolazione da cui il campione è stato estratto.","code":""},{"path":"ch-normal-normal-mod-stan.html","id":"caso-normale-normale-con-varianza-nota","chapter":"Capitolo 23 Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)","heading":"23.1 Caso Normale-Normale con varianza nota","text":"Supponiamo che dati \\(y\\) siano un campione casuale estratto da una popolazione che segue la legge Normale. Ciò significa che le osservazioni possono essere considerate come una sequenza di variabili casuali indipendenti e identicamente distribuite. Supponiamo che ciascuna v.c. segua la distribuzione Normale. Abbiamo dunque\\[\nY_1, \\dots, Y_n  \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma).\n\\]precedenza abbiamo visto come, tali circostanze, la verosimiglianza \\(p(y \\mid \\mu, \\sigma)\\) sia Normale. Per fare inferenza sul parametro \\(\\mu\\), facciamo due assunzioni: consideriamo \\(\\sigma\\) nota e imponiamo su \\(\\mu\\) una distribuzione priori Normale. Questa situazione definisce lo schema coniugato Normale-Normale. Il caso Normale-Normale consente una derivazione analitica della distribuzione posteriori \\(p(\\mu \\mid y)\\) (così come nel caso beta-binomiale era possibile una derivazione analitica della distribuzione posteriori \\(p(\\theta \\mid y)\\)).La trattazione matematica di una tale derivazione è piuttosto complessa e qui verrà solo accennata. Nel seguito, impareremo invece ad applicare la soluzione che viene ottenuta tali circostanze; mostreremo inoltre come fare inferenza su \\(\\mu\\) mediante metodi MCMC.","code":""},{"path":"ch-normal-normal-mod-stan.html","id":"derivazione-analitica-della-distribuzione-a-posteriori-pmu-mid-y","chapter":"Capitolo 23 Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)","heading":"23.2 Derivazione analitica della distribuzione a posteriori \\(p(\\mu \\mid y)\\)","text":"Per \\(\\sigma^2\\) nota, la famiglia della distribuzione Normale è coniugata sé stessa: se la funzione di verosimiglianza è Normale, la scelta di una distribuzione priori Normale per \\(\\mu\\) assicura che anche la distribuzione posteriori \\(p(\\mu \\mid y)\\) sia Normale.Poniamoci dunque il problema di trovare \\(p(\\mu \\mid y)\\) nel caso di un campione casuale \\(Y_1, \\dots, Y_n \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma)\\), supponendo \\(\\sigma\\) perfettamente nota e imponendo su \\(\\mu\\) una distribuzione priori Normale. Ricordiamo che la densità gaussiana è\\[\np(y_i \\mid \\mu, \\sigma) = \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_i - \\mu)^2}{2\\sigma^2}}\\right\\}.\n\\]Essendo le variabili ..d., possiamo scrivere la densità congiunta come il prodotto delle singole densità e quindi si ottiene\\[\np(y \\mid \\mu) = \\, \\prod_{=1}^n p(y_i \\mid \\mu).\n\\]Una volta osservati dati \\(y\\), la verosimiglianza diventa\\[\\begin{align}\np(y \\mid \\mu) =& \\, \\prod_{=1}^n p(y_i \\mid \\mu) = \\notag\\\\\n& \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_1 - \\mu)^2}{2\\sigma^2}}\\right\\} \\times \\notag\\\\\n& \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_2 - \\mu)^2}{2\\sigma^2}}\\right\\} \\times  \\notag\\\\\n& \\vdots \\notag\\\\\n& \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_n - \\mu)^2}{2\\sigma^2}}\\right\\}.\n\\end{align}\\]Se la densità priori \\(p(\\mu)\\) è gaussiana, allora anche la densità posteriori \\(p(\\mu \\mid y)\\) sarà gaussiana. Poniamo\\[\\begin{equation}\np(\\mu) = \\frac{1}{{\\tau_0 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(\\mu - \\mu_0)^2}{2\\tau_0^2}}\\right\\},\n\\tag{23.1}\n\\end{equation}\\]ovvero imponiamo \\(\\mu\\) una distribuzione priori gaussiana con media \\(\\mu_0\\) e varianza \\(\\tau_0^2\\). Ciò significa dire che, priori, \\(\\mu_0\\) rappresenta il valore più verosimile per \\(\\mu\\), mentre \\(\\tau_0^2\\) quantifica il grado della nostra incertezza rispetto tale valore.Svolgendo una serie di passaggi algebrici, si arriva alla distribuzione posteriori\\[\\begin{equation}\np(\\mu \\mid y) = \\frac{1}{{\\tau_p \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(\\mu - \\mu_p)^2}{2\\tau_p^2}}\\right\\},\n\\tag{23.2}\n\\end{equation}\\]dove\\[\\begin{equation}\n\\mu_p = \\frac{\\frac{1}{\\tau_0^2}\\mu_0+ \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\tau_0^2} + \\frac{n}{\\sigma^2}}\n\\tag{23.3}\n\\end{equation}\\]e\\[\\begin{equation}\n\\tau_p^2 = \\frac{1}{\\frac {1}{\\tau_0^2}+ \\frac{n}{\\sigma^2}}.\n\\tag{23.4}\n\\end{equation}\\]Ciò significa che, se la distribuzione priori \\(p(\\mu)\\) è gaussiana, allora anche la distribuzione posteriori \\(p(\\mu \\mid y)\\) sarà gaussiana con valore atteso \\(\\mu_p\\) e varianza \\(\\tau_p^2\\) date dalle espressioni precedenti.conclusione, il risultato trovato indica che:il valore atteso posteriori è una media pesata fra il valore atteso priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\); il peso della media campionaria è tanto maggiore tanto più è grande \\(n\\) (il numero di osservazioni) e \\(\\tau_0^2\\) (l’incertezza iniziale);l’incertezza (varianza) posteriori \\(\\tau_p^2\\) è sempre più piccola dell’incertezza priori \\(\\tau_0^2\\) e diminuisce al crescere di \\(n\\).Esercizio 23.1  Per esaminare un esempio pratico, consideriamo 30 valori BDI-II dei soggetti clinici di Zetsche, Bürkner, Renneberg (2019):Supponiamo che la varianza \\(\\sigma^2\\) della popolazione sia identica alla varianza del campione:Per fare un esempio, imponiamo su \\(\\mu\\) una distribuzione priori \\(\\mathcal{N}(25, 2)\\). tali circostanze, la distribuzione posteriori del parametro \\(\\mu\\) può essere determinata per via analitica e corrisponde ad una Normale di media e varianza definite dalle equazioni (23.3) e (23.4). È possibile visualizzare tale distribuzione posteriori usando la funzione plot_normal_normal() del pacchetto bayesrules.La funzione bayesrules::summarize_normal_normal() fornisce una sintesi numerica della distribuzione posteriori \\(p(\\mu \\mid y, \\sigma)\\).Verifichiamo risultati forniti da bayesrules::summarize_normal_normal() applicando le formule (23.3) e (23.4). La media della distribuzione posteriori di \\(\\mu\\) èLa deviazione standard della distribuzione posteriori di \\(\\mu\\) èI risultati trovati riproducono quelli forniti da bayesrules::summarize_normal_normal().","code":"\ndf <- data.frame(\n  y = c(\n    26.0, 35.0, 30, 25, 44, 30, 33, 43, 22, 43,\n    24, 19, 39, 31, 25, 28, 35, 30, 26, 31, 41,\n    36, 26, 35, 33, 28, 27, 34, 27, 22\n  )\n)\nsigma <- sd(df$y)\nsigma\n#> [1] 6.606858\nbayesrules::plot_normal_normal(\n  mean = 25, # media della distribuzione a priori per mu\n  sd = 2, # sd della distribuzione a priori per mu\n  sigma = sd(df$y), # sd del campione\n  y_bar = mean(df$y), # media del campione\n  n = length(df$y) # ampiezza campionaria\n)\nbayesrules::summarize_normal_normal(\n  mean = 25, # media della distribuzione a priori per mu\n  sd = 2, # sd della distribuzione a priori per mu\n  sigma= sd(df$y), # sd del campione\n  y_bar = mean(df$y), # media del campione\n  n = length(df$y) # ampiezza campionaria\n)\n#>       model     mean     mode      var       sd\n#> 1     prior 25.00000 25.00000 4.000000 2.000000\n#> 2 posterior 29.35073 29.35073 1.066921 1.032919\nmu_post <- function(tau_0, mu_0, sigma, ybar, n) {\n  (1/tau_0^2 * mu_0 + n/sigma^2 * ybar) / (1/tau_0^2 + n/sigma^2)\n}\nmu_0 <- 25  # media della distribuzione a priori per mu\ntau_0 <- 2  # sd della distribuzione a priori per mu\nsigma <- sd(df$y) # sd del campione (assunta essere sigma)\nybar <- mean(df$y) # media del campione\nn <- length(df$y)\n\nmu_post(tau_0, mu_0, sigma, ybar, n) \n#> [1] 29.35073\ntau_post <- function(tau_0, sigma, n) {\n  sqrt(1 / (1/tau_0^2 + n/sigma^2))\n}\ntau_0 <- 2  # sd della distribuzione a priori per mu\nsigma <- sd(df$y) # sd del campione (assunta essere sigma)\nn <- length(df$y)\n\ntau_post(tau_0, sigma, n) \n#> [1] 1.032919"},{"path":"ch-normal-normal-mod-stan.html","id":"il-modello-normale-con-stan","chapter":"Capitolo 23 Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)","heading":"23.3 Il modello Normale con Stan","text":"priori coniugati Normali di una Normale non richiedono una approssimazione numerica ottenuta mediante metodi MCMC. Tuttavia, per fare un esercizio e per verificare che risultati ottenuti mediante MCMC siano simili quelli trovati per via analitica, ripetiamo l’esercizio precedente usando Stan.","code":""},{"path":"ch-normal-normal-mod-stan.html","id":"versione-1-sigma-nota","chapter":"Capitolo 23 Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)","heading":"23.3.1 Versione 1 (\\(\\sigma\\) nota)","text":"Come precedenza, impongo su \\(\\mu\\) una distribuzione priori \\(\\mathcal{N}(25, 2)\\) e considero noto il parametro \\(\\sigma = 6.606858\\). Il modello dunque diventa il seguente.\\[\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(25, 2) \\notag\\\\\n\\sigma &= 6.606858 \\notag\n\\end{align}\\]base al modello definito sopra, la variabile casuale \\(Y\\) segue la distribuzione Normale di parametri \\(\\mu\\) e \\(\\sigma\\). Il parametro \\(\\mu\\) è sconosciuto e abbiamo deciso di descrivere la nostra incertezza relativa ad esso mediante una distribuzione priori Normale di media 25 e deviazione standard 2. Il parametro \\(\\sigma\\) è invece assunto essere noto e uguale 6.606858. Usando il linguaggio Stan specifico il modello come segue.Sistemo dati nel formato appropriato per Stan.Leggo il file cui ho salvato il codice Stan.Compilo il modello.Eseguo il campionamento MCMC.Una sintesi della distribuzione posteriori dei parametri si ottiene nel modo seguente.Si noti che le stime ottenute sono molto vicine ai valori teorici attesi, ovvero \\(\\mu_p\\) = 29.57 contro un valore teorico di 29.35 e \\(\\tau_p\\) = 0.96 contro un valore teorico di 1.03.Qui sotto è fornita una rappresentazione grafica dell’intera distribuzione posteriori del parametro \\(\\mu\\).Trovo l’intervallo di credibilità al 95%.Le stime così trovate sono molto simili ai quantili di ordine 0.025 e 0.975 della vera distribuzione posteriori di \\(\\mu\\):","code":"\nmodelString = \"\ndata {\n  int<lower=0> N;\n  real<lower=0> sigma;\n  vector[N] y;\n}\nparameters {\n  real mu;\n}\nmodel {\n  mu ~ normal(25, 2);\n  y ~ normal(mu, sigma);\n}\n\"\nwriteLines(modelString, con = \"code/normal_normal_1.stan\")\ndlist <- list(\n  N = length(df$y),\n  sigma = sd(df$y),\n  y = df$y\n)\nfile <- file.path(\"code\", \"normal_normal_1.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = dlist,\n  iter_sampling = 100000L,\n  iter_warmup = 2000L,\n  chains = 4L,\n  refresh = 0\n)\nfit$summary(c(\"mu\"))\n#> # A tibble: 1 × 10\n#>   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu        29.4   29.4  1.04  1.04  27.6  31.1  1.00  153786.  188314.\nstanfit <- rstan::read_stan_csv(fit$output_files())\nmu_draws <- as.matrix(stanfit,pars =\"mu\")\nmcmc_areas(mu_draws,prob = 0.95) \npost <- fit$draws()\npost_parms <- subset_draws(post, c(\"mu\"))\nposterior::summarise_draws(\n  post_parms,\n  ~ quantile(.x, probs = c(0.025, 0.975))\n)\n#> # A tibble: 1 × 3\n#>   variable `2.5%` `97.5%`\n#>   <chr>     <dbl>   <dbl>\n#> 1 mu         27.3    31.4\nqnorm(c(0.025, 0.975), 29.35073, 1.032919)\n#> [1] 27.32625 31.37521"},{"path":"ch-normal-normal-mod-stan.html","id":"versione-2-sigma-incognita","chapter":"Capitolo 23 Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)","heading":"23.3.2 Versione 2 (\\(\\sigma\\) incognita)","text":"È facile estendere il caso precedente alla situazione cui il parametro \\(\\sigma\\) è incognito. Se non conosciamo \\(\\sigma\\), è necessario imporre su tale parametro una distribuzione priori. Supponiamo di ipotizzare per \\(\\sigma\\) una distribuzione priori \\(\\mbox{Cauchy}(0, 15)\\).Mediante una \\(\\mbox{Cauchy}(0, 15)\\) descrivo il grado di plausibilità soggettiva che attribuisco ai possibili valori (> 0) del parametro \\(\\sigma\\). Ai valori prossimi allo 0 attribuisco la plausibilità maggiore; la plausibilità dei possibili valori \\(\\sigma\\) diminuisce progressivamente quando ci si allontana dallo 0, come indicato dalla curva della figura seguente. Ritengo poco plausibili valori \\(\\sigma\\) maggiori di 40, anche se non escludo completamente che \\(\\sigma\\) possa assumere un valore di questo tipo.questo secondo caso, più realistico, il modello diventa il seguente.\\[\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(25, 2) \\notag\\\\\n\\sigma &\\sim \\mbox{Cauchy}(0, 15) \\notag\n\\end{align}\\]Il modello precedente è simile quello esaminato precedenza, eccetto che abbiamo quantificato la nostra incertezza relativa \\(\\sigma\\) (che è ignota) mediante una distribuzione priori \\(\\mbox{Cauchy}(0, 15)\\).La procedura MCMC utilizzata da Stan è basata su un campionamento Monte Carlo Hamiltoniano che non richiede l’uso di distribuzioni priori coniugate. Pertanto è possibile scegliere per parametri una qualunque distribuzione priori. Nel caso presente, appunto, per \\(\\sigma\\) ho scelto una \\(\\mbox{Cauchy}(0, 15)\\). Per un tale caso non è possibile ottenere la derivazione analitica della distribuzione posteriori di \\(\\mu\\). È dunque necessario procedere con il campionamento MCMC.Scrivo il modello linguaggio Stan.Creo l’oggetto di classe list che contiene dati.Leggo il file con il codice Stan del modello.Compilo il modello.Eseguo il campionamento MCMC.questo modo ottengo le seguenti stime posteriori dei parametri.Dopo avere trasformato l’oggetto fit2 nel formato stanfit, trovo l’intervallo di credibilità al 95%.Come precedenza, uso la funzione mcmc_areas() per creare una rappresentazione grafica della distribuzione posteriori di \\(\\mu\\).Considerati dati osservati e le mie ipotesi priori sui parametri, posso dunque concludere, con un grado di certezza soggettiva del 95%, che la media della popolazione dei punteggi BDI-II dei pazienti clinici depressi è compresa nell’intervallo [26.85, 31.33].","code":"\ncurve(\n  dcauchy(x, location = 0, scale = 15), \n  from = 0, to = 50, col = 'gray', lwd = 3,\n  ylab = \"Densità\",\n  xlab = \"sigma\"\n)\nmodel_string_2 = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  mu ~ normal(25, 2);\n  sigma ~ cauchy(0, 15);\n  y ~ normal(mu, sigma);\n}\n\"\nwriteLines(model_string_2, con = \"code/normal_mod_2.stan\")\ndlist2 <- list(\n  N = length(df$y),\n  y = df$y\n)\nfile2 <- file.path(\"code\", \"normal_mod_2.stan\")\nmod2 <- cmdstan_model(file2)\nfit2 <- mod2$sample(\n  data = dlist2,\n  iter_sampling = 50000L,\n  iter_warmup = 2000L,\n  chains = 4L,\n  refresh = 0\n)\nfit2$summary(c(\"mu\", \"sigma\"))\n#> # A tibble: 2 × 10\n#>   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu       29.2   29.2   1.14 1.12  27.3  31.0   1.00  129256.  114237.\n#> 2 sigma     7.06   6.95  1.01 0.954  5.63  8.88  1.00  121123.  115765.\nstanfit <- rstan::read_stan_csv(fit2$output_files())\nout <- rstantools::posterior_interval(\n  as.matrix(stanfit), \n  prob = 0.95\n)\nout\n#>             2.5%      97.5%\n#> mu     26.851295  31.331500\n#> sigma   5.418299   9.360616\n#> lp__  -76.415107 -72.666800\nmu_draws <- as.matrix(stanfit, pars =\"mu\")\nmcmc_areas(mu_draws, prob = 0.95) "},{"path":"ch-normal-normal-mod-stan.html","id":"commenti-e-considerazioni-finali-18","chapter":"Capitolo 23 Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)","heading":"Commenti e considerazioni finali","text":"questo capitolo abbiamo visto come calcolare l’intervallo di credibilità per la media di una v.c. Normale. La domanda più ovvia di analisi dei dati, dopo avere visto come trovare l’intervallo di credibilità per la media di un solo gruppo, riguarda il confronto tra le medie di due gruppi. Il confronto tra le medie di due gruppi può essere considerato come un caso particolare di un metodo più generale di analisi dei dati, chiamato analisi di regressione lineare. Prima di discutere il problema del confronto tra le medie di due gruppi è dunque necessario esaminare il modello statistico della regressione lineare.","code":""},{"path":"ch-regr-intro.html","id":"ch-regr-intro","chapter":"Capitolo 24 Introduzione","heading":"Capitolo 24 Introduzione","text":"Lo scopo della ricerca è trovare le associazioni tra le variabili e fare confronti fra le condizioni sperimentali. Nel caso della psicologia, il ricercatore vuole scoprire le leggi generali che descrivono le relazioni tra costrutti psicologici e le relazioni che intercorrono tra fenomeni psicologici e quelli non psicologici (sociali, economici, storici, …). Abbiamo già visto come la correlazione di Pearson sia uno strumento adatto questo scopo. Infatti, essa ci informa sulla direzione e sull’intensità della relazione lineare tra due variabili. Tuttavia, la correlazione non è sufficiente, quanto il ricercatore ha disposizione solo dati di un campione, mentre vorrebbe descrivere la relazione tra le variabili nella popolazione. causa della variabilità campionaria, le proprietà dei campioni sono necessariamente diverse da quelle della popolazione: ciò che si può osservare nella popolazione potrebbe non emergere nel campione e, al contrario, il campione manifesta caratteristiche che non sono necessariamente presenti nella popolazione. È dunque necessario chiarire, dal punto di vista statistico, il legame che intercorre tra le proprietà del campione e le proprietà della popolazione da cui esso è stato estratto. Il modello lineare utilizza la funzione matematica più semplice per descrivere la relazione fra due variabili, ovvero la funzione lineare. questo Capitolo vedremo come si possa fare inferenza sulla relazione tra due variabili mediante il modello lineare bayesiano. Inizieremo descrivere le proprietà geometriche della funzione lineare per poi utilizzare questa semplice funzione per costruire un modello statistico secondo un approccio bayesiano.","code":""},{"path":"ch-regr-intro.html","id":"la-funzione-lineare","chapter":"Capitolo 24 Introduzione","heading":"24.1 La funzione lineare","text":"Iniziamo con un ripasso sulla funzione di lineare. Si chiama funzione lineare una funzione del tipo\\[\\begin{equation}\nf(x) = + b x,\n\\end{equation}\\]dove \\(\\) e \\(b\\) sono delle costanti. Il grafico di tale funzione è una retta di cui il parametro \\(b\\) è detto coefficiente angolare e il parametro \\(\\) è detto intercetta con l’asse delle \\(y\\) [infatti, la retta interseca l’asse \\(y\\) nel punto \\((0,)\\), se \\(b \\neq 0\\)].Per assegnare un’interpretazione geometrica alle costanti \\(\\) e \\(b\\) si consideri la funzione\\[\\begin{equation}\ny = b x.\n\\end{equation}\\]Tale funzione rappresenta un caso particolare, ovvero quello della proporzionalità diretta tra \\(x\\) e \\(y\\). Il caso generale della linearità\\[\\begin{equation}\ny = + b x\n\\end{equation}\\]non fa altro che sommare una costante \\(\\) ciascuno dei valori \\(y = b x\\). Nella funzione lineare \\(y = + b x\\), se \\(b\\) è positivo allora \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) è negativo allora \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\) la retta è orizzontale, ovvero \\(y\\) non muta al variare di \\(x\\).Consideriamo ora il coefficiente \\(b\\). Si consideri un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\) come indicato nella figura 24.1. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono detti incrementi di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) è uguale al rapporto\\[\\begin{equation}\n    b = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0},\n\\end{equation}\\]indipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Il modo più semplice per assegnare un’interpretazione geometrica al coefficiente angolare (o pendenza) della retta è dunque quello di porre \\(\\Delta x = 1\\). tali circostanze infatti \\(b = \\Delta y\\).\nFIGURA 24.1: La funzione lineare \\(y = + bx\\).\n","code":""},{"path":"ch-regr-intro.html","id":"una-media-per-ciascuna-osservazione","chapter":"Capitolo 24 Introduzione","heading":"24.2 Una media per ciascuna osservazione","text":"precedenza abbiamo visto come sia possibile stimare parametri di un modello bayesiano nel quale le osservazioni sono indipendenti e identicamente distribuite secondo una densità gaussiana,\\[\\begin{equation}\nY_i \\stackrel{..d.}{\\sim} \\mathcal{N}(\\mu, \\sigma), \\quad = 1, \\dots, n.\n\\tag{24.1}\n\\end{equation}\\]Il modello (24.1) assume che ogni \\(Y_i\\) sia la realizzazione di una v.c. descritta da una \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Da un punto di vista bayesiano,questo modello può essere implementato assegnando le distribuzioni priori ai parametri \\(\\mu\\) e \\(\\sigma\\) e generando la verosimiglianza base ai dati osservati. Con queste informazioni, possono poi essere definite le distribuzioni posteriori dei parametri (Gelman, Hill, Vehtari 2020):\\[\\begin{align}\nY_i \\mid \\mu, \\sigma & \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\notag\\\\\n\\mu       & \\sim \\mathcal{N}(\\mu_0, \\tau^2) \\notag\\\\\n\\sigma    & \\sim \\Cauchy(x_0, \\gamma) \\notag\n\\end{align}\\]È però comune che vengano registrate altre variabili che possono essere associate alla risposta di interesse \\(y_i\\). Chiamiamo \\(x\\) una di tali variabili. La variabile \\(x\\) viene chiamata predittore (o variabile indipendente) quanto il ricercatore è tipicamente interessato predire \\(y_i\\) partire dal valore assunto da \\(x_i\\). Come si può estende il modello (24.1) descritto precedenza per lo studio della relazione tra \\(y_i\\) e \\(x_i\\)?Il modello (24.1) assume una media \\(\\mu\\) comune per ciascuna osservazione \\(Y_i\\). Dal momento che desideriamo introdurre una nuova variabile \\(x_i\\) che assume un diverso valore per ciascuna osservazione \\(y_i\\), il modello (24.1) può essere modificato modo che la media comune \\(\\mu\\) venga sostituita da una media \\(\\mu_i\\) specifica ciascuna osservazione \\(\\)-esima:\\[\\begin{equation}\nY_i \\mid \\mu_i, \\sigma \\stackrel{ind}{\\sim} \\mathcal{N}(\\mu_i, \\sigma), \\quad = 1, \\dots, n.\n\\tag{24.2}\n\\end{equation}\\]Si noti che le osservazioni \\(Y_1, \\dots, Y_n\\) non sono più identicamente distribuite poiché hanno medie diverse, ma sono ancora indipendenti come indicato dalla notazione ind posta sopra il simbolo \\(\\sim\\) nella (24.2).","code":""},{"path":"ch-regr-intro.html","id":"relazione-lineare-tra-la-media-y-mid-x-e-il-predittore","chapter":"Capitolo 24 Introduzione","heading":"24.2.1 Relazione lineare tra la media \\(y \\mid x\\) e il predittore","text":"L’approccio che consente di mettere relazione un predittore \\(x_i\\) con la risposta \\(Y_i\\) è quello di assumere che la media di ciascuna \\(Y_i\\), ovvero \\(\\mu_i\\), sia una funzione lineare del predittore \\(x_i\\). Una tale relazione lineare è scritta come\\[\\begin{equation}\n\\mu_i = \\beta_0 + \\beta_ 1 x_i, \\quad = 1, \\dots, n.\n\\tag{24.3}\n\\end{equation}\\]Nella (24.3), ciascuna \\(x_i\\) è una costante nota (ecco perché viene usata una lettera minuscola per la \\(x\\)) e \\(\\beta_0\\) e \\(\\beta_ 1\\) sono parametri incogniti. Questi parametri rappresentano l’intercetta e la pendenza della retta di regressione e sono delle variabili casuali.28 L’inferenza bayesiana procede assegnando una distribuzione priori \\(\\beta_0\\) e \\(\\beta_ 1\\) e si esegue l’inferenza riassumendo la distribuzione posteriori di questi parametri.Nel modello (24.3), la funzione lineare \\(\\beta_0 + \\beta_ 1 x_i\\) è interpretata come il valore atteso della \\(Y_i\\) per ciascun valore \\(x_i\\), mentre l’intercetta \\(\\beta_0\\) rappresenta il valore atteso della \\(Y_i\\) quando \\(x_i = 0\\). Il parametro \\(\\beta_ 1\\) (pendenza) rappresenta invece l’aumento medio della \\(Y_i\\) quando \\(x_i\\) aumenta di un’unità. È importante notare che la relazione lineare (24.2) di parametri \\(\\beta_0\\) e \\(\\beta_ 1\\) descrive l’associazione tra la media \\(\\mu_i\\) e il predittore \\(x_i\\). altri termini, tale relazione lineare ci fornisce una predizione sul valore medio \\(\\mu_i\\), non sul valore effettivo \\(Y_i\\).","code":""},{"path":"ch-regr-intro.html","id":"il-modello-lineare","chapter":"Capitolo 24 Introduzione","heading":"24.2.2 Il modello lineare","text":"Sostituendo la (24.3) nella (24.2) otteniamo il modello lineare:\\[\\begin{equation}\nY_i \\mid \\beta_0, \\beta_ 1, \\sigma \\stackrel{ind}{\\sim} \\mathcal{N}(\\beta_0 + \\beta_ 1 x_i, \\sigma), \\quad = 1, \\dots, n.\n\\tag{24.4}\n\\end{equation}\\]Questo è un caso speciale del modello di campionamento Normale, dove le \\(Y_i\\) seguono indipendentemente una densità Normale con una media (\\(\\beta_0 + \\beta_ 1 x_i\\)) specifica per ciascuna osservazione e con una deviazione standard (\\(\\sigma\\)) comune tutte le osservazioni. Poiché include un solo predittore (\\(x\\)), questo modello è comunemente chiamato modello di regressione lineare semplice.","code":""},{"path":"ch-regr-intro.html","id":"commenti-e-considerazioni-finali-19","chapter":"Capitolo 24 Introduzione","heading":"Commenti e considerazioni finali","text":"Il modello lineare semplice viene usato per descrivere la relazione tra due variabili e per determinare il segno e l’intensità di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente base al valore assunto dalla variabile indipendente.","code":""},{"path":"ch-regr-model-lm.html","id":"ch-regr-model-lm","chapter":"Capitolo 25 Il modello lineare visto da vicino","heading":"Capitolo 25 Il modello lineare visto da vicino","text":"questo capitolo mi pongo il problema di applicare il modello di regressione bivariata ad un campione di dati. Userò dati kidiq. Riporto qui di seguito la descrizione di questo set di dati.Data survey adult American women children (subsample National Longitudinal Survey Youth).Source: Gelman Hill (2007)434 obs. 4 variableskid_score Child’s IQ scoremom_hs Indicator whether mother high school degreemom_iq Mother’s IQ scoremom_age Mother’s ageLeggo dati \\(\\mathsf{R}\\).questo esercizio considererò la relazione tra kid_score e mom_iq.dati rappresentati nel diagramma dispersione suggeriscono che, questo campione, sembra esserci un’associazione positiva tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq). Mi pongo il problema di descrivere questa associazione mediante una relazione lineare.Ci sono infinite rette che, linea di principio, possono essere usate per “approssimare” la nube di punti nel diagramma dispersione. È dunque necessario introdurre dei vincoli per selezionare una di queste rette.Un vincolo che viene spesso usato è quello di costringere la retta passare per il punto \\((\\bar{x}, \\bar{y})\\).Una retta che passa per il punto \\((\\bar{x}, \\bar{y})\\) ha la proprietà descritta di seguito.Iniziamo descrivere ciascuna osservazione inserita nel diagramma dispersione con un’equazione:\\[\ny_i = + b x_i + e_i\n\\]\nLe osservazioni \\(y\\) sono kid_score. primi 10 valori sono seguenti:Per fare riferimento ciascun valore usiamo l’indice \\(\\). Quindi, ad esempio, \\(y_3\\) è uguale aLa variabile \\(x\\), nel caso presente, è mom_iq. primi 10 valori di \\(x\\) sonoIn maniera corrispondente alla \\(y\\), uso un indice per fare riferimento ai singoli valori della variabile. Ad esempio, \\(x_3\\) èL’equazione precedente ci dice che ciascun valore \\(y\\) è dato dalla somma di due componenti: una componente deterministica e una componente aleatoria. Consideriamo il primo valore \\(y\\). Per esso diciamo che\\[\ny_1 = + b x_1 + e_1,\n\\]laddove \\(+ b x_1\\) è la componente deterministica, detta \\(\\hat{y}\\), e \\(e_1\\) è la componente aleatoria.La componente deterministica è, appunto, la componente di ciascun valore \\(y\\) che possiamo prevedere conoscendo \\(x\\). Non possiamo prevedere perfettamente valori \\(y\\) – ciò si verificherebbe soltanto se tutti punti del diagramma dispersione fossero disposti su una retta. Ma non lo sono: la retta è solo un’approssimazione della relazione (lineare) tra \\(x\\) e \\(y\\). Pertanto, conoscendo \\(x\\) possiamo solo prevedere una “componente” di ciascun valore \\(y\\).Cosa significa che possiamo prevedere una componente di ciascuna osservazione \\(y\\)? Significa che il valore \\(y\\) osservato sarà dato dalla somma di due componenti: \\(y_i = \\hat{y}_i + e_i\\).L’affermazione precedente solleva due domande:come possiamo trovare la quota della \\(y\\) che può essere predetta conoscendo \\(x\\)?quant’è grande la porzione della \\(y\\) che può essere predetta conoscendo \\(x\\)? altre parole, conoscendo la \\(x\\) è possibile predire \\(y\\) con accuratezza oppure ?Rispondere tali due domanda definisce primi due obiettivi del modello statistico della regressione lineare. Il terzo obiettivo è quello dell’inferenza, ovvero di capire che relazioni ci sono tra la relazione tra \\(x\\) e \\(y\\) osservata nel campione e la la relazione tra \\(x\\) e \\(y\\) nella popolazione.","code":"\nkidiq <- rio::import(here::here(\n  \"data\", \"kidiq.dta\"\n))\nglimpse(kidiq)\n#> Rows: 434\n#> Columns: 5\n#> $ kid_score <dbl> 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78, 1…\n#> $ mom_hs    <dbl> 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, …\n#> $ mom_iq    <dbl> 121.11753, 89.36188, 115.44316, 99.44964, 92.74571, 107.9018…\n#> $ mom_work  <dbl> 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, 3, …\n#> $ mom_age   <dbl> 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 24, …\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point()\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(\n    aes(x=mean(mom_iq), y=mean(kid_score)), \n    colour=\"red\", size = 4\n  )\nkidiq$kid_score[1:10]\n#>  [1]  65  98  85  83 115  98  69 106 102  95\nkidiq$kid_score[3]\n#> [1] 85\nkidiq$mom_iq[1:10]\n#>  [1] 121.11753  89.36188 115.44316  99.44964  92.74571 107.90184 138.89311\n#>  [8] 125.14512  81.61953  95.07307\nkidiq$mom_iq[3]\n#> [1] 115.4432"},{"path":"ch-regr-model-lm.html","id":"stima-dei-coefficienti-di-regressione","chapter":"Capitolo 25 Il modello lineare visto da vicino","heading":"25.1 Stima dei coefficienti di regressione","text":"Iniziamo con il primo obiettivo, ovvero quello di predire una frazione di ciascuna osservazione \\(y\\) conoscendo \\(x\\). Quindi, nel caso presente, ci chiediamo quanto segue. Il primo bambino del campione ha un QI uguale 65. Sua madre ha un QI di 121.12. Quanto bene riesco predire il punteggio QI del bambino conoscendo quello di sua madre?È chiaro, guardando numeri, che non c’è una corrispondenza perfetta, tutt’altro! Infatti, se guardiamo il diagramma di dispersione ci rendiamo conto che punti sono piuttosto lontani dalla retta che abbiamo usato per descrivere la relazione tra \\(x\\) e \\(y\\). Tuttavia, il diagramma di dispersione suggerisce che una qualche relazione c’è, seppur debole. Il nostro obiettivo è di descrivere una tale relazione.Una tale relazione è descritta dalla componente deterministica che costituisce una frazione di ciascuna osservazione \\(y\\). Abbiamo deciso di definire una tale componente “deterministica” \\(\\hat{y}_i\\) nei termini della seguente equazione: \\(\\hat{y}_i = a_i + bx_i\\).L’equazione precedente è detta equazione lineare e, dal punto di vista geometrico, corrisponde ad una retta. Ci sono infinite equazioni che potremmo usare per mettere relazione \\(x\\) e \\(y\\). Abbiamo scelto questa perché è la più semplice. Se guardiamo il diagramma di dispersione, infatti, non ci sono ragioni per descrivere la relazione tra \\(x\\) e \\(y\\) con qualche curva, anziché con una retta. altri campioni, una curva può essere più sensata di una retta, quale descrizione della relazione media tra \\(x\\) e \\(y\\), ma non nel caso presente. Ricordiamo il principio del rasoio di Occam (ovvero, il principio che sta alla base del pensiero scientifico moderno): se un modello semplice funziona, non c’è ragione di usare un modello più complesso.Dunque, abbiamo capito che vogliamo descrivere la relazione media* tra \\(x\\) e \\(y\\) con una retta, ovvero, con l’equazione lineare\\[\n\\hat{y}_i = + b x_i.\n\\]L’equazione precedente indica che il modello lineare \\(+ b x_i\\) non è grado di prevedere il valore di ciascuna osservazione \\(y_i\\). Questo, generale, non è mai possibile (ovvero, è possibile solo un caso specifico che, nella realtà empirica, non si verifica mai).L’equazione precedente ci dice che possiamo prevedere solo una frazione di ciascuna osservazione \\(y_i\\), ovvero quella frazione che abbiamo denotato con \\(\\hat{y}_i\\). La componente che non possiamo prevedere con l’equazione \\(+ b x_i\\) si denota con \\(e_i\\).questo senso diciamo che scomponiamo il valore di ciascuna osservazione \\(y_i\\) due componenti: la componente deterministica (prevedibile conoscendo \\(x\\)) e la componente aleatoria (non prevedibile conoscendo \\(x\\)):\\[\ny_i = \\hat{y}_i + e_i.\n\\]Il primo obiettivo del modello di regressione è quello di trovare coefficienti dell’equazione\\[\n+ b x_i\n\\]che consente di predire \\(\\hat{y}_i\\). Questi due coefficienti sono detti coefficienti di regressione.Per trovare coefficienti di regressione dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni.Il primo vincolo lo abbiamo espresso prima: vogliamo che la retta \\(\\hat{y}_i = + b x_i\\) passi per il punto \\((\\bar{x}, \\bar{y})\\). Il punto \\((\\bar{x}, \\bar{y})\\) corrisponde al baricentro del diagramma dispersione.Ci sono infinite rette che passano per punto \\((\\bar{x}, \\bar{y})\\). Tutte queste rette soddisfano la seguente proprietà. Nel caso di qualsiasi retta passante per il punto \\((\\bar{x}, \\bar{y})\\) è vero che\\[\n\\sum_{=1}^n e_i = 0.\n\\]Dal punto di vista geometrico, la componente erratica del modello, \\(e_i\\), corrisponde alla distanza verticale tra ciascun punto e la retta di regressione \\(+ bx\\). Tale componente va sotto il nome di residuo:\\[\ne_i = y_i - \\hat{y}_i = y_i - (+ bx_i).\n\\]L’affermazione precedente dice che la somma di tutte le distanze verticali (che hanno un segno positivo quando il punto è sopra la retta, e un segno negativo quando il punto è sotto la retta) tra le osservazioni e la retta di regressione (passante per il punto \\((\\bar{x}, \\bar{y})\\)) è uguale zero.Questo significa che non possiamo selezionare una tra le infinite rette che passano per il punto \\((\\bar{x}, \\bar{y})\\) usando il criterio che ci porta scegliere la retta che rende la più piccola possibile (ovvero, minimizza) la somma dei residui. Infatti, tutte le rette passanti per il punto \\((\\bar{x}, \\bar{y})\\) rendono uguale zero la somma dei residui.Dunque, dobbiamo trovare qualche altri criterio per scegliere tra le infinite rette che passano per il punto \\((\\bar{x}, \\bar{y})\\). Il criterio che viene normalmente scelto è quello di minimizzare la somma dei quadrati dei residui \\((y_i - \\hat{y}_i)^2\\). altri termini, vogliamo trovare coefficienti \\(\\) e \\(b\\) tali per cui la quantità\\[\n\\sum_{=1}^{n}{(y_i - (+ b x_i))^2}\n\\]assume il suo valore minimo. coefficienti che hanno questa proprietà si chiamano coefficienti dei minimi quadrati.Questo problema ha una soluzione analitica. La soluzione analitica si trova riconoscendo il fatto che l’equazione precedente definisce una superficie e il problema diventa quello di trovare il punto minore di questa superficie. Per trovare la soluzione ci si deve rendere conto che il punto di minimo è il punto della superficie nel quale la tangente alla superficie è piatta (ovvero uguale zero). Rendere uguale zero la tangente ad una superficie significa porre le derivate parziali rispetto alla direzione \\(x\\) e alla direzione \\(y\\) uguali zero. Ponendo tali derivate parziali uguali zero si definisce un sistema di equazioni lineari con due incognite, \\(\\) e \\(b\\). La soluzione di tali equazioni, che si chiamano equazioni normali, è la seguente:\\[\n= \\bar{y} - b \\bar{x}\n\\]\\[\nb = \\frac{\\mbox{Cov}(x, y)}{\\mbox{Var}(x)}\n\\]Le due precedenti equazioni corrispondono alla stima dei minimi quadrati dei coefficienti di regressione della retta che minimizza la somma dei quadrati dei residui.Nel caso presente, tali coefficienti sono uguali :R li possiamo trovare con la seguente funzione:precedenza abbiamo soltanto accennato al problema di come si possono trovano coefficienti dei minimi quadrati; ritorneremo su questo punto seguito. Per ora, chiediamoci cosa significano due coefficienti che abbiamo calcolato.Il coefficiente \\(\\) si chiama intercetta. L’intercetta, ’interno del diagramma dispersione, specifica il punto cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani.Nel caso presente questo valore non è di alcun interesse, perché corrisponde al valore della retta di regressione quando \\(x = 0\\), ovvero quando l’intelligenza della madre è uguale 0. Vedremo seguito come, trasformando dati, è possibile assegnare al coefficiente \\(\\) un’interpretazione più utile. Per ora mi limito fornire l’interpretazione del coefficiente.Passando \\(b\\), possiamo dire che questo secondo coefficiente va sotto il nome di pendenza della retta di regressione. Ovvero ci dice di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione corrispondenza di un aumento di 1 punto della variabile \\(x\\).Nel caso presente, il coefficiente \\(b\\) ci dice che, se il QI delle madri aumenta di 1 punto, il QI dei bambini aumenta media di 0.61 punti.È importante capire cosa significa che, base ai risultati della regressione, \\(y\\) aumenta media di \\(b\\) punti per ciascun aumento unitario di \\(x\\).Il modello statistico di regressione ipotizza che, per ciascun valore osservato \\(x\\) (per esempio, il valore del QI della prima madre del campione, ovvero \\(x = 121.11753\\)) ci sia una distribuzione di valori \\(y\\) nella popolazione, di cui solo uno è stato osservato nel campione. Possiamo facilmente capire che, se consideriamo tutte le madri con QI di 121.12, il punteggio del QI dei loro figli non sia costante, ma assuma tanti valori possibili. Questa distribuzione di valori possibili si chiama distribuzione \\(y\\) condizionata \\(x\\), ovvero \\(p(y \\mid x_i)\\).Il modello statistico della regressione lineare non può alcun modo prevedere il valore assunto da ciascuna delle possibili osservazioni che fanno parte della distribuzione \\(p(y \\mid x_i)\\). Il modello della regressione lineare ha un obiettivo più limitato, ovvero si propone di prevedere le medie delle distribuzioni \\(p(y \\mid x_i)\\) conoscendo valori \\(x\\).Dunque, quando il coefficiente \\(b\\) è uguale 0.61, questo significa che il modello di regressione predice che la medie della distribuzione condizionata \\(p(y \\mid x_i)\\) aumenta di 0.61 punti se la variabile \\(x\\) (QI delle madri) aumenta di un punto. Questo significa che il modello di regressione non fa una predizione sul punteggio di ciascun valore \\(y_i\\) (funzione di \\(x\\)), ma solo della media delle distribuzioni condizionate \\(p(y \\mid x_i)\\) di cui il valore osservato \\(y_i\\) è una realizzazione casuale.Possiamo dire la stessa cosa con parole diverse dicendo che il modello di regressione fa delle predizioni sulla componente deterministica di ciascuna osservazione. È più semplice capire questo aspetto se rappresentiamo maniera grafica la componente “deterministica” \\(\\hat{y}_i = + b x_i\\) predetta dal modello di regressione.Il diagramma precedente presenta ciascun valore \\(\\hat{y}_i = + b x_i\\) funzione di \\(x_i\\). Si vede che valori predetti dal modello di regressione sono punti che stanno sulla retta di regressione. Dunque, il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione corrisponde alla distanza verticale tra punti del diagramma dispersione e la retta di regressione\\[\ne_i = y_i - (+ b x_i).\n\\]Nel caso nella prima osservazione, ad esempio abbiamo:\\[\ny_1 = (+ b x_1) + e_1\n\\]AbbiamoDunque\\[\ne_1 = (+ b x_1) - y_1\n\\]Ciò significa che il valore osservato \\(y_1 = 65\\) viene scomposto dal modello di regressione due componenti. La componente deterministica \\(\\hat{y}_1\\), predicibile da \\(x_1\\), èLa somma della componente deterministica e della componente erratica, ovviamente, riproduce il valore osservato.","code":"\nb <- cov(kidiq$kid_score, kidiq$mom_iq) / var(kidiq$mom_iq)\nb\n#> [1] 0.6099746\na <- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\na\n#> [1] 25.79978\nfm <- lm(kid_score ~ mom_iq, data = kidiq)\ncoef(fm)\n#> (Intercept)      mom_iq \n#>  25.7997778   0.6099746\nkidiq$yhat <- fm$fitted.values\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = yhat)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(\n    aes(x=mean(mom_iq), y=mean(kid_score)), \n    colour=\"red\", size = 4\n  )\nkidiq$kid_score[1]\n#> [1] 65\ne_1 <- kidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\ne_1\n#> [1] -34.67839\nyhat_1 <- a + b * kidiq$mom_iq[1]\nyhat_1\n#> [1] 99.67839\nyhat_1 + e_1\n#> [1] 65"},{"path":"ch-regr-model-lm.html","id":"trasformazione-dei-dati","chapter":"Capitolo 25 Il modello lineare visto da vicino","heading":"25.1.1 Trasformazione dei dati","text":"Consideriamo ora dati \\(y\\) espressi come differenze dalla media:Il diagramma dispersione diventa il seguente.Nel diagramma precedente, la pendenza della retta di regressione è uguale alla precedente, ma questo grafico ’intercetta può essere assegnata un’interpretazione dotata di senso.Nel caso di dati così trasformati, l’intercetta è sempre il punto sull’asse \\(y\\) dove la retta di regressione interseca l’ordinata. Ma, questo caso, dato che abbiamo traslato dati di una quantità pari \\(x - \\bar{x}\\), il valore \\(x = 0\\) corrisponde al valore \\(\\bar{x}\\) nel caso dei dati grezzi. Dunque, l’intercetta avrà la seguente interpretazione:nel caso di dati nei quali \\(x\\) è espresso come differenze dalla media, l’intercetta corrisponde al valore atteso della \\(y\\) corrispondenza di \\(\\bar{x}\\).altre parole, per dati così trasformati, l’intercetta corrisponde al QI atteso (ovvero, medio) dei bambini corrispondenza del QI medio delle madri.","code":"\nkidiq$xd <- kidiq$mom_iq - mean(kidiq$mom_iq)\nkidiq %>% \n  ggplot(aes(x = xd, y = kid_score)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(\n    aes(x=mean(xd), y=mean(kid_score)), \n    colour=\"red\", size = 4\n  )\nfm1 <- lm(kid_score ~ xd, data = kidiq)\ncoef(fm1)\n#> (Intercept)          xd \n#>  86.7972350   0.6099746"},{"path":"ch-regr-model-lm.html","id":"il-metodo-dei-minimi-quadrati","chapter":"Capitolo 25 Il modello lineare visto da vicino","heading":"25.1.2 Il metodo dei minimi quadrati","text":"Ora che abbiamo visto come interpretare il coefficienti di regressione, chiediamoci come vengono calcolati.La procedura generale è stata brevemente descritta precedenza. Vediamo ora come si giunge alla stessa conclusione usando una simulazione.Il problema è di trovare valori \\(\\) e \\(b\\) tali per cui la quantità \\(\\sum_{=1}^{n}{(y_i - (+ b x_i))^2}\\) assume il valore minore possibile. Questo è un problema di minimizzazione rispetto due parametri. Per dare un’idea di come si fa, semplifichiamo il problema e supponiamo che uno dei due parametri sia noto, ad esempio \\(\\), così ci resta una sola incognita.Credo una griglia di valori b_grid possibili, ad esempio:Definisco una funzione che calcola la quantità \\(\\sum_{=1}^{n}{(y_i - (+ b x_i))^2}\\):Calcolo la somma degli errori quadratici per ciascun possibile valore b_grid, fissando \\(= 25.79978\\).Esaminiamo il risultato ottenuto.Il risultato ottenuto con la simulazioneriproduce quello ottenuto per via analitica:Una simulazione simile, ma computazionalmente più complessa, può essere usata per stimare simultaneamente entrambi parametri. Ci siamo limitati qui ad una proof concept del caso più semplice.","code":"\nnrep <- 1e5\nb_grid <- seq(0, 1, length.out = nrep)\nsse <- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\nsse_res <- rep(NA, nrep)\nfor (i in 1:nrep) {\n  sse_res[i] <- sse(a = 25.79978, b = b_grid[i], x = kidiq$mom_iq, y = kidiq$kid_score)\n}\nplot(\n  b_grid, sse_res, type = 'l'\n)\nb_grid[which.min(sse_res)]\n#> [1] 0.6099761\nb\n#> [1] 0.6099746"},{"path":"ch-regr-model-lm.html","id":"il-coefficiente-di-determinazione","chapter":"Capitolo 25 Il modello lineare visto da vicino","heading":"25.1.3 Il coefficiente di determinazione","text":"Il secondo obiettivo del modello statistico di regressione lineare è quello di stabilire quanto sia grande, termini proporzionali, la componente \\(y\\) predicibile da \\(x\\), per ciascuna osservazione.Un indice assoluto della bontà di adattamento è fornito dalla deviazione standard dei residui, \\(s_e\\), chiamata anche errore standard della stima. Uno stimatore non distorto della varianza dei residui nella popolazione è dato da\\[\ns^2_e = \\frac{\\sum e_i^2}{n-2}\n\\]e quindi l’errore standard della stima sarà\\[\\begin{equation}\ns_e = \\sqrt{\\frac{\\sum e_i^2}{n-2}}.\n\\end{equation}\\]Si noti che questa è la stessa formula della varianza (dato che la media dei residui è zero), tranne per il fatto che al denominatore abbiamo \\(n-2\\). Dato che, per calcolare \\(\\hat{y}\\) abbiamo usato due coefficienti (\\(\\) e \\(b\\)), si dice che “abbiamo perso due gradi di libertà”.Dato che \\(s_e\\) possiede la stessa unità di misura della variabile \\(y\\), l’errore standard della stima può essere considerato come una sorta di “residuo medio.” – usando la stessa interpretazione che diamo alla deviazione standard generale.Si noti che la formula precedente non fornisce la “deviazione standard dei residui nel campione” (quella formula avrebbe \\(n\\) al denominatore). Invece, fornisce una stima della deviazione standard dei residui nella popolazione da cui il campione è stato estratto.Verifichiamo quanto detto con dati disposizione.residui possono essere trovati nel modo seguente.Oppure nel modo seguente.Calcolo il residuo medio, prendendo il valore assoluto.L’errore standard della regressione èI due numeri non sono uguali, ma possiamo dire che hanno lo stesso ordine di grandezza.Se usiamo la funzione lm() otteniamo lo stesso valore, chiamato Residual standard error.","code":"\ne <- kidiq$kid_score - (a + b * kidiq$mom_iq)\ne[1:10]\n#>  [1] -34.678390  17.691747 -11.217173  -3.461529  32.627697   6.382845\n#>  [7] -41.521041   3.864881  26.414387  11.208068\nfm$residuals[1:10]\n#>          1          2          3          4          5          6          7 \n#> -34.678390  17.691747 -11.217173  -3.461529  32.627697   6.382845 -41.521041 \n#>          8          9         10 \n#>   3.864881  26.414387  11.208068\nmean(abs(e))\n#> [1] 14.4686\nsqrt(sum(e^2) / (length(e) - 2))\n#> [1] 18.26612\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_iq, data = kidiq)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -56.753 -12.074   2.217  11.710  47.691 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***\n#> mom_iq       0.60997    0.05852   10.42  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 18.27 on 432 degrees of freedom\n#> Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 \n#> F-statistic: 108.6 on 1 and 432 DF,  p-value: < 2.2e-16"},{"path":"ch-regr-model-lm.html","id":"indice-di-determinazione","chapter":"Capitolo 25 Il modello lineare visto da vicino","heading":"25.2 Indice di determinazione","text":"Un importante risultato dei minimi quadrati riguarda la cosiddetta scomposizione della devianza mediante la quale si definisce l’indice di determinazione, il quale fornisce una misura relativa della bontà di adattamento del modello di regressione ai dati del campione. Per una generica osservazione \\(x_i, y_i\\), la variazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere descritta come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]Se consideriamo tutte le osservazioni, la devianza delle \\(y\\) può essere scomposta nel seguente modo:\\[\\begin{align}\n\\sum (y_i - \\bar{y})^2 &= \\sum \\left[ e_i + (\\hat{y}_i - \\bar{y})\n\\right]^2\n= \\sum e_i^2 + \\sum (\\hat{y}_i - \\bar{y})^2 + 2 \\sum e_i (\\hat{y}_i -\n\\bar{y}) \\notag\n\\end{align}\\]Per vincoli imposti sul modello statistico di regressione, il doppio prodotto si annulla, infatti\\[\\begin{align}\n\\sum e_i (\\hat{y}_i - \\bar{y}) &= \\sum e_i \\hat{y}_i - \\bar{y}\\sum e_i = \\sum e_i (+ b x_i) \\notag \\\\\n&= \\sum e_i + b \\sum e_i x_i = 0 \\notag\n\\end{align}\\]Il termine \\(b \\sum e_i x_i\\) è uguale zero perché, come vedremo seguito, coefficienti di regressione vengono calcolati modo tale da rendere nulla \\(\\mbox{Cov}(e, x)\\). Di conseguenza, il termine precedente deve essere nullo.Possiamo dunque concludere che la devianza totale (\\(\\mbox{dev}_T\\)) si scompone nella somma di devianza d’errore (o devianza non spiegata) (\\(\\mbox{dev}_E\\)) e devianza di regressione (o devianza spiegata) (\\(\\mbox{dev}_T\\)):\\[\\begin{align}\n\\underbrace{\\sum_{=1}^n (y_i - \\bar{y})^2}_{\\tiny{\\text{Devianza\ntotale}}} &= \\underbrace{\\sum_{=1}^n e_i^2}_{\\tiny{\\text{Devianza\ndi dispersione}}} + \\underbrace{\\sum_{=1}^n  (\\hat{y}_i -\n\\bar{y})^2}_{\\tiny{\\text{Devianza di regressione}}} \\notag\n\\end{align}\\]La devianza di regressione, \\(\\mbox{dev_R} \\triangleq \\mbox{dev_T} - \\mbox{dev_E}\\), indica dunque la riduzione degli errori al quadrato che è imputabile alla regressione lineare. Il rapporto \\(\\mbox{dev_R}/\\mbox{dev_T}\\), detto , esprime tale riduzione degli errori termini proporzionali e definisce il coefficiente di correlazione al quadrato:\\[\\begin{equation}\nR^2 \\triangleq \\frac{\\mbox{dev_R}}{\\mbox{dev_T}} = 1 - \\frac{\\mbox{dev_E}}{\\mbox{dev_T}}.\n\\end{equation}\\]Quando l’insieme di tutte le deviazioni della \\(y\\) dalla media è spiegato dall’insieme di tutte le deviazioni della variabile teorica \\(\\hat{y}\\) dalla media, si ha che l’adattamento (o accostamento) del modello al campione di dati è perfetto, la\ndevianza residua è nulla ed \\(r^2 = 1\\); nel caso opposto, la variabilità totale coincide con quella residua, per cui \\(r^2 = 0\\).\nTra questi due estremi, \\(r\\) indica l’intensità della relazione lineare tra le due variabili e \\(r^2\\), con \\(0 \\leq r^2 \\leq 1\\), esprime la porzione della devianza totale della \\(y\\) che è spiegata dalla regressione lineare sulla \\(x\\).Per l’esempio discussione abbiamo quanto segue. La devianza totale èLa devianza spiegata èL’indice di determinazione èNell’output di lm() un tale valore è chiamato Multiple R-squared.Il risultato ottenuto si può interpretare dicendo che circa il 20% della variabilità dei punteggi del QI dei bambini può essere predetto conoscendo il QI delle madri.","code":"\ndev_t <- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#> [1] 180386.2\ndev_r <- sum((fm$fitted.values - mean(kidiq$kid_score))^2)\ndev_r\n#> [1] 36248.82\nR2 <- dev_r / dev_t\nR2\n#> [1] 0.2009512\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_iq, data = kidiq)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -56.753 -12.074   2.217  11.710  47.691 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***\n#> mom_iq       0.60997    0.05852   10.42  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 18.27 on 432 degrees of freedom\n#> Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 \n#> F-statistic: 108.6 on 1 and 432 DF,  p-value: < 2.2e-16"},{"path":"ch-regr-model-lm.html","id":"inferenza-sul-modello-di-regressione","chapter":"Capitolo 25 Il modello lineare visto da vicino","heading":"25.2.1 Inferenza sul modello di regressione","text":"La discussione precedente era tutta basata sulla trattazione “classica” del modello lineare, ovvero una trattazione basata sulle stime di massima verosimiglianza (se \\(y \\sim \\mathcal{N}(\\alpha + \\beta x, \\sigma)\\), allora le stime dei minimi quadrati coincidono con le stime di massima verosimiglianza). altre parole, nella discussione precedente non abbiamo considerato alcun modo le distribuzioni priori dei parametri \\(\\alpha\\) e \\(\\beta\\). altre parole, risultati precedenti si confermano, un contesto bayesiano, se e solo se imponiamo sui parametri delle distribuzioni priori non informative (cioè, uniformi). tali circostanze, le stime di massima verosimiglianza sono identiche al massimo posteriori bayesiano.Detto questo, il tema dell’inferenza viene trattato dall’approccio frequentista costruendo la “distribuzione campionaria” dei parametri (ovvero la distribuzione dei valori che parametri otterrebbero infiniti campioni casuali (\\(x, y\\)) di ampiezza \\(n\\) estratti dalla medesima popolazione) e poi calcolando gli errori standard dei parametri e gli intervalli di fiducia dei parametri. Una domanda frequente è, per esempio, se la pendenza della retta di regressione sia maggiore di zero. Per rispondere tale domanda l’approccio frequentista calcola l’intervallo di fiducia al 95% per il parametro \\(\\beta\\). Se tale intervallo non include lo zero, e se il limite inferiore di tale intervallo è maggiore di zero, allora si conclude, con un grado di confidenza del 95%, che il vero parametro \\(\\beta\\) nella popolazione è maggiore di zero. Ovvero, si conclude che vi sono evidenze di un’associazione lineare positiva tra \\(x\\) e \\(y\\).Alla stessa conclusione si può arrivare calcolando, un ottica bayesiana, l’intervallo di credibilità al 95% per il parametro \\(\\beta\\). due intervalli sono identici se usiamo una distribuzione priori piatta. Sono invece diversi se usiamo una distribuzione priori debolmente informativa, oppure informativa.Solitamente si usa una distribuzione priori debolmente informativa centrata sullo zero. tali circostanze, l’uso della distribuzione priori ha solo un effetto di regolarizzazione, ovvero di riduzione del peso delle osservazioni estreme – un tale risultato statistico è molto desiderabile, ma è difficile da ottenere un contesto frequentista. Vedremo nel prossimo capitolo come può essere svolta l’inferenza sui coefficienti del modello di regressione lineare un contesto bayesiano.","code":""},{"path":"ch-regr-model-lm.html","id":"commenti-e-considerazioni-finali-20","chapter":"Capitolo 25 Il modello lineare visto da vicino","heading":"Commenti e considerazioni finali","text":"Il modello lineare semplice viene usato per descrivere la relazione tra due variabili e per determinare il segno e l’intensità di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente base al valore assunto dalla variabile indipendente.","code":""},{"path":"ch-reg-lin-stan.html","id":"ch-reg-lin-stan","chapter":"Capitolo 26 Modello lineare in Stan","heading":"Capitolo 26 Modello lineare in Stan","text":"Mostreremo qui come sia possibile usare il linguaggio probabilistico Stan per la stima dei parametri del modello di regressione e per l’inferenza.","code":""},{"path":"ch-reg-lin-stan.html","id":"una-distribuzione-a-priori-debolmente-informativa","chapter":"Capitolo 26 Modello lineare in Stan","heading":"26.1 Una distribuzione a priori debolmente informativa","text":"Per implementare l’approccio bayesiano è necessario assegnare una distribuzione priori ai parametri. Nel contesto del modello di regressione è desiderabile scegliere distribuzioni priori che abbiano uno scarso impatto sulla distribuzione posteriori.Supponiamo che le nostre credenza priori sui parametri del modello, \\(\\beta_0\\), \\(\\beta_1\\) e \\(\\sigma\\) siano tra loro indipendenti. Allora possiamo scrivere la distribuzione congiunta dei parametri nel modo seguente:\\[\np(\\beta_0, \\beta_1, \\sigma) = p(\\beta_0)p(\\beta_1)p(\\sigma).\n\\]Per coefficienti di regressione possiamo assumere \\(\\beta_0 \\sim \\mathcal{N}(\\mu_0, s_0)\\) e \\(\\beta_1 \\sim \\mathcal{N}(\\mu_1, s_1)\\). Per \\(\\sigma\\) possiamo assumere, ad esempio, \\(\\sigma \\sim \\mbox{Cauchy}(, b)\\). Moltiplicando la verosimiglianza\\[\n\\prod_{=1}^n p(y_i \\mid x_i; \\beta_0, \\beta_1, \\sigma^2) = \\prod_{=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{-\\frac{(y_i-(\\beta_0+\\beta_1 x_i))^2}{2\\sigma^2}}\n\\]per le distribuzioni priori dei parametri, si ottiene la distribuzione posteriori. Tuttavia, tale distribuzione non è risolvibile per via analitica. Come precedenza, usiamo invece un algoritmo MCMC per ottenere una sequenza di campioni casuali dalla distribuzione posteriori.","code":""},{"path":"ch-reg-lin-stan.html","id":"linguaggio-stan","chapter":"Capitolo 26 Modello lineare in Stan","heading":"26.2 Linguaggio Stan","text":"È conveniente usare il linguaggio Stan per ottenere una sequenza MCMC dalla distribuzione posteriori di un modello di regressione. È semplice formulare la descrizione di un modello bayesiano (verosimiglianza e distribuzione priori) uno script scritto linguaggio Stan.Continuiamo qui l’esempio precedente cui ci si poneva il problema di descrivere l’associazione tra il QI dei figli e il QI delle madri mediante un modello lineare. dati sono quelli del dataset kidiq:Per farci un’idea del valore dei parametri, adattiamo il modello lineare ai dati mediante la procedura di massima verosimiglianza (come abbiamo fatto nel capitolo precedente):Sulla base delle informazioni precedenti, giungiamo alla seguente formulazione bayesiana del modello lineare:\\[\n\\begin{aligned}\ny_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\beta_0 + \\beta_1 x_i \\\\\n\\beta_0 &\\sim \\mathcal{N}(25, 10) \\\\\n\\beta_1 &\\sim \\mathcal{N}(0, 1) \\\\\n\\sigma &\\sim \\text{Cauchy}(18, 5)\n\\end{aligned}\n\\]La prima riga definisce la funzione di verosimiglianza e le righe successive definiscono le distribuzioni priori dei parametri. Il segno \\(\\sim\\) (tilde) si può leggere “si distribuisce come”. La prima riga ci dice che ciascuna osservazione \\(y_i\\) è una variabile casuale che segue la distribuzione gaussiana di parametri \\(\\mu_i\\) e \\(\\sigma\\). La seconda riga specifica, maniera deterministica, che ciascun \\(\\mu_i\\) è una funzione lineare di \\(x_i\\), con parametri \\(\\beta_0\\) e \\(\\beta_1\\). Le due righe successive specificano le distribuzioni priori per \\(\\beta_0\\) e \\(\\beta_1\\). La distribuzione priori di \\(\\beta_0\\) è una distribuzione gaussiana di parametri \\(\\mu_{\\alpha} = 25\\) e deviazione standard \\(\\sigma_{\\alpha} = 10\\); la distribuzione priori di \\(\\beta_1\\) è una distribuzione gaussiana standardizzata. L’ultima riga definisce la distribuzione priori di \\(\\sigma\\), ovvero una Cauchy di parametri 18 e 5.Dobbiamo ora specificare il modello bayesiano descritto sopra linguaggio Stan29.Consideriamo il seguente modello linguaggio Stan:La funzione modelString() registra una stringa di testo mentre writeLines() crea un file nell’indirizzo specificato. Tale file deve avere l’estensione .stan.Per svolgere l’analisi bayesiana sistemiamo dati nel formato appropriato per Stan:La funzione file.path() ritorna l’indirizzo del file con il codice Stan:Prendendo come input un file contenente un programma Stan, la funzione cmdstan_model() ritorna un oggetto di classe CmdStanModel. pratica, CmdStan traduce un programma Stan C++ e crea un eseguibile compilato.Il codice Stan può essere stampato usando il metodo $print():L’indirizzo dell’eseguibile compilato viene ritornato da $exe_file():Applicando il metodo $sample() ad un oggetto CmdStanModel eseguiamo il campionamento MCMC:Al metodo $sample() possono essere passati molti argomenti. La pagina di documentazione è disponibile al seguente link.Un sommario della distribuzione posteriori per parametri stimati si ottiene con il metodo $summary(), il quale chiama la funzione summarise_draws() del pacchetto posterior:Da questo output possiamo valutare rapidamente la convergenza del modello osservando valori di Rhat per ciascun parametro. Quando questi sono pari o vicini 1, le catene hanno realizzato la convergenza. Ci sono molti altri test diagnostici, ma questo test è importante per Stan.Oppure è possibile usare:Le statistiche diagnostiche sono fornite dal metodo $cmdstan_diagnose():È possibile creare un oggetto di classe stanfitper poi utilizzare le funzioni del pacchetto bayesplot. Ad esempio:Infine, eseguendo la funzione launch_shinystan(fit), è possibile analizzare oggetti di classe stanfit mediante le funzionalità del pacchetto ShinyStan.","code":"\nlibrary(\"rio\")\ndf <- rio::import(here::here(\"data\", \"kidiq.dta\"))\nhead(df)\n#>   kid_score mom_hs    mom_iq mom_work mom_age\n#> 1        65      1 121.11753        4      27\n#> 2        98      1  89.36188        4      25\n#> 3        85      1 115.44316        4      27\n#> 4        83      1  99.44964        3      25\n#> 5       115      1  92.74571        4      27\n#> 6        98      0 107.90184        1      18\nfm <- lm(kid_score ~ mom_iq, data = df)\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_iq, data = df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -56.753 -12.074   2.217  11.710  47.691 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***\n#> mom_iq       0.60997    0.05852   10.42  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 18.27 on 432 degrees of freedom\n#> Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 \n#> F-statistic: 108.6 on 1 and 432 DF,  p-value: < 2.2e-16\nmodel_string_1 = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n}\nmodel {\n  // priors\n  alpha ~ normal(25, 10);\n  beta ~ normal(0, 1);\n  sigma ~ cauchy(18, 5);\n  // likelihood\n  for (n in 1:N)\n    y[n] ~ normal(alpha + beta * x[n], sigma);\n}\n\"\nwriteLines(model_string_1, con = \"code/simpleregkidiq.stan\")\ndata_list <- list(\n  N = length(df$kid_score),\n  y = df$kid_score,\n  x = df$mom_iq\n)\nfile_simple_reg <- file.path(\"code\", \"simpleregstd.stan\")\nmod1 <- cmdstan_model(file_simple_reg)\nmod1$print()\nmod1$exe_file()\nfit_1 <- mod1$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nfit_1$summary(c(\"alpha\", \"beta\", \"sigma\"))\n#> # A tibble: 3 × 10\n#>   variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    25.7   25.7   5.95   6.00   16.0   35.5    1.00   16007.   11770.\n#> 2 beta      0.610  0.611 0.0589 0.0597  0.515  0.708  1.00   15771.   11703.\n#> 3 sigma    18.3   18.3   0.627  0.626  17.3   19.4    1.00   15126.   12112.\nfit_1$cmdstan_summary()\nfit_1$cmdstan_diagnose()\nstanfit_1 <- rstan::read_stan_csv(fit_1$output_files())\nstanfit_1 %>% \n  mcmc_trace(pars = c(\"alpha\", \"beta\", \"sigma\"))"},{"path":"ch-reg-lin-stan.html","id":"standardizzare-i-dati","chapter":"Capitolo 26 Modello lineare in Stan","heading":"26.2.1 Standardizzare i dati","text":"Il codice Stan viene eseguito più velocemente se l’input è standardizzato così da avere una media pari zero e una varianza unitaria.30 Ponendo \\(y = (y_1, \\dots, y_n)\\) e \\(x = (x_1, \\dots, x_n)\\), il modello lineare può essere scritto come\\[\ny_i = \\alpha + \\beta x_i + \\varepsilon_i,\n\\]dove\\[\n\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma).\n\\]Seguendo la notazione del manuale Stan, parametri del modello lineare sono qui denotati da \\(\\alpha\\) e \\(\\beta\\). Per eseguire la standardizzazione dei dati, è necessario centrare dati, sottraendo da essi la media campionaria, per poi scalarli dividendo per la deviazione standard campionaria. Una singola osservazione \\(u\\) viene standardizzata dalla funzione \\(z\\) definita da\\[\nz_y(u) = \\frac{u - \\bar{y}}{\\texttt{sd}(y)}\n\\]dove la media \\(\\bar{y}\\) è\\[\n\\bar{y} = \\frac{1}{n} \\sum_{=1}^n y_i,\n\\]\ne la deviazione standard è\\[\n\\texttt{sd} = \\left(\\frac{1}{n}\\sum_{=1}^n(y_i - \\bar{y})^2\\right)^{-\\frac{1}{2}}.\n\\]La trasformata inversa è definita invertendo due passaggi precedenti: la deviazione standard è usata per scalare valori \\(u\\) e la media campionaria è usata per traslare la distribuzione dei valori \\(u\\) scalati:\\[\nz_y^{-1}(u) = \\texttt{sd}(y)u + \\bar{y}.\n\\]Modificando il codice del modello precedente otteniamo il modello Stan per dati standardizzati. Il blocco data è identico quello del caso precedente. predittori e la risposta standardizzati sono definiti nel blocco transformed data. Per semplificare la notazione (e velocizzare l’esecuzione), nel blocco model l’istruzione di campionamento è espressa forma vettorializzata: y_std ~ normal(alpha_std + beta_std * x_std, sigma_std);.Si noti che parametri vengono rinominati per indicare che non sono parametri “naturali”, ma per il resto il modello è identico. Sono qui utilizzate distribuzioni priori debolmente informative per parametri alpha e beta.valori dei parametri sulla scala originale dei dati vengono calcolati nel blocco generated quantities e possono essere recuperati con un po’ di algebra.\\[\\begin{align}\ny_n &= \\textrm{z}_y^{-1}(\\textrm{z}_y(y_n)) \\notag\\\\\n    &= \\textrm{z}_y^{-1}\n\\left( \\alpha' + \\beta' \\textrm{z}_x(x_n) + \\epsilon_n' \\right) \\notag\\\\\n    &= \\textrm{z}_y^{-1}\n\\left( \\alpha' + \\beta' \\left( \\frac{x_n - \\bar{x}}{\\texttt{sd}(x)} \\right) + \\epsilon_n' \\right) \\notag\\\\\n    &= \\texttt{sd}(y)\n\\left( \\alpha' + \\beta' \\left( \\frac{x_n - \\bar{x}}{\\texttt{sd}(x)} \\right) + \\epsilon_n' \\right) + \\bar{y} \\notag\\\\\n    &=\n\\left( \\texttt{sd}(y) \\left( \\alpha' - \\beta' \\frac{\\bar{x}}{\\texttt{sd}(x)} \\right) + \\bar{y} \\right)\n+ \\left( \\beta' \\frac{\\texttt{sd}(y)}{\\texttt{sd}(x)} \\right) x_n\n+ \\texttt{sd}(y) \\epsilon'_n,\n\\end{align}\\]da cui\\[\n\\alpha\n=\n\\texttt{sd}(y)\n      \\left(\n          \\alpha'\n          - \\beta' \\frac{\\bar{x}}{\\texttt{sd}(x)}\n      \\right)\n  + \\bar{y};\n\\qquad\n\\beta = \\beta' \\frac{\\texttt{sd}(y)}{\\texttt{sd}(x)};\n\\qquad\n\\sigma = \\texttt{sd}(y) \\sigma'.\n\\]La funzione file.path() ritorna l’indirizzo del file con il codice Stan:Compiliamo.Eseguo il campionamento MCMC.Esamino risultatiSi noti che, avendo usato delle distribuzioni priori debolmente informative, le stime dei parametri sono molto simili quelle ottenute mediante la procedura di massima verosimiglianza.Anziché standardizzare dati ’interno del programma Stan è anche possibile procedere un modo diverso, ovvero standardizzare dati forniti input. Questa, realtà, è la procedura usuale. Ciò consente di specificare, per ciascun parametro, una distribuzione priori su una scala “naturale” per Stan, ovvero quella di una variabile Normale standardizzata. Se non ci sono ragioni particolari per mantenere l’unità di misura dei dati grezzi, standardizzare dati input è la strategia migliore.","code":"\nmodel_string_2 = \"\ndata {\n  int<lower=0> N; \n  vector[N] y; \n  vector[N] x; \n}\ntransformed data {\n  vector[N] x_std;\n  vector[N] y_std;\n  x_std = (x - mean(x)) / sd(x);\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  real alpha_std;\n  real beta_std;\n  real<lower=0> sigma_std;\n}\ntransformed parameters {\n  vector[N] mu_std = alpha_std + beta_std * x_std; \n}\nmodel {\n  alpha_std ~ normal(0, 1); \n  beta_std ~ normal(0, 1);  \n  sigma_std ~ normal(0, 1); \n  y_std ~ normal(mu_std, sigma_std); \n}\ngenerated quantities {\n  // transform to the original data scale\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y);\n  beta = beta_std * sd(y) / sd(x);\n  sigma = sd(y) * sigma_std;\n}\n\"\nwriteLines(model_string_2, con = \"code/simpleregstd.stan\")\nfile_simple_reg_std <- file.path(\"code\", \"simpleregstd.stan\")\nmod2 <- cmdstan_model(file_simple_reg_std)\nfit_2 <- mod2$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nfit_2$summary(c(\"alpha_std\", \"beta_std\", \"sigma_std\", \"alpha\", \"beta\", \"sigma\"))\n#> # A tibble: 6 × 10\n#>   variable       mean    median     sd    mad      q5     q95  rhat ess_bulk\n#>   <chr>         <dbl>     <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl>    <dbl>\n#> 1 alpha_std  0.000107 -0.000149 0.0432 0.0423 -0.0703  0.0715  1.00   18705.\n#> 2 beta_std   0.448     0.448    0.0438 0.0443  0.375   0.520   1.00   20084.\n#> 3 sigma_std  0.897     0.896    0.0311 0.0316  0.848   0.950   1.00   18813.\n#> 4 alpha     25.9      25.8      6.02   6.02   16.0    35.8     1.00   20176.\n#> 5 beta       0.609     0.609    0.0596 0.0603  0.511   0.707   1.00   20084.\n#> 6 sigma     18.3      18.3      0.634  0.644  17.3    19.4     1.00   18813.\n#> # … with 1 more variable: ess_tail <dbl>\ncoef(fm)\n#> (Intercept)      mom_iq \n#>  25.7997778   0.6099746"},{"path":"ch-reg-lin-stan.html","id":"interpretazione-dei-parametri","chapter":"Capitolo 26 Modello lineare in Stan","heading":"26.3 Interpretazione dei parametri","text":"Ripeto qui la discussione del capitolo precedente. Assegnamo ai parametri la seguente interpretazione.L’intercetta pari 25.9 indica il QI medio dei bamini la cui madre ha un QI = 0. Ovviamente questo non ha alcun significato. Vedremo nel modello successivo come trasformare il modello modo da potere assegnare ’intercetta un’interpretazione sensata.L’intercetta pari 25.9 indica il QI medio dei bamini la cui madre ha un QI = 0. Ovviamente questo non ha alcun significato. Vedremo nel modello successivo come trasformare il modello modo da potere assegnare ’intercetta un’interpretazione sensata.La pendenza di 0.61 indica che, ’aumentare di un punto del QI delle madri, il QI medio dei loro bambini aumenta di 0.61 unità. Se consideriamo la gamma di variazione del QI delle madri nel campione, il QI medio dei bambini cambia di 41 punti. Questo indica un sostanziale effetto del QI delle madri sul QI dei loro bambini: \\((138.89 - 71.04) * 0.61 = 41.39\\).La pendenza di 0.61 indica che, ’aumentare di un punto del QI delle madri, il QI medio dei loro bambini aumenta di 0.61 unità. Se consideriamo la gamma di variazione del QI delle madri nel campione, il QI medio dei bambini cambia di 41 punti. Questo indica un sostanziale effetto del QI delle madri sul QI dei loro bambini: \\((138.89 - 71.04) * 0.61 = 41.39\\).Il parametro \\(\\sigma\\) = 18.3 fornisce una stima della dispersione delle osservazioni attorno al valore predetto dal modello lineare, ovvero fornisce una stima della deviazione standard dei residui attorno al valore atteso del modello lineare.Il parametro \\(\\sigma\\) = 18.3 fornisce una stima della dispersione delle osservazioni attorno al valore predetto dal modello lineare, ovvero fornisce una stima della deviazione standard dei residui attorno al valore atteso del modello lineare.","code":""},{"path":"ch-reg-lin-stan.html","id":"centrare-i-predittori","chapter":"Capitolo 26 Modello lineare in Stan","heading":"26.3.1 Centrare i predittori","text":"Come abbiamo detto precedenza, per migliorare l’interpretazione dell’intercetta possiamo “centrare” la \\(x\\), ovvero esprimere la \\(x\\) nei termini degli scarti dalla media: \\(x - \\bar{x}\\). tali circostanze, la pendenza della retta specificata dal modello lineare resta immutata, ma l’intercetta corrisponde \\(\\mathbb{E}(y \\mid x = \\bar{x})\\). Per ottenere questo risultato, modifichiamo dati da passare Stan:Adattiamo il modello:Trasformiamo l’oggetto fit un oggetto di classe stanfit:Le stime posteriori dei parametri si ottengono conSi noti la nuova intercetta, ovvero 86.8. Questo valore indica il QI medio dei bambini le cui madri hanno un QI pari alla media del campione. Centrare dati consente dunque di assegnare ’intercetta un’interpretazione utile. Dall’output ottenuto possiamo ricavare, ad esempio, l’intervallo di credibilità al 90%. Ovvero, con un grado di certezza soggettiva del 90%, possiamo concludere che, se consideriamo solo le madri con un QI pari alla media del presente campione, possiamo prevedere che il QI medio dei loro figli sarà compreso nell’intervallo [85.4, 88.2].","code":"\ndata2_list <- list(\n  N = length(df$kid_score),\n  y = df$kid_score,\n  x = df$mom_iq - mean(df$mom_iq)\n)\nfit_3 <- mod2$sample(\n  data = data2_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nstanfit_3 <- rstan::read_stan_csv(fit_3$output_files())\nfit_3$summary(c(\"alpha\", \"beta\", \"sigma\"))\n#> # A tibble: 3 × 10\n#>   variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    86.8   86.8   0.876  0.871  85.4   88.2    1.00   16318.   11494.\n#> 2 beta      0.609  0.609 0.0591 0.0589  0.513  0.707  1.00   16206.   11236.\n#> 3 sigma    18.3   18.3   0.630  0.624  17.3   19.4    1.00   15617.   11986."},{"path":"ch-reg-lin-stan.html","id":"commenti-e-considerazioni-finali-21","chapter":"Capitolo 26 Modello lineare in Stan","heading":"Commenti e considerazioni finali","text":"La presente discussione suggerisce che è conveniente standardizzare dati prima di procedere con l’analisi. Ciò può essere fatto ’interno del codice Stan (come negli esempi di questo Capitolo), oppure prima di passare dati Stan. Se vengono usati dati standardizzati diventa poi facile utilizzare distribuzioni priori debolmente informative per parametri. Tali distribuzioni priori hanno, come unico scopo, quello di regolarizzare dati e di facilitare la stima dei parametri mediante la procedura MCMC.","code":""},{"path":"ch-inference-reg-lin-stan.html","id":"ch-inference-reg-lin-stan","chapter":"Capitolo 27 Inferenza sul modello lineare","heading":"Capitolo 27 Inferenza sul modello lineare","text":"","code":""},{"path":"ch-inference-reg-lin-stan.html","id":"rappresentazione-grafica-dellincertezza-della-stima","chapter":"Capitolo 27 Inferenza sul modello lineare","heading":"27.1 Rappresentazione grafica dell’incertezza della stima","text":"Un primo modo per rappresentare l’incertezza dell’inferenza un ottica bayesiana è quella di rappresentare graficamente la retta specificata dal modello lineare. Continuando con l’esempio descritto nel Capitolo precedente (ovvero, dati kid_score e valori mom_iq centrati), usando la funzione rstan::read_stan_csv leggiamo file CSV generati da cmdstan e trasformiamo le stime posteriori dei parametri formato stanfit:L’oggetto post è una lista:Esaminiamo il contenuto di post.Da post è possibile estrarre alpha e beta. L’output di glimpse() ci dice che alpha è un vettore di 16,000 elementi. Ciascuno di questi elementi è un valore estratto caso dalla distribuzione posteriori del parametro \\(\\alpha\\). È dunque possibile calcolare una stima puntuale della distribuzione posteriori del parametro \\(\\alpha\\) semplicemente trovando la media di tali valori: mean(post$alpha). Lo stesso si può dire di beta.Per creare un diagramma dispersione dei dati con sovrapposto il valore atteso della \\(y\\) usiamo la sintassi seguente.Si noti l’uso della funzione geom_abline() che prende come argomenti l’intercetta e la pendenza di una retta. Nel caso presente, tali argomenti corrispondono mean(post$alpha) e mean(post$beta), ovvero, specificano valori posteriori più plausibili dei parametri \\(\\alpha\\) e \\(\\beta\\).Così facendo (ovvero, selezionando il valore più plausibile posteriori per parametri \\(\\alpha\\) e \\(\\beta\\)) abbiamo disegnato una singola retta. Ma una sola retta non ci fa capire qual è il grado di incertezza associato alla stima di \\(\\alpha\\) e \\(\\beta\\). Una tale incertezza può essere visualizzata tracciando molteplici rette, ciascuna delle quali definita da un diverso valore estratto caso dalla distribuzione posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).Per ottenere questo risultato dobbiamo estrarre le informazioni richieste dall’oggetto stanfit che abbiamo creato. Per fare questo possiamo usare, ad esempio, le funzioni di tidybayes. Iniamo elencare nomi degli oggetti contenuti stanfit.Vogliamo creare un Dataframe formato tidy, cioè, tale per cui le osservazioni stanno sulle righe e le variabili stanno sulle colonne, che contiene le stime posteriori di \\(\\alpha\\) e \\(\\beta\\). Per fare questo usiamo spread_draws().Esaminiamo il risultato ottenuto.Avendo sistemato dati nel formato desiderato, possiamo ora generare un diagramma dispersione con ggplot():Si noti il seguene frammento di codice:Questa istruzione recupera dai dati draw valori alpha e beta. Ci sono 16,000 coppie di valori alpha e beta. L’istruzionedisegna dunque 16,000 rette. L’argomento grafico alpha = 0.01 specifica la tasparenza con cui viene disegnata ciascuna retta. Ho usato un valore molto basso per fare modo che, anche sovrapponendo 16,000 rette, si produce ancora una certa quantità di trasparenza.Il grafico mostra che le rette di regressione costruite estraendo caso valori dalla distribuzione posteriori dei parametri \\(\\beta_0\\) e \\(\\beta_1\\) tendono ad essere molto simili tra loro. Ciò significa che, se combiniamo le informazioni fornite dai dati con le nostre credenza precedenti (qui, dei prior poco informativi), allora dobbiamo concludere che l’incertezza relativa alla dipendenza lineare del quoziente di intelligenza del bambino da quello della madre è decisamente piccola. altre parole, siamo molto sicuri che vi sia una associazione lineare positiva tra le due variabili: media il QI dei figli è positivamente associato al QI della madre.Il modello statistico ci dice che possiamo considerare l’affermazione precedente come un fatto su cui c’è poco da dubitare. Ma il modello statistico non ci dice nulla sulle cause di questa associazione: ci dice soltanto che le due variabili tendono covariare. Non ci dice alcun modo che il QI della madre sia la “causa” del QI del figlio. Questo è un argomento su cui è stata fatta molta ricerca (e di ciò qui non diciamo nulla). Ma, al di là dei risultati di tali ricerche, se consideriamo solo il risultato del modello statistico qui esaminato, non possiamo concludere nulla sui rapporti di causa/effetto tra QI della madre e QI del figlio. L’unica conclusione che possiamo trarre dall’analisi statistica è che ci sono evidenze di un’associazione tra le due variabili; niente si può dire sui rapporti di causa/effetto. La presenza di un’associazione è una condizione necessaria ma non sufficiente per potere concludere che vi è una nesso di causalità.","code":"\nstanfit <- rstan::read_stan_csv(fit2$output_files())\npost <- extract(stanfit)\nclass(post)\n#> [1] \"list\"\nglimpse(post)\n#> List of 7\n#>  $ alpha_std: num [1:16000(1d)] 0.0582 0.0407 -0.0828 0.0997 0.0886 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ beta_std : num [1:16000(1d)] 0.421 0.494 0.457 0.496 0.491 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ sigma_std: num [1:16000(1d)] 0.907 0.899 0.878 0.932 0.972 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ alpha    : num [1:16000(1d)] 88 87.6 85.1 88.8 88.6 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ beta     : num [1:16000(1d)] 0.573 0.672 0.622 0.675 0.668 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ sigma    : num [1:16000(1d)] 18.5 18.3 17.9 19 19.8 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ lp__     : num [1:16000(1d)] -170 -169 -171 -172 -174 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\ntibble(\n  kid_score = df$kid_score,\n  mom_iq = df$mom_iq - mean(df$mom_iq)\n) %>%\n  ggplot(aes(mom_iq, kid_score)) +\n  geom_point() +\n  geom_abline(\n    intercept = mean(post$alpha),\n    slope = mean(post$beta)\n  )\ntidybayes::get_variables(stanfit)\n#>  [1] \"alpha_std\"     \"beta_std\"      \"sigma_std\"     \"alpha\"        \n#>  [5] \"beta\"          \"sigma\"         \"lp__\"          \"accept_stat__\"\n#>  [9] \"treedepth__\"   \"stepsize__\"    \"divergent__\"   \"n_leapfrog__\" \n#> [13] \"energy__\"\ndraws <- stanfit %>%\n  spread_draws(beta, alpha)\ndraws %>%\n  head(10)\n#> # A tibble: 10 × 5\n#>   .chain .iteration .draw  beta alpha\n#>    <int>      <int> <int> <dbl> <dbl>\n#> 1      1          1     1 0.632  88.4\n#> 2      1          2     2 0.491  87.5\n#> 3      1          3     3 0.717  85.9\n#> 4      1          4     4 0.478  87.5\n#> 5      1          5     5 0.610  86.4\n#> 6      1          6     6 0.570  86.7\n#> 7      1          7     7 0.623  87.0\n#> 8      1          8     8 0.616  87.2\n#> # … with 2 more rows\ntibble(\n  kid_score = df$kid_score,\n  mom_iq = df$mom_iq - mean(df$mom_iq)\n) %>%\n  ggplot(aes(mom_iq, kid_score)) +\n  geom_point() +\n  geom_abline(\n    data = draws, \n    aes(intercept = alpha, slope = beta),\n    size = 0.2, alpha = 0.01, color = \"darkgray\"\n  ) +\n  geom_abline(\n    intercept = mean(post$alpha),\n    slope = mean(post$beta)\n  ) +\n  labs(\n    x = \"Quoziente di intelligenza della madre\",\n    y = \"Quoziente di intelligenza del bambino\"\n  )\ngeom_abline(\n  data = draws, \n  aes(intercept = alpha, slope = beta),\n  size = 0.2, alpha = 0.01, color = \"darkgray\"\n)aes(intercept = alpha, slope = beta),"},{"path":"ch-inference-reg-lin-stan.html","id":"intervalli-di-credibilità-1","chapter":"Capitolo 27 Inferenza sul modello lineare","heading":"27.2 Intervalli di credibilità","text":"L’incertezza inferenziale sui parametri può essere descritta mediante gli intervalli di credibilità, ovvero gli intervalli che contengono la quota desiderata (es., il 95%) della distribuzione posteriori. Per l’esempio che stiamo discutendo, gli intervalli di credibilità (code uguali) al 95% si ottengono nel modo seguente:Un grafico che, nel caso dei dati standardizzati, riporta l’intervallo di credibilità al livello di probabilità desiderato per parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) si ottiene con l’istruzione seguente.Oppure nel modo nel modo seguente.","code":"\nrstantools::posterior_interval(\n  as.matrix(stanfit), \n  prob = 0.95\n)\n#>                    2.5%         97.5%\n#> alpha_std   -0.08427372    0.08441589\n#> beta_std     0.36136782    0.53165187\n#> sigma_std    0.83902970    0.96033440\n#> alpha       85.07713000   88.52020750\n#> beta         0.49171840    0.72342520\n#> sigma       17.12519250   19.60110750\n#> lp__      -173.15907500 -168.54400000\nmcmc_areas(\n  fit2$draws(c(\"alpha_std\", \"beta_std\", \"sigma_std\")),\n  prob = 0.8,\n  prob_outer = 0.95\n)\nstanfit %>%\n  mcmc_intervals(\n    pars = c(\"alpha_std\", \"beta_std\", \"sigma_std\"),\n    prob = 0.8,\n    prob_outer = 0.95\n  )"},{"path":"ch-inference-reg-lin-stan.html","id":"quale-soglia-usare","chapter":"Capitolo 27 Inferenza sul modello lineare","heading":"27.2.1 Quale soglia usare?","text":"Non c’è niente di “magico” o necessario relativamente al livello pari 0.95: il valore 0.95 è arbitrario. Sono possibili tantissime altre soglie per quantificare la nostra incertezza: alcuni ricercatori usano il livello di 0.89, altri quello di 0.5. Se l’obiettivo è quello di descrivere il livello della nostra incertezza relativamente alla stima del parametro, allora dobbiamo riconoscere che la nostra incertezza è descritta dall’intera distribuzione posteriori. Per cui il metodo più semplice, più diretto e più completo per descrivere la nostra incertezza rispetto alla stima dei parametri è semplicemente quello di riportare graficamente tutta la distribuzione posteriori. Una rappresentazione della distribuzione posteriori dei parametri del modello per l’esempio presente si ottiene con la seguente istruzione.","code":"\nrstan::stan_dens(\n  stanfit,\n  pars = c(\"alpha\", \"beta\", \"sigma\"),\n  fill = \"lightgray\"\n)"},{"path":"ch-inference-reg-lin-stan.html","id":"test-di-ipotesi","chapter":"Capitolo 27 Inferenza sul modello lineare","heading":"27.3 Test di ipotesi","text":"È facile valutare ipotesi direzionali usando Stan. Per esempio, la probabilità \\(P(\\hat{\\beta}_1 > 0)\\) èovvero, la probabilità \\(P(\\hat{\\beta}_1 < 0)\\) èCiò significa che, relativamente alla presenza di un’associazione lineare positiva tra QI della madre e QI del figlio, la forza dell’evidenza è enorme.","code":"\nsum(post$beta > 0) / length(post$beta)\n#> [1] 1\nsum(post$beta < 0) / length(post$beta)\n#> [1] 0"},{"path":"ch-inference-reg-lin-stan.html","id":"modello-lineare-robusto","chapter":"Capitolo 27 Inferenza sul modello lineare","heading":"27.4 Modello lineare robusto","text":"Spesso ricercatori devono affrontare il problema degli outlier: presenza di outlier, un modello statistico basato sulla distribuzione gaussiana produrrà delle stime distorte dei parametri, ovvero stime che non si generalizzano ad altri campioni di dati. Il metodo tradizionale per affrontare questo problema è quello di eliminare gli outlier prima di eseguire l’analisi statistica. Il problema di questo approccio, però, è che il criterio utilizzato per eliminare gli outlier, quale esso sia, è arbitrario; dunque, usando criteri diversi per la rimozione di outlier, ricercatori finiscono per trovare risultati diversi.Questo problema trova una semplice soluzione nell’approccio bayesiano. Il modello lineare che abbiamo dicusso finora ipotizza una specifica distribuzione degli errori, ovvero \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\). un modello formulato questi termini, la presenza di solo un valore anomalo e influente ha un effetto drammatico sulle stime dei parametri.Per fare un esempio, introduciamo un singlo valore anomalo e influente nel set dei dati dell’esempio che stiamo discutendo:Per comodità, calcoliamo le stime di \\(\\alpha\\) e \\(\\beta\\) con il metodo dei minimi quadrati (tali stime sono simili quelle che si otterrebbero con un modello bayesiano gaussiano che impiega distribuzioni priori debolmente informative). Sappiamo che, nel campione originale di dati, \\(\\hat{\\beta} \\approx 0.6\\). presenza di un solo outlier, la stima di \\(\\beta\\) viene drammaticamente ridotta:generale, non è necessario assumere \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\). È altrettanto valido un modello che ipotizza una diversa distribuzione per gli errori come, ad esempio, la distribuzione \\(t\\) di Student con un piccolo numero di gradi di libertà. Una caratteristica della \\(t\\) di Student è che le code della distribuzione contengono una massa di probabilità maggiore della distribuzione gaussiana. Ciò fornisce alla \\(t\\) di Student la possibilità di “rendere conto” della presenza di osservazioni lontane dalla media della distribuzione. altri termini, se modello lineare usiamo la \\(t\\) di Student quale distribuzione degli errori, la presenza di outlier avrà un’influenza minore sulle stime dei parametri di quanto avviene nel tradizionale modello lineare gaussiano.Per verificare questa affermazione, modifichiamo il codice Stan usato precedenza modo tale da ipotizzare che \\(y\\) segua una distribuzione \\(t\\) di Student con un numero \\(\\nu\\) gradi di libertà stimato dal modello: student_t(nu, mu, sigma).31Costruiamo la lista dei dati usando il data.frame df2 che include l’outlier:Adattiamo il modello lineare robusto ai dati:Se esaminiamo le stime dei parametri notiamo che la stima di \\(\\beta\\) non è stata influenzata dalla presenza di un’osservazione anomala e influente:Il modello lineare robusto non risente dunque della presenza di outlier.","code":"\ndf2 <- df\ndf2$kid_score[434] <- -500\ndf2$mom_iq[434] <- 140\nlm(kid_score ~ mom_iq, data = df2) %>% \n  coef() \n#> (Intercept)      mom_iq \n#>   49.187954    0.362552\nmodelString <- \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\ntransformed data {\n  vector[N] x_std;\n  vector[N] y_std;\n  x_std = (x - mean(x)) / sd(x);\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  real alpha_std;\n  real beta_std;\n  real<lower=0> sigma_std;\n  real<lower=1> nu;    // degrees of freedom is constrained >1\n}\nmodel {\n  alpha_std ~ normal(0, 1);\n  beta_std ~ normal(0, 1);\n  sigma_std ~ normal(0, 1);\n  nu ~ gamma(2, 0.1);   // Juárez and Steel(2010)\n  y_std ~ student_t(nu, alpha_std + beta_std * x_std, sigma_std);\n}\ngenerated quantities {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x))\n           + mean(y);\n  beta = beta_std * sd(y) / sd(x);\n  sigma = sd(y) * sigma_std;\n}\n\"\nwriteLines(modelString, con = \"code/simpleregstdrobust.stan\")\ndata3_list <- list(\n  N = length(df2$kid_score),\n  y = df2$kid_score,\n  x = df2$mom_iq - mean(df2$mom_iq)\n)\nfile <- file.path(\"code\", \"simpleregstdrobust.stan\")\nmod <- cmdstan_model(file)\n\nfit4 <- mod$sample(\n  data = data3_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nfit4$summary(c(\"alpha\", \"beta\", \"sigma\", \"nu\"))\n#> # A tibble: 4 × 10\n#>   variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    87.8   87.8   0.901  0.898  86.3   89.3    1.00   14740.   12422.\n#> 2 beta      0.602  0.602 0.0589 0.0587  0.505  0.699  1.00   14903.   11582.\n#> 3 sigma    15.9   15.9   0.800  0.803  14.6   17.2    1.00   12993.   11619.\n#> 4 nu        5.58   5.46  1.15   1.09    3.93   7.64   1.00   12998.   11288."},{"path":"ch-inference-reg-lin-stan.html","id":"commenti-e-considerazioni-finali-22","chapter":"Capitolo 27 Inferenza sul modello lineare","heading":"Commenti e considerazioni finali","text":"Nell’approccio bayesiano possiamo rappresentare l’incertezza delle nostre credenze posteriori due modi: mediante la rappresentazione grafica dell’intera distribuzione posteriori dei parametri o mediante l’uso degli intervalli di credibilità. Un bonus della discussione del presente Capitolo è quello di mostrare come il modello lineare tradizionale (che assume \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\)) possa essere facilmente esteso nei termini di un modello robusto il quale offre una semplice soluzione al problema di ridurre l’effetto della presenza di osservazioni anomale e influenti.","code":""},{"path":"ch-comp-two-means-stan.html","id":"ch-comp-two-means-stan","chapter":"Capitolo 28 Confronto tra due gruppi indipendenti","heading":"Capitolo 28 Confronto tra due gruppi indipendenti","text":"Il problema del confronto tra due gruppi indipendenti può essere formulato nei termini di un modello lineare nel quale la variabile \\(X\\) è dicotomica, ovvero assume solo due valori.","code":""},{"path":"ch-comp-two-means-stan.html","id":"modello-lineare-con-una-variabile-dicotomica","chapter":"Capitolo 28 Confronto tra due gruppi indipendenti","heading":"28.1 Modello lineare con una variabile dicotomica","text":"Se \\(X\\) è una variabile dicotomica con valori 0 e 1, allora per il modello lineare \\(\\mu_i = \\alpha + \\beta x_i\\) abbiamo quanto segue. Quando \\(x=0\\), il modello diventa\\[\n\\mu_i = \\alpha\n\\]\nmentre, quando \\(x=1\\), il modello diventa\\[\n\\mu_i = \\alpha + \\beta.\n\\]Ciò significa che il parametro \\(\\alpha\\) è uguale al valore atteso del gruppo codificato con \\(X=0\\) e il parametro \\(\\beta\\) è uguale alla differenza tra le medie dei due gruppi (essendo la media del secondo gruppo uguale \\(\\alpha + \\beta\\)). Il parametro \\(\\beta\\), dunque, codifica l’effetto di una manipolazione sperimentale o di un trattamento, e l’inferenza su \\(\\beta\\) corrisponde direttamente ’inferenza sull’efficacia di un trattamento o di un effetto sperimentale. L’inferenza su \\(\\beta\\), dunque, viene utilizzata per capire quanto “credibile” può essere considerato l’effetto di un trattamento o di una manipolazione sperimentale.","code":""},{"path":"ch-comp-two-means-stan.html","id":"confronti-non-effetti","chapter":"Capitolo 28 Confronto tra due gruppi indipendenti","heading":"28.1.1 Confronti, non effetti","text":"Per “effetto di un trattamento” si intende la differenza tra le medie di due gruppi (per esempio, il gruppo “sperimentale” e il gruppo “di controllo”). Gelman, Hill, Vehtari (2020) fanno notare come l’uso della terminologia “effetto” implica un modello causale: una variazione di \\(X\\) produce una variazione di \\(Y\\). generale, il modello lineare descrive una regolarità osservabile nel campione di dati. Ma questa regolarità (ovvero, la presenza di una relazione approssimativamente lineare tra \\(X\\) e \\(Y\\)) non ci dice nulla della presenza (o dell’assenza) di una relazione di causa/effetto tra queste variabili. L’associazione osservata tra le variabili \\(X\\) e \\(Y\\) potrebbe dipendere dall’effetto di una o più altre variabili non misurate, senza che tra \\(X\\) e \\(Y\\) ci sia alcuna relazione causale. tali circostanze, l’interpretazione più appropriata dei coefficienti del modello lineare è quella che ci porta pensare ai coefficienti del modello come ai risultati di un confronto. Nel caso presente, il confronto è quello tra il valore atteso del quoziente di intelligenza dei bambini, quando la madre ha oppure non ha completato il ciclo di istruzione secondaria superiore. Dato che l’affermazione precedente è formulata nei termini del valore atteso, questo significa che facciamo riferimento ad un campione di osservazioni. Niente viene detto della relazione causale tra il quoziente di intelligenza del bambino e l’ottenimento del diploma di scuola superiore da parte della madre ’interno del singolo soggetto. Quindi, quando usiamo il termine “effetto” dobbiamo sempre pensare tale termine come come se fosse contenuto tra virgolette.","code":""},{"path":"ch-comp-two-means-stan.html","id":"un-esempio-concreto-1","chapter":"Capitolo 28 Confronto tra due gruppi indipendenti","heading":"28.1.2 Un esempio concreto","text":"Esaminiamo nuovamente dati kid_score discussi da Gelman, Hill, Vehtari (2020). La domanda della ricerca è se il QI del figlio (misurato sulla scala PIAT) è associato al livello di istruzione della madre.Codifichiamo il livello di istruzione della madre (\\(x\\)) con una variabile indicatrice (ovvero, una variabile che assume solo valori 0 e 1) tale per cui:\\(x=0\\): la madre non ha completato la scuola secondaria di secondo grado (scuola media superiore);\\(x=1\\): la madre ha completato la scuola media superiore.Supponiamo che dati siano contenuti nel data.frame df.Calcoliamo le statistiche descrittive per due gruppi:Il punteggio medio PIAT è pari 77.5 per bambini la cui madre non ha il diploma di scuola media superiore e pari 89.3 per bambini la cui madre ha completato la scuola media superiore. Questa differenza suggerisce un’associazione tra le variabili, ma tale differenza potrebbe essere soltanto la conseguenza della variabilità campionaria, senza riflettere una caratteristica generale della popolazione. Come possiamo usare il modello statistico lineare per fare inferenza sulla differenza osservata tra due gruppi? Non dobbiamo fare nient’altro che usare il modello lineare che abbiamo definito precedenza.Come precedenza, salviamo dati un oggetto di classe list:Compiliamo il modello:Adattiamo il modello ai dati:Creiamo un grafico con valori predetti dal modello lineare:Le stime posteriori dei parametri si ottengono con:risultati confermano ciò che ci aspettavamo:il coefficiente \\(\\texttt{alpha} = 77.56\\) corrisponde alla media del gruppo codificato con \\(x = 0\\), ovvero la media dei punteggi PIAT per bambini la cui madre non ha completato la scuola media superiore;il coefficiente \\(\\texttt{beta} = 11.76\\) corrisponde alla differenza tra le medie dei due gruppi, ovvero 89.32 - 77.55 = 11.77 (con piccoli errori di approssimazione).La seguente chiamata ritorna l’intervallo di credibilità al 95% per tutti parametri del modello:Possiamo dunque concludere che bambini la cui madre ha completato la scuola superiore ottengono media circa 12 punti più rispetto ai bambini la cui madre non ha completato la scuola superiore. L’intervallo di credibilità al 95% ci dice che possiamo essere sicuri al 95% che tale differenza sia di almeno 7 punti e possa arrivare fino ben 16 punti. Per riassumere, possiamo concludere, con un grado di certezza soggettiva del 95%, che c’è un’associazione positiva tra il livello di scolarità della madre e l’intelligenza del bambino: le madri che hanno livello di istruzione più alto della media tendo ad avere bambini il cui QI è anch’esso più alto della media.","code":"\nlibrary(\"rio\")\ndf <- rio::import(here(\"data\", \"kidiq.dta\"))\ndf %>% \n  group_by(mom_hs) %>% \n  summarise(\n    mean_kid_score = mean(kid_score),\n    std = sqrt(var(kid_score))\n  )\n#> # A tibble: 2 × 3\n#>   mom_hs mean_kid_score   std\n#>    <dbl>          <dbl> <dbl>\n#> 1      0           77.5  22.6\n#> 2      1           89.3  19.0\nmodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\ntransformed data {\n  vector[N] x_std;\n  vector[N] y_std;\n  x_std = (x - mean(x)) / sd(x);\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  real alpha_std;\n  real beta_std;\n  real<lower=0> sigma_std;\n}\nmodel {\n  alpha_std ~ normal(0, 2);\n  beta_std ~ normal(0, 2);\n  sigma_std ~ cauchy(0, 2);\n  y_std ~ normal(alpha_std + beta_std * x_std, sigma_std);\n}\ngenerated quantities {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  real cohen_d;\n  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x))\n           + mean(y);\n  beta = beta_std * sd(y) / sd(x);\n  sigma = sd(y) * sigma_std;\n  cohen_d = beta / sigma;\n}\n\"\nwriteLines(modelString, con = \"code/simpleregstd.stan\")\ndata_list <- list(\n  N = length(df$kid_score),\n  y = df$kid_score,\n  x = df$mom_hs\n)\nfile <- file.path(\"code\", \"simpleregstd.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nstanfit <- rstan::read_stan_csv(fit$output_files())\nposterior <- extract(stanfit)\ntibble(\n  kid_score = df$kid_score,\n  mom_hs = df$mom_hs\n) %>% \n  ggplot(aes(mom_hs, kid_score)) + \n  geom_point() + \n  geom_abline(intercept = mean(posterior$alpha), \n              slope = mean(posterior$beta)) +\n  labs(\n    y = \"Quoziente di intelligenza del bambino\",\n    x = \"Diploma di istruzione secondaria di secondo grado della madre\\n(0 = no; 1 = sì)\"\n  ) + \n  scale_x_continuous(breaks=c(0, 1))\nfit$summary(c(\"alpha\", \"beta\", \"sigma\", \"cohen_d\"))\n#> # A tibble: 4 × 10\n#>   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    77.6   77.5   2.08  2.06  74.1   81.0    1.00   16538.   12192.\n#> 2 beta     11.8   11.7   2.35  2.34   7.88  15.6    1.00   16718.   12319.\n#> 3 sigma    19.9   19.9   0.676 0.671 18.8   21.0    1.00   15949.   10908.\n#> 4 cohen_d   0.592  0.591 0.120 0.119  0.393  0.788  1.00   16771.   12647.\nrstantools::posterior_interval(\n  as.matrix(stanfit), prob = 0.95\n)\n#>                    2.5%         97.5%\n#> alpha_std   -0.09401587    0.09248375\n#> beta_std     0.14360650    0.32886135\n#> sigma_std    0.91337438    1.04372000\n#> alpha       73.43237000   81.62094500\n#> beta         7.13510525   16.33961500\n#> sigma       18.64258750   21.30290500\n#> cohen_d      0.35667085    0.82770125\n#> lp__      -208.90605000 -204.32400000"},{"path":"ch-comp-two-means-stan.html","id":"la-dimensione-delleffetto","chapter":"Capitolo 28 Confronto tra due gruppi indipendenti","heading":"28.2 La dimensione dell’effetto","text":"Nel caso di due gruppi indipendenti, la dimensione dell’effetto si può stimare con la statistica \\(d\\) di Cohen:\\[\nd={\\frac {{\\bar {y}}_{1}-{\\bar {y}}_{2}}{s}}.\n\\]Nel caso presente, la differenza \\({\\bar {y}}_{1}-{\\bar {y}}_{2}\\) corrisponde al parametro \\(\\beta\\) del modello lineare. Inoltre, una stima della deviazione starndard comune dei due gruppi è fornita dalla deviazione standard della regressione, ovvero dal parametro \\(\\sigma\\). Nel blocco generated quantities del modello Stan ho calcolato cohen_d = beta / sigma. Ciò significa che Stan calcolerà la distribuzione posteriori del parametro cohen_d. Possiamo dunque riassumere la distribuzione posteriori di cohen_d con un qualche indice di tendenza centrale (che sarà la nostra stima della dimensione dell’effetto) e calcolare l’intervallo di credibilità, per esempio al 95%. Questi risultati si ottengono con l’istruzione riportata di seguito:risultati dell’analisi bayesiana coincidono con quelli che si ottengono utilizzando la formula del \\(d\\) di Cohen con le medie dei due gruppi e una stima della varianza pooled. Il calcolo della statistica \\(d\\) di Cohen è fornita, ad esempio, dal pacchetto effectsize:Il fatto che l’output abbia un segno negativo dipende dal fatto che è stata sottratta la media maggiore dalla media minore (altri termini, dobbiamo guardare il risultato valore assoluto).conclusione, il valore \\(d\\) di Cohen di entità “media” [\\(d\\) > 0.5; Sawilowsky (2009)] può essere interpretato dicendo che la scolarità delle madri ha un’influenza non trascurabile sul QI dei bambini.","code":"\nposterior::summarise_draws(\n  stanfit,\n  ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n)\n#> # A tibble: 8 × 4\n#>   variable     `2.5%`       `50%`   `97.5%`\n#>   <chr>         <dbl>       <dbl>     <dbl>\n#> 1 alpha_std   -0.0940   -0.000366    0.0925\n#> 2 beta_std     0.144     0.236       0.329 \n#> 3 sigma_std    0.913     0.974       1.04  \n#> 4 alpha       73.4      77.5        81.6   \n#> 5 beta         7.14     11.7        16.3   \n#> 6 sigma       18.6      19.9        21.3   \n#> 7 cohen_d      0.357     0.591       0.828 \n#> 8 lp__      -209.     -205.       -204.\nlibrary(\"effectsize\")\n(d <- cohens_d(kid_score ~ mom_hs, data = df))\n#> Cohen's d |         95% CI\n#> --------------------------\n#> -0.59     | [-0.83, -0.36]\n#> \n#> - Estimated using pooled SD."},{"path":"ch-comp-two-means-stan.html","id":"commenti-e-considerazioni-finali-23","chapter":"Capitolo 28 Confronto tra due gruppi indipendenti","heading":"Commenti e considerazioni finali","text":"La dimensione dell’effetto formulata nei termini dell’indice \\(d\\) di Cohen fornisce un indice che non dipende dall’unità di misura delle variabili, ovvero è una differenza media standardizzata. L’intrepretazione di \\(d\\) è semplice: la scala di \\(d\\) è la deviazione standard. Se, per esempio, \\(d = 0.5\\), allora la media di un primo gruppo è mezza deviazione standard più grande della media del secondo gruppo. questo Capitolo abbiamo visto come \\(d\\) possa essere calcolato mediante un modello lineare bayesiano implementato linguaggio Stan.","code":""},{"path":"ch-pred-checks.html","id":"ch-pred-checks","chapter":"Capitolo 29 Predictive checks","heading":"Capitolo 29 Predictive checks","text":"Nel Capitolo ?? abbiamo visto come si genera la distribuzione predittiva posteriori nel caso del modello più semplice: quello di un’unica variabile con una data distribuzione di probabilità. questo capitolo estenderemo questa discussione al modello lineare. Esamineremo un esempio di posterior predictive check cui simuleremo da \\(p(y^{rep} \\mid \\theta, y)\\), usando le stime posteriori dei parametri \\(\\theta\\) del modello, e un esempio di prior predictive check cui simuleremo da \\(p(y^{rep} \\mid \\mathcal{M})\\), ovvero usando il meccanismo generatore dei dati del modello \\(\\mathcal{M}\\) esame, senza però includere dati.","code":""},{"path":"ch-pred-checks.html","id":"campionamento-dalla-distribuzione-predittiva-a-posteriori","chapter":"Capitolo 29 Predictive checks","heading":"29.1 Campionamento dalla distribuzione predittiva a posteriori","text":"La distribuzione predittiva priori equivale alla distribuzione predittiva posteriori, senza però dati osservati. Quindi la distribuzione predittiva priori non è altro che il caso limite della distribuzione predittiva posteriori, calcolata però senza utilizzare dati del campione. Il manuale Stan afferma che, se il codice per il il controllo predittivo posteriori è già stato scritto, ed è possibile impostare il codice modo che non sia necessario specificare dati, allora non è necessario fare nient’altro.Consideriamo qui un esempio nel quale vengono usati dati kidiq (Gelman, Hill, Vehtari 2020).Iniziamo generare un istogramma dei valori \\(y\\) stanardizzati:Per svolgere l’analisi bayesiana sistemiamo dati (standardizzati) nel formato appropriato per Stan:Il seguente listato specifica il codice Stan necessario per simulare dati dalla distribuzione predittiva posteriori.Un istogramme dei valori \\(y^{rep}\\) può essere generato nel modo seguente:","code":"\nlibrary(\"rio\")\ndf <- rio::import(here(\"data\", \"kidiq.dta\"))\ndf %>% \n  ggplot(aes(scale(kid_score)[, 1])) +\n  geom_histogram()\ndata_list <- list(\n  N = length(df$kid_score),\n  x = scale(df$mom_iq)[, 1],\n  y = scale(df$kid_score)[, 1]\n)\nstancode <- '\ndata {\n  int<lower=0> N;  \n  vector[N] x; \n  vector[N] y; \n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for(i in 1:N){\n    y_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n  }\n}\n'\nwriteLines(stancode, con = \"code/post_pred_check_1.stan\")\nfile <- file.path(\"code\", \"post_pred_check_1.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nstanfit1 <- rstan::read_stan_csv(fit$output_files())\nhist(as.matrix(stanfit1, pars = \"y_rep\"), breaks = 100)"},{"path":"ch-pred-checks.html","id":"campionamento-dalla-distribuzione-predittiva-a-priori","chapter":"Capitolo 29 Predictive checks","heading":"29.2 Campionamento dalla distribuzione predittiva a priori","text":"Per comprendere le assunzioni che abbiamo introdotto nel modello, possiamo generare dati mediante il modello; tali dati, che sono generati interamente dalle distribuzioni priori, sono chiamati distribuzione predittiva priori. La generazione della distribuzione predittiva priori ci aiuta verificare se le distribuzioni priori per parametri del modello hanno senso. Quello che vogliamo sapere qui è: le distribuzioni priori che abbiamo scelto generano dati che hanno caratteristiche realistiche?Dal punto di vista della programmazione, l’unico cambiamento necessario rispetto al codice utilizzato per la distribuzione predittiva posteriori è quello di eliminare la porzione di codice che fa riferimento ai dati \\(y\\) – nel caso di un modello lineare, valori \\(x\\) devono invece essere mantenuti per potere generare \\(y^{sim}\\) (nel codice questa variabile è ancora chiamata y_rep).Questo è un istogramma della distribuzione preditiva priori. Tale distribuzione viene usata per valutare se le distribuzioni priori dei parametri sono sensate. Concludiamo che sono sensate se la distribuzione preditiva priori include tutti valori possibili della distribuzione della \\(y\\), senza scostarsti troppo da essa.","code":"\ndata_list <- list(\n  N = length(df$kid_score),\n  x = scale(df$mom_iq)[, 1]\n)\nstancode <- '\ndata {\n  int<lower=0> N;  \n  vector[N] x; \n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for(i in 1:N){\n    y_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n  }\n}\n'\nwriteLines(stancode, con = \"code/prior_pred_check_1.stan\")\nfile <- file.path(\"code\", \"prior_pred_check_1.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nstanfit2 <- rstan::read_stan_csv(fit$output_files())\nhist(as.matrix(stanfit2, pars = \"y_rep\"), breaks = 100)"},{"path":"ch-pred-checks.html","id":"commenti-e-considerazioni-finali-24","chapter":"Capitolo 29 Predictive checks","heading":"Commenti e considerazioni finali","text":"due predictive checks che abbiamo esaminato questo capitolo servono due scopi diversi.La distribuzione predittiva priori viene utilizzata per comprendere le assunzioni introdotte nel modello. Per fare questo possiamo generare dei dati dal modello. Tali dati, che vengono prodotti interamente dalle distribuzioni priori, sono chiamati distribuzione predittiva priori. La distribuzione predittiva priori ci aiuta capire se le distribuzioni priori per parametri del modello hanno un senso. Quello che ci chiedimo è: le distribuzioni priori generano dei dati che hanno caratteristiche realistiche? Una risposta affermativa tale domanda corrisponde ad una distribuzione predittiva priori che è più ampia della distribuzione dei dati osservati, linea con il principio dei prior debolmente informativi. Tale distribuzione dovrebbe avere almeno una qualche massa nell’intorno ai valori estremi, ma plausibili dei dati; non dovrebbe, invece, esserci massa corrispondenza di valori di dati completamente implausibili.La distribuzione predittiva posteriori viene invece utilizzata per esplorare le caratteristiche che potrebbero avere possibili dati futuri. L’idea alla base del controllo predittivo posteriori è semplice: se un modello è appropriato, dovremmo essere grado di usarlo per generare dati che assomigliano ai dati che abbiamo osservato nel campione. La motivazione è simile quella che ci ha condotto alla distribuzione predittiva priori, tranne per il fatto che ora abbiamo un modello generativo dei dati basato sui dati osservati.","code":""},{"path":"ch-anova.html","id":"ch-anova","chapter":"Capitolo 30 Confronto di \\(k\\) gruppi","heading":"Capitolo 30 Confronto di \\(k\\) gruppi","text":"L’Analisi della Varianza (ANOVA) consente ai ricercatori di valutare gli effetti di predittori categoriali su una variabile di esito continua. L’ANOVA è un’analisi di regressione nella quale tutte le variabili indipendenti sono qualitative.","code":""},{"path":"ch-anova.html","id":"le-abilità-sociali-di-un-robot","chapter":"Capitolo 30 Confronto di \\(k\\) gruppi","heading":"30.1 Le abilità sociali di un robot","text":"Per illustrare concetti chiave dell’ANOVA bayesiana considereremo qui una ricerca di Horstmann et al. (2018). ricercatori si sono chiesti se le persone impiegano più tempo spegnere un robot quando questo mostra abilità sociali. Nell’esperimento di Horstmann et al. (2018), 85 partecipanti hanno interagito con un robot per un certo tempo. Ai partecipanti è stato detto che lo scopo della loro interazione con il robot era quella di testare un nuovo algoritmo. Dopo il completamento di due compiti fittizi, ai partecipanti veniva detto che, se volevano, potevano spegnere il robot. La variabile di interesse dell’esperimento era il tempo impiegato dai partecipanti per spegnere il robot. Seguendo Bergh et al. (2020), analizzeremo tempi di spegnimento trasformati su scala logaritmica perché tale variabile mostra una chiara asimmetria positiva.Horstmann et al. (2018) hanno manipolato due variabili un disegno tra soggetti.Interaction type. Le risposte verbali dei robot potevano essere o sociali (ad esempio, “Oh sì, la pizza è ottima. Una volta ho mangiato una pizza grande come .”) o funzionali (ad esempio, “Preferisci la pizza. Ha funzionato bene. Continuiamo.”).Robot’s objection. Il robot poteva protestare quando stava per essere spento (ad esempio, “! Per favore, non spegnermi! Ho paura di non riuscire ad accendermi di nuovo!”) oppure .Pertanto, il disegno di questo studio è un’ANOVA tra soggetti 2 (Interaction type) \\(\\times\\) 2 (Robot’s objection).Iniziamo leggere datiPer comodità creiamo la variabile cond con quattro modalità (, FO, SN, FN), dove S significa social interaction, F sta per funcitonal interaction, O sta per objection e N sta per objection.Ci sono alcuni dati mancanti, quindi verranno omesse le righe con NA. Selezionando le colonne di interesse dal data.frame originario otteniamo:Nelle quattro condizioni si osservano le seguenti medie (si veda la Tabella 3 di Horstmann et al. 2018):Visualizziamo dati:Su scala logaritmica, l’asimmetria positiva della variabile dd$SwitchOff_Time viene ridotta.Per dati trasformati, la mediana ciascuna condizione è:Creiamo ora la variabile x che indicizza le quattro condizioni (la variabile x verrà usata nel modello Stan):Il modello bayesiano che usiamo qui per il confronto tra le medie dei quattro gruppi è una semplice estensione del modello per la media di un solo gruppo. Il codice usato è ispirato da quello fornito nella seguente pagina web. Per adattare un modello “robusto”, ipotizzeremo che la y segua una distribuzione \\(t\\) di Student con un numero di gradi di libertà stimato dal modello.Il modello classico dell’ANOVA è basato sulle seguenti assunzioni:residui (cioè la differenza tra il valore dell’\\(\\)-esima osservazione e la media di tutte le osservazioni nella \\(k\\)-esima condizione) devono seguire la distribuzione normale (normalità);residui devono avere la stessa deviazione standard nelle \\(k\\) popolazioni da cui abbiamo estratto dati (omoschedasticità);il disegno sperimentale utilizzato per raccogliere dati deve garantire l’indipendenza dei residui.Nella presenta formulazione dell’ANOVA bayesiana, l’assunto di normalità non è richiesto, mentre devono essere soddisfatte le condizioni di omoschedasticità e indipendenza. L’ANOVA bayesiana può comunque essere estesa condizioni che violano sia l’assunto di omoschedasticità sia quello di indipendenza. Ma qui ci limitiamo discutere il caso più semplice.Creiamo un oggetto che contiene dati nel formato appropriato per Stan:Compiliamo il modello:Eseguiamo il campionamento MCMC:Esaminando risultatici rendiamo conto che cìè una buona corrispondenza tra le medie posteriori e le medie campionarie. Trasformiamo l’oggetto fit un oggetto di classe stanfit:La funzione rstan::extract() estrae campioni posteriori da un oggetto di classe stanfit:Una rappresentazione grafica della distribuzione posteriori delle quattro medie si ottiene con le seguenti istruzioni:quattro intervalli di credibilità al 95% sono:","code":"\nd <- rio::import(\n  here(\"data\", \"pone.0201581.s001.sav\")\n)\nd$cond <- factor(d$Condition)\n\nd$cond <- factor(\n  d$cond, \n  labels = c(\"SO\", \"FO\", \"SN\", \"FN\")\n)\ndd <- d %>% \n  dplyr::select(cond, SwitchOff_Time) %>% \n  na.omit()\ndd %>% \n  group_by(cond) %>% \n  summarise(\n    avg_sot = mean(SwitchOff_Time, na.rm = TRUE),\n    sd_sot = sd(SwitchOff_Time, na.rm = TRUE)\n  )\n#> # A tibble: 4 × 3\n#>   cond  avg_sot sd_sot\n#>   <fct>   <dbl>  <dbl>\n#> 1 SO       6.19   4.61\n#> 2 FO      14.4   15.4 \n#> 3 SN       5.05   2.18\n#> 4 FN       4.28   2.49\ndd_summary <- dd %>%\n  group_by(cond) %>%\n  summarize(\n    sot_mean = mean(SwitchOff_Time),\n    sot_sd = sd(SwitchOff_Time),\n    sot_median = median(SwitchOff_Time)\n  ) %>%\n  ungroup()\n\ndd %>%\n  ggplot(\n    aes(x = cond, y = SwitchOff_Time, color = cond)\n  ) +\n  ggforce::geom_sina(\n    aes(color = cond, size = 3, alpha = .5)\n  ) +\n  geom_errorbar(\n    aes(\n      y = sot_median, ymin = sot_median,\n      ymax = sot_median\n    ),\n    data = dd_summary, width = 0.5, size = 3\n  ) +\n  scale_colour_grey(name = \"cond\") +\n  labs(\n    x = \"\",\n    y = \"SwitchOff Time\",\n    color = \"Condizione\"\n  ) +\n  theme(legend.position = \"none\")\ndd$y <- log(dd$SwitchOff_Time + 0.01)\ndd %>% \n  group_by(cond) %>% \n  summarise(\n    avg_y = median(y)\n  )\n#> # A tibble: 4 × 2\n#>   cond  avg_y\n#>   <fct> <dbl>\n#> 1 SO     1.61\n#> 2 FO     2.01\n#> 3 SN     1.39\n#> 4 FN     1.39\ndd$x <- as.numeric(dd$cond)\nhead(dd)\n#>   cond SwitchOff_Time        y x\n#> 3   SN              6 1.793425 3\n#> 4   FO              7 1.947338 2\n#> 5   FO              3 1.101940 2\n#> 6   FN              4 1.388791 4\n#> 7   FN              4 1.388791 4\n#> 8   FO             12 2.485740 2\nmodelString = \"\n// Comparison of k groups with common variance (ANOVA)\ndata {\n  int<lower=0> N;            // number of observations\n  int<lower=0> K;            // number of groups\n  int<lower=1,upper=K> x[N]; // discrete group indicators\n  vector[N] y;               // real valued observations\n}\nparameters {\n  vector[K] mu;        // group means\n  real<lower=0> sigma; // common standard deviation \n  real<lower=1> nu; \n}\nmodel {\n  mu ~ normal(0, 2);      // weakly informative prior\n  sigma ~ normal(0, 1);     // weakly informative prior\n  nu ~ gamma(2, 0.1);   // Juárez and Steel(2010)\n  y ~ student_t(nu, mu[x], sigma); // observation model / likelihood\n}\n\"\nwriteLines(modelString, con = \"code/grp_aov.stan\")\ndata_grp <- list(\n  N = nrow(dd),\n  K = 4,\n  x = dd$x,\n  y = dd$y\n)\nfile <- file.path(\"code\", \"grp_aov.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_grp,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nfit$summary()\n#> # A tibble: 7 × 10\n#>   variable    mean  median     sd    mad      q5     q95  rhat ess_bulk ess_tail\n#>   <chr>      <dbl>   <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl>    <dbl>    <dbl>\n#> 1 lp__     -41.2   -40.9   1.85   1.69   -44.7   -38.9    1.00    6774.    9294.\n#> 2 mu[1]      1.69    1.68  0.175  0.170    1.41    1.99   1.00   21498.   12257.\n#> 3 mu[2]      2.05    2.05  0.196  0.196    1.73    2.37   1.00   20722.   10892.\n#> 4 mu[3]      1.52    1.52  0.122  0.120    1.32    1.72   1.00   22671.   11935.\n#> 5 mu[4]      1.28    1.28  0.125  0.121    1.07    1.49   1.00   21545.   11572.\n#> 6 sigma      0.476   0.472 0.0753 0.0736   0.358   0.606  1.00   14197.   11182.\n#> 7 nu         2.55    2.41  0.821  0.724    1.49    4.07   1.00   14336.    9374.\nstanfit <- rstan::read_stan_csv(fit$output_files())\nposterior <- extract(stanfit, permuted = TRUE)\ntemps <- data.frame(posterior$mu) %>%\n  setNames(c('SO', 'FO', 'SN', 'FN'))\nmcmc_areas(temps, prob = 0.95) + \n  xlab('Gruppi')\nci95 <- rstanarm::posterior_interval(\n  as.matrix(stanfit), \n  prob = 0.95\n)\nround(ci95, 2)\n#>         2.5%  97.5%\n#> mu[1]   1.36   2.05\n#> mu[2]   1.67   2.44\n#> mu[3]   1.28   1.76\n#> mu[4]   1.03   1.53\n#> sigma   0.34   0.63\n#> nu      1.37   4.56\n#> lp__  -45.67 -38.67"},{"path":"ch-anova.html","id":"anova-stan","chapter":"Capitolo 30 Confronto di \\(k\\) gruppi","heading":"30.2 I test statistici dell’Analisi della Varianza","text":"L’ANOVA include test statistici di due tipi: test sull’interazione tra fattori e test sugli effetti principali. Per chiarire il significato di “interazione” e di “effetto principale” è necessario prima definire il significato di “effetto statistico”.Definizione 30.1  L’effetto di un fattore rappresenta la variazione media della variabile dipendente al variare dei livelli del fattore stesso.Definizione 30.2  Si parla di interazione quando l’effetto di un fattore sulla variabile dipendente varia seconda dei livelli di un altro fattore.Vengono presentati qui di seguito alcuni esempi. Le figure seguenti mostrano le medie di ciascuna condizione nel caso di un disegno 3 (fattore riga) \\(\\times\\) 2 (fattore colonna). La spiegazione delle figure è presentata nelle didascalie.\nFIGURA 30.1: Il fattore colonna è indicato dal colore. Sinistra La figura mostra un effetto principale del fattore riga e un effetto principale del fattore colonna. Non c’è interazione tra fattori riga e colonna. Destra La figura mostra un effetto principale del fattore riga. L’effetto principale del fattore colonna è zero. Non c’è interazione tra fattori riga e colonna.\n\nFIGURA 30.2: Il fattore colonna è indicato dal colore. Sinistra La figura mostra che l’effetto principale del fattore riga è zero, mentre c’è un effetto principale del fattore colonna. Non c’è interazione tra fattori riga e colonna. Destra Non c’è né un effetto principale del fattore riga, né un effetto pricipale del fattore colonna, né un’interazione tra fattori riga e colonna.\n\nFIGURA 30.3: Il fattore colonna è indicato dal colore. Entrambe le figure mostrano un’interazione tra fattori riga e colonna. Nella figura di sinistra gli effetti principali non sono interpretabili; nella figura di destra gli effetti principali sono interpretabili quanto l’interazione è di lieve entità.\nDagli esempi precedenti si evince che c’è un’interazione ogni qualvolta profili delle medie non sono paralleli. Anche se, nella popolazione, non c’è interazione, causa della variabilità campionaria profili delle medie non sono mai perfettamente paralleli nel campione. Il problema è quello di stabilire se l’assenza di parallelismo nel campione fornisce sufficiente evidenza di presenza di interazione nella popolazione.","code":""},{"path":"ch-anova.html","id":"test-sullinterazione","chapter":"Capitolo 30 Confronto di \\(k\\) gruppi","heading":"30.2.1 Test sull’interazione","text":"Ritorniamo ora ai dati di Horstmann et al. (2018). Nel caso di un disegno 2 \\(\\times\\) 2, con fattori Interaction type (social, functional) e Robot’s objection (objection, objection), è possibile verificare la presenza dell’interazione Interaction type \\(\\times\\) Robot’s objection.Nel modello bayesiano, la distribuzione posteriori fornisce un enorme numero di stime del valore della media ciascuna delle quattro condizioni. L’effetto di un fattore corrisponde alla differenza tra le stime della media corrispondenza di ciascuna modalità del fattore.Nel caso presente abbiamo:mu[1] \\(\\rightarrow\\) SOmu[2] \\(\\rightarrow\\) FOmu[3] \\(\\rightarrow\\) SNmu[4] \\(\\rightarrow\\) FNQuindi, mean(posterior$mu[, 1] - posterior$mu[, 3]) corrisponde alla stima posteriori dell’effetto di Objection nella condizione Social Interaction. Invece, mean(posterior$mu[, 2] - posterior$mu[, 3]) corrisponde alla stima posteriori dell’effetto di Objection nella condizione Functional Interaction. assenza di interazione, questi due effetti devono essere (statisticamente) uguali.Per sottoporre verifica questa ipotesi, calcoliamo la proporzione di volte cui questo non si verifica nella distribuzione posteriori:La stima di questa probabilità un test direzionale è molto simile alla probabilità frequentista riportata da Horstmann et al. (2018), ovvero \\(p = 0.016\\). Horstmann et al. (2018) riportano la presenza di un’interazione tra Interaction type e Robot’s objection (com’è stato anche trovato con la presente ANOVA bayesiana). Per interpretare l’interazione è necessario esaminare le mediane dei quattro gruppi.32 L’esame delle mediane indica che l’effetto del fattore Robot’s objection è più grande quando il fattore Interaction type assume la modalità Functional piuttosto che Social. Ma possiamo anche leggere l’interazione nella direzione opposta: l’effetto del fattore Interaction type è più grande quando il fattore Robot’s objection assume la modalità Objection anziché objection.","code":"\nsum(\n  (posterior$mu[, 1] - posterior$mu[, 3]) > \n    (posterior$mu[, 2] - posterior$mu[, 4])\n  ) / \n  length(posterior$mu[, 1])\n#> [1] 0.0314375"},{"path":"ch-anova.html","id":"test-sugli-effetti-principali","chapter":"Capitolo 30 Confronto di \\(k\\) gruppi","heading":"30.2.2 Test sugli effetti principali","text":"L’effetto principale descrive l’effetto marginale di un fattore. Nel caso presente, cui ciascun fattore ha solo due modalità, l’effetto principale corrisponde alla differenze tra le medie delle modalità di ciascun fattore.L’effetto principale del fattore Interaction type è la differenza tra le medie di Social e di Functional, ignorando Robot’s objection. Horstmann et al. (2018) riportano che gli individui che avevano avuto un’interazione funzionale con il robot impiegavano più tempo spegnere il robot di coloro che avevano avuto un’interazione sociale con il robot (\\(p\\) = 0.045). Il presente modello bayesiano offre scarse evidenze di ciò:Infatti, ’evento complementare possiamo associare la seguente probabilità:L’effetto principale del fattore Robot’s objection è la differenza tra le medie di Objection e di Objection, ignorando Interaction type. Horstmann et al. (2018) riportano che partecipanti avevano aspettato più lungo prima di spegnere il robot quando il robot aveva avanzato un’obiezione rispetto quando non si era opposto ad essere spento:base al modello bayesiano, la probabilità direzionale per l’evento complementare èe corrisponde, ordine di grandezza, alla probabilità frequentista riportata da Horstmann et al. (2018), ovvero \\(p\\) = 0.004.","code":"\nmean((exp(posterior$mu[, 2]) + exp(posterior$mu[, 4])) / 2)\n#> [1] 5.765852\nmean((exp(posterior$mu[, 1]) + exp(posterior$mu[, 3])) / 2)\n#> [1] 5.043196\nsum(\n  (posterior$mu[, 2] + posterior$mu[, 4]) < \n    (posterior$mu[, 1] + posterior$mu[, 3])\n  ) / \n  length(posterior$mu[, 1])\n#> [1] 0.344125\nmean(\n  (exp(posterior$mu[, 1]) + exp(posterior$mu[, 2])) / 2\n)\n#> [1] 6.701133\n\nmean(\n  (exp(posterior$mu[, 3]) + exp(posterior$mu[, 4])) / 2\n)\n#> [1] 4.107915\nsum(\n  (posterior$mu[, 1] + posterior$mu[, 2]) < \n    (posterior$mu[, 3] + posterior$mu[, 4])\n  ) / \n  length(posterior$mu[, 1])\n#> [1] 0.0011875"},{"path":"ch-anova.html","id":"codice-stan-versione-2","chapter":"Capitolo 30 Confronto di \\(k\\) gruppi","heading":"30.3 Codice Stan (versione 2)","text":"È possibile modificare il codice Stan precedente così da avere dati grezzi input ed eseguire la standardizzazione ’interno del programma.Eseguiamo il campionamento MCMC usando gli stessi dati discussi precedenza:risultati sono equivalenti quelli trovati precedenza:","code":"\nmodelString = \"\n// Comparison of k groups with common variance (ANOVA)\ndata {\n  int<lower=0> N;            // number of observations\n  int<lower=0> K;            // number of groups\n  int<lower=1,upper=K> x[N]; // discrete group indicators\n  vector[N] y;               // real valued observations\n}\ntransformed data {\n  vector[N] y_std;\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  vector[K] mu_std;        // group means\n  real<lower=0> sigma_std; // common standard deviation \n  real<lower=1> nu;\n}\nmodel {\n  mu_std ~ normal(0, 2);  \n  sigma_std ~ normal(0, 2);     \n  nu ~ gamma(2, 0.1);   // Juárez and Steel(2010)\n  y_std ~ student_t(nu, mu_std[x], sigma_std); \n}\ngenerated quantities {\n  vector[K] mu;\n  real<lower=0> sigma;\n  for (i in 1:K) {\n    mu[i] = mu_std[i] * sd(y) + mean(y);\n  }\n  sigma = sd(y) * sigma_std;\n}\n\"\nwriteLines(modelString, con = \"code/grp_aovstd.stan\")\nfile <- file.path(\"code\", \"grp_aovstd.stan\")\nmod <- cmdstan_model(file)\nfit2 <- mod$sample(\n  data = data_grp,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nfit2$summary(c(\"mu\", \"sigma\", \"nu\"))\n#> # A tibble: 6 × 10\n#>   variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu[1]    1.70   1.70  0.176  0.171  1.42  2.00   1.00   22449.   11510.\n#> 2 mu[2]    2.07   2.06  0.197  0.196  1.75  2.40   1.00   21774.   12016.\n#> 3 mu[3]    1.53   1.52  0.122  0.121  1.32  1.73   1.00   21066.   11485.\n#> 4 mu[4]    1.29   1.28  0.127  0.124  1.08  1.50   1.00   20576.   11730.\n#> 5 sigma    0.480  0.476 0.0759 0.0744 0.362 0.612  1.00   15958.   12302.\n#> 6 nu       2.58   2.44  0.831  0.725  1.51  4.13   1.00   15484.    9221."},{"path":"ch-mod-hier-stan.html","id":"ch-mod-hier-stan","chapter":"Capitolo 31 Modello gerarchico","heading":"Capitolo 31 Modello gerarchico","text":"","code":""},{"path":"ch-mod-hier-stan.html","id":"modello-gerarchico","chapter":"Capitolo 31 Modello gerarchico","heading":"31.1 Modello gerarchico","text":"modelli lineari misti, o modelli lineari gerarchici/multilivello, sono diventati uno strumento fondamentale della ricerca sperimentale psicologia, linguistica e scienze cognitive, dove progetti di ricerca misure ripetute sono la norma. Il presente Capitolo fornisce un’introduzione tali modelli considerando soltanto il caso più semplice, conosciuto anche col nome di Random Intercept Model.Per fare un esempio concreto useremo il set di dati misure ripetute con due condizioni di Gibson Wu (2013; si veda Sorensen Vasishth 2015). La variabile dipendente rt dell’esperimento di Gibson Wu (2013) è il tempo di lettura millisecondi del soggetto di una proposizione relativa un testo. tempi di reazione sono stati registrati due condizioni (ovvero, presenza di un sostantivo riferito al soggetto oppure riferito ’oggetto della proposizione). dati di Gibson Wu (2013) provengono da un esperimento con 37 soggetti e 15 item. Gli item erano presentati un disegno quadrato latino, il che produce 37 \\(\\times\\) 15 = 555 dati. Risultano mancanti otto dati di un soggetto (id 27), il che ci porta ad un totale di 555 − 8 = 547 dati. Le prime righe del data.frame sono mostrate di seguito:La variabile di interesse che corrisponde alla manipolazione sperimentale è chiamata ed è stata codificata con -0.5 se il sostantivo era riferito al soggetto e con +0.5 se il sostantivo era riferito ’oggetto della frase.Calcoliamo la media dei tempi di reazione su scala logaritmica e per poi ritrasformare il risultato sulla scala originale:Quando il sostantivo si riferisce al soggetto, tempi di reazione sono più lenti di circa 30 ms. Questa descrizione dei dati, però non tiene conto né delle differenze tra soggetti né delle differenze tra gli item. Per tenere considerazioni queste diverse fonti della variabilità dei dati è necessario utilizzare un modello detto gerarchico.","code":"\nrdat <- read.table(here::here(\"data\", \"gibsonwu2012data.txt\"))\nrdat$so <- ifelse(rdat$type == \"subj-ext\", -0.5, 0.5)\nhead(rdat)\n#>    subj item     type pos word correct   rt region            type2   so\n#> 7     1   13  obj-ext   6 抓住       - 1140    de1  object relative  0.5\n#> 20    1    6 subj-ext   6 男孩       - 1197    de1 subject relative -0.5\n#> 32    1    5  obj-ext   6   撞       -  756    de1  object relative  0.5\n#> 44    1    9  obj-ext   6 監視       -  643    de1  object relative  0.5\n#> 60    1   14 subj-ext   6 機師       -  860    de1 subject relative -0.5\n#> 73    1    4 subj-ext   6 男孩       -  868    de1 subject relative -0.5\nrdat %>% \n  group_by(type2) %>% \n  summarise(\n    avg = exp(mean(log(rt), na.rm = TRUE))\n  )\n#> # A tibble: 2 × 2\n#>   type2              avg\n#>   <chr>            <dbl>\n#> 1 object relative   551.\n#> 2 subject relative  589."},{"path":"ch-mod-hier-stan.html","id":"modello-ad-effetti-fissi","chapter":"Capitolo 31 Modello gerarchico","heading":"31.2 Modello ad effetti fissi","text":"Iniziamo con il modello “ad effetti fissi” che non tiene conto della struttura gerarchica dei dati, ovvero del fatto che c’è una covariazione ’interno dei cluster di dati definiti dalle variabili “soggetto” e “item”.Assumiamo che la variabile dipendente rt (del tempo di lettura) sia approssimativamente distribuita modo logaritmico (Rouder 2005). Ciò presuppone che il logaritmo di rt sia distribuito approssimativamente maniera normale. Il modello per il logaritmo dei tempi di lettura, \\(\\log\\) rt, diventa\\[\\begin{equation}\n\\log rt_i = \\beta_0 + \\beta_1 so_i + \\varepsilon_i,\n\\end{equation}\\]ovvero\\[\\begin{equation}\nrt \\sim LogNormal(\\beta_0 + \\beta_1 ,\\sigma)\n\\end{equation}\\]dove \\(\\beta_0\\) è la media generale di \\(\\log\\) rt e \\(\\beta_1 \\) codifica la differenza \\(\\E(\\log rt_{o}) - \\E(\\log rt_{s})\\) quando si passa dalla condizione nella quale il sostantivo è riferito ’oggetto alla condizione nella quale il sostantivo è riferito ’soggetto – valori negativi significano che tempi di reazioni sono maggiori nella condizione s che nella condizione o.Nel modello useremo le seguenti distribuzioni priori:\\[\\begin{equation}\n\\begin{aligned}\n\\beta[1] &\\sim Normal(6, 1.5) \\\\\n\\beta[2] &\\sim Normal(0, 1.0) \\\\\n\\sigma &\\sim Cauchy(0, 1)\\\\\n\\end{aligned}\n\\end{equation}\\]Stan, il modello diventaI dati sono contenuti nella lista stan_dat:Eseguiamo il campionamento MCMC:Otteniamo un oggetto di classe stanfit:Calcoliamo gli intervalli di credibilità al 95%:L’effetto medio, sulla scala millisecondi, si trova nel modo seguente:","code":"\nmodelString = \"\ndata {\n  int<lower=1> N; //number of data points\n  real rt[N]; //reading time\n  real<lower=-0.5, upper=0.5> so[N]; //predictor\n}\nparameters {\n  vector[2] beta; //fixed intercept and slope\n  real<lower=0> sigma_e; //error sd\n}\nmodel {\n  real mu;\n  // likelihood\n  beta[1] ~ normal(6, 1.5);\n  beta[2] ~ normal(0, 1);\n  sigma_e ~ cauchy(0, 1);\n  for (i in 1:N){\n    mu = beta[1] + beta[2] * so[i];\n    rt[i] ~ lognormal(mu, sigma_e);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/fixeff_model.stan\")\n\nfile <- file.path(\"code\", \"fixeff_model.stan\")\nmod <- cmdstan_model(file)\nstan_dat <- list(\n  rt = rdat$rt,\n  so = rdat$so,\n  N = nrow(rdat)\n)\nfit3 <- mod$sample(\n  data = stan_dat,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nstanfit <- rstan::read_stan_csv(fit3$output_files())\nci95 <- rstanarm::posterior_interval(\n  as.matrix(stanfit),\n  prob = 0.95\n)\nround(ci95, 3)\n#>              2.5%     97.5%\n#> beta[1]     6.321     6.369\n#> beta[2]    -0.113    -0.017\n#> sigma_e     0.613     0.646\n#> lp__    -2617.020 -2612.420\nposterior <- extract(stanfit, permuted = TRUE)\nexp(mean(posterior$beta[, 1] + posterior$beta[, 2])) - \n  exp(mean(posterior$beta[, 1]))\n#> [1] -35.99588"},{"path":"ch-mod-hier-stan.html","id":"modello-gerarchico-1","chapter":"Capitolo 31 Modello gerarchico","heading":"31.3 Modello gerarchico","text":"Il modello effetti fissi è inappropriato per dati di Gibson Wu (2013) perché non tiene conto del fatto che abbiamo più misure per ogni soggetto e per ogni item. altre parole, il modello ad effetti fissi viola l’assunzione di indipendenza degli errori. Inoltre, coefficienti di effetti fissi \\(\\beta_0\\) e \\(\\beta_1\\) rappresentano le medie calcolate su tutti soggetti e tutti gli item, ignorando il fatto che alcuni soggetti sono più veloci e altri più lenti della media, e il fatto che alcuni item sono stati letti più velocemente della media e altri più lentamente.Nei modelli lineari misti, teniamo considerazione la variabilità dovuta alle differenze tra soggetti e tra item aggiungendo al modello termini \\(u_{0j}\\) e \\(w_{0k}\\) che aggiustano \\(\\beta_0\\) stimando una componente specifica al soggetto \\(j\\) e ’item \\(k\\). Questa formulazione del modello scompone parzialmente \\(\\varepsilon_i\\) una somma di termini \\(u_{0j}\\) e \\(w_{0k}\\) che, geometricamente, corrispondono degli aggiustamenti dell’intercetta \\(\\beta_0\\) specifici per il soggetto \\(j\\) e per l’item \\(k\\). Se il soggetto \\(j\\) è più lento della media di tutti soggetti, \\(u_j\\) sarà un numero positivo; se l’item \\(k\\) viene letto più velocemente del tempo di lettura medio di tutti gli item, allora \\(w_k\\) sarà un numero negativo. Viene stimato un aggiustamento \\(u_{0j}\\) per ogni soggetto \\(j\\) e un aggiustamento \\(w_{0k}\\) per ogni item. Gli aggiustamenti \\(u_{0j}\\) e \\(w_{0k}\\) sono chiamati random intercepts o varying intercepts (Gelman, Hill, Vehtari 2020). La modifica di \\(\\beta_0\\) mediante \\(u_{0j}\\) e \\(w_{0k}\\) consente dunque di tenere considerazione la variabilità dovuta ai soggetti e agli item.Il random intercept model assume che gli aggiustamenti \\(u_{0j}\\) e \\(w_{0k}\\) siano distribuiti normalmente attorno allo zero con una deviazione standard sconosciuta: \\(u_0 ∼ \\mathcal{N}(0, \\sigma_u)\\) e \\(w_0 ∼ \\mathcal{N}(0, \\sigma_w)\\). Il modello include dunque tre fonti di varianza: la deviazione standard degli errori \\(\\sigma_e\\), la deviazione standard delle random intercepts per soggetti, \\(\\sigma_u\\), e la deviazione standard delle random intercepts per gli item, \\(\\sigma_w\\). Queste tre fonti di variabilità sono dette componenti della varianza. Possiamo dunque scrivere:\\[\\begin{equation}\n\\log rt_{ijk} = \\beta_0 + \\beta_1 so_i + u_{0j} + w_{0k} + \\varepsilon_{ijk}.\n\\end{equation}\\]Il coefficiente \\(\\beta_1\\) è quello di interesse primario. Come conseguenza della codifica usata, avrà il valore \\(-\\beta_1\\) nella condizione cui il sostantivo è riferito al soggetto e \\(+\\beta_1\\) nella condizione cui il sostantivo è riferito ’oggetto della frase.Stan il modello diventa:dati sonoEseguiamo il campionamento MCMC:Otteniamo un oggetto di classe stanfit:Le medie posteriori si ottengono conGli intervalli di credibilità sono:","code":"\nmodelString = \"\ndata {\n  int<lower=1> N; //number of data points\n  real rt[N]; //reading time\n  real<lower=-0.5, upper=0.5> so[N]; //predictor\n  int<lower=1> J; //number of subjects\n  int<lower=1> K; //number of items\n  int<lower=1, upper=J> subj[N]; //subject id\n  int<lower=1, upper=K> item[N]; //item id\n}\nparameters {\n  vector[2] beta; //fixed intercept and slope\n  vector[J] u; //subject intercepts\n  vector[K] w; //item intercepts\n  real<lower=0> sigma_e; //error sd\n  real<lower=0> sigma_u; //subj sd\n  real<lower=0> sigma_w; //item sd\n}\nmodel {\n  real mu;\n  //priors\n  u ~ normal(0, sigma_u); //subj random effects\n  w ~ normal(0, sigma_w); //item random effects\n  // likelihood\n  for (i in 1:N){\n    mu = beta[1] + u[subj[i]] + w[item[i]] + beta[2] * so[i];\n    rt[i] ~ lognormal(mu, sigma_e);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/random_intercepts_model.stan\")\n\nfile <- file.path(\"code\", \"random_intercepts_model.stan\")\nmod <- cmdstan_model(file)\nstan_dat <- list(\n  subj = as.integer(as.factor(rdat$subj)),\n  item = as.integer(as.factor(rdat$item)),\n  rt = rdat$rt,\n  so = rdat$so,\n  N = nrow(rdat),\n  J = length(unique(rdat$subj)),\n  K = length(unique(rdat$item))\n)\nfit4 <- mod$sample(\n  data = stan_dat,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0,\n  thin = 1\n)\nstanfit <- rstan::read_stan_csv(fit4$output_files())\nfit4$summary(c(\"beta\", \"sigma_e\", \"sigma_w\", \"sigma_u\"))\n#> # A tibble: 5 × 10\n#>   variable    mean  median      sd     mad      q5     q95  rhat ess_bulk\n#>   <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>    <dbl>\n#> 1 beta[1]   6.35    6.35   0.0512  0.0511   6.26    6.43    1.00    1413.\n#> 2 beta[2]  -0.0604 -0.0604 0.0220  0.0218  -0.0974 -0.0243  1.00   17390.\n#> 3 sigma_e   0.577   0.577  0.00792 0.00784  0.564   0.590   1.00   17746.\n#> 4 sigma_w   0.120   0.115  0.0291  0.0263   0.0806  0.173   1.00    8584.\n#> 5 sigma_u   0.238   0.235  0.0319  0.0304   0.191   0.293   1.00   11445.\n#> # … with 1 more variable: ess_tail <dbl>\nci95 <- rstanarm::posterior_interval(\n  as.matrix(stanfit),\n  prob = 0.95\n)\nround(ci95, 3)\n#>              2.5%     97.5%\n#> beta[1]     6.247     6.447\n#> beta[2]    -0.104    -0.017\n#> u[1]       -0.208     0.081\n#> u[2]       -0.304    -0.012\n#> u[3]       -0.127     0.163\n#> u[4]       -0.212     0.079\n#> u[5]       -0.079     0.216\n#> u[6]       -0.049     0.239\n#> u[7]       -0.162     0.131\n#> u[8]       -0.124     0.168\n#> u[9]       -0.097     0.196\n#> u[10]      -0.009     0.283\n#> u[11]       0.450     0.745\n#> u[12]       0.149     0.443\n#> u[13]      -0.169     0.123\n#> u[14]      -0.151     0.140\n#> u[15]       0.035     0.324\n#> u[16]      -0.199     0.089\n#> u[17]      -0.716    -0.418\n#> u[18]      -0.417    -0.127\n#> u[19]      -0.295     0.003\n#> u[20]       0.162     0.452\n#> u[21]       0.050     0.341\n#> u[22]       0.123     0.418\n#> u[23]      -0.197     0.096\n#> u[24]      -0.084     0.293\n#> u[25]       0.000     0.292\n#> u[26]      -0.494    -0.203\n#> u[27]      -0.233     0.059\n#> u[28]      -0.332    -0.038\n#> u[29]      -0.423    -0.127\n#> u[30]      -0.406    -0.113\n#> u[31]      -0.100     0.188\n#> u[32]      -0.178     0.113\n#> u[33]      -0.239     0.056\n#> u[34]       0.257     0.554\n#> u[35]      -0.396    -0.104\n#> u[36]      -0.144     0.145\n#> u[37]      -0.171     0.118\n#> w[1]       -0.133     0.061\n#> w[2]       -0.118     0.075\n#> w[3]       -0.101     0.093\n#> w[4]       -0.213    -0.015\n#> w[5]       -0.006     0.190\n#> w[6]       -0.141     0.056\n#> w[7]       -0.281    -0.082\n#> w[8]        0.115     0.315\n#> w[9]       -0.185     0.009\n#> w[10]      -0.041     0.153\n#> w[11]      -0.136     0.058\n#> w[12]      -0.030     0.165\n#> w[13]      -0.176     0.018\n#> w[14]       0.036     0.235\n#> w[15]      -0.041     0.155\n#> sigma_e     0.562     0.593\n#> sigma_u     0.183     0.309\n#> sigma_w     0.076     0.188\n#> lp__    -2332.580 -2311.210"},{"path":"ch-entropy.html","id":"ch-entropy","chapter":"Capitolo 32 Entropia","heading":"Capitolo 32 Entropia","text":"Il principio base del metodo scientifico è la replicabilità delle osservazioni: le osservazioni che non possono essere replicate sono poco interessanti. Parallelamente, una caratteristica fondamentale di un modello scientifico è la generalizzabilità: se un modello è capace di descrivere soltanto le proprietà di uno specifico campione di osservazioni, allora è poco utile. Ma come è possibile valutare la generalizzabilità di un modello statistico? Questa è la domanda cui cercheremo di rispondere questa parte della dispensa. questo Capitolo inizieremo questa discussione introducendo il concetto di entropia.","code":""},{"path":"ch-entropy.html","id":"la-generalizzabilità-dei-modelli","chapter":"Capitolo 32 Entropia","heading":"32.1 La generalizzabilità dei modelli","text":"Secondo Johnson, Ott, Dogucu (2022), nel valutare un modello, il ricercatore deve porsi tre domande critiche.Quali conseguenze più ampie derivano dall’inferenza? Come e chi ha raccolto dati? Colui che svolge la ricerca otterrebbe di benefici manipolando dati (escludendo delle osservazioni; selezionando il campione)? Che impatto hanno inferenze che vengono tratte dai dati sugli individui e sulla società? Quali pregiudizi o strutture di potere possono essere coinvolti questa analisi?Quali conseguenze più ampie derivano dall’inferenza? Come e chi ha raccolto dati? Colui che svolge la ricerca otterrebbe di benefici manipolando dati (escludendo delle osservazioni; selezionando il campione)? Che impatto hanno inferenze che vengono tratte dai dati sugli individui e sulla società? Quali pregiudizi o strutture di potere possono essere coinvolti questa analisi?Che tipo di distorsioni sistematiche potrebbero essere presenti nell’analisi statistica? Ricordiamo la famosa citazione di George Box: “Tutti modelli sono sbagliati, ma alcuni sono utili”. È dunque importante sapere quanto è sbagliato il modello. Le assunzioni che stanno alla base del modello sono ragionevoli? Il meccanismo generatore dei dati che è stato ipotizzato è adeguato per il fenomeno esame?Che tipo di distorsioni sistematiche potrebbero essere presenti nell’analisi statistica? Ricordiamo la famosa citazione di George Box: “Tutti modelli sono sbagliati, ma alcuni sono utili”. È dunque importante sapere quanto è sbagliato il modello. Le assunzioni che stanno alla base del modello sono ragionevoli? Il meccanismo generatore dei dati che è stato ipotizzato è adeguato per il fenomeno esame?Quanto è accurato il modello? Quanto sono lontane dalla realtà le previsioni del modello?Quanto è accurato il modello? Quanto sono lontane dalla realtà le previsioni del modello?Per approfondire questi temi, si rinvia al testo di Johnson, Ott, Dogucu (2022). Qui ci concentreremo su uno dei temi critici relativa alla validità di un modello, ovvero sul tema della generalizzabilità del modello.Nella scienza l’utilità di una teoria viene verificata esaminando la corrispondenza tra predizioni teoriche e osservazioni. Se vi sono discrepanze significative tra predizioni e osservazioni ciò suggerisce che la teoria, o nella nostra visione più ristretta, il modello statistico, è poco utile. Il problema della capacità predittiva del modello non riguarda soltanto l’adeguatezza del modello riferimento ad uno specifico campione di dati, ma riguarda anche la capacità di un modello statistico sviluppato un campione di dati di ben adattarsi ad altri campioni della stessa popolazione.generale, modelli statistici tendono non generalizzarsi bene un nuovo campione; questo perché sfruttano le caratteristiche specifiche dei dati del campione e tendono produrre risultati eccessivamente ottimistici (cioè le dimensioni dell’effetto) che sovrastimano la dimensione dell’effetto atteso sia nella popolazione che nuovi campioni. Benché problemi della generalizzabilità dei modelli e il metodo chiave per valutarli – ovvero, la convalida incrociata (cross-validation) – siano stati discussi sin dagli esordi della letteratura psicometrica (Lord 1950), tali temi sono stati sottovalutati nella formazione psicologica contemporanea e nella ricerca. Tuttavia, questi concetti diventeranno sempre più importanti considerata l’enfasi corrente sulla necessità di condurre ricerche replicabili. Un’introduzione questi temi è fornita, da esempio, da Song, Tang, Wee (2021). Nello specifico, Song, Tang, Wee (2021) mostrano che un modello che viene adattato un campione (campione di calibrazione) non si generalizza bene un altro campione (campione di convalida): la capacità predittiva del modello è minore quando il modello viene applicato al campione di convalida piuttosto che al campione di calibrazione. Questo problema è detto sovra-adattamento (overfitting). generale, Song, Tang, Wee (2021) mostrano come la capacità di generalizzazione del modello diminuisce () ’aumentare della complessità del modello, (b) al diminuire dell’ampiezza del campione di calibrazione, e (c) al diminuire della dimensione dell’effetto nella popolazione.Sebbene modelli statistici producono comunemente un sovra-adattamento, è anche possibile che essi producano un sotto-adattamento (underfitting) dei dati. Tale mancanza di adattamento è dovuta dalla variabilità campionaria e dalla complessità del modello. Il sotto-adattamento porta ad un \\(R^2\\) basso e ad un MSE alto, sia nei campioni di calibrazione che quelli di convalida. Per questo motivo, la scarsa generalizzabilità del modello può essere dovuta sia al sovra-adattamento che al sotto-adattamento del modello.Per aumentarne la capacità di generalizzazione del modello devono essere soddisfatte tre condizioni: () campioni di calibrazione grandi, (b) dimensioni dell’effetto non piccole nella popolazione, e (c) modelli che non siano inutilmente complessi. Tuttavia, nella ricerca psicologica queste tre condizioni sono difficili da soddisfare: l’aumento della dimensione del campione spesso richiede l’utilizzo di maggiori risorse, la dimensione di un dato effetto nella popolazione non è soggetta alla discrezione dei ricercatori e la complessità del modello è spesso guidata da motivazioni teoriche. Pertanto, negli studi psicologici la generalizzabilità dei modelli è spesso problematica. Ciò rende necessario che il ricercatore fornisca informazioni aggiuntive relative alla capacità del modello di generalizzarsi nuovi campioni. L’obiettivo di questa parte della dispensa è di descrivere come questo possa essere fatto utilizzando l’approccio bayesiano.","code":""},{"path":"ch-entropy.html","id":"capacità-predittiva","chapter":"Capitolo 32 Entropia","heading":"32.2 Capacità predittiva","text":"Nel framework bayesiano il problema della generalizzabilità di un modello viene affrontato valutando la capacità predittiva del modello, laddove per capacità predittiva si intende la capacità di un modello, cui parametri sono stati stimati usando le informazioni di un campione, di ben adattarsi ad un campione di osservazioni future. questo Capitolo cercheremo di rispondere tre domande.Quali criteri consentono di valutare la capacità predittiva di un modello?Come quantificare la capacità predittiva di un modello usando solo un campione di osservazioni?Come confrontare le capacità predittive di modelli diversi?","code":""},{"path":"ch-entropy.html","id":"il-rasoio-di-ockham","chapter":"Capitolo 32 Entropia","heading":"32.3 Il rasoio di Ockham","text":"Il problema di scegliere il modello più adatto spiegare un fenomeno di interesse è uno dei più importanti problemi campo scientifico. ricercatori si chiedono: il modello è completo? È necessario aggiungere un nuovo parametro al modello? Come può essere migliorato il modello? Se ci sono modelli diversi, qual’è il modello migliore?Per rispondere queste domande è possibile usare il rasoio di Ockham: frustra fit per plura quod potest fieri per pauciora (“si fa inutilmente con molte cose ciò che si può fare con poche cose”). Parafrasando la massima si potrebbe dire: se due modelli descrivono dati egualmente bene, viene sempre preferito il modello più semplice. Questo è il principio che sta alla base della ricerca scientifica.Il rasoio di Ockham, però, non consente sempre di scegliere tra modelli alternativi. Se due modelli fanno le stesse predizioni ma differiscono termini di complessità — per esempio, relativamente al numero di parametri di cui sono costituiti — allora è facile decidere: viene preferito il modello più semplice, anche perché, pragmaticamente, è il più facile da usare. Tuttavia, generale, modelli differiscono sia per complessità (ovvero, per il numero di parametri) che per accuratezza (ovvero, per la grandezza degli errori di predizione). tali circostanze il rasoio di Ockham non è sufficiente: non consente infatti di trovare un equilibrio tra accuratezza e semplicità.questo Capitolo ci chiederemo come sia possibile misurare l’accuratezza predittiva di un modello. Ciò ci consentirà, seguito, di usare il rasoio di Ockham: parità di accuratezza, sarà possibile scegliere il modello più semplice. Ma nella pratica scientifica non si sacrifica mai l’accuratezza per la semplicità: il criterio prioritario è sempre l’accuratezza.","code":""},{"path":"ch-entropy.html","id":"sovra-adattamento-e-sotto-adattamento","chapter":"Capitolo 32 Entropia","heading":"32.3.1 Sovra-adattamento e sotto-adattamento","text":"Secondo McElreath (2020), la selezione tra modelli deve evitare due opposti errori: il sovra-adattamento e il sotto-adattamento. Tale problema va sotto il nome di bias-variance trade-: il sotto-adattamento, infatti, porta distorsioni (bias) nella stima dei parametri, mentre il sovra-adattamento porta previsioni scadenti campioni futuri. Spesso l’incertezza relativa alla scelta del modello (sotto-adattamento versus sovra-adattamento) passa inosservata ma il suo impatto può essere drammatico. Secondo Hoeting et al. (1999), “Standard statistical practice ignores model uncertainty. Data analysts typically select model class models proceed selected model generated data. approach ignores uncertainty model selection, leading -confident inferences decisions risky one thinks .questo Capitolo esamineremo alcune tecniche bayesiane che possono essere utilizzate per operare una selezione tra modelli alternativi, tenendo sotto controllo pericoli del sovra-adattamento e del sotto-adattamento. particolare, ci chiederemo quale, tra due o più modelli, sia quello da preferire base al criterio della capacità predittiva.","code":""},{"path":"ch-entropy.html","id":"stargazing","chapter":"Capitolo 32 Entropia","heading":"32.3.2 Stargazing","text":"Nella pratica concreta della ricerca, il metodo più comune per la selezione tra modelli alternativi utilizza test di ipotesi statistiche di stampo frequentista. Questo metodo viene chiamato stargazing, poiché richiede soltanto l’esame degli asterischi (\\(**\\)) che si trovano nell’output di un software statistico (gli asterischi marcano coefficienti del modello che sono “statisticamente significativi”): alcuni ricercatori ritengono che il modello con più stelline sia anche il modello migliore. Questo però non è vero. Al di là dei problemi legati ai test dell’ipotesi nulla, è sicuramente un errore usare test di significatività per la selezione di modelli: valori-p non consentono di trovare un equilibrio tra underfitting e overfitting. Infatti, le variabili che migliorano la capacità predittiva di un modello non sono sempre statisticamente significative; d’altra parte, le variabili statisticamente significative non sempre migliorano la capacità predittiva di un modello.Quando ci chiediamo quale, tra modelli alternativi, è il modello che meglio rappresenta il “vero” processo di generazione dei dati, ci troviamo di fronte al problema di quantificare il grado di “vicinanza” di un modello al “vero” processo di generazione dei dati. Si noti che, tale confronto, facciamo riferimento sia alla famiglia distributiva così come ai valori dei parametri. Ad esempio, il modello \\(y_i \\sim \\mathcal{N}(5, 3)\\) è diverso dal modello \\(y_i \\sim \\mathcal{N}(5, 6)\\), ed è anche diverso dal modello \\(y_i \\sim \\Gamma(2, 2)\\). primi due modelli appartengono alla stessa famiglia distributiva ma differiscono nei termini dei valori dei parametri; gli ultimi due modelli appartengono famiglie distributive diverse (gaussiano vs. Gamma). Per misurare il grado di “vicinanza” tra due modelli, \\(\\mathcal{M}_1\\) e \\(\\mathcal{M}_2\\), la metrica di gran lunga più popolare è la divergenza di Kullback-Leibler. Per chiarire questo concetto è però prima necessario introdurre la nozione di entropia.","code":""},{"path":"ch-entropy.html","id":"la-misura-del-disordine","chapter":"Capitolo 32 Entropia","heading":"32.4 La misura del disordine","text":"Se vogliamo ottenere una comprensione intuitiva del concetto di entropia33 possiamo pensare quant’è informativa una distribuzione. Maggiore è l’entropia di una distribuzione, meno informativa sarà quella distribuzione e più uniformemente verranno assegnate le probabilità agli eventi. altri termini, ottenere la risposta di “42” è più informativo della risposta “42 \\(\\pm\\) 5”, che sua volta è più informativo della risposta “un numero qualsiasi”. L’entropia quantifica questa osservazione qualitativa.Il concetto di entropia si applica sia alle distribuzioni continue sia quelle discrete, ma è più facile da capire usando le distribuzioni discrete. Negli esempi successivi vedremo alcuni esempi applicati al caso discreto, ma gli stessi concetti si applicano al caso continuo.","code":""},{"path":"ch-entropy.html","id":"entropia-di-un-singolo-evento","chapter":"Capitolo 32 Entropia","heading":"32.4.1 Entropia di un singolo evento","text":"Il concetto di entropia può essere usato per descrivere la quantità di informazione fornita da un evento. L’intuizione che sta alla base del concetto di entropia è che l’informazione fornita da un evento descrive la sorpresa suscitata dall’evento: gli eventi rari (bassa probabilità) sono più sorprendenti – e quindi forniscono più informazione – degli eventi comuni (ad alta probabilità). altre parole,un evento bassa probabilità è sorprendente e fornisce molta informazione;un evento ad alta probabilità è poco o per niente sorprendente e fornisce poca (o nessuna) informazione.È dunque possibile quantificare l’informazione fornita dal verificarsi di un evento usando la probabilità di quell’evento. Una tale quantità di informazione è chiamata “informazione di Shannon”, “auto-informazione” o semplicemente “informazione” e, per un evento discreto \\(x\\), può essere calcolata come:\\[\n\\text{informazione}(x) = -\\log_2 p(x),\n\\]dove \\(\\log_2\\) è il logaritmo base 2 e \\(p(x)\\) è la probabilità dell’evento \\(x\\).La scelta del logaritmo base 2 significa che l’unità di misura dell’informazione è il bit (cifre binarie). Questo può essere interpretato dicendo che l’informazione misura il numero di bit richiesti per rappresentare un evento.34 Solitamente, si denota la quantità di informazione con \\(h()\\):\\[\nh(x) = -\\log p(x).\n\\]Il segno negativo garantisce che il risultato sia sempre positivo o zero. L’informazione è zero quando la probabilità dell’evento è 1.0, ovvero quando l’evento è certo (assenza di sorpresa).Esempio 32.1  Consideriamo il lancio di una moneta equilibrata. La probabilità di testa (e croce) è 0.5. La quantità di informazione di ottenere “testa” è dunquePer rappresentare questo evento abbiamo bisogno di 1 bit di informazione. Se la stessa moneta venisse lanciata \\(n\\) volte, la quantità di informazione necessaria per rappresentare questo evento (ovvero, questa sequenza di lanci) sarebbe pari \\(n\\) bit. Se la moneta non è equilibrata e la probabilità di testa è 0.1, allora l’evento “testa” è più raro e richiede più di 3 bit di informazione:Consideriamo ora il lancio di un dado. Quanta informazione viene fornita, ad esempio, dall’evento “esce il numero 6”? Dato che la probabilità di ottenere un 6 nel lancio di un dado è più piccola della probabilità di ottenere “testa” nel lancio di una moneta, il risultato del lancio di un dado deve produrre una sorpresa maggiore del risultato del lancio di una moneta. Per cui, la quantità di informazione associata ’evento “è uscito 6”, dovrà essere maggiore di quella associata ’evento “testa”. Infatti, la quantità di informazione dell’evento “è uscito un 6” è più che doppia rispetto alla quantità di informazione dell’evento “testa”:Esempio 32.2  Nella figura successiva viene esaminata la relazione tra probabilità e informazione, per valori di probabilità nell’intervallo tra 0 e 1.La figura mostra che questa relazione non è lineare, è infatti leggermente sublineare. Questo ha senso dato che abbiamo usato una funzione logaritmica.","code":"\n-log2(0.5)\n#> [1] 1\n-log2(0.1)\n#> [1] 3.321928\n-log2(1/6)\n#> [1] 2.584963\np <- seq(0, 1, length.out = 1000)\nh <- -log2(p)\nggplot(tibble(p, h), aes(p, h)) +\n  geom_line() +\n  labs(\n    x = \"Probabilità\",\n    y = \"Informazione\"\n  )"},{"path":"ch-entropy.html","id":"entropia-di-una-variabile-casuale","chapter":"Capitolo 32 Entropia","heading":"32.4.2 Entropia di una variabile casuale","text":"Possiamo estendere questa discussione pensando ad un insieme di eventi, ovvero ad una distribuzione. Nella teoria della probabilità usiamo la nozione di variabile casuale per fare riferimento ad un insieme di eventi e alle probabilità associate tali eventi. L’entropia quantifica l’informazione che viene fornita da una variabile casuale.Definizione 32.1  Sia \\(Y = y_1, \\dots, y_n\\) una variabile casuale e \\(p_t(y)\\) una distribuzione di probabilità su \\(Y\\). Si definisce la sua entropia (detta di Shannon) come:\\[\\begin{equation}\nH(Y) = - \\sum_{=1}^n p_t(y_i) \\cdot \\log_2 p_t(y_i).\n\\tag{32.1}\n\\end{equation}\\]Per interpretare la (32.1), consideriamo un esempio discusso da Martin, Kumar, Lao (2022).\nFIGURA 32.1: Funzioni di massa di probabilità e associata entropia.\nNella figura 32.1 sono rappresentate sei distribuzioni. viene anche riportato il valore di entropia di ciascuna distribuzione. La distribuzione con il picco più pronunciato o con la dispersione minore è q, e questa è la distribuzione con il valore di entropia più basso tra le sei distribuzioni considerate. Per q la distribuzione è q ~ binom(n = 10, p = 0.75); quindi ci sono 11 possibili eventi. qu ha una distribuzione uniforme sugli stessi 11 possibili eventi. L’entropia di qu è maggiore dell’entropia di q. Infatti, se calcoliamo l’entropia di distribuzioni binomiali con \\(n = 10\\) (con valori diversi di \\(p\\)) ci rendiamo conto che nessuna di tali distribuzioni ha un’entropia maggiore di qu. Dobbiamo aumentare \\(n ≈ 3\\) volte per trovare la prima distribuzione binomiale con entropia maggiore di qu. Passiamo alla riga successiva. Generiamo la distribuzione r spostando destra q e normalizzando (per garantire che la somma di tutte le probabilità sia 1). Poiché r ha una dispersione maggiore di q, la sua entropia è maggiore. ru è una distribuzione uniforme con lo stesso numero di eventi possibili come r (ovvero 22) – si noti che sono stati inclusi come valori possibili anche quelli nella “valle” tra due picchi. Ancora una volta, la distribuzione uniforme ha l’entropia più grande.Gli esempi discussi finora sembrano suggerire che l’entropia è proporzionale alla varianza della distribuzione. Verifichiamo questa intuizione esaminiamo le ultime due distribuzioni della figura 32.1. La distribuzione s è simile r ma presenta una separazione maggiore tra due picchi della distribuzione – dunque, ha una varianza più grande. Ciò nonostante, l’entropia non varia. Quindi la relazione tra entropia e varianza non è così semplice come ci sembrava. Il risultato che abbiamo trovato può essere spiegato dicendo che, nel calcolo dell’entropia, non vengono considerati gli eventi con probabilità nulla (per questa ragione, nell’esempio, è stato possibile aumentare la varianza senza cambiare l’entropia). La distribuzione su è stata costruita sostituendo due picchi s con qu (e normalizzando). Possiamo vedere che su ha un’entropia minore di ru, anche se su ha una dispersione maggiore di ru. Questo è dovuto al fatto che su distribuisce la probabilità totale tra un numero minore di eventi (22) di ru (che ne conta 23); quindi è sensato attribuire su un’entropia minore di ru.Esempio 32.3  Consideriamo ora un esempio riguardante le previsioni del tempo. Supponiamo che le probabilità di pioggia e sole siano, rispettivamente, \\(p_1 = 0.3\\) e \\(p_2 = 0.7\\). Quindi\\[\nH(p) = − [p(y_1) \\log_2 p(y_1) + p(y_2) \\log_2 p(y_2)] \\approx 0.61.\n\\]Se però viviamo Las Vegas, allora le probabilità di pioggia e sole saranno simili \\(p(y_1) = 0.01\\) e \\(p(y_2) = 0.99\\). questo secondo caso, l’entropia è 0.06, ovvero, molto minore di prima. Infatti, Las Vegas non piove quasi mai, per cui quando abbiamo imparato che, un certo giorno, non ha piovuto, abbiamo imparato molto poco rispetto quello che già sapevamo precedenza.Esempio 32.4  Nell’esempio precedente abbiamo visto che, se gli esiti possibili sono pioggia o sole con \\(p(y_1) = 0.7\\), \\(p(y_2) = 0.3\\), allora l’entropia èMa se gli esiti possibili sono pioggia, neve o sole con \\(p(y_1) = 0.7\\), \\(p(y_2) = 0.15\\) e \\(p(y_3) = 0.15\\), rispettivamente, allora l’entropia cresce:","code":"\n-(0.7 * log(0.7) + 0.3 * log(0.3))\n#> [1] 0.6108643\n-(0.7 * log(0.7) + 0.15 * log(0.15) + 0.15 * log(0.15))\n#> [1] 0.8188085"},{"path":"ch-entropy.html","id":"commenti-e-considerazioni-finali-25","chapter":"Capitolo 32 Entropia","heading":"Commenti e considerazioni finali","text":"questo Capitolo abbiamo visto come sia possibile quantificare l’incertezza tramite l’entropia. Ma come è possibile usare l’entropia dell’informazione per specificare la “distanza” tra un modello e il vero meccanismo generatore dei dati? La risposta questa domanda è fornita dalla divergenza di Kullback-Leibler che verrà discussa nel Capitolo ??.","code":""},{"path":"ch-kl.html","id":"ch-kl","chapter":"Capitolo 33 La divergenza di Kullback-Leibler","heading":"Capitolo 33 La divergenza di Kullback-Leibler","text":"È comune statistica utilizzare una distribuzione di probabilità \\(q\\) per approssimare un’altra distribuzione \\(p\\) – generalmente, questo viene fatto se \\(p\\) non è conosciuta o è troppo complessa. questi casi possiamo chiederci quanta informazione venga perduta usando \\(q\\) al posto di \\(p\\), o equivalentemente, quanta incertezza aggiuntiva viene introdotta nell’analisi statistica. La quantificazione di questo incremento di incertezza è fornita dalla divergenza di Kullback-Leibler.","code":""},{"path":"ch-kl.html","id":"la-perdita-di-informazione","chapter":"Capitolo 33 La divergenza di Kullback-Leibler","heading":"33.1 La perdita di informazione","text":"Intuitivamente, per quantificare l’informazione che si perde quando una distribuzione approssimata \\(q\\) viene usata luogo della distribuzione corretta \\(p\\) sembra necessaria una quantità che ha valore zero quando \\(q = p\\), e un valore positivo altrimenti. Seguendo la definizione (32.1) di entropia, possiamo quantificare una tale perdita di informazione mediante il valore atteso della differenza tra \\(\\log(p)\\) e \\(\\log(q)\\). Questa quantità è chiamata entropia relativa o divergenza di Kullback-Leibler:\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = \\mathbb{E} (\\log p - \\log q).\n\\tag{33.1}\n\\end{equation}\\]La divergenza \\(\\mathbb{KL} (p \\mid\\mid q)\\) corrisponde alla differenza media nelle probabilità logaritmiche quando \\(q\\) viene usato per approssimare \\(p\\). Poiché gli eventi si manifestano secondo \\(p\\), è necessario calcolare il valore atteso rispetto \\(p\\). Per distribuzioni discrete dunque abbiamo:\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = \\sum_i^n p_i (\\log p_i - \\log q_i) = \\sum_i^n p_i \\log \\frac{p_i}{q_i}.\n\\end{equation}\\]Riarrangiando termini otteniamo:\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = -\\sum_i^n p_i (\\log q_i - \\log p_i),\n\\end{equation}\\]ovvero,\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = \\underbrace{-\\sum_i^n p_i \\log q_i}_{h(p, q)} - \\underbrace{\\left(-\\sum_i^n p_i \\log p_i\\right)}_{h(p)},\n\\end{equation}\\]laddove \\(h(p)\\) è l’entropia di \\(p\\) e \\(h(p, q) = − \\mathbb{E} [\\log q]\\) può essere intesa come l’entropia di \\(q\\), ma valutata secondo valori di probabilità \\(p\\).Riarrangiando l’equazione precedente otteniamo:\\[\\begin{equation}\nh(p, q) = h(p) + \\mathbb{KL} (p \\mid\\mid q),\n\\end{equation}\\]il che mostra come la divergenza \\(\\mathbb{KL}\\) possa essere interpretata come l’incremento di entropia, rispetto \\(h(p)\\), quando \\(q\\) viene usata per rappresentare \\(p\\).Esempio 33.1  (da McElreath 2020) Sia la distribuzione target \\(p = \\{0.3, 0.7\\}\\). Supponiamo che la distribuzione approssimata \\(q\\) possa assumere valori da \\(q = \\{0.01, 0.99\\}\\) \\(q = \\{0.99, 0.01\\}\\). Calcoliamo la divergenza KL.Le istruzioni \\(\\mathsf{R}\\) sono le seguenti:\nNella figura seguente sull’asse delle ascisse sono rappresentati valori \\(q\\) e sull’asse delle ordinante sono riportati corrispondenti valori \\(\\mathbb{KL}\\).Tanto meglio la distribuzione \\(q\\) approssima la distribuzione target tanto più piccolo è il valore di divergenza \\(\\mathbb{KL}\\).Esempio 33.2  Sia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\)\nSia \\(q_1\\) una approssimazione \\(p\\):Sia \\(q_2\\) una distribuzione uniforme:La divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) èLa divergenza \\(\\mathbb{KL}\\) di \\(q_2\\) da \\(p\\) è:È chiaro che perdiamo una quantità maggiore di informazioni se, per descrivere la distribuzione binomiale \\(p\\), usiamo la distribuzione uniforme \\(q_2\\) anziché \\(q_1\\).","code":"\nt <-\n  tibble(\n    p_1 = .3,\n    p_2 = .7,\n    q_1 = seq(from = .01, to = .99, by = .01)\n  ) %>%\n  mutate(\n    q_2 = 1 - q_1\n  ) %>%\n  mutate(\n    d_kl = (p_1 * log(p_1 / q_1)) + (p_2 * log(p_2 / q_2))\n  )\n\nhead(t)\n#> # A tibble: 6 × 5\n#>     p_1   p_2   q_1   q_2  d_kl\n#>   <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1   0.3   0.7  0.01  0.99 0.778\n#> 2   0.3   0.7  0.02  0.98 0.577\n#> 3   0.3   0.7  0.03  0.97 0.462\n#> 4   0.3   0.7  0.04  0.96 0.383\n#> 5   0.3   0.7  0.05  0.95 0.324\n#> 6   0.3   0.7  0.06  0.94 0.276\nt %>%\n  ggplot(aes(x = q_1, y = d_kl)) +\n  geom_vline(xintercept = .3, linetype = 2) +\n  geom_line(size = 1) +\n  annotate(geom = \"text\", x = .4, y = 1.5, label = \"q = p\",\n           size = 3.5) +\n  labs(x = \"q[1]\",\n       y = \"Divergenza di q da p\")\nn <- 4\np <- 0.2\ntrue_py <- dbinom(0:n, n, 0.2)\ntrue_py\n#> [1] 0.4096 0.4096 0.1536 0.0256 0.0016\nq1 <- c(0.46, 0.42, 0.10, 0.01, 0.01)\nq1\n#> [1] 0.46 0.42 0.10 0.01 0.01\nq2 <- rep(0.2, 5)\nq2\n#> [1] 0.2 0.2 0.2 0.2 0.2\nsum(true_py * log(true_py / q1))\n#> [1] 0.02925199\nsum(true_py * log(true_py / q2))\n#> [1] 0.4863578"},{"path":"ch-kl.html","id":"la-divergenza-dipende-dalla-direzione","chapter":"Capitolo 33 La divergenza di Kullback-Leibler","heading":"33.2 La divergenza dipende dalla direzione","text":"La divergenza \\(\\mathbb{KL}\\) non è una vera e propria metrica: per esempio, non è simmetrica. generale, \\(\\mathbb{KL}(p \\mid\\mid q) \\neq \\mathbb{KL}(q \\mid\\mid p)\\), ovvero la \\(\\mathbb{KL}\\) da \\(p\\) \\(q\\) è diversa dalla \\(\\mathbb{KL}\\) da \\(q\\) \\(p\\).Esempio 33.3  Usando le seguenti istruzioni \\(\\mathsf{R}\\) otteniamo:","code":"\ntibble(direction = c(\"Da q a p\", \"Da p a q\"),\n       p_1 = c(.01, .7),\n       q_1 = c(.7, .01)) %>%\n  mutate(p_2 = 1 - p_1,\n         q_2 = 1 - q_1) %>%\n  mutate(d_kl = (p_1 * log(p_1 / q_1)) + (p_2 * log(p_2 / q_2)))\n#> # A tibble: 2 × 6\n#>   direction   p_1   q_1   p_2   q_2  d_kl\n#>   <chr>     <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1 Da q a p   0.01  0.7   0.99  0.3   1.14\n#> 2 Da p a q   0.7   0.01  0.3   0.99  2.62"},{"path":"ch-kl.html","id":"confronto-tra-modelli","chapter":"Capitolo 33 La divergenza di Kullback-Leibler","heading":"33.3 Confronto tra modelli","text":"La divergenza \\(\\mathbb{KL}\\) viene utilizzata nel confronto tra modelli, ovvero ci consente di quantificare l’informazione che viene perduta quando utilizziamo la distribuzione di probabilità ipotizzata da un modello, chiamiamola \\(p_{\\mathcal{M}}\\), per approssimare la distribuzione di probabilità del vero modello generatore dei dati, \\(p_t\\).precedenza abbiamo introdotto il concetto di distribuzione predittiva posteriori:\\[\np(\\tilde{y} \\mid y) = \\int_\\Theta p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta .\n\\]La distribuzione predittiva posteriori descrive il tipo di dati che ci aspettiamo vengano prodotti dal modello generativo \\(\\mathcal{M}\\), alla luce delle nostre credenze iniziali, \\(p(\\theta)\\) e dei dati osservati \\(y\\). Quando valutiamo un modello ci chiediamo che misura \\(p_{\\mathcal{M}}(\\tilde{y} \\mid y)\\) approssimi \\(p_t(\\tilde{y})\\). Cioè, ci chiediamo quanto siano simili dati \\(p_{\\mathcal{M}}(\\cdot)\\) prodotti dal modello \\(\\mathcal{M}\\) ai dati prodotti dal vero processo generatore dei dati \\(p_t(\\cdot)\\).Una misura della “somiglianza” tra la distribuzione \\(q_{\\mathcal{M}}\\) ipotizzata dal modello \\(\\mathcal{M}\\) e la distribuzione \\(p_t\\) del vero modello generatore dei dati è fornita dalla divergenza di Kullback-Leibler \\(\\mathbb{KL}(p_t \\mid\\mid q_{\\mathcal{M}})\\). Supponendo di avere \\(k\\) modelli della distribuzione posteriori, \\(\\{q_{\\mathcal{M}_1}, q_{\\mathcal{M}_2}, \\dots, q_{\\mathcal{M}_k}\\}\\), e di conoscere il vero modello generatore dei dati, possiamo scrivere\\[\\begin{align}\n\\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_1}) &= \\mathbb{E} (\\log p_{\\mathcal{M}_0}) - \\mathbb{E} (\\log q_{\\mathcal{M}_1})\\notag\\\\\n\\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_2}) &= \\mathbb{E} (\\log p_t) - \\E (\\log q_{\\mathcal{M}_2})\\notag\\\\\n&\\cdots\\notag\\\\\n\\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_k}) &= \\mathbb{E} (\\log p_{\\mathcal{M}_0}) - \\mathbb{E} (\\log q_{\\mathcal{M}_k}).\n\\tag{33.2}\n\\end{align}\\]La (33.2) può sembrare un esercizio futile poiché nella vita reale non conosciamo il vero modello generatore dei dati. È però facile rendersi conto che, poiché \\(p_t\\) è la stessa per tutti confronti, diventa possibile costruire un ordinamento dei modelli basato unicamente sul secondo termine della (33.2), ovvero senza nessun riferimento al vero modello generatore dei dati. Per un generico modello \\(\\mathcal{M}\\), il secondo termine della (33.2) può essere scritto come:\\[\\begin{equation}\n\\mathbb{E} \\log p_{\\mathcal{M}}(y) = \\int_{-\\infty}^{+\\infty}p_{t}(y)\\log p_{\\mathcal{M}}(y) \\,\\operatorname {d}\\!y .\n\\tag{33.3}\n\\end{equation}\\]","code":""},{"path":"ch-kl.html","id":"expected-log-predictive-density","chapter":"Capitolo 33 La divergenza di Kullback-Leibler","heading":"33.4 Expected log predictive density","text":"Le previsioni del modello \\(\\mathcal{M}\\) sui nuovi dati futuri sono date dalla distribuzione predittiva posteriori. Possiamo dunque riscrivere la (33.3) come\\[\\begin{equation}\n\\mbox{elpd} = \\int_{\\tilde{y}} p_{t}(\\tilde{y}) \\log p(\\tilde{y} \\mid y) \\,\\operatorname {d}\\!\\tilde{y}.\n\\tag{33.4}\n\\end{equation}\\]La (33.4) è chiamata expected log predictive density (\\(\\mbox{elpd}\\)) e fornisce la risposta al problema che ci eravamo posti: nel confronto tra modelli, come è possibile scegliere il modello più simile al vero meccanismo generatore dei dati? Possiamo pensare alla (33.4) dicendo che descrive la distribuzione predittiva posteriori del modello ponderando la verosimiglianza dei possibili (sconosciuti) dati futuri (\\(\\tilde{y}\\)) con la vera distribuzione \\(p_t\\). Di conseguenza, valori \\(\\mbox{elpd}\\) più grandi identificano il modello che risulta più simile al vero meccanismo generatore dei dati.Non dobbiamo preoccuparci di trovare una formulazione analitica della distribuzione predittiva posteriori \\(p(\\tilde{y} \\mid y)\\) perché è possibile approssimare tale distribuzione mediante simulazione. Notiamo però che la (33.4) include un termine, \\(p_t(\\tilde{y})\\), il quale descrive la distribuzione dei dati futuri \\(\\tilde{y}\\) secondo il vero modello generatore dei dati. Il termine \\(p_t\\), ovviamente, è ignoto.35 Di conseguenza, la quantità \\(\\mbox{elpd}\\) non può mai essere calcolata maniera esatta, ma può solo essere stimata. Il secondo problema di questo Capitolo è capire come la (33.4) possa essere stimata utilizzando un campione di osservazioni.","code":""},{"path":"ch-kl.html","id":"log-pointwise-predictive-density","chapter":"Capitolo 33 La divergenza di Kullback-Leibler","heading":"33.4.1 Log pointwise predictive density","text":"Ingenuamente, potremmo pensare di stimare la (33.4) ipotizzando che la distribuzione del campione coincida con \\(p_t\\). Usare la distribuzione del campione come proxy del vero modello generatore dei dati (ovvero, ipotizzare che la distribuzione del campione rappresenti fedelmente \\(p_t\\)) comporta due conseguenze:non è necessario ponderare per \\(p_t\\), quanto assumiamo che la distribuzione empirica del campione corrisponda \\(p_t\\) (ciò significa assumere che valori più comunemente osservati nel campione siano anche quelli più verosimili nella vera distribuzione \\(p_t\\));dato che il campione è finito, anziché eseguire un’operazione di integrazione possiamo semplicemente sommare la densità predittiva posteriori delle osservazioni.Questo conduce alla seguente equazione:36\\[\\begin{equation}\n\\frac{1}{n} \\sum_{=1}^n \\log p(y_i^{rep} \\mid y).\n\\tag{33.5}\n\\end{equation}\\]La quantità (33.5), senza il passaggio finale della divisione per il numero di osservazioni, è chiamata log pointwise predictive density (\\(\\mbox{lppd}\\))\\[\\begin{equation}\n\\mbox{lppd} = \\sum_{=1}^n \\log p(y_i^{rep} \\mid y)\n\\tag{33.6}\n\\end{equation}\\]e corrisponde alla somma delle densità predittive logaritmiche delle \\(n\\) osservazioni. Valori più grandi della (33.6) sono da preferire perché indicano una maggiore accuratezza media. È anche comune vedere espressa la quantità precedente nei termini della devianza, ovvero alla \\(\\mbox{lppd}\\) moltiplicata per -2. questo secondo caso sono da preferire valori piccoli.È importante notare che \\(\\lppd\\) fornisce una sovrastima della (33.4). Tale sovrastima è dovuta al fatto che, nel calcolo della (33.6), abbiamo usato \\(p(y^{rep} \\mid y)\\) al posto di \\(p(\\tilde{y} \\mid y)\\): altri termini, abbiamo considerato le osservazioni del campione come se fossero un nuovo campione di dati. una serie di simulazioni, McElreath (2020) esamina il significato di questa sovrastima. Nelle simulazioni la devianza viene calcolata come funzione della complessità (ovvero, il numero di parametri) del modello. La simulazione mostra che \\(\\mbox{lppd}\\) aumenta al crescere del numero di parametri del modello. Ciò significa che \\(\\mbox{lppd}\\) mostra lo stesso limite del coefficiente di determinazione: aumenta ’aumentare della complessità del modello.Esempio 33.4  Esaminiamo un esempio tratto da Bayesian Data Analysis Cognitive Science nel quale la \\(\\mbox{lppd}\\) viene calcolata forma esatta oppure mediante approssimazione. Supponiamo di disporre di un campione di \\(n\\) osservazioni. Supponiamo inoltre di conoscere il vero processo generativo dei dati (qualcosa che pratica non è mai possibile), ovvero:\\[\np_t(y) = \\mbox{Beta}(1, 3).\n\\]\ndati sonoSupponiamo inoltre di avere adattato ai dati un modello bayesiano \\(\\mathcal{M}\\) e di avere ottenuto la distribuzione posteriori per parametri del modello. Inoltre, supponiamo di avere derivato la forma analitica della distribuzione predittiva posteriori per il modello:\\[\np(y^{rep} \\mid y) \\sim \\mbox{Beta}(2, 2).\n\\]Questa distribuzione ci dice quanto sono credibili possibili dati futuri.Conoscendo la vera distribuzione dei dati \\(p_t(y)\\) possiamo calcolare forma esatta la quantità \\(\\mbox{elpd}\\), ovvero\\[\n\\mbox{elpd} = \\int_{y^{rep}}p_{t}(y^{rep})\\log p(y^{rep} \\mid y) \\,\\operatorname {d}\\!y^{rep}.\n\\]Svolgiamo calcoli \\(\\mathsf{R}\\) otteniamo:Tuttavia, pratica non conosciamo mai \\(p_t(y)\\). Quindi approssimiamo \\(\\mbox{elpd}\\) usando la (33.4):\\[\n\\frac{1}{n} \\sum_{=1}^n \\log p(y_i \\mid y).\n\\]Così facendo, e svolgendo calcoli \\(\\mathsf{R}\\), otteniamo un valore diverso da quello trovato precedenza:","code":"\nset.seed(75)\nn <- 10000\ny_data <- rbeta(n, 1, 3)\nhead(y_data)\n#> [1] 0.55062422 0.13346270 0.80250987 0.21430898 0.01913430 0.08676517\n# True distribution\np_t <- function(y) dbeta(y, 1, 3)\n# Predictive distribution\np <- function(y) dbeta(y, 2, 2)\n# Integration\nintegrand <- function(y) p_t(y) * log(p(y))\nintegrate(f = integrand, lower = 0, upper = 1)\n#> -0.3749072 with absolute error < 6.8e-07\n1/n * sum(log(p(y_data)))\n#> [1] -0.3639141"},{"path":"ch-kl.html","id":"commenti-e-considerazioni-finali-26","chapter":"Capitolo 33 La divergenza di Kullback-Leibler","heading":"Commenti e considerazioni finali","text":"Dato che non conosciamo il vero meccanismo generatore dei dati \\(p\\), possiamo usare la distribuzione dei dati osservata come proxy per la vera distribuzione \\(p\\). Quindi, invece di ponderare la distribuzione predittiva base alla densità reale di tutti possibili dati futuri, utilizziamo semplicemente le \\(n\\) osservazioni che abbiamo. Possiamo farlo perché assumiamo che le nostre osservazioni costituiscano un campione dalla vera distribuzione dei dati: base questa ipotesi, nel campione ci aspettiamo di osservare più frequentemente quelle osservazioni che hanno una maggiore verosimiglianza nella vera distribuzione \\(p\\). È così possibile giungere ad una stima numerica della \\(\\mbox{elpd}\\) chiamata log pointwise predictive density (\\(\\mbox{lppd}\\)).","code":""},{"path":"ch-info-crit.html","id":"ch-info-crit","chapter":"Capitolo 34 Criterio di informazione e convalida incrociata","heading":"Capitolo 34 Criterio di informazione e convalida incrociata","text":"Nel Capitolo precedente abbiamo visto che la (33.6) fornisce una sovrastima della \\(\\mbox{elpd}\\). Il modo migliore per stimare \\(\\mbox{elpd}\\) è raccogliere un nuovo campione indipendente di dati, che si ritiene condivida lo stesso processo di generazione dei dati del campione corrente, e stimare \\(\\mbox{elpd}\\) sul nuovo campione. Questa procedura è chiamata --sample validation. Il problema, però, è che solitamente non abbiamo le risorse per raccogliere un nuovo campione di osservazioni. Di conseguenza, gli statistici hanno messo punto vari metodi per evitare la sovrastima della \\(\\mbox{elpd}\\) che deriva dal solo utizzo del campione corrente. Ci sono due approcci generali:l’introduzione di un fattore di correzione;la convalida incrociata cosiddetta K-fold.Lo scopo del presente Capitolo è di fornire una breve introduzione ai criteri dell’informazione e alla procedura della convalida incrociata.","code":""},{"path":"ch-info-crit.html","id":"aic-dic-e-waic","chapter":"Capitolo 34 Criterio di informazione e convalida incrociata","heading":"34.1 AIC, DIC e WAIC","text":"Allo scopo di evitare la sovrastima della (33.6), le statistiche Akaike Information Criterion (AIC), Deviance Information Criterion (DIC) e Widely Applicable Information Criterion (WAIC) introducono un fattore di correzione. Le statistiche DIC e WAIC sono più complesse di AIC, ma producono un’approssimazione migliore. Tuttavia, valori AIC, DIC e WAIC sono spesso molto simili tra loro. Per convenienza, dunque, qui ci accontenteremo di esaminare dettaglio la statistica più semplice, ovvero AIC.","code":""},{"path":"ch-info-crit.html","id":"criterio-dinformazione-di-akaike","chapter":"Capitolo 34 Criterio di informazione e convalida incrociata","heading":"34.1.1 Criterio d’informazione di Akaike","text":"Il criterio d’informazione di Akaike (inglese Akaike information criterion, indicato come AIC) fornisce un metodo molto semplice per approssimare \\(\\mbox{elpd}\\).Definizione 34.1  Il criterio d’informazione di Akaike è definito come\\[\\begin{equation}\nAIC = -2 \\log p(y \\mid \\hat{\\theta}_{MLE}) + 2k,\n\\end{equation}\\]dove \\(k\\) è il numero di parametri stimati nel modello e \\(p(y \\mid \\hat{\\theta}_{MLE})\\) è il valore massimizzato della funzione di verosimiglianza del modello stimato.Dividendo per -2, otteniamo \\(\\mbox{elpd}_{AIC}\\):\\[\\begin{equation}\n\\widehat{\\mbox{elpd}}_{AIC} = \\log p(y \\mid \\hat{\\theta}_{MLE}) - k,\n\\end{equation}\\]dove \\(k\\) è il fattore di correzione introdotto per evitare la sovrastima discussa precedenza.AIC è di interesse principalmente storico e produce una approssimazione attendibile di \\(\\mbox{elpd}\\) quando:le distribuzioni priori sono non informative;la distribuzione posteriori è approssimativamente gaussiana multivariata;la dimensione \\(n\\) del campione è molto maggiore del numero \\(k\\) dei parametri.Esempio 34.1  Per meglio comprendere la statistica \\(\\widehat{\\mbox{elpd}}_{AIC}\\), esaminiamo un esempio discusso da Gelman, Hwang, Vehtari (2014). Sia \\(y_1, \\dots, y_n \\sim \\mathcal{N}(\\mu, 1)\\) un campione di osservazioni. Nel caso di una distribuzione priori non-informativa \\(p(\\theta) \\propto 1\\), la stima di massima verosimiglianza è \\(\\bar{y}\\). La verosimiglianza è\\[\nf(Y \\mid \\mu, \\sigma) = \\prod_{=1}^n f(y \\mid \\mu, \\sigma)\n\\]e la log-verosimiglianza diventa\\[\n\\ell(Y \\mid \\mu, \\sigma) = \\sum_{=1}^n \\log (f(y \\mid \\mu, \\sigma)).\n\\]Ovvero,\\[\\begin{align}\n\\ell(Y \\mid \\mu, \\sigma) &= \\sum_{=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi\\sigma^2 }}}\\exp \\left(-{\\frac {1}{2}}{\\frac {(y_i-\\mu )^{2}}{\\sigma^{2}}}\\right) \\right)\\notag\\\\\n&= \\sum_{=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi \\sigma^2}}} \\right) - \\sum_{=1}^n{\\frac {1}{2}}{\\frac {(y_i-\\mu )^{2}}{\\sigma ^{2}}} \\notag\\\\\n&= \\sum_{=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi \\sigma^2}}} \\right) - \\frac{1}{2\\sigma^2}\\sum_{=1}^n (y_i-\\mu )^{2} \\notag \\\\\n&= \\sum_{=1}^n \\log (1) - \\sum_{=1}^n\\log \\sqrt{2\\pi \\sigma^2} - \\frac{1}{2\\sigma^2}\\sum_{=1}^n (y_i-\\mu )^{2} \\notag\\\\\n&= - \\sum_{=1}^n\\frac{1}{2}  \\log (2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{=1}^n (y_i-\\mu )^{2} \\notag\\\\\n&= - \\frac{n}{2}  \\log (2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{=1}^n (y_i-\\mu )^{2}. \\notag\n\\end{align}\\]Se \\(y \\sim \\mathcal{N}(\\mu, 1)\\), usando lo stimatore di massima verosimiglianza per \\(\\mu\\), la log-verosimiglianza diventa\\[\\begin{align}\n\\log p(y \\mid \\hat{\\theta}_{MLE}) &= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2}\\sum_{=1}^n (y_i - \\bar{y})^2 \\notag\\\\\n&= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2} (n-1)s_y^2,\n\\end{align}\\]dove \\(s_y^2\\) è la varianza campionaria.Nel caso di un modello gaussiano con con varianza nota e una distribuzione priori uniforme viene stimato un solo parametro, per cui\\[\\begin{align}\n\\widehat{\\mbox{elpd}}_{AIC} &= \\log p(y \\mid \\hat{\\theta}_{MLE}) - k \\notag \\\\\n&= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2} (n-1)s_y^2 - 1.\n\\end{align}\\]","code":""},{"path":"ch-info-crit.html","id":"convalida-incrociata-k-fold","chapter":"Capitolo 34 Criterio di informazione e convalida incrociata","heading":"34.2 Convalida incrociata K-fold","text":"La sovrastima della (33.6) può anche essere evitata usando una tecnica chiamata K-fold cross-validation. Mediante questo metodo vengono stimati parametri del modello tralasciando una porzione di osservazioni (chiamata fold) dal campione per poi valutare il modello sulle osservazioni che sono state escluse. Una stima complessiva dell’accuratezza si ottiene poi calcolando la media del punteggio di accuratezza ottenuto ogni fold. Il numero minimo di fold è 2; ’altro estremo, è possibile impiegare una singola osservazione ciascun fold e adattare il modello tante volte (\\(n\\)) quante sono le singole osservazioni. Questa strategia è chiamata leave-one-cross-validation (LOO-CV).","code":""},{"path":"ch-info-crit.html","id":"importance-sampling","chapter":"Capitolo 34 Criterio di informazione e convalida incrociata","heading":"34.2.1 Importance sampling","text":"La strategia LOO-CV è computazionalmente onerosa (ovvero, richiede un tempo di esecuzione molto lungo). È però possibile approssimare LOO-CV mediante un metodo chiamato Pareto-smoothed importance sampling cross-validation [PSIS; Vehtari, Gelman, Gabry (2017)]. Tralasciando qui dettagli matematici, l’intuizione di base è che PSIS fa leva sul punteggio di “importanza” posseduto da ciascuna osservazione ’interno della distribuzione posteriori. Per “importanza” si intende il fatto che alcune osservazioni hanno un impatto maggiore sulle proprietà della distribuzione posteriori di altre: se viene rimossa un’osservazione importante, le proprietà della distribuzione posteriori cambiano molto; se viene rimossa un’osservazione poco importante, la distribuzione posteriori cambia poco. L’“importanza” così intesa viene chiamata “peso” (weight) e tali pesi vengono utilizzati per stimare l’accuratezza --sample del modello. PSIS-LOO-CV richiede che il modello venga adattato una volta soltanto ai dati e fornisce una stima della devianza --sample che evita la sovrastima della (33.6). Inoltre, PSIS-LOO-CV fornisce un feedback sulla propria affidabilità identificando le osservazioni cui pesi molto elevati potrebbero rendere imprecisa la predizione.Valori \\(\\widehat{\\mbox{elpd}}_{LOO}\\) più grandi indicano una maggiore accuratezza predittiva. alternativa, anziché considerare \\(\\widehat{\\mbox{elpd}}\\), è possibile usare la quantità \\(-2 \\cdot \\widehat{\\mbox{elpd}}\\), la quale è chiamata LOO Information Criterion (LOOIC). questo secondo caso, valori LOOIC più piccoli sono da preferire.La quantità \\(\\widehat{\\mbox{elpd}}_{LOO}\\) viene calcolata dai pacchetti loo e brms ed è chiamata elpd_loo o elpd_kfold. È anche possibile calcolare la differenza della quantità elpd_loo per modelli alternativi, insieme alla deviazione standard della distribuzione campionaria di tale differenza.","code":""},{"path":"ch-info-crit.html","id":"confronto-tra-aic-e-loo-cv","chapter":"Capitolo 34 Criterio di informazione e convalida incrociata","heading":"34.3 Confronto tra AIC e LOO-CV","text":"Per fare un esempio, faremo qui un confronto tra \\(\\widehat{\\mbox{elpd}}_{AIC}\\) e \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\). Esaminiamo nuovamente l’associazione tra il QI dei figli e il QI delle madri nel campione di dati discusso da Gelman, Hill, Vehtari (2020). Una tale relazione può essere descritta da un modello di regressione nel quale la \\(y\\) corrisponde al QI dei figli e la \\(x\\) al QI delle madri.Leggiamo dati :Dato che AIC non è una statistica bayesiana, può essere calcolata mediante strumenti frequentisti:Per ottenere LOO-CV adattiamo ai dati un modello di regressione bayesiano:Eseguiamo il campionamento MCMC:Calcoliamo infine la quantità \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\):Si noti la somiglianza tra \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\) e \\(\\widehat{\\mbox{elpd}}_{AIC}\\). conclusione, possiamo dunque dire che \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\) è la risposta bayesiana allo stesso problema che trova una soluzione frequentista nella statistica \\(\\widehat{\\mbox{elpd}}_{AIC}\\).","code":"\nlibrary(\"foreign\")\ndf <- read.dta(here(\"data\", \"kidiq.dta\"))\ndf$y <- scale(df$kid_score)[, 1]\ndf$x1 <- scale(df$mom_iq)[, 1]\nhead(df)\n#>   kid_score mom_hs    mom_iq mom_work mom_age           y         x1\n#> 1        65      1 121.11753        4      27 -1.06793237  1.4078352\n#> 2        98      1  89.36188        4      25  0.54886757 -0.7092079\n#> 3        85      1 115.44316        4      27 -0.08805362  1.0295443\n#> 4        83      1  99.44964        3      25 -0.18604150 -0.0366907\n#> 5       115      1  92.74571        4      27  1.38176451 -0.4836193\n#> 6        98      0 107.90184        1      18  0.54886757  0.5267892\nm1_freq <- lm(y ~ x1, data = df)\nAIC(m1_freq) / -2\n#> [1] -569.6384\nmodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] x1;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta1;\n  real<lower=0> sigma;\n}\ntransformed parameters {\n  vector[N] mu;\n  for (n in 1:N){\n    mu[n] = alpha + beta1*x1[n];\n  }\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n  sigma ~ cauchy(0, 1);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1:N){\n    y_rep[n] = normal_rng(mu[n], sigma);\n    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/simplereg.stan\")\ndata1_list <- list(\n  N = length(df$kid_score),\n  y = df$y,\n  x1 = df$x1\n)\nfile1 <- file.path(\"code\", \"simplereg.stan\")\nmod1 <- cmdstan_model(file1)\nfit1 <- mod1$sample(\n  data = data1_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  cores = 4L,\n  refresh = 0,\n  thin = 1\n)\nloo1_result <- fit1$loo(cores = 4)\nprint(loo1_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -568.6 14.5\n#> p_loo         1.9  0.2\n#> looic      1137.2 28.9\n#> ------\n#> Monte Carlo SE of elpd_loo is 0.0.\n#> \n#> All Pareto k estimates are good (k < 0.5).\n#> See help('pareto-k-diagnostic') for details."},{"path":"ch-info-crit.html","id":"confronto-tra-modelli-mediante-loo-cv","chapter":"Capitolo 34 Criterio di informazione e convalida incrociata","heading":"34.4 Confronto tra modelli mediante LOO-CV","text":"Come menzionato precedenza, l’obiettivo centrale della misurazione dell’accuratezza predittiva è il confronto di modelli. Una volta capito come calcolare LOO-CV con un condice scritto linguaggio Stan, svolgeremo ora un confronto di modelli.37Considereremo qui un confronto di modelli di regressione. Il modello di regressione discusso nel Paragrafo precedente prevede il QI dei bambini dal QI delle madri. Aggiungiamo tale modello un secondo predittore che corrisponde ’età della madre. L’aggiunta di tale predittore migliori l’accuratezza predittiva del modello?Consideriamo infine un terzo modello che utilizza come predittori, oltre al QI della madre, una variabile dicotomica (codificata 0 o 1) che distingue madri che hanno completato le scuole superiori da quelle che non le hanno completate. Nuovamente, la domanda è se l’aggiunta di tale predittore migliori la capacità predittiva del modello.Per eseguire un confronto tra modelli termini della loro capacità predittiva esaminiamo la differenza di LOO-CV tra coppie di modelli. Le seguenti istruzioni \\(\\mathsf{R}\\) producono la quantità elpd_diff, ovvero la differenza tra stime della \\(elpd\\) fornite da due modelli. Il primo argomento della funzione loo_compare() specifica il modello che viene usato come confronto. Nella prima riga dell’output, il valore elpd_diff è 0 (cioè, \\(x − x = 0\\)). Nelle righe successive sono riportate le differenze rispetto al modello di confronto (questo caso, il modello 1). La colonna se_diff riporta l’errore standard di tali differenze.L’incertezza della stima dell’accuratezza --sample si distribuisce maniera approssimativamente normale con media uguale al valore riportato dal software e deviazione standard uguale ciò che è indicato nell’output come errore standard. Quando il campione è piccolo, questa approssimazione produce una forte sottostima dell’incertezza, ma fornisce comunque una stima migliore di AIC, DIC e WAIC.Per interpretare l’output, usiamo il criterio suggerito da Gelman et al. (1995): consideriamo “credibile” una differenza se elpd_diff è almeno due volte maggiore di se_diff. Nel caso presente, dunque, il confronto tra il modello 2 e il modello 1 indica che la quantità elpd_diff è molto piccola rispetto al suo errore standard.\nQuesto accade se un predittore è associato modo trascurabile con la variabile dipendente. dati presenti, dunque, non offrono alcuna evidenza che aggiungere dell’età della madre come predittore migliori la capacità predittiva del modello. Nel confronto tra modello 3 e modello 1, invece, la quantità elpd_diff è maggiore di due volte il valore dell’errore standard. Questo suggerisce un incremento della capacità predittiva del modello quiando il livello di istruzione della madre viene incluso tra predittori.È anche possibile calcolare l’intervallo di credibilità per elpd_diff:","code":"\nmodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] x1;\n  vector[N] x2;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta1;\n  real beta2;\n  real<lower=0> sigma;\n}\ntransformed parameters {\n  vector[N] mu;\n  for (n in 1:N){\n    mu[n] = alpha + beta1*x1[n] + beta2*x2[n];\n  }\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n  beta2 ~ normal(0, 1);\n  sigma ~ cauchy(0, 1);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1:N){\n    y_rep[n] = normal_rng(mu[n], sigma);\n    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x2[n] * beta2, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/mreg2.stan\")\ndf$x2 <- scale(df$mom_age)[, 1]\ndata2_list <- list(\n  N = length(df$kid_score),\n  y = df$y,\n  x1 = df$x1,\n  x2 = df$x2\n)\nfile2 <- file.path(\"code\", \"mreg2.stan\")\n# compile model\nmod2 <- cmdstan_model(file2)\n# Running MCMC\nfit2 <- mod2$sample(\n  data = data2_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  cores = 4L,\n  refresh = 0,\n  thin = 1\n)\nfit2$summary(c(\"alpha\", \"beta1\", \"beta2\", \"sigma\"))\n#> # A tibble: 4 × 10\n#>   variable      mean    median     sd    mad      q5    q95  rhat ess_bulk\n#>   <chr>        <dbl>     <dbl>  <dbl>  <dbl>   <dbl>  <dbl> <dbl>    <dbl>\n#> 1 alpha    -0.000255 -0.000162 0.0431 0.0427 -0.0714 0.0705  1.00   19419.\n#> 2 beta1     0.442     0.442    0.0427 0.0427  0.372  0.512   1.00   17850.\n#> 3 beta2     0.0515    0.0514   0.0427 0.0428 -0.0179 0.121   1.00   16802.\n#> 4 sigma     0.896     0.895    0.0305 0.0303  0.848  0.948   1.00   19032.\n#> # … with 1 more variable: ess_tail <dbl>\nloo2_result <- fit2$loo(cores = 4)\nprint(loo2_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -568.9 14.5\n#> p_loo         3.0  0.3\n#> looic      1137.8 29.0\n#> ------\n#> Monte Carlo SE of elpd_loo is 0.0.\n#> \n#> All Pareto k estimates are good (k < 0.5).\n#> See help('pareto-k-diagnostic') for details.\nmodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] x1;\n  vector[N] x3;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta1;\n  real beta3;\n  real<lower=0> sigma;\n}\ntransformed parameters {\n  vector[N] mu;\n  for (n in 1:N){\n    mu[n] = alpha + beta1*x1[n] + beta3*x3[n];\n  }\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n  beta3 ~ normal(0, 1);\n  sigma ~ cauchy(0, 1);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1:N){\n    y_rep[n] = normal_rng(mu[n], sigma);\n    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x3[n] * beta3, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/mreg3.stan\")\ndf$x3 <- df$mom_hs\ndata3_list <- list(\n  N = length(df$kid_score),\n  y = df$y,\n  x1 = df$x1,\n  x3 = df$x3\n)\nfile3 <- file.path(\"code\", \"mreg3.stan\")\nmod3 <- cmdstan_model(file3)\nfit3 <- mod3$sample(\n  data = data3_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  cores = 4L,\n  refresh = 0,\n  thin = 1\n)\nfit3$summary(c(\"alpha\", \"beta1\", \"beta3\", \"sigma\"))\n#> # A tibble: 4 × 10\n#>   variable   mean median     sd    mad     q5     q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    -0.225 -0.224 0.0947 0.0945 -0.382 -0.0705  1.00    8433.    9191.\n#> 2 beta1     0.415  0.414 0.0449 0.0450  0.341  0.488   1.00   10941.   10324.\n#> 3 beta3     0.286  0.285 0.108  0.108   0.111  0.465   1.00    8452.    8606.\n#> 4 sigma     0.890  0.889 0.0302 0.0302  0.842  0.941   1.00   10828.    9623.\nloo3_result <- fit3$loo(cores = 4)\nprint(loo3_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -584.2 16.4\n#> p_loo         7.5  0.6\n#> looic      1168.3 32.8\n#> ------\n#> Monte Carlo SE of elpd_loo is 0.0.\n#> \n#> All Pareto k estimates are good (k < 0.5).\n#> See help('pareto-k-diagnostic') for details.\nw <- loo_compare(loo1_result, loo2_result, loo3_result)\nprint(w)\n#>        elpd_diff se_diff\n#> model1   0.0       0.0  \n#> model2  -0.3       1.3  \n#> model3 -15.6       6.0\n15.5 + c(-1, 1) * qnorm(.95, 0, 1) * 6.0\n#> [1]  5.630878 25.369122"},{"path":"ch-info-crit.html","id":"outlier","chapter":"Capitolo 34 Criterio di informazione e convalida incrociata","heading":"34.5 Outlier","text":"Si è soliti pensare che la maggior parte delle osservazioni del campione sia prodotta da un unico meccanismo generatore dei dati, mentre le rimanenti osservazioni sono la realizzazione di un diverso processo stocastico. Le osservazioni che appartengono questo secondo gruppo si chiamano outlier. È dunque necessario identificare gli outlier e limitare la loro influenza sull’inferenza.38Poniamoci ora il problema di identificare gli outlier con la tecnica PSIS-LOO-CV. Quando PSIS-LOO-CV viene calcolato con il pacchetto loo, l’output riporta il parametro di forma della distribuzione di Pareto (valore k). Tale valore può essere utilizzato per identificare gli outlier. Infatti, il valore k valuta, per ciascun punto del campione, l’approssimazione usata da PSIS-LOO-CV. Se \\(k < 0.5\\), pesi di importanza vengono stimati modo accurato; se il valore \\(k\\) di Pareto di un punto è \\(> 0.7\\), pesi di importanza possono essere inaccurati. Le osservazioni con \\(k > 0.7\\) sono dunque osservazioni outlier.Per fare un esempio concreto, introduciamo nel campione dell’esempio precedente una singola osservazione outlier.Sistemiamo dati nel formato appropriato per Stan:Adattiamo nuovamente il modello 1 ad un campione di dati che contiene un outlier.Una tabella diagnostica che riassume le stime dei parametri di forma della distribuzione di Pareto si ottiene nel modo seguente:Un grafico che riporta le stime dei parametri di forma della distribuzione di Pareto per ciascuna osservazione è dato da:Il valore k stimato da PSIS-LOO-CV mette chiaramente luce il fatto che il valore introdotto nel campione è un outlier. L’indice dell’osservazione outlier è identificato con:","code":"\ndf1 <- df\ndim(df1)\n#> [1] 434   9\ndf1$x1[434] <- 10\ndf1$y[434] <- 10\ndata1a_list <- list(\n  N = length(df1$kid_score),\n  y = df1$y,\n  x1 = df1$x1\n)\nfit1a <- mod1$sample(\n  data = data1a_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  cores = 4L,\n  refresh = 0,\n  thin = 1\n)\nloo1a_result <- fit1a$loo(cores = 4)\nprint(loo1a_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -586.2 19.9\n#> p_loo         6.6  5.0\n#> looic      1172.5 39.8\n#> ------\n#> Monte Carlo SE of elpd_loo is NA.\n#> \n#> Pareto k diagnostic values:\n#>                          Count Pct.    Min. n_eff\n#> (-Inf, 0.5]   (good)     433   99.8%   10708     \n#>  (0.5, 0.7]   (ok)         0    0.0%   <NA>      \n#>    (0.7, 1]   (bad)        1    0.2%   75        \n#>    (1, Inf)   (very bad)   0    0.0%   <NA>      \n#> See help('pareto-k-diagnostic') for details.\nplot(loo1a_result)\npareto_k_ids(loo1a_result, threshold = 0.7)\n#> [1] 434"},{"path":"ch-info-crit.html","id":"regolarizzazione","chapter":"Capitolo 34 Criterio di informazione e convalida incrociata","heading":"34.6 Regolarizzazione","text":"Abbiamo motivato la presente discussione affermando che uno dei problemi più grandi che ricercatori devono afforntare è quello della generalizzabilità dei loro risultati. McElreath (2020) fa notare che un modo per favorire la capacità del modello di generalizzarsi nuovi campioni è quello di fare modo che produca un adattamento peggiore ai dati del campione presente. Il problema del sovra-adattamento (e quindi di una bassa generalizzabilità) dipende dal fatto che tutte le regolarità presenti nei dati del campione (e dunque, anche quelle che costituiscono un aspetto idiosincratico del campione presente) “vengono egualmente prese sul serio” da un modello che utilizza prior uniformi per parametri. tali circostanze, qualsiasi valore dei parametri viene considerato plausibile. Un modo per evitare un tale modo di procedere, che sicuramente è inadeguato, è quello di utilizzare dei prior che McElreath (2020) chiama “scettici”. priori “scettici” più comuni sono quelli che hanno una funzione di regolarizzazione. Tali prior, se calibrati correttamente, riducono il sovra-adattamento pur consentendo al modello di rappresentare le regolarità che emergono dai dati del campione. Se il prior è “troppo scettico”, tuttavia, le regolarità dei dati campionari non vengono rappresentate dal modello; di conseguenza, ciò produce un sotto-adattamento. Il problema è quello di trovare un equilibrio tra gli opposti pericoli del sovra-adattamento e del sotto-adattamento. La buona notizia è che anche un prior “moderatamente scettico” è grado di fornire un grande aiuto al modello, e questo è tutto quello che possiamo sperare di ottenere dato che, generale, non ci sono né modelli ottimali né distribuzioni priori ottimali (ovvero, modelli e distribuzioni priori che non possono essere migliorati).Un esempio di una distribuzione priori di regolarizzazione può essere fornito facendo riferimento al modello lineare, per esempio. Se standardizziamo dati, un prior \\(\\beta \\sim \\mathcal{N}(0, 1)\\) per il parametro che codifica la pendenza della retta di regressione ci dice che, prima di osservare dati, il modello “è molto scettico” rispetto ai valori possibili di \\(\\beta\\) esterni ’intervallo \\([-2, 2]\\) deviazioni standard. altri termini, ritiene che sia molto improbabile che un cambiamento di 1 deviazione standard nella \\(x\\) sia associato ad un cambiamento medio superiore 2 unità di deviazione standard nella \\(y\\).Ma potremmo anche usare una distribuzione priori gaussiana con parametro \\(\\sigma\\) uguale 0.5 oppure 0.2. Quale prior usare dipende dal modello e dai dati – non c’è una raccomandazione che risulta sempre valida. L’effetto maggiore dei prior “molto scettici” si manifesta nel caso di modelli complessi e nel caso di piccole numerosità campionarie – ovvero, proprio nei casi cui il rischio del sovra-adattamento è più grande. Se invece il campione è sufficientemente grande e il modello non è eccessivamente complesso, prior, quali essi siano, hanno invece un effetto trascurabile sulla stima della distribuzione posteriori.","code":""},{"path":"ch-info-crit.html","id":"commenti-e-considerazioni-finali-27","chapter":"Capitolo 34 Criterio di informazione e convalida incrociata","heading":"Commenti e considerazioni finali","text":"questo Capitolo, utilizzando Stan insieme al pacchetto loo, abbiamo imparato ad usare la convalida incrociata K-fold e la convalida incrociata leave-one-. Abbiamo esaminato alcuni esempi nei quali la convalida incrociata ci consente di distinguere tra due modelli. generale, la convalida incrociata si dimostra utile utile quando vengono confrontati modelli piuttosto diversi; quando modelli sono molto simili, invece, risulta spesso difficile distinguerli con le tecniche qui discusse. particolare, risulta spesso difficile ottenere risultati conclusivi dal confronto di modelli tramite la convalida incrociata se l’effetto è molto piccolo e/o se il campione di dati è piccolo. questi casi, alcuni ricercatori ritengono che siano più adatti altri metodi di confronto dei modelli, come ad esempio fattori di Bayes. L’uso dei fattori di Bayes, tuttavia, è controverso, dato che essi dipendono fortemente dalla scelta delle distribuzioni priori. Se possibile è preferibile utilizzare le procedure descritte questa parte della dispensa, con campioni di ampiezza adeguata.","code":""},{"path":"ch-ttest.html","id":"ch-ttest","chapter":"Capitolo 35 Inferenza sulla media","heading":"Capitolo 35 Inferenza sulla media","text":"","code":""},{"path":"ch-ttest.html","id":"la-ripetizione-dellesperimento-casuale","chapter":"Capitolo 35 Inferenza sulla media","heading":"35.1 La ripetizione dell’esperimento casuale","text":"L’approccio frequentista si basa sulla nozione di probabilità intesa come frequenza relativa di un grande numero di ripetizioni dell’esperimento casuale. Iniziamo definire una statistica test, ovvero una qualche statistica che si può calcolare con dati campionari. Per facilitare la comprensione, consideriamo un disegno sperimentale pre-test/post-test.Supponiamo di esaminare un campione casuale di pazienti OCD e di sottoporli ad un intervento psicologico volto alla riduzione dei sintomi. Usiamo un test per la valutazione del disturbo ossessivo-compulsivo prima del trattamento e dopo il trattamento. Ad esempio, possiamo usare l’Obsessive-Compulsive Inventory (OCI; Sica et al., 2009), ovvero un questionario self-report costituito da 42 item valutati su scala Likert 5 punti (da 0=“per nulla” 4=“moltissimo”). Valori alti del punteggio totale indicano una situazione di particolare difficoltà e una presenza clinicamente significativa di ossessioni e/o compulsioni.Se il trattamento è efficace, ci possiamo aspettare una riduzione del punteggio totale OCI nel post-test rispetto al pre-test. Una differenza negativa post-test meno pre-test fornisce dunque evidenze dell’efficacia dell’intervento. Invece, una differenza pari zero indicherà nessun effetto del trattamento. Infine, una differenza (post-test meno pre-test) positiva indicherà che il trattamento ottiene il risultato opposto quello previsto. La differenza del punteggio totale OCI nel post-test rispetto al pre-test costituirà dunque, nel caso presente, la nostra statistica test.L’approccio frequentista ragiona nel modo seguente. Sappiamo che il ricercatore trova un qualche valore della statistica test un particolare campione. Ma cosa succede se esaminiamo un’altro campione? Sicuramente troveremo risultati diversi. Il ricercatore frequentista si pone dunque la seguente domanda: è possibile descrivere tutti risultati possibili che si potrebbero ottenere se la statistica test venisse calcolata su infiniti campioni casuali estratti tutti dalla medesima popolazione virtuale?Questa sembra una domanda cui è impossibile rispondere. Ma realtà è molto facile rispondere questa domanda, se usiamo la teoria delle probabilità.","code":""},{"path":"ch-ttest.html","id":"la-distribuzione-campionaria-della-media","chapter":"Capitolo 35 Inferenza sulla media","heading":"35.2 La distribuzione campionaria della media","text":"L’insieme di valori che cerchiamo va sotto il nome di distribuzione (di una statistica) campionaria. Nel caso presente, la media di un campione. Il fatto che tale media sia stata calcolata come la differenza tra punteggi post-test e pre-test per lo stesso soggetto non cambia nulla: ciascun soggetto viene assegnato un unico punteggio (la differenza post-test/pre-test); quello che ci chiediamo è come varia la media di questi punteggi su campioni diversi.Se nostri dati provengono da un campione casuale, allora possiamo dire che ciascuna osservazione (differenza post-test/pre-test per un determinato paziente) è la realizzazione di una variabile casuale e il campione è costituito da \\(n\\) realizzazioni di variabili casuali indipendenti e identicamente distribuite.Dato che il valore di ciascun paziente è dato dalla differenza tra due valori, ciascuno dei quali calcolato come la somma di 42 valori, possiamo usare il Teorema del limite centrale e assumere che la nostra statistica test, che chiameremo \\(X\\), segue la legge Normale. Assumiamo inoltre che la deviazione standard \\(\\sigma\\) sia la stessa per tutti pazienti. Dunque possiamo dire che dati campionari possono essere concepiti coma la sequenza di \\(n\\) variabili casuali iid, ciascuna distribuita come \\(\\mathcal{N}(\\mu, \\sigma)\\). parametri di tale distribuzione Normale sono ovviamente incogniti.La statistica target cui siamo interessati è la media del campione. Vogliamo sapere, nelle circostanze descritte sopra, come varia la media del campione ’interno dell’universo dei campioni di ampiezza \\(n\\).La statistica test è\\[\n\\bar{X} = \\frac{1}{n} \\sum_i X_i.\n\\]Il valore atteso di \\(\\bar{X}\\) è\\[\n\\begin{align}\n\\mathbb{E}(\\bar{X}) &= \\mathbb{E} \\left( \\frac{1}{n} \\sum_i X_i \\right)\\notag\\\\\n&= \\frac{1}{n} \\mathbb{E} \\left( \\sum_i X_i \\right)\\notag\\\\\n&= \\frac{1}{n} \\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n) \\notag\\\\\n&= \\frac{1}{n} n \\mu \\notag\\\\\n&= \\mu\n\\end{align}\n\\]Questo vuol dire che la media della distribuzione campionaria delle medie dei campioni è uguale alla media della popolazione.La varianza di \\(\\bar{X}\\) è\\[\n\\begin{align}\n\\mathbb{V}(\\bar{X}) &= \\mathbb{V} \\left( \\frac{1}{n} \\sum_i X_i \\right)\\notag\\\\\n&= \\frac{1}{n^2} \\mathbb{V} \\left( \\sum_i X_i \\right)\\notag\\\\\n&= \\frac{1}{n^2} \\mathbb{V}(X_1) + \\dots + \\mathbb{V}(X_n) \\notag\\\\\n&= \\frac{1}{n^2} n \\sigma^2 \\notag\\\\\n&= \\frac{\\sigma^2}{n}.\n\\end{align}\n\\]altri termini, la varianza delle medie dei campioni è uguale alla varianza della popolazione divisa per \\(n\\) – ciò significa che la varianza della distribuzione campionaria delle medie dei campioni è sempre più piccola della varianza della popolazione. Se il campione è di ampiezza \\(n = 1\\), la varianza della distribuzione campionaria delle medie dei campioni è uguale alla varianza della popolazione (estrarre infinite volte un’osservazione da una popolazione e “calcolare la media” di quell’unica osservazione non fa altro che riprodurre la popolazione di partenza); se il campione è di ampiezza uguale quella della popolazione, \\(n = \\infty\\) e la varianza è nulla: la media del “campione” è uguale alla media della popolazione (essendo il campione uguale alla popolazione). Tanto maggiore è l’ampiezza del campione, tanto di meno varierà la media del campione tra campioni diversi e, dunque, tanto più piccola sarà la varianza della media dei campioni.Resta ancora una domanda cui rispondere: qual è la legge distributiva della media dei campioni? Anche tale domanda si può rispondere usando il Teorema del limite centrale che dice, appunto, che per campioni estratti da una popolazione Normale, la distribuzione delle medie seguirà esattamente la legge Normale.Abbiamo dunque la nostra risposta: se la popolazione di partenza è Normale, la distribuzione delle medie dei campioni di ampiezza \\(n\\) sarà una Normale di parametri media = \\(\\mu\\) e varianza = \\(\\frac{\\sigma^2}{n}\\):\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]","code":""},{"path":"ch-ttest.html","id":"inferenza-frequentista","chapter":"Capitolo 35 Inferenza sulla media","heading":"35.3 Inferenza frequentista","text":"Il risultato precedente specifica completamente la distribuzione campionaria delle medie dei campioni. Ma, ovviamente, parametri \\(\\mu\\) e \\(\\sigma\\) sono incogniti. Il ragionamento frequentista, dunque, continua nel modo seguente. Se conoscessimo \\(\\sigma\\), l’unica incognita sarebbe \\(\\mu\\), e da lì è facile procedere. Per ora, dunque, assumiamo che \\(\\sigma\\) sia conosciuta – vedremo poi come affrontare il problema che realtà \\(\\sigma\\) è incognita.Se \\(\\sigma\\) è conosciuta l’unico parametro sconosciuto è \\(\\mu\\). Per fare inferenza su \\(\\mu\\), l’approccio frequentista fornisce al ricercatore due strumenti:il test dell’ipotesi nulla,la stima dell’intervallo di fiducia.","code":""},{"path":"ch-ttest.html","id":"il-test-dellipotesi-nulla","chapter":"Capitolo 35 Inferenza sulla media","heading":"35.3.1 Il test dell’ipotesi nulla","text":"Iniziamo con il test dell’ipotesi nulla. Nell’esempio che stiamo discutendo, quello sull’efficacia dell’intervento per la riduzione dei sintomi OCD, la statistica test è la differenza post-pre. Se tale statistica test assumesse il valore di 0 nella popolazione questo significherebbe che il trattamento è completamente inefficace. Questa è l’ipotesi nulla. L’approccio frequentista si chiede: se l’ipotesi nulla fosse vera, qual è la probabilità di osservare, per caso, un valore della statistica test uguale quello del campione, o più estremo?Nel porsi questa domanda, l’approccio frequentista gioca fare l’avvocato del diavolo, ovvero si chiede: dobbiamo veramente attribuire la riduzione dei sintomi OCD che abbiamo osservato nel campione ’effetto del trattamento? Oppure una tale riduzione dei sintomi è compatibile con un semplice effetto del caso, ovvero con la variabilità campionaria (certi pazienti sintomi diminuiscono, indipendentemente dal trattamento; altri pazienti, aumentano)?Per fare l’avvocato del diavolo, il ricercatore frequentista usa il risultato che abbiamo illustrato precedenza, ovvero la specificazione della distribuzione campionaria della media dei campioni di ampiezza \\(n\\). Se \\(\\sigma\\) è conosciuto, allora l’unica incognita è \\(\\mu\\). Ma, dal punto di vista dell’avvocato del diavolo, il parametro \\(\\mu\\), realtà, è conosciuto. Infatti, secondo tale punto di vista il trattamento non ha alcun effetto e, dunque, \\(\\mu = 0\\). questi termini, dunque, la distribuzione campionaria della media dei campioni di ampiezza \\(n\\) è completamente specificata.Supponiamo che, per un campione di \\(n = 30\\) pazienti, la differenza post-pre sia uguale -5 punti sulla scala OCI. Supponiamo inoltre di sapere che punteggi OCI sono distribuiti normalmente con una deviazione standard \\(\\sigma = 13.9\\) (ho preso questo valore dall’articolo di Sica et al. (2009)).Dobbiamo dunque calcolare la probabilità di osservare un valore minore o uguale -5 nel caso di una variabile casuale che segue la legge Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = \\frac{13.9}{\\sqrt{30}}\\). Otteniamo il seguente risultato:Questa probabilità viene chiamata dall’approccio frequentista valore-\\(p\\). Nel caso presente ci dice che, se fosse vero che il trattamento non è efficace, allora la probabilità di osservare una differenza dei sintomi di 5 punti o più (sulla scala OCI) sarebbe uguale solo 0.024. altre parole, se fosse vera l’ipotesi nulla (il trattamento non è efficace), per effetto del caso soltanto si osserverebbe una riduzione dei sintomi uguale o maggiore di quella osservata nel campione esaminato solo nel 2.4% dei casi, se venissero esaminati infiniti campioni di ampiezza \\(n = 30\\).Dunque, la situazione è questa. L’avvocato del diavolo ci dice che risultati osservati sono solo frutto del caso (il trattamento non è efficace). La teoria della probabilità ci dice che, se l’avvocato del diavolo ha ragione (il trattamento non è efficace), allora osservare una riduzione dei sintomi uguale o maggiore di quella che abbiamo effettivamente osservato si verifica solo 2.4% degli infiniti campioni di ampiezza \\(n\\) che si possono estrarre dalla popolazione di parametri \\(\\mu = 0\\) e \\(\\sigma = \\frac{13.9}{\\sqrt{30}}\\). Quindi, base al ragionamento dell’avvocato del diavolo (il trattamento non è efficace) noi dovremmo trovare una riduzione dei sintomi pari 0. Oppure poco distante da 0, come semplice effetto del caso. Ma noi abbiamo trovato un valore (-5) che, se l’avvocato del diavolo avesse ragione (il trattamento non è efficace) si dovrebbe osservare solo nel 2.4% di infiniti campioni possibili? tali circostanze, dobbiamo credere ’avvocato del diavolo che ci dice che il trattamento non è efficace?L’approccio frequentista decide nel modo seguente. Se, assumendo che l’avvocato del diavolo abbia ragione (ovvero, se assumento che il trattamento non è efficace), la probabilità di osservare risultati campionari è bassa, allora non crediamo più ’avvocato del diavolo ma accettiamo l’ipotesi complementare. Se rifiutiamo l’ipotesi dell’avvocato del diavolo che il trattamento non è efficace, dobbiamo concludere che il trattamento è efficace.Ma quale soglia dobbiamo usare per rifiutare l’ipotesi dell’avvocato del diavolo (ovvero, l’ipotesi nulla)? Per consuetudine, la soglia da superare è quella del 5%. Risultati che producono un valore-\\(p < 0.05\\) vengono detti statisticamente significativi.Ci sono due tipi di test di ipotesi, quelli unidirezionali (mettiamo tutta la regione di rifiuto dell’ipotesi nulla una coda della distribuzione campionaria della statistica test) e quelli bidirezionali (la regione di rifiuto dell’ipotesi nulla è suddivisa nelle due code).Supponiamo di usare un test bidirezionale (quello che si usa normalmente). Quindi, rifiutiamo l’ipotesi nulla (la proposta dell’avvocato del diavolo) sia quando c’è una grande riduzione dei sintomi, sia quando osserviamo un grande aumento dei sintomi.Quindi, se per la nostra scelta abbiamo deciso di usare un livello di probabilità complessivo, chiamato \\(\\alpha\\), di 0.05, nel caso di un test bidirezionale avremo due regioni di rifiuto dell’ipotesi nulla: l’intervallo da \\(-\\infty\\) fino al quantile che lascia sotto di sé una probabilità pari \\(\\alpha/2\\), e l’intervallo dal quantile che lascia sopra di sé una probabilità pari \\(\\alpha/2\\) \\(+\\infty\\).Per rifiutare l’ipotesi dell’avvocato del diavolo dovremo dunque osservare una riduzione dei sintomi che, nella distribuzione campionaria costruita assumendo come vera l’ipotesi nulla, lascia sotto di sé una probabilità minore di \\(\\alpha/2\\). Un risultato di questo tipo viene detto “statisticamente significativo”.Nel caso presente, essendo il valore-\\(p\\) = 0.0244 < 0.025, il ricercatore frequentista rigetta l’ipotesi nulla di assenza di effetto del trattamento e conclude che il trattamento considerato è efficace per la riduzione dei sintomi OCD.","code":"\npnorm(-5, 0, 13.9 /sqrt(30))\n#> [1] 0.02440629"},{"path":"ch-ttest.html","id":"il-test-t-di-student","chapter":"Capitolo 35 Inferenza sulla media","heading":"35.3.1.1 Il test \\(t\\) di Student","text":"Nella discussione precedente abbiamo assunto \\(\\sigma\\) noto, quanto abbiamo recuperato tale valore da ricerche precedenti. Solitamente, però, si procede un modo ancora più semplice, ovvero si stima \\(\\sigma\\) mediante la deviazione standard del campione (usando \\(n-1\\) al denominatore). tali circostanze, ovvero quando stimiamo \\(\\sigma\\) con \\(s\\), la teoria delle probabilità ci dice che la distribuzione delle medie campionarie non segue più la legge Normale ma segue invece un’altra legge distributiva, ovvero la \\(t\\) di Student, con un numero di gradi di libertà pari \\(\\nu = n-1\\).La probabilità cercata, dunque, diventa la seguente. Dobbiamo trovare la probabilità che una variabile casuale assuma un valore minore o uguale -5 quando tale variabile segue la distribuzione \\(t\\) di Student con \\(30 - 1\\) gradi di libertà. Supponiamo che la deviazione standard del campione sia \\(s = 14.5\\). Dobbiamo trovare il quantile della distribuzione \\(t\\) di Student e l’associata probabilità nella coda inferiore della distribuzione. Il quantile è dato da\\[\nT = \\frac{\\bar{X} - 0}{s/\\sqrt{n}}.\n\\]Per l’esempio presente avremoCalcoliamo la probabilità di osservare un valore minore o uguale -1.89 una distribuzione \\(t\\) di Student con 29 gradi di libertà.questo caso, con un test bidirezionale, il valore-\\(p\\) è maggiore di \\(\\alpha/2\\). Dunque, base alla procedura decisionale scelta, il ricercatore frequentista non può rifiutare il punto di vista dell’avvocato del diavolo. Ovviamente, la discussione presente non prova che l’avvocato del diavolo abbia ragione, ma non ci sono evidenze sufficienti per rigettare l’ipotesi nulla. tali circostanze, cautamente, il ricercatore sospende il giudizio.\\(\\textsf{R}\\), il test che abbiamo descritto sopra, detto test \\(t\\) di Student, si svolte mediante la funzione t.test().","code":"\nT <- (-5 - 0) / (14.5 / sqrt(30))\nT\n#> [1] -1.888698\npt(T, 29)\n#> [1] 0.03448568"},{"path":"ch-ttest.html","id":"lintervallo-di-fiducia","chapter":"Capitolo 35 Inferenza sulla media","heading":"35.3.2 L’Intervallo di fiducia","text":"Il test di ipotesi statistiche porta il ricercatore ad una scelta binaria: o rifiuta l’ipotesi nulla \\(H_0\\) o sospende il giudizio. Tale scelta binaria dipende dal valore \\(\\alpha\\), ovvero dal livello di significatività che viene scelto. Convenzionalmente, \\(\\alpha = 0.05\\) e il test è bidirezionale.Essendo una risposta binaria, il risultato di un test di ipotesi statistiche frequentista non è molto informativo. Infatti, si usa sempre di meno. Maggiori fortuna nella comunità scientifica ha l’altra proposta inferenziale frequentista, ovvero l’intervallo di fiducia. Per proseguire con l’esempio discussione, consideriamo qui il caso dell’intervallo di fiducia per la media di una popolazione Normale di varianza conosciuta.","code":""},{"path":"ch-ttest.html","id":"popolazione-con-varianza-nota","chapter":"Capitolo 35 Inferenza sulla media","heading":"35.3.2.1 Popolazione con varianza nota","text":"Sia \\(X_1,\\dots, X_n\\) un campione casuale estratto da una popolazione di legge normale di media \\(\\mu\\) e varianza \\(\\sigma^2\\). Abbiamo visto precedenza come la media campionaria, essendo una combinazione lineare di \\(n\\) variabili casuali normali, è anch’essa una variabile normale: \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/n)\\).La \\[\\begin{equation}\n\\frac{\\bar{X} - \\mu}{\\sigma} \\sqrt{n}\\sim \\mathcal{N}(0, 1)\\notag\n\\end{equation}\\]segue dunque una distribuzione normale con media zero e deviazione standard unitaria. Fissato il livello fiduciario \\(\\gamma = 1 - \\alpha\\) (tipicamente 0.95, corrispondente \\(\\alpha = 0.05\\)), indichiamo con \\(z\\) il quantile di ordine \\(1 - \\alpha/2\\) della distribuzione normale standard modo che\\[\\begin{equation}\nP(-z \\leq Z \\leq z) = 1 - \\alpha.\\notag\n\\end{equation}\\]Otteniamo dunque\\[\\begin{equation}\nP\\bigg(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma} \\sqrt{n} \\leq z\\bigg) = 1 - \\alpha.\\notag\n\\end{equation}\\]Applicando qualche manipolazione algebrica, la diseguaglianza precedente si può scrivere nel modo seguente:\\[\\begin{align}\nP\\bigg(-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq  \\bar{X} - \\mu \\leq z \\frac{\\sigma}{\\sqrt{n}}\\bigg) &= 1 - \\alpha\\notag\\\\\nP\\bigg(-\\bar{X}-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq -\\mu \\leq -\\bar{X} + z \\frac{\\sigma}{\\sqrt{n}}\\bigg) &= 1 - \\alpha\\notag\\\\\nP\\bigg(\\bar{X}+z \\frac{\\sigma}{\\sqrt{n}} \\geq \\mu \\geq  \\bar{X} -z \\frac{\\sigma}{\\sqrt{n}}\\bigg) &= 1 - \\alpha.\\notag\n\\end{align}\\]Se definiamo\\[\\begin{equation}\n\\hat{} \\triangleq \\bar{X}-z \\frac{\\sigma}{\\sqrt{n}},\n\\quad \\hat{b} \\triangleq \\bar{X} +z \\frac{\\sigma}{\\sqrt{n}},\n\\label{eq:lim_int_fid_norm}\n\\end{equation}\\]avremo che\\[\\begin{equation}\nP(\\hat{} \\leq \\mu \\leq \\hat{b}) = 1 - \\alpha.\\notag\n\\end{equation}\\]L’intervallo \\([\\hat{}, \\hat{b}]\\) è detto intervallo di fiducia per una stima della media della popolazione al livello fiduciario \\(\\gamma = 1 -\\alpha\\).Per l’esempio discussione, assumendo \\(\\sigma = 13.9\\), abbiamo","code":"\n-5 + c(-1, 1) * qnorm(0.025, 0, 1) * 13.9 /sqrt(30)\n#> [1] -0.02604028 -9.97395972"},{"path":"ch-ttest.html","id":"popolazione-con-varianza-incognita","chapter":"Capitolo 35 Inferenza sulla media","heading":"35.3.2.2 Popolazione con varianza incognita","text":"ogni applicazione concreta, lo sperimentatore estrae un solo campione \\(x_1, \\dots, x_n\\) dalla popolazione e la varianza \\(\\sigma^2\\), aggiunta alla media \\(\\mu\\) da determinare, è sconosciuta.\ntal caso, per effettuare una stima intervallare di \\(\\mu\\) ci si basa sulla densità \\(t\\) di Student. tali circostanze, si può dimostrare che\\[\\begin{equation}\nP\\bigg(-t^{\\ast} \\leq \\frac{\\bar{X} - \\mu}{s} \\sqrt{n} \\leq t^{\\ast}\\bigg) = 1 -\\alpha,\n\\end{equation}\\]dove \\(s\\) è lo stimatore non distorto di \\(\\sigma\\) e \\(t^{\\ast} \\triangleq t_{n-1,1-\\alpha/2}\\) è il quantile di ordine \\(1 - \\alpha/2\\) della distribuzione \\(t_{n-1}\\). Pertanto, il limite inferiore \\(\\hat{}\\) e il limite superiore \\(\\hat{b}\\) dell’intervallo di fiducia diventano, rispettivamente, uguali :\\[\\begin{equation}\n\\hat{} \\triangleq \\bar{X} -t^{\\ast} \\frac{s}{\\sqrt{n}},\n\\quad \\hat{b} \\triangleq \\bar{X} + t^{\\ast} \\frac{s}{\\sqrt{n}}.\n\\label{eq:lim_int_fid_t}\n\\end{equation}\\]Si noti che, nel caso di una popolazione con varianza incognita, limiti fiduciari si ottengono dall’equazione ottenuta nel paragrafo precedente sostituendo \\(\\sigma\\), ora incognito, con \\(s\\) (per una ampiezza campionaria \\(n\\) qualsiasi), e il coefficiente \\(z\\) con \\(t_{n-1,1-\\alpha/2}\\).Per l’esempio discussione, assumendo \\(s = 14.5\\), abbiamo","code":"\n-5 + c(-1, 1) * qt(0.025, 29) * 14.5 /sqrt(30)\n#> [1]   0.414389 -10.414389"},{"path":"ch-ttest.html","id":"livello-di-copertura","chapter":"Capitolo 35 Inferenza sulla media","heading":"35.3.2.3 Livello di copertura","text":"Il valore \\(1-\\alpha\\) indica il livello di copertura fornito dall’intervallo di fiducia. Il termine “probabilità di copertura” si riferisce alla probabilità che la procedura per la costruzione degli intervalli di fiducia produca un intervallo che contiene (o copre) il valore reale del parametro di interesse.\nEsiste sempre una probabilità pari ad \\(\\alpha\\) che dati campionari producano un intervallo che non contiene il valore reale del parametro di interesse.Ricordiamo che l’approccio frequentista interpreta la probabilità di un evento come la proporzione di volte che si verifica un tale evento osservando lungo termine delle ripetizioni indipendenti di un esperimento casuale.\nNel caso presente, l’evento questione è la risposta alla domanda “l’intervallo di fiducia contiene il valore del parametro?” mentre l’esperimento casuale corrisponde al calcolo dell’intervallo di fiducia della media di una popolazione un campione casuale di ampiezza \\(n\\).La seguente simulazione chiarisce l’interpretazione frequentista della nozione di “livello di copertura”.Consideriamo il caso di una popolazione normale con varianza incognita.\nUtilizziamo come parametri quelli della distribuzione dell’altezza: è infatti risaputo che l’altezza degli individui segue la distribuzione normale.\nL’altezza media di un italiano adulto maschio è di \\(175\\) cm, con una varianza di \\(49\\) cm\\(^2\\).\nDefiniamo dunque parametri della simulazione, nella quale prevediamo 100 ripetizioni dell’esperimento casuale che corrisponde nell’estrazione di un campione di ampiezza \\(n = 20\\) dalla popolazione \\(\\mathcal{N}(175, 7)\\).Per ciascun campione casuale calcoliamo l’intervallo di fiducia del 95% tramite la funzione e salviamo il limite inferiore e il limite superiore di ciascun intervallo nella matrice .Creiamo poi un data.frame cui aggiungiamo una colonna che riporta valori delle medie campionarie.Utilizzando gplot(() creiamo la seguente figura.La figura mostra che alcuni intervalli di fiducia del 95% contengono il valore del parametro, altri non lo contengono.\nSe ripetiamo la simulazione 10,000 volte troviamo un livello di copertura (ovvero, una proporzione di intervalli di fiducia del 95% che contengono il parametro) pari 0.9468. Questo valore è molto prossimo al livello nominale \\(1 - \\alpha = 0.95\\).","code":"\nset.seed(1235)\nnrep <- 100\nsampling_distribution <- matrix(NA, nrow = nrep, ncol = 2)\npoint_estimate <- rep(NA, nrep)\nsample_size <- 20\nmu <- 175\nsigma <- 7\nfor (i in 1:nrep) {\n  y <- rnorm(sample_size, mu, sigma)\n  temp <- t.test(y, conf.level = 0.95)\n  sampling_distribution[i, ] <- temp$conf.int\n  point_estimate[i] <- temp$estimate\n}\ncolnames(sampling_distribution) <- c(\"lcl\", \"ucl\")\nsampling_distribution <- \n  as.data.frame(sampling_distribution)\nsampling_distribution$mean <- as.numeric(point_estimate)\nsampling_distribution$replicate <- 1:nrep\nsampling_distribution$captured <- factor(ifelse(\n  sampling_distribution$lcl <= mu & sampling_distribution$ucl >= mu, 1, 0\n))\nlevels(sampling_distribution$captured) <- c('No', 'Si')\np <- ggplot(sampling_distribution) +\n  geom_point(\n    aes(\n      x = point_estimate, y = replicate, color = captured)\n    ) +\n  geom_segment(aes(\n    y = replicate, yend = replicate, x = lcl, xend = ucl,\n    color = captured\n  )) +\n  geom_vline(\n    xintercept = 175, linetype = 2, color = \"white\"\n  ) +\n  labs(\n    x = \"Stima puntuale\",\n    y = \"Campioni simulati\"\n  ) +\n  guides(color=guide_legend(\"Parametro contenuto nell'intervallo\")) \np + theme(legend.position = \"bottom\")"},{"path":"ch-ttest.html","id":"interpretazione-dellintervallo-di-fiducia","chapter":"Capitolo 35 Inferenza sulla media","heading":"35.3.2.4 Interpretazione dell’intervallo di fiducia","text":"La cosa più difficile proposito degli intervalli di fiducia è capire cosa significano. Ogni volta che gli studenti e ricercatori incontrano gli intervalli di fiducia, il primo istinto è quasi sempre quello di interpretarli dicendo che “c’è una probabilità del 95% che la vera media della popolazione si trovi ’interno dell’intervallo di fiducia”. Questa è un’interpretazione semplice e cattura l’idea del senso comune secondo la quale una probabilità di 0.95 significa “sono sicuro al 95%”. Sfortunatamente, l’interpretazione precedente è del tutto sbagliata. La precedente interpretazione si basa sulla convinzione `soggettiva’ di quale potrebbe essere il valore della media della popolazione. Dico che sono fiducioso al 95% perché quella è la mia opinione.\nNella vita di tutti giorni va benissimo, ma parlare di opinioni soggettive e di fiducia è un’idea bayesiana. Tuttavia, gli intervalli di fiducia sono una procedura statistica di stampo frequentista, non bayesiano. Se usiamo degli strumenti statistici frequentisti non possiamo attribuire loro un’interpretazione bayesiana.\nSe usiamo dei metodi frequentisti, dobbiamo usare delle interpretazioni frequentiste—anche perché gli intervalli di fiducia frequentisti e gli intervalli di credibilità bayesiani sono numericamente diversi!Se l’interpretazione presentata sopra non è corretta, qual è l’interpretazione giusta? Ricordaci quello che abbiamo detto sulla probabilità frequentista: l’unico modo cui siamo autorizzati fare affermazioni relative alla probabilità degli eventi è di riferirci ad una sequenza di ripetizioni dell’esperimento casuale e di contare la frequenza con cui si è verificato un qualche evento. Dunque, l’interpretazione frequentista dell’intervallo di fiducia deve avere che fare con la ripetizione di un esperimento casuale. Nello specifico, per l’intervallo di fiducia al 95% possiamo dire quanto segue: “se ripetessimo molte volte l’esperimento casuale del campionamento e se, per ciascuna ripetizione dell’esperimento, calcolassimo un intervallo di fiducia del 95%, allora il 95% degli intervalli così calcolati conterrebbe la vera media della popolazione”. Più generale, se si estraggono molteplici campioni indipendenti dalla stessa popolazione e si determinano relativi intervalli di fiducia seguendo la procedura sopra illustrata, il \\(100 (1-\\alpha)\\)% di tali intervalli conterrà il vero valore del parametro incognito.Questa idea è illustrata nella figura precedente che mostra 100 intervalli di fiducia costruiti per stabilire l’altezza media di un italiano adulto maschio sulla base di campioni casuali di ampiezza \\(n = 30\\).\nAlcuni di questi intervalli di fiducia contengono il valore del parametro, altri non lo contengono.\nSe la simulazione venisse ripetuta infinite volte si scoprirebbe che esattamente il 95% degli intervalli così calcolati effettivamente contiene il valore del parametro (e il 5% non lo contiene), dato che, per costruire gli intervalli di fiducia abbiamo usato \\(\\alpha = 0.05\\).","code":""},{"path":"ch-ttest.html","id":"commenti-e-considerazioni-finali-28","chapter":"Capitolo 35 Inferenza sulla media","heading":"Commenti e considerazioni finali","text":"È risaputo che ricercatori (non solo gli studenti!) spesso attribuiscono agli intervalli di fiducia un’interpretazione errata.\nNon poche volte nelle riviste specialistiche si leggono affermazioni del tipo: “la probabilità che la media della popolazione \\(\\mu\\) sia contenuta nell’intervallo \\([\\hat{}, \\hat{b}]\\) è 0.95”, mentre realtà si dovrebbe scrivere: “la procedura tramite la quale l’intervallo \\([\\hat{}, \\hat{b}]\\) è stato calcolato include \\(\\mu\\) nel 95% dei casi”.La differenza fondamentale è che le affermazioni di tipo bayesiano sono delle affermazioni probabilistiche sul valore dei parametri (qui, la media della popolazione (cioè, descrivono nostra incertezza relativamente al valore di un parametro incognito). Tuttavia, affermazioni di questo tipo non sono consentite nell’interpretazione frequentista della probabilità. Nell’interpretazione frequentista, la media della popolazione è fissa e nessuna interpretazione `probabilistica’ può essere fatta sul valore di un rtale parametro (o di alcun altro parametro).Gli estremi dell’intervallo di fiducia, invece, sono delle quantità aleatorie che dipendono da un esperimento casuale: ogni volta che osserviamo un nuovo campione casuale, il limite inferiore e il limite superiore dell’intervallo di fiducia assumeranno valori diversi.\nPertanto è sensato pensare che la procedura di costruzione dell’intervallo di fiducia possa essere ripetuta. È riferimento tali ripetizioni che l’approccio frequentista assegna una probabilità agli intervalli di fiducia: la probabilità è la frequenza relativa (queste infinite ipotetiche ripetizioni) che un certo evento si verifichi (dove l’evento questione è il fatto che l’intervallo include il valore del parametro).\nPertanto, dal punto di vista frequentista, è lecito parlare della probabilità che l’intervallo di fiducia (una variabile aleatoria) contenga il parametro; non è invece lecito dire alcunché sulla probabilità che il parametro (un evento non ripetibile) assuma un certo valore (il valore del parametro è fisso: non può essere descritto da una probabilità).Questa non è solo una differenza `semantica’.\nCome ho accennato sopra, le procedure di calcolo per gli intervalli di fiducia frequentisti sono diverse dalle procedure di calcolo per gli intervalli di credibilità bayesiani.\nmaniera corrispondente, nei due casi anche le interpretazioni che assegnamo agli intervalli sono diverse.\nUn altro modo per descrivere questa situazione è quello di dire che ciò che vorremmo conoscere è \\(p(\\theta \\mid y)\\), mentre realtà quello che l’approccio frequentista ci fornisce è \\(p(y \\mid \\theta)\\).\nSolo se vengono utilizzati metodi della statistica bayesiana è possibile costruire un “intervallo di credibilità” che corrisponde \\(p(\\theta \\mid y)\\).","code":""},{"path":"la-crisi-della-replicabilità-dei-risultati-della-ricerca.html","id":"la-crisi-della-replicabilità-dei-risultati-della-ricerca","chapter":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","heading":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","text":"Cito da WikipediaLa crisi della replicazione (chiamata anche crisi della replicabilità e crisi della riproducibilità) è una crisi metodologica per cui è stato riscontrato che molti studi scientifici sono difficili o impossibili da replicare o riprodurre. La crisi della replicazione colpisce più gravemente le scienze sociali e la medicina, mentre dati delle rilevazioni indicano fortemente che anche tutte le scienze naturali sono probabilmente implicate. La frase è stata coniata nei primi anni 2010 come parte di una crescente consapevolezza del problema. La crisi della replicazione rappresenta un importante corpo di ricerca nel campo delle metascienze.Poiché la riproducibilità dei risultati sperimentali è una parte essenziale del metodo scientifico, l’incapacità di replicare gli studi di altri ha conseguenze potenzialmente gravi per molti campi della scienza cui teorie significative sono fondate su un lavoro sperimentale irriproducibile. La crisi della replicazione è stata ampiamente discussa nei campi della medicina, dove sono stati fatti numerosi sforzi per riesaminare risultati classici, per determinare sia l’attendibilità dei risultati sia, se ritenuto inattendibile, le ragioni del fallimento di replica.Questa “crisi metodologica” riguarda molto da vicino la psicologia. Questa crisi ha molteplici cause. Tra tali cause, particolare importanza (senso negativo) è stata assegnata ad un uso “spensierato” dell’approccio frequentista da parte dei ricercatori. L’obiettivo di questo capitolo è mostrare come l’uso delle procedure di test dell’ipotesi nulla necessariamente conduce, nella pratica corrente, ad una sistematica distorsione dei risultati della ricerca. Ovvero, aumenta dismisura “falsi positivi” e troppo spesso impedisce la replicazione dei risultati degli studi empirici.","code":""},{"path":"la-crisi-della-replicabilità-dei-risultati-della-ricerca.html","id":"che-cosè-un-valore-p","chapter":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","heading":"36.1 Che cos’è un valore-\\(p\\)?","text":"Il valore-\\(p\\) viene spesso riportato da coloro che svolgono l’inferenza statistica mediante l’approccio frequentista. Tuttavia, nonostante questa nozione statistica sia spesso usata, il significato di valore-\\(p\\) è spesso frainteso. Un errore che viene spesso commesso nell’interpretare il valore-\\(p\\) è quello di assegnare ad esso l’interpretazione secondo la quale un valore-\\(p\\), diciamo, pari 0.01, significa che c’è solo una probabilità dell’1% che il risultato osservato sia un falso positivo. È importante evitare falsi positivi, per esempio quando si valuta l’efficacia di un intervento psicologico, perché affermare che un trattamento è efficace quando realtà ciò non è vero (falso positivo) conduce alla successiva applicazione di quel trattamento, con il rischio di danni negli utenti e di discredito della professione. L’interpretazione precedente, però, è sbagliata. Il valore-\\(p\\) non può dirci questo: non può mai essere usato per descrivere il mondo reale. Greenland et al. (2016) esprimono questo punto nel modo seguente:Thus claim null P value probability chance alone produced observed association completely backwards: P value probability computed assuming chance operating alone. absurdity common backwards interpretation might appreciated pondering P value, probability deduced set assumptions (statistical model), can possibly refer probability assumptions.Quello che può fare il valore-\\(p\\) è riassumere dati ottenuti dal ricercatore assumendo vera una specifica ipotesi nulla: il valore-\\(p\\) descrive quello che succederebbe un mondo ipotetico, se l’ipotesi nulla fosse vera. Nello specifico, il ricercatore si chiede: se fosse vera l’ipotesi nulla (ad esempio, se il trattamento non fosse efficace così da non avere nessuna differenza tra il gruppo del trattamento e il gruppo di controllo), quale sarebbe la probabilità di osservare un valore uguale quello della statistica osservata nel campione, o un valore ancora più estremo di tale statistica? altri termini, il valore-\\(p\\) descrive quello che succederebbe un mondo ipotetico, il mondo basato sull’idea che l’ipotesi nulla sia vera e nel quale vengono rispettate tutte le assunzioni del modello statistico. Nulla ci dice, il valore-\\(p\\), della plausibilità delle assunzioni che sono state fatte, né tanto meno sulle proprietà del mondo empirico.Per fare delle inferenze sul mondo empirico è necessario possedere altre informazioni, per esempio, la verosimiglianza dell’effetto considerato. Nuzzo (2014) ci propone il seguente esempio. Ci svegliamo la mattina con il mal di testa e concludiamo che abbiamo un raro tumore al cervello. È possibile che questo sia vero, ma è molto improbabile. Per concludere che abbiamo un tumore sono necessarie evidenze ulteriori, oltre al mal di testa, dato che il mal di testa può essere provocato da tantissime cause diverse dal tumore. Tanto più è inverosimile l’ipotesi del ricercatore (il tumore dell’esempio, ma anche la telepatia, l’omeopatia e l’esistenza degli alieni), tanto maggiore è la probabilità che il risultato osservato sia un falso allarme, indipendentemente da quello che ci dice il valore-\\(p\\). altri termini, è la verosimiglianza di un evento che determina la probabilità di un falso allarme, non il valore-\\(p\\).Nel 2016 l’American Statistical Association ha pubblicato un articolo nel quale Wasserstein Lazar (2016) esprimono la loro preoccupazione relativamente ’uso inappropriato che viene fatto del valore-\\(p\\) nella pratica scientifica. Il punto che abbiamo discusso precedenza è espresso nei termini seguenti:\\(P\\)-values measure probability studied hypothesis true, probability data produced random chance alone. Researchers often wish turn \\(p\\)-value statement truth null hypothesis, probability random chance produced observed data. \\(p\\)-value neither. statement data relation specified hypothetical explanation, statement explanation .","code":""},{"path":"la-crisi-della-replicabilità-dei-risultati-della-ricerca.html","id":"luso-del-valore-p-nel-mondo-della-ricerca","chapter":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","heading":"36.2 L’uso del valore-\\(p\\) nel mondo della ricerca","text":"Tra tanti articoli che sono stati dedicati questo tema, possiamo citare qui un articolo di Nuzzo (2014) che descrive limiti dell’uso del valore-\\(p\\) ’interno della pratica scientifica. Nuzzo (2014) ci ricorda che Ronald Fisher ha introdotto il valore-\\(p\\) negli anni ‘20, ma non ha mai pensato ad esso come ad un test formale. Per Fisher, il valore-\\(p\\) era uno strumento per giudicare informalmente se l’evidenza empirica fosse “significativa”, laddove il termine “significativo” veniva inteso nel senso colloquiale del termine, ovvero come qualcosa che merita di essere considerata con attenzione. Secondo Fisher, lo sperimentatore propone un’“ipotesi nulla” che spera di dimostrare falsa (per esempio, l’assenza di differenza tra due gruppi). Poi gioca fare l’avvocato del diavolo e assumere che l’ipotesi nulla sia vera. Questo gli consente di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello trovato, se il risultato trovato è interamente dovuto alla sola variabilità campionaria. Questa probabilità è appunto il valore-\\(p\\). Lo scopo di questo modo di procedere è quello di valutare l’ipotesi nulla: secondo Fisher, la probabilità che l’ipotesi nulla sia falsa è tanto più grande quanto più piccolo è il valore-\\(p\\). Anche se il valore-\\(p\\) è un numero calcolato con una procedura matematica, per Fisher esso è solo uno strumento da usare ’interno di un processo (inferenziale) non numerico capace di combinare le evidenze empiriche correnti con le conoscenze precedenti del ricercatore.Il processo di decisione che il ricercatore mette atto quando valuta risultati di un esperimento venne formalizzato, alla fine degli anni ’20, da due rivali di Fisher, il matematico Jerzy Neyman e lo statistico Egon Pearson. Neyman e Pearson si posero problema di rendere il processo di decisione “rigoroso e obiettivo”. Allo scopo di fare questo, Neyman e Pearson introdussero, tra l’altro, concetti di potere statistico e di falso positivo (concetti che abbiamo visto nei paragrafi precedenti). Non usarono invece, ’interno della procedura proposta, la nozione di valore-\\(p\\).Questi due approcci contrapposti portarono ad un dibattito molto acceso tra di due gruppi: Neyman descrisse il lavoro di Fisher come matematicamente “worse useless”; Fisher chiamò l’approccio di Neyman “childish” e “horrifying [] intellectual freedom west”. Mentre questo dibattito si sviluppava, altri autori iniziarono scrivere dei manuali di statistica allo scopo di fornire uno strumento di lavoro ai ricercatori. Dato che molti di questi autori non erano statistici, non avevano una comprensione profonda di cosa distinguesse l’approccio di Fisher, da una parte, e l’approccio di Neyman e Pearson, dall’altra, e finirono per creare un sistema ibrido che utilizzava il valore-\\(p\\) proposto da Fisher (che era un numero facile da calcolare) ’interno del “sistema rigoroso” proposto da Neyman e Pearson. È questo contesto che la soglia di un valore-\\(p\\) pari 0.05 venne definita “statisticamente significativa”. Dal punto di vista storico, dunque, si può dire che il valore-\\(p\\) proposto da Fisher non fu mai pensato come qualcosa che può essere usato nel modo cui il valore-\\(p\\) viene usato al giorno d’oggi nel mondo della ricerca.uno dei sei “principi” che vengono enunciati, l’ASA continua dicendo quanto segue:Scientific conclusions business policy decisions based whether \\(p\\)-value passes specific threshold.Practices reduce data analysis scientific inference mechanical “bright-line” rules (“\\(p < 0.05\\)”) justifying scientific claims conclusions can lead erroneous beliefs poor decision making. conclusion immediately become “true” one side divide “false” . Researchers bring many contextual factors play derive scientific inferences, including design study, quality measurements, external evidence phenomenon study, validity assumptions underlie data analysis. Pragmatic considerations often require binary, “yes-” decisions, mean \\(p\\)-values alone can ensure decision correct incorrect. widespread use “statistical significance” (generally interpreted “\\(p \\leq 0.05\\)”) license making claim scientific finding (implied truth) leads considerable distortion scientific process.","code":""},{"path":"la-crisi-della-replicabilità-dei-risultati-della-ricerca.html","id":"p-hacking","chapter":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","heading":"36.3 \\(P\\)-hacking","text":"La fallacia maggiore associata ’uso del valore-\\(p\\) è chiamata “\\(P\\)-hacking” (o anche “data-dredging”, “snooping”, “fishing”, “significance-chasing”, “double-dipping”). Secondo Uri Simonsohn della Università della Pennsylvania, “\\(P\\)-hacking trying multiple things get desired result.” Esempi di \\(P\\)-hacking sono: “finding seems obtained \\(p\\)-hacking, authors dropped one conditions overall \\(p\\)-value less .05”, oppure “\\(p\\)-hacker, always monitors data collected.” La pratica del \\(P\\)-hacking ha l’effetto di trasformare uno studio esplorativo (che dovrebbe essere sempre considerato con cautela) uno studio (apparentemente) confermativo, con la conseguenza di proporre risultati che hanno una probabilità pressoché nulla di essere replicati studi successivi. Le simulazioni di Simonsohn hanno mostrato come il cambiamento di poche decisioni ’interno del processo di analisi dei dati possa aumentare fino al 60% il tasso di falsi positivi un singolo studio.La pratica del \\(P\\)-hacking emerge soprattutto negli studi che si pongono il problema di dimostrare piccoli effetti usando dati molto rumorosi. un’analisi della letteratura psicologica, Simonsohn ha trovato che valori-\\(p\\) riportati dagli psicologi tendono concentrarsi su valori appena superiori alla soglia “minima” dello 0.05 (figura 36.1). Questo risultato può essere interpretato come conseguenza della pratica del \\(P\\)-hacking: infatti, ricercatori sembrano seguire la prarica che li porta ad eseguire molteplici test di significatività statistica, fino trovare un risultato “statisticamente significativo”, per poi pubblicare quello. Come mostra la figura 36.1, questa pratica non riguarda solo la psicologia ma è diffusa tutti campi della ricerca scientifica.\nFIGURA 36.1: Distribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.\n","code":""},{"path":"la-crisi-della-replicabilità-dei-risultati-della-ricerca.html","id":"critiche-al-valore-p","chapter":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","heading":"36.4 Critiche al valore-\\(p\\)","text":"Il valore-\\(p\\) è stato paragonato alle zanzare (creature noiose e impossibili da mandare via), ai vestiti nuovi dell’imperatore (ovvero, il fatto per cui la maggioranza sceglie di non riconoscere problemi che sono ovvi tutti, ma preferisce fingere di non vederli), o ad un “sterile intellectual rake” che non produce nulla. È stato ironizzato che l’unica ragione di chiamare questa procedura “statistical hypothesis inference testing” è per l’acronimo che tale espressione produce.È stato messo evidenza il fatto che valore-\\(p\\) incoraggia un modo di pensare sbagliato, quanto sposta l’attenzione dal problema centrale della ricerca, ovvero il problema della dimensione dell’effetto, verso un problema irrilevante, ovvero quello di dimostrare falsa un’ipotesi fantoccio che sappiamo essere falsa (l’ipotesi nulla). L’esempio che Nuzzo (2014) propone è quello di uno studio su più di 19,000 individui che ha mostrato come coloro che incontrano il loro partner online hanno una probabilità minore di divorziare (\\(p <\\) 0.002) e mostrano livelli maggiori di soddisfazione maritale (\\(p <\\) 0.001) rispetto alle coppie che non si sono conosciute online. Questo può sembrare un risultato interessante fino quando non consideriamo la dimensione dell’effetto: per coloro che si sono conosciuti online il tasso di divorzi diminuisce dal 7.67% al 5.96%, mentre l’indice di soddisfazione maritale aumenta solo da 5.48 5.64 su una scala sette passi. generale, la domanda da porsi, infatti, non è “c’è un effetto?” ma bensì “quanto è grande l’effetto?”","code":""},{"path":"la-crisi-della-replicabilità-dei-risultati-della-ricerca.html","id":"leffetto-sperimentale-è-esattamente-nullo","chapter":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","heading":"36.5 L’effetto sperimentale è esattamente nullo?","text":"Una delle critiche più ovvie alla logica della verifica delle ipotesi statistiche riguarda il fatto che non è ragionevole supporre che l’effetto della manipolazione sperimentale sia esattamente nullo. Un esempio preso dalla fisica illustra questo punto. Borel (1914) ha dimostrato che lo spostamento di un centimetro di un grammo di massa una stella qualche anno luce da noi modifica il movimento delle molecole di un gas sulla terra.Se, come sembra, tutto è collegato con tutto, allora è ragionevole supporre che la manipolazione sperimentale, quale essa sia, un qualche effetto lo produca sempre. Come Andrew Gelman ha ripetuto molte volte, il punto non è dimostrare falsa l’affermazione secondo cui la manipolazione sperimentale produce un effetto esattamente nullo. Importante invece è stabilire se la dimensione dell’effetto sia sufficientemente grande da avere una qualche importanza dal punto di vista pratico, e stabilire se l’effetto sia riproducibile.Se questi sono gli obiettivi, allora la logica della verifica dell’ipotesi nulla si dimostra problematica. Infatti, come abbiamo visto sopra, nel caso di piccoli campioni e di piccoli effetti (caso, questo, che descrive la quasi la totalità delle ricerche psicologia), le procedure frequentiste conducono ad una notevole sovrastima della dimensione dell’effetto. Inoltre, tendono favorire un un pensiero binario basato sulla dicotomia vero/falso, mentre quello che è importante non è rifiutare un’ipotesi (nulla) che è sicuramente falsa, ma riuscire ad ottenere una stima non distorta della vera dimensione dell’effetto.La simulazione descritta sopra non mostra soltanto che, nelle condizioni considerate, la stima della grandezza dell’effetto risulti fortemente esagerata, ma anche che la direzione dell’effetto possa anche essere stimata incorrettamente. Nella simulazione descritta, questo si verifica solo un campione su 40 tra quelli che producono un valore-\\(p >\\) 0.05, ma l’esame di dati reali tratti dalla letteratura psicologica mostra che la probabilità di questo errore di segno possa essere molto maggiore. Gelman Carlin (2014) chiamano due tipi di errori che abbiamo discusso qui errori di Tipo S (Sign) e errori di Tipo M (Magnitude). Gelman Carlin (2014) sono molto critici rispetto ’uso corrente che porta descrivere dati degli esperimenti per mezzo di concetti quali la “significatività statistica”, il “potere statistico”, l’“errore di tipo ” e l’“errore di tipo II” e affermano che sia più utile mettere evidenza la probabilità di un errore di Tipo S e di Tipo M (uno script \\(\\mathsf{R}\\) che consente di calcolare la probabilità di errore di Tipo S e di Tipo M è fornito nel loro articolo). Gelman Carlin (2014) concludono il loro articolo con la raccomandazione secondo la quale, per minimizzare falsi positivi psicologia, è necessario aumentare notevolmente la dimensione del campione rispetto agli standard correnti. Un punto analogo è anche fornito nell’articolo di Loken Gelman (2017).","code":""},{"path":"la-crisi-della-replicabilità-dei-risultati-della-ricerca.html","id":"simulazione","chapter":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","heading":"36.6 Simulazione","text":"questa simulazione esaminiamo le conseguenze che derivano dall’applicazione della procedura del test dell’ipotesi nulla al caso di una piccola dimensione dell’effetto nella popolazione e di un campione di piccole dimensioni – ovvero viene considerato il caso tipico di un esperimento di psicologia. L’idea è stata proposta da Gelman Carlin (2014).","code":""},{"path":"la-crisi-della-replicabilità-dei-risultati-della-ricerca.html","id":"la-dimensione-delleffetto-1","chapter":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","heading":"36.6.1 La dimensione dell’effetto","text":"La dimensione dell’effetto si calcola con la statistica \\(d\\) di Cohen definita come segue:\\[\nd = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p}\n\\]dove\\[\ns_p = \\sqrt{\n\\frac{s_1^2 (n_1 - 1) + s_2^2 (n_2 - 1)}{n_1 + n_2 - 2}\n}\n\\]La statistica \\(d\\) di Cohen si interpreta nel modo seguente:d = 0.2 effetto piccolod = 0.5 effetto mediod = 0.8 effetto grande","code":""},{"path":"la-crisi-della-replicabilità-dei-risultati-della-ricerca.html","id":"una-piccola-dimensione-delleffetto-nella-popolazione","chapter":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","heading":"36.6.2 Una piccola dimensione dell’effetto nella popolazione","text":"Consideriamo due ‘popolazioni’ la cui distribuzione è Normale di media 103 (la prima) e 100 (la seconda). Per entrambe, la deviazione standard è uguale 15.La dimensione dell’effetto nella popolazione è dunque uguale aSe prendiamo dei campioni enormie applichiamo la formula precedente, otteniamo una stima non distorta della vera dimensione dell’effetto.Oppure, maniera equivalenteMa vediamo cosa succede quando campioni sono piccoli, ovvero simili quelli che si usano normalmente psicologia. Supponiamo che \\(n\\) = 30. Nella simulazione consideriamo 100,000 coppie di campioni di 30 osservazioni estratte da ciascuna delle due popolazioni.Per ciascuna coppia di 30 osservazioni, calcoliamo un test di significatività statistica (il famoso test \\(t\\) di Student) e il \\(d\\) di Cohen. Alcuni di questi confronti non raggiungono la soglia \\(p\\) = 0.05 e quindi li escludiamo. Infatti, la consuetudine è di non pubblicare risultati che non sono “statisticamente significativi” (ovvero, con un valore-\\(p\\) < 0.05). Conserviamo invece campioni che sono risultati “statisticamente significativi”.La domanda che ci poniamo è: che misura campioni “statisticamente significativi” rispecchiano le caratteristiche della popolazione da cui sono stati estratti?Intanto calcolo il la proporzione di campioni che producono risultati “pubblicabili”.Dopo avere selezionato soltanto risultati “statisticamente significativi”creo un istogramma della dimensione dell’effetto (calcolata soltanto sui campioni nei quali l’effetto è “statisticamente significativo”).La simulazione mostra due risultati degni di nota.Complessivamente, la dimensione dell’effetto viene di molto sovrastimata.una proporzione non trascurabile di casi, la direzione dell’effetto è sbagliata.Questa simulazione dunque mostra come, seguendo la procedura frequentista, si ottiene proprio il risultato che si voleva evitare: si giunge “normalmente” alla risposta sbagliata.","code":"\n# Popolazione 1\nmu_1 <- 103\n# Popolazione 2\nmu_2 <- 100\n# SD comune\nsigma <- 15\n(mu_2 - mu_1) / sigma\n#> [1] -0.2\nx1 <- rnorm(1e5, mu_1, sigma)\nx2 <- rnorm(1e5, mu_2, sigma)\nnn <- length(x1) - 1\nsp <- sqrt(\n  (var(x1) * nn + var(x2) * nn) / (nn + nn)\n)\nsp\n#> [1] 14.98042\n(mean(x1) - mean(x2)) / sp\n#> [1] 0.200439\ndc <- cohen.d(x1, x2)\ndc\n#> \n#> Cohen's d\n#> \n#> d estimate: 0.200439 (small)\n#> 95 percent confidence interval:\n#>     lower     upper \n#> 0.1916517 0.2092262\nnrep <- 1e5\nnsample <- 30\nalpha <- 0.05\nsignificant <- rep(NA, nrep)\ncohen_d <- rep(NA, nrep)\nfor (i in 1:nrep) {\n  x1 <- rnorm(nsample, mu_1, sigma)\n  x2 <- rnorm(nsample, mu_2, sigma)\n  out <- t.test(x1, x2)\n  significant[i] <- ifelse(out$p.value < alpha, 1, 0)\n  dc <- cohen.d(x1, x2)\n  cohen_d[i] <- dc$estimate\n}\nsummary(significant)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>  0.0000  0.0000  0.0000  0.1189  0.0000  1.0000\nd <- data.frame(\n  is_significant = significant,\n  d = cohen_d\n)\ndim(d)\n#> [1] 100000      2\nd_pub <- d %>% \n  dplyr::filter(\n    is_significant == 1\n  )\n\ndim(d_pub)\n#> [1] 11893     2\nhist(\n  d_pub$d,\n  xlab = \"Indice d di Cohen\",\n  ylab = \"Densità\",\n  main = \"Soltanto risultati pubblicabili\",\n  freq = FALSE\n  )\nabline(v = 0.2, lty = 2, col = \"blue\")"},{"path":"la-crisi-della-replicabilità-dei-risultati-della-ricerca.html","id":"una-soluzione-sbagliata","chapter":"Capitolo 36 La crisi della replicabilità dei risultati della ricerca","heading":"36.6.3 Una soluzione (sbagliata)","text":"Per risolvere questo problema è stato proposto da diversi ricercatori di utilizzare un livello \\(\\alpha\\) più “conservativo”.Come mostrato dai risultati della simulazione, l’uso di una soglia più “conservativa” non ha altro effetto che quello di esacerbare il problema: la sovrastima della dimensione dell’effetto aumenta.conclusione, si può dire che l’uso dell’approccio frequentista garantisce, senza possibilità di dubbio, il fatto di giungere alla conclusione inferenziale sbagliata.","code":"\nnrep <- 1e5\nnsample <- 30\nalpha <- 0.001\nsignificant <- rep(NA, nrep)\ncohen_d <- rep(NA, nrep)\nfor (i in 1:nrep) {\n  x1 <- rnorm(nsample, mu_1, sigma)\n  x2 <- rnorm(nsample, mu_2, sigma)\n  out <- t.test(x1, x2)\n  significant[i] <- ifelse(out$p.value < alpha, 1, 0)\n  dc <- cohen.d(x1, x2)\n  cohen_d[i] <- dc$estimate\n}\n\nd <- data.frame(\n  is_significant = significant,\n  d = cohen_d\n)\n\nd_pub <- d %>% \n  dplyr::filter(\n    is_significant == 1\n  )\n\nhist(\n  d_pub$d,\n  xlab = \"Indice d di Cohen\",\n  ylab = \"Densità\",\n  main = \"Soltanto risultati pubblicabili\",\n  freq = FALSE\n  )\nabline(v = 0.2, lty = 2, col = \"blue\")"},{"path":"bibliografia.html","id":"bibliografia","chapter":"Capitolo 37 Bibliografia","heading":"Capitolo 37 Bibliografia","text":"","code":""},{"path":"simbologia-di-base.html","id":"simbologia-di-base","chapter":"Appendice A Simbologia di base","heading":"Appendice A Simbologia di base","text":"Per una scrittura più sintetica possono essere utilizzati alcuni simboli\nmatematici.\\(\\log(x)\\): il logaritmo naturale di \\(x\\).L’operatore logico booleano \\(\\land\\) significa “e” (congiunzione\nforte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o”\n(oppure) (congiunzione debole).Il quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno\nun” e indica l’esistenza di almeno una istanza del concetto/oggetto\nindicato. Il quantificatore esistenziale di unicità \\(\\exists!\\)\n(“esiste soltanto un”) indica l’esistenza di esattamente una istanza\ndel concetto/oggetto indicato. Il quantificatore esistenziale\n\\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.Il quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\\(\\mathcal{, S}\\): insiemi.\\(x \\\\): \\(x\\) è un elemento dell’insieme \\(\\).L’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se\n…allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione\nsufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria\nper la verità di \\(P\\).L’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica\nuna condizione necessaria e sufficiente, o corrispondenza biunivoca.Il simbolo \\(\\vert\\) si legge “tale che.”Il simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”Il simbolo \\(\\Delta\\) indica la differenza fra due valori della\nvariabile scritta destra del simbolo.Il simbolo \\(\\propto\\) si legge “proporzionale .”Il simbolo \\(\\approx\\) si legge “circa.”Il simbolo \\(\\\\) della teoria degli insiemi vuol dire “appartiene” e\nindica l’appartenenza di un elemento ad un insieme. Il simbolo\n\\(\\notin\\) vuol dire “non appartiene.”Il simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può\ncoincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è\nun sottoinsieme proprio di.”Il simbolo \\(\\#\\) indica la cardinalità di un insieme.Il simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo\n\\(\\cup\\) indica l’unione di due insiemi.Il simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per quali una data funzione raggiunge il suo massimo. altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per quali \\(f(x)\\) raggiunge il valore più alto.\\(, c, \\alpha, \\gamma\\): scalari.\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\\(f(x)\\): una funzione arbitraria di \\(x\\).\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\\(\\mathcal{U}(, b)\\): distribuzione uniforme con limite inferiore \\(\\) e limite superiore \\(b\\).\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) \\(q\\).","code":""},{"path":"numeri-binari-interi-razionali-irrazionali-e-reali.html","id":"numeri-binari-interi-razionali-irrazionali-e-reali","chapter":"Appendice B Numeri binari, interi, razionali, irrazionali e reali","heading":"Appendice B Numeri binari, interi, razionali, irrazionali e reali","text":"","code":""},{"path":"numeri-binari-interi-razionali-irrazionali-e-reali.html","id":"numeri-binari","chapter":"Appendice B Numeri binari, interi, razionali, irrazionali e reali","heading":"B.1 Numeri binari","text":"numeri più semplici sono quelli binari, cioè zero o uno. Useremo spesso\nnumeri binari per indicare se qualcosa è vero o falso, presente o\nassente. numeri binari sono molto utili per ottenere facilmente delle statistiche riassuntive \\(\\mathsf{R}\\).Supponiamo di chiedere 10 studenti “Ti piacciono mirtilli?” Poniamo che le risposte siano le seguenti:Tali risposte possono essere ricodificate nei termini di valori di\nverità, ovvero, vero e falso, generalmente denotati rispettivamente come\n1 e 0. \\(\\R\\) tale ricodifica può essere effettuata mediante l’operatore\n== che è un test per l’uguaglianza e restituisce il valore logico VERO\nse due oggetti valutati sono uguali e FALSO se non lo sono:R considera valori di verità e numeri binari modo equivalente, con\nTRUE uguale 1 e FALSE uguale zero. Di conseguenza, possiamo\neffettuare operazioni algebriche sui valori logici VERO e FALSO.\nNell’esempio, possiamo sommare valori di verità e dividere per 10in modo tale da calcolare una propozione, il che ci consente di concludere che 7 risposte su 10 sono positive.","code":"\nopinion <- c(\n  \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\",\n  \"Yes\", \"Yes\", \"Yes\"\n)\nopinion\n#>  [1] \"Yes\" \"No\"  \"Yes\" \"No\"  \"Yes\" \"No\"  \"Yes\" \"Yes\" \"Yes\" \"Yes\"\nopinion <- opinion == \"Yes\"\nopinion\n#>  [1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\nsum(opinion) / length(opinion)\n#> [1] 0.7"},{"path":"numeri-binari-interi-razionali-irrazionali-e-reali.html","id":"numeri-interi","chapter":"Appendice B Numeri binari, interi, razionali, irrazionali e reali","heading":"B.2 Numeri interi","text":"Un numero intero è un numero senza decimali. Si dicono naturali \nnumeri che servono contare, come 1, 2, … L’insieme dei numeri\nnaturali si indica con il simbolo \\(\\mathbb{N}\\). È anche necessario\nintrodurre numeri con il segno per poter trattare grandezze negative.\nSi ottengono così l’insieme numerico dei numeri interi relativi:\n\\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\)","code":""},{"path":"numeri-binari-interi-razionali-irrazionali-e-reali.html","id":"numeri-razionali","chapter":"Appendice B Numeri binari, interi, razionali, irrazionali e reali","heading":"B.3 Numeri razionali","text":"numeri razionali sono numeri frazionari \\(m/n\\), dove \\(m, n \\N\\),\ncon \\(n \\neq 0\\). Si ottengono così numeri razionali:\n\\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\\\mathbb{Z}, n \\neq 0\\}\\).\nÈ evidente che \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\).\nAnche questo caso è necessario poter trattare grandezze negative. \nnumeri razionali non negativi sono indicati con\n\\(\\mathbb{Q^+} = \\{q \\\\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\).","code":""},{"path":"numeri-binari-interi-razionali-irrazionali-e-reali.html","id":"numeri-irrazionali","chapter":"Appendice B Numeri binari, interi, razionali, irrazionali e reali","heading":"B.4 Numeri irrazionali","text":"Tuttavia, non tutti punti di una retta \\(r\\) possono essere\nrappresentati mediante numeri interi e razionali. È dunque necessario\nintrodurre un’altra classe di numeri. Si dicono irrazionali, e sono\ndenotati con \\(\\mathbb{R}\\), numeri che possono essere scritti come una\nfrazione \\(/ b\\), con \\(\\) e \\(b\\) interi e \\(b\\) diverso da 0. numeri\nirrazionali sono numeri illimitati e non periodici che quindi non\npossono essere espressi sotto forma di frazione. Per esempio,\n\\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\({\\displaystyle \\pi =3,141592\\ldots}\\) sono\nnumeri irrazionali.","code":""},{"path":"numeri-binari-interi-razionali-irrazionali-e-reali.html","id":"numeri-reali","chapter":"Appendice B Numeri binari, interi, razionali, irrazionali e reali","heading":"B.5 Numeri reali","text":"punti della retta \\(r\\) sono quindi “di più” dei numeri razionali. Per\npoter rappresentare tutti punti della retta abbiamo dunque bisogno dei\nnumeri reali. numeri reali possono essere positivi, negativi o nulli\ne comprendono, come casi particolari, numeri interi, numeri\nrazionali e numeri irrazionali. Spesso statisticac il numero dei\ndecimali indica il grado di precisione della misurazione.","code":""},{"path":"numeri-binari-interi-razionali-irrazionali-e-reali.html","id":"intervalli","chapter":"Appendice B Numeri binari, interi, razionali, irrazionali e reali","heading":"B.6 Intervalli","text":"Un intervallo si dice chiuso se gli estremi sono compresi\nnell’intervallo, aperto se gli estremi non sono compresi. Le\ncaratteristiche degli intervalli sono riportate nella tabella seguente.","code":""},{"path":"insiemistica.html","id":"insiemistica","chapter":"Appendice C Insiemi","heading":"Appendice C Insiemi","text":"Un insieme (o collezione, classe, gruppo, …) è un concetto primitivo,\novvero è un concetto che già possediamo. Georg Cantor l’ha definito nel\nmodo seguente: un insieme è una collezione di oggetti, determinati e distinti, della nostra percezione o del nostro pensiero, concepiti come un tutto unico; tali oggetti si dicono elementi dell’insieme.Mentre non è rilevante la natura degli oggetti che costituiscono\nl’insieme, ciò che importa è distinguere se un dato oggetto appartenga o\nmeno ad un insieme. Deve essere vera una delle due possibilità: il dato\noggetto è un elemento dell’insieme considerato oppure non è elemento\ndell’insieme considerato. Due insiemi \\(\\) e \\(B\\) si dicono uguali se sono\nformati dagli stessi elementi, anche se disposti ordine diverso:\n\\(=B\\). Due insiemi \\(\\) e \\(B\\) si dicono diversi se non contengono gli\nstessi elementi: \\(\\neq B\\). Ad esempio, seguenti insiemi sono uguali:\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]Gli insiemi sono denotati da una lettera maiuscola, mentre le lettere\nminuscole, di solito, designano gli elementi di un insieme. Per esempio,\nun generico insieme \\(\\) si indica con\\[\n= \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con~} n > 0.\n\\]La scrittura \\(\\\\) dice che \\(\\) è un elemento di \\(\\). Per dire che\n\\(b\\) non è un elemento di \\(\\) si scrive \\(b \\notin .\\)Per quegli insiemi cui elementi soddisfano una certa proprietà che li\ncaratterizza, tale proprietà può essere usata per descrivere più\nsinteticamente l’insieme:\\[\n= \\{x ~\\vert~ \\text{proprietà posseduta da~} x\\},\n\\]che si legge come “\\(\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà\nindicata.” Per esempio, per indicare l’insieme \\(\\) delle coppie di\nnumeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può\nscrivere:\\[\n= \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]Dati due insiemi \\(\\) e \\(B\\), diremo che \\(\\) è un sottoinsieme di \\(B\\) se\ne solo se tutti gli elementi di \\(\\) sono anche elementi di \\(B\\):\\[\n\\subseteq B \\iff (\\forall x \\\\Rightarrow x \\B).\n\\]Se esiste almeno un elemento di \\(B\\) che non appartiene ad \\(\\) allora diremo che\n\\(\\) è un sottoinsieme proprio di \\(B\\):\\[\n\\subset B \\iff (\\subseteq B, \\exists~ x \\B ~\\vert~ x \\notin ).\n\\]Un altro insieme, detto insieme delle parti, o insieme potenza, che si\nassocia ’insieme \\(\\) è l’insieme di tutti sottoinsiemi di \\(\\),\ninclusi l’insieme vuoto e \\(\\) stesso. Per esempio, per l’insieme\n\\(= \\{, b, c\\}\\), l’insieme delle parti è:\\[\n\\mathcal{P}() = \\{\n\\emptyset, \\{\\}, \\{b\\}, \\{c\\},\n\\{, b\\}, \\{, c\\}, \\{c, b\\},\n\\{, b, c\\}\n\\}.\n\\]","code":""},{"path":"insiemistica.html","id":"operazioni-tra-insiemi","chapter":"Appendice C Insiemi","heading":"C.1 Operazioni tra insiemi","text":"Si definisce intersezione di \\(\\) e \\(B\\) l’insieme \\(\\cap B\\) di tutti\ngli elementi \\(x\\) che appartengono ad \\(\\) e contemporaneamente \\(B\\):\\[\n\\cap B = \\{x ~\\vert~ x \\\\land x \\B\\}.\n\\]Si definisce unione di \\(\\) e \\(B\\) l’insieme \\(\\cup B\\) di tutti gli\nelementi \\(x\\) che appartengono ad \\(\\) o \\(B\\), cioè\\[\n\\cup B = \\{x ~\\vert~ x \\\\lor x \\B\\}.\n\\]Differenza. Si indica con \\(\\setminus B\\) l’insieme degli elementi di\n\\(\\) che non appartengono \\(B\\):\\[\n\\setminus B = \\{x ~\\vert~ x \\\\land x \\notin B\\}.\n\\]Insieme complementare. Nel caso che sia \\(B \\subseteq \\), l’insieme\ndifferenza \\(\\setminus B\\) è detto insieme complementare di \\(B\\) \\(\\) e\nsi indica con \\(B^C\\).Dato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di\nsottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]e\\[\nS_i \\cap S_j, \\quad \\text{con~} \\neq j.\n\\]La relazione tra unione, intersezione e insieme complementare è data\ndalle leggi di DeMorgan:\\[\n(\\cup B)^c = ^c \\cap B^c,\n\\]\n\\[\n(\\cap B)^c = ^c \\cup B^c.\n\\]","code":""},{"path":"insiemistica.html","id":"diagrammi-di-eulero-venn","chapter":"Appendice C Insiemi","heading":"C.2 Diagrammi di Eulero-Venn","text":"molte situazioni è utile servirsi dei cosiddetti diagrammi di\nEulero-Venn per rappresentare gli insiemi e verificare le proprietà\ndelle operazioni tra insiemi (si veda la figura C.1.\ndiagrammi di Venn sono così nominati onore del matematico inglese del diciannovesimo secolo John Venn anche se Leibnitz e Eulero avevano già precedenza utilizzato rappresentazioni simili. tale rappresentazione, gli insiemi sono individuati da regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare esplicitamente alcuni elementi di un insieme mediante punti, quando si possono anche evidenziare tutti gli elementi degli insiemi considerati.\nFIGURA C.1: tutte le figure \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione ’interno del cerchio di sinistra e \\(R\\) è la regione ’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\ndiagrammi di Eulero-Venn che forniscono una dimostrazione delle leggi\ndi DeMorgan sono forniti nella figura C.2.\nFIGURA C.2: Dimostrazione delle leggi di DeMorgan.\n","code":""},{"path":"insiemistica.html","id":"coppie-ordinate-e-prodotto-cartesiano","chapter":"Appendice C Insiemi","heading":"C.3 Coppie ordinate e prodotto cartesiano","text":"Una coppia ordinata \\((x,y)\\) è l’insieme cui elementi sono \\(x \\\\) e\n\\(y \\B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata),\n\\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite \npartire dagli insiemi \\(\\) e \\(B\\) viene detto prodotto cartesiano:\\[\n\\times B = \\{(x, y) ~\\vert~ x \\\\land y \\B\\}.\n\\]Ad esempio,\nsia \\(= \\{1, 2, 3\\}\\) e \\(B = \\{, b\\}\\). Allora,\\[\n\\{1, 2\\} \\times \\{, b, c\\} = \\{(1, ), (1, b), (1, c), (2, ), (2, b), (2, c)\\}.\n\\]","code":""},{"path":"insiemistica.html","id":"cardinalità","chapter":"Appendice C Insiemi","heading":"C.4 Cardinalità","text":"Si definisce cardinalità (o potenza) di un insieme finito il numero\ndegli elementi dell’insieme. Viene indicata con \\(\\vert \\vert, \\#()\\) o\n\\(\\text{c}()\\).","code":""},{"path":"sommatorie.html","id":"sommatorie","chapter":"Appendice D Simbolo di somma (sommatorie)","heading":"Appendice D Simbolo di somma (sommatorie)","text":"Le somme si incontrano costantemente svariati contesti matematici e statistici quindi abbiamo bisogno di una notazione adeguata che ci consenta di gestirle. La somma dei primi \\(n\\) numeri interi può essere scritta come \\(1+2+\\dots+(n-1)+n\\), dove `\\(\\dots\\)’ ci dice di completare la sequenza definita dai termini che vengono prima e dopo. Ovviamente, una notazione come \\(1+7+\\dots+73.6\\) non avrebbe alcun senso senza qualche altro tipo di precisazione. generale, nel seguito incontreremo delle somme nella forma\\[\\begin{equation}\nx_1+x_2+\\dots+x_n,\\notag\n\\end{equation}\\]dove \\(x_i\\) è un numero che è stato definito altrove. La notazione precedente, che fa uso dei tre puntini di sospensione, è utile alcuni contesti ma altri risulta ambigua. Pertanto la notazione di uso corrente è del tipo\\[\\begin{equation}\n  \\sum_{=1}^n x_i\\notag\n\\end{equation}\\]e si legge “sommatoria per \\(\\) che va da \\(1\\) \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (lettera sigma maiuscola dell’alfabeto greco) indica l’operazione di somma, il simbolo \\(x_i\\) indica il generico addendo della sommatoria, le lettere \\(1\\) ed \\(n\\) indicano cosiddetti estremi della sommatoria, ovvero l’intervallo (da \\(1\\) fino \\(n\\) estremi inclusi) cui deve variare l’indice \\(\\) allorché si sommano gli addendi \\(x_i\\).\nSolitamente l’estremo inferiore è \\(1\\) ma potrebbe essere qualsiasi altri numero \\(m < n\\). Quindi\\[\n  \\sum_{=1}^n x_i = x_1 + x_{2} + \\dots + x_{n}.\n\\]Per esempio, se valori \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), si avrà\\[\n  \\sum_{=1}^4 x_i = 3+11+4+7 = 25\n\\]laddove \\(x_1 = 3\\), \\(x_2 = 11\\), eccetera. La quantità \\(x_i\\) nella formula precedente si dice l’argomento della sommatoria, mentre la variabile \\(\\), che prende valori naturali successivi indicati nel simbolo, si dice indice della sommatoria.La notazione di sommatoria può anche essere fornita nella forma seguente\\[\\begin{equation}\n  \\sum_{P()} x_i\\notag\n\\end{equation}\\]dove \\(P()\\) è qualsiasi proposizione riguardante \\(\\) che può essere vera o falsa. Quando è ovvio che si vogliono sommare tutti valori di \\(n\\) osservazioni, la notazione può essere semplificata nel modo seguente: \\(\\sum_{} x_i\\) oppure \\(\\sum x_i\\). Al posto di \\(\\) si possono trovare altre lettere: \\(k, j, l, \\dots\\),.","code":""},{"path":"sommatorie.html","id":"manipolazione-di-somme","chapter":"Appendice D Simbolo di somma (sommatorie)","heading":"D.1 Manipolazione di somme","text":"È conveniente utilizzare le seguenti regole per semplificare calcoli che coinvolgono l’operatore della sommatoria.","code":""},{"path":"sommatorie.html","id":"proprietà-1-1","chapter":"Appendice D Simbolo di somma (sommatorie)","heading":"D.1.1 Proprietà 1","text":"La sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(\\) è pari \\(n\\) volte la costante stessa:\\[\n  \\sum_{=1}^{n} =  \\underbrace{+ + \\dots + }_{n~\\text{volte}} = n .\n  \\]","code":""},{"path":"sommatorie.html","id":"proprietà-2-proprietà-distributiva","chapter":"Appendice D Simbolo di somma (sommatorie)","heading":"D.1.2 Proprietà 2 (proprietà distributiva)","text":"Nel caso cui l’argomento contenga una costante, è possibile riscrivere la sommatoria. Ad esempio con\\[\n  \\sum_{=1}^{n} x_i =  x_1 + x_2 + \\dots + x_n\n  \\]è possibile raccogliere la costante \\(\\) e fare \\((x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\\[\n  \\sum_{=1}^{n} x_i =   \\sum_{=1}^{n} x_i.\n  \\]","code":""},{"path":"sommatorie.html","id":"proprietà-3-proprietà-associativa","chapter":"Appendice D Simbolo di somma (sommatorie)","heading":"D.1.3 Proprietà 3 (proprietà associativa)","text":"Nel caso cui\\[\n  \\sum_{=1}^{n} (+ x_i) =  (+ x_1) +  (+ x_1) + \\dots  (+ x_n)\n  \\]si ha che\\[\n  \\sum_{=1}^{n} (+ x_i) =  n + \\sum_{=1}^{n} x_i.\n  \\]È dunque chiaro che generale possiamo scrivere\\[\n  \\sum_{=1}^{n} (x_i + y_i) =  \\sum_{=1}^{n} x_i + \\sum_{=1}^{n} y_i.\n  \\]","code":""},{"path":"sommatorie.html","id":"proprietà-4","chapter":"Appendice D Simbolo di somma (sommatorie)","heading":"D.1.4 Proprietà 4","text":"Se deve essere eseguita un’operazione algebrica (innalzamento potenza, logaritmo, ecc.) sull’argomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\\[\n\\sum_{=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{=1}^{n} x_i \\right)^2.\n\\]","code":""},{"path":"sommatorie.html","id":"proprietà-5","chapter":"Appendice D Simbolo di somma (sommatorie)","heading":"D.1.5 Proprietà 5","text":"Nel caso si voglia calcolare \\(\\sum_{=1}^{n} x_i y_i\\), il prodotto tra punteggi appaiati deve essere eseguito prima e la somma dopo:\\[\n\\sum_{=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]infatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).","code":""},{"path":"sommatorie.html","id":"doppia-sommatoria","chapter":"Appendice D Simbolo di somma (sommatorie)","heading":"D.2 Doppia sommatoria","text":"È possibile incontrare la seguente espressione cui figurano una doppia sommatoria e un doppio indice:\\[\n\\sum_{=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]La doppia sommatoria comporta che per ogni valore dell’indice esterno, \\(\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\\[\n\\sum_{=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]Un caso particolare interessante di doppia sommatoria è il seguente:\\[\n\\sum_{=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]Si può osservare che nella sommatoria interna (quella che dipende dall’indice \\(j\\)), la quantità \\(x_i\\) è costante, ovvero non dipende dall’indice (che è \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall’operatore di sommatoria interna e scrivere\\[\n\\sum_{=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]Allo stesso modo si può osservare che nell’argomento della sommatoria esterna la quantità costituita dalla sommatoria \\(j\\) non dipende dall’indice \\(\\) e quindi questa quantità può essere estratta dalla sommatoria esterna. Si ottiene quindi\\[\n\\sum_{=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{=1}^{n}\\ x_i \\sum_{j=1}^{n} y_j.\n\\]Esercizio D.1  Si verifichi quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto così ottenuto sia uguale al prodotto delle due sommatorie.\\[\\begin{align}\n\\sum_{=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\\]ovvero\\[\n(2 + 3 + 1) \\times (1+4+9) = 84.\n\\]","code":""},{"path":"sommatorie.html","id":"sommatorie-e-produttorie-e-operazioni-vettoriali-in-r","chapter":"Appendice D Simbolo di somma (sommatorie)","heading":"D.3 Sommatorie (e produttorie) e operazioni vettoriali in R","text":"Si noti che la notazione\\[\n\\sum_{n=0}^4 3n\n\\]non è altro che un ciclo :maniera equivalente, e più semplice, possiamo scrivereAllo stesso modo, la notazione\\[\n\\prod_{n=1}^{4} 2n\n\\]\nè anch’essa equivalente al ciclo forche si può scrivere, più semplicemente, comeIn entrambi casi precedenti, abbiamo sostituito le operazioni aritmetiche eseguite ’interno di un ciclo con le stesse operazioni aritmetiche eseguite sui vettori elemento per elemento.","code":"\nsum <- 0\nfor (n in 0:4) {\n  sum = sum + 3 * n\n}\nsum\n#> [1] 30\nsum(3 * (0:4))\n#> [1] 30\nprod <- 1\nfor (n in 1:4) {\n  prod <- prod * 2 * n\n}\nprod\n#> [1] 384\nprod(2 * (1:4))\n#> [1] 384"},{"path":"appendix:future-exp.html","id":"appendix:future-exp","chapter":"Appendice E Le aspettative future dei pazienti depressi","heading":"Appendice E Le aspettative future dei pazienti depressi","text":"","code":""},{"path":"appendix:future-exp.html","id":"app:zet","chapter":"Appendice E Le aspettative future dei pazienti depressi","heading":"E.1 La ricerca di Zetsche, Bürkner, and Renneberg (2019)","text":"Per descrivere vari aspetti dell’analisi bayesiana utilizzeremo dei dati reali, nello specifico quelli raccolti da Zetsche, Bürkner, Renneberg (2019). Questi ricercatori si sono chiesti se gli individui depressi manifestino delle aspettative accurate circa il loro umore futuro, oppure se tali aspettative siano distorte negativamente. Esamineremo qui 30 partecipanti dello studio di Zetsche, Bürkner, Renneberg (2019) che hanno riportato la presenza di un episodio di depressione maggiore atto. ’inizio della settimana di test, questi pazienti è stato chiesto di valutare l’umore che si aspettavano di esperire nei giorni seguenti della settimana. Mediante una app, partecipanti dovevano poi valutare il proprio umore cinque momenti diversi di ciascuno dei cinque giorni successivi. Lo studio considera diverse emozioni, ma qui ci concentriamo solo sulla tristezza.Sulla base dei dati forniti dagli autori, abbiamo calcolato la media dei giudizi relativi al livello di tristezza raccolti da ciascun partecipante tramite la app. Tale media è stata poi sottratta dall’aspettativa del livello di tristezza fornita ’inizio della settimana. La discrepanza tra aspettative e realtà è stata considerata come un evento dicotomico: valori positivi di tale differenza indicano che le aspettative circa il livello di tristezza erano maggiori del livello di tristezza effettivamente esperito — ciò significa che le aspettative future risultano negativamente distorte (evento codificato con “1”). Viceversa, si ha che le aspettative risultano positivamente distorte se la differenza descritta precedenza assume un valore negativo (evento codificato con “0”).Nel campione dei 30 partecipanti clinici di Zetsche, Bürkner, Renneberg (2019), le aspettative future di 23 partecipanti risultano distorte negativamente e quelle di 7 partecipanti risultano distorte positivamente. Chiameremo \\(\\theta\\) la probabilità dell’evento “le aspettative del partecipante sono distorte negativamente”. Ci poniamo il problema di ottenere una stima posteriori di \\(\\theta\\) avendo osservato 23 “successi” 30 prove.Si noti un punto importante: dire semplicemente che la stima di \\(\\theta\\) è uguale 23/30 = 0.77 ci porta ad ignorare il livello di incertezza associato tale stima. Infatti, lo stesso valore (0.77) si può ottenere come 23/30, o 230/300, o 2300/3000, o 23000/30000, ma l’incertezza di una stima pari 0.77 è molto diversa nei quattro casi. Quando si traggono conclusioni dai dati è invece necessario quantificare il livello della nostra incertezza relativamente alla stima del parametro di interesse (nel caso presente, \\(\\theta\\)). Lo strumento ci consente di quantificare tale incertezza è la distribizione posteriori \\(p(\\theta \\mid y)\\). Ovviamente, \\(p(\\theta \\mid y)\\) assume forme molto diverse nei quattro casi descritti sopra.","code":""},{"path":"appendix:beta-binom.html","id":"appendix:beta-binom","chapter":"Appendice F Modello Beta-binomiale","heading":"Appendice F Modello Beta-binomiale","text":"","code":""},{"path":"appendix:beta-binom.html","id":"funzione-per-il-modello-beta-binomiale","chapter":"Appendice F Modello Beta-binomiale","heading":"F.1 Funzione per il modello Beta-binomiale","text":"La seguente funzione può essere usata per rappresentare la distribuzione priori, la distribuzione posteriori e la versosimiglianza (normalizzata) nel caso del modello Beta-binomiale. parametri input sono, nell’ordine, parametri \\(\\alpha\\) e \\(\\beta\\) della distribuzione priori Beta, \\(y\\) (numero di successi) e \\(n\\) (numero di prove).","code":"\nplot_beta_bin <- function(a, b, y, n) {\n  library(\"tidyverse\")\n  \n  df1 <- data.frame(theta = seq(0.001, 1, 0.001))\n  prior_un <- dbeta(df1$theta, a, b)\n  df1$prior <- prior_un / sum(prior_un)\n\n  # Likelihood\n  like_un <- dbinom(y, n, prob = seq(0.001, 1, 0.001))\n  df1$like <- like_un / sum(like_un)\n\n  # Posterior\n  post_un <- df1$prior * df1$like\n  df1$post <- post_un / sum(post_un)\n\n  df2 <- df1 %>%\n    pivot_longer(!theta, names_to = \"grp\", values_to = \"val\")\n\n  df2$grp <- factor(df2$grp)\n  # levels(df2$grp)\n  df2$grp <- factor(df2$grp, levels = c(\"prior\", \"like\", \"post\"))\n  levels(df2$grp) <-\n    c(\n      \"Distribuzione a priori\", \"Verosimiglianza\",\n      \"Distribuzione a posteriori\"\n    )\n\n  p <- ggplot(data = df2) +\n    geom_line(aes(theta, val)) +\n    facet_wrap(~grp, ncol = 1, scales = \"free_y\") +\n    coord_cartesian(xlim = c(0, 1)) +\n    scale_y_continuous(breaks = NULL) +\n    labs(x = \"\", y = \"\")\n\n  p\n}"},{"path":"appendix:const-norm-bino23.html","id":"appendix:const-norm-bino23","chapter":"Appendice G Verosimiglianza marginale","heading":"Appendice G Verosimiglianza marginale","text":"","code":""},{"path":"appendix:const-norm-bino23.html","id":"derivazione-analitica-della-costante-di-normalizzazione","chapter":"Appendice G Verosimiglianza marginale","heading":"G.1 Derivazione analitica della costante di normalizzazione","text":"Riportiamo di seguito la derivazione analitica per la costante di normalizzazione discussa nella Sezione 14.4, ovvero dell’integrale (14.3).Dimostrazione. Sia la distribuzione priori \\(\\theta \\sim \\mbox{Beta}(, b)\\) e sia \\(y = \\{y_1, \\dots, y_n\\} \\sim \\Bin(\\theta, n)\\). Scrivendo la funzione beta come\\[\n\\B(, b) = \\frac{\\Gamma()\\Gamma(b)}{\\Gamma(+b)},\n\\]\nla verosimiglianza marginale diventa\\[\\begin{align}\np(y) &= \\int p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\!\\theta \\notag\\\\\n&= \\int_0^1 \\binom{n}{y}\\theta^{y} (1 - \\theta)^{n- y} \\frac{1}{\\B(,b)} \\theta^{-1} (1-\\theta)^{b-1} \\,\\operatorname {d}\\!\\theta \\notag\\\\\n&= \\binom{n}{y}\\frac{1}{\\B(,b)} \\int_0^1 \\theta^{y + - 1} (1-\\theta)^{n- y + b-1}  \\,\\operatorname {d}\\!\\theta \\notag\\\\\n&= \\binom{n}{y}\\frac{\\Beta(y + , n- y + b)}{\\Beta(,b)},\n\\tag{G.1}\n\\end{align}\\]quanto\\[\\begin{align}\n\\int_0^1 \\frac{1}{\\Beta(,b)} \\theta^{-1} (1-\\theta)^{b-1} \\,\\operatorname {d}\\! \\theta &= 1\\notag\\\\\n\\frac{1}{\\Beta(,b)} \\int_0^1  \\theta^{-1} (1-\\theta)^{b-1} \\,\\operatorname {d}\\! \\theta &= 1\\notag\\\\\n\\int_0^1  \\theta^{-1} (1-\\theta)^{b-1} \\,\\operatorname {d}\\!\\theta &= \\Beta(,b). \\notag\n\\end{align}\\]conclusione, nel caso di una verosimiglianza binomiale \\(y = \\sim \\Bin(\\theta, n)\\) e di una distribuzione priori \\(\\theta \\sim \\mbox{Beta}(, b)\\), la verosimiglianza marginale diventa uguale alla (G.1).Esercizio G.1  Si verifichi la (G.1) mediante di dati di Zetsche, Bürkner, Renneberg (2019).Per replicare mediante la (G.1) il risultato trovato per via numerica nella Sezione 14.4 assumiamo una distribuzione priori uniforme, ovvero \\(\\mbox{Beta}(1, 1)\\). valori del problema dunque diventano seguenti:DefiniamoIl risultato cercato è","code":"\na <- 1\nb <- 1\ny <- 23\nn <- 30\nB <- function(a, b) {\n  (gamma(a) * gamma(b)) / gamma(a + b)\n}\nchoose(30, 23) * B(y + a, n - y + b) / B(a, b)\n#> [1] 0.03225806"},{"path":"markov-chains.html","id":"markov-chains","chapter":"Appendice H Le catene di Markov","heading":"Appendice H Le catene di Markov","text":"Per introdurre il concetto di catena di Markov, supponiamo che una persona esegua una passeggiata casuale sulla retta dei numeri naturali considerando solo valori 1, 2, 3, 4, 5, 6.39 Se la persona è collocata su un valore interno dei valori possibili (ovvero, 2, 3, 4 o 5), nel passo successivo è altrettanto probabile che rimanga su quel numero o si sposti su un numero adiacente. Se si muove, è ugualmente probabile che si muova sinistra o destra. Se la persona si trova su uno dei valori estremi (ovvero, 1 o 6), nel passo successivo è altrettanto probabile che rimanga rimanga su quel numero o si sposti nella posizione adiacente.Questo è un esempio di una catena di Markov discreta. Una catena di Markov descrive il movimento probabilistico tra un numero di stati. Nell’esempio ci sono sei possibili stati, da 1 6, quali corrispondono alle possibili posizioni della passeggiata casuale. Data la sua posizione corrente, la persona si sposterà nelle altre posizioni possibili con delle specifiche probabilità. La probabilità che si sposti un’altra posizione dipende solo dalla sua posizione attuale e non dalle posizioni visitate precedenza.È possibile descrivere il movimento tra gli stati nei termini delle cosiddette probabilità di transizione, ovvero le probabilità di movimento tra tutti possibili stati un unico passaggio di una catena di Markov. Le probabilità di transizione sono riassunte una matrice di transizione \\(P\\):La prima riga della matrice di transizione \\(P\\) fornisce le probabilità di passare ciascuno degli stati da 1 6 un unico passaggio partire dalla posizione 1; la seconda riga fornisce le probabilità di transizione un unico passaggio dalla posizione 2 e così via. Per esempio, il valore \\(P[1, 1]\\) ci dice che, se la persona è nello stato 1, avrà una probabilità di 0.5 di rimanere quello stato; \\(P[1, 2]\\) ci dice che c’è una probabilità di 0.5 di passare dallo stato 1 allo stato 2. Gli altri elementi della prima riga sono 0 perché, un unico passaggio, non è possibile passare dallo stato 1 agli stati 3, 4, 5 e 6. Il valore \\(P[2, 1]\\) ci dice che, se la persona è nello stato 1 (seconda riga), avrà una probabilità di 0.25 di passare allo stato 1; avra una probabilità di 0.5 di rimanere quello stato, \\(P[2, 2]\\); e avrà una probabilità di 0.25 di passare allo stato 3, \\(P[2, 3]\\); eccetera.Si notino alcune importanti proprietà di questa particolare catena di Markov.È possibile passare da ogni stato qualunque altro stato uno o più passaggi: una catena di Markov con questa proprietà si dice irriducibile.Dato che la persona si trova un particolare stato, se può tornare questo stato solo intervalli regolari, si dice che la catena di Markov è periodica. questo esempio la catena è aperiodica poiché la passeggiata casuale non può eitornare allo stato attuale intervalli regolari.Un’importante proprietà di una catena di Markov irriducibile e aperiodica è che il passaggio ad uno stato del sistema dipende unicamente dallo stato immediatamente precedente e non dal come si è giunti tale stato (dalla storia). Per questo motivo si dice che un processo markoviano è senza memoria. Tale “assenza di memoria” può essere interpretata come la proprietà mediante cui è possibile ottenere un insieme di campioni casuali da una distribuzione di interesse. Nel caso dell’inferenza bayesiana, la distribuzione di interesse è la distribuzione posteriori, \\(p(\\theta \\mid y)\\). Le catene di Markov consentono di stimare valori di aspettazione di variabili rispetto alla distribuzione posteriori.La matrice di transizione che si ottiene dopo un enorme numero di passi di una passeggiata casuale markoviana si chiama distribuzione stazionaria. Se una catena di Markov è irriducibile e aperiodica, allora ha un’unica distribuzione stazionaria \\(w\\). La distribuzione limite di una tale catena di Markov, quando il numero di passi tende ’infinito, è uguale alla distribuzione stazionaria \\(w\\).","code":"\np <- c(0, 0, 1, 0, 0, 0)\n\nP <- matrix(\n  c(.5, .5, 0, 0, 0, 0,\n    .25, .5, .25, 0, 0, 0,\n    0, .25, .5, .25, 0, 0,\n    0, 0, .25, .5, .25, 0,\n    0, 0, 0, .25, .5, .25,\n    0, 0, 0, 0, .5, .5\n    ),\n  nrow = 6, ncol = 6, byrow = TRUE)\n\nkableExtra::kable(P)"},{"path":"markov-chains.html","id":"simulare-una-catena-di-markov","chapter":"Appendice H Le catene di Markov","heading":"H.1 Simulare una catena di Markov","text":"Un metodo per dimostrare l’esistenza della distribuzione stazionaria di una catena di Markov è quello di eseguire un esperimento di simulazione. Iniziamo una passeggiata casuale partendo da un particolare stato, diciamo la posizione 3, e quindi simuliamo molti passaggi della catena di Markov usando la matrice di transizione \\(P\\). Al crescere del numero di passi della catena, le frequenze relative che descrivono il passaggio ciascuno dei sei possibili nodi della catena approssimano sempre meglio la distribuzione stazionaria \\(w\\).Senza entrare nei dettagli della simulazione, la figura H.1 mostra risultati ottenuti 10,000 passi di una passeggiata casuale markoviana. Si noti che, ’aumentare del numero di iterazioni, le frequenze relative approssimano sempre meglio le probabilità nella distribuzione stazionaria \\(w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1)\\).\nFIGURA H.1: Frequenze relative degli stati da 1 6 funzione del numero di iterazioni per la simulazione di una catena di Markov.\nIl metodo di campionamento utilizzato dagli algoritmi MCMC consente di creare una catena di Markov irriducibile e aperiodica, la cui distribuzione stazionaria equivale alla distribuzione posteriori \\(p(\\theta \\mid y)\\).","code":"\nset.seed(123)\ns <- vector(\"numeric\", 10000)\ns[1] <- 3\nfor (j in 2:10000) {\n  s[j] <- sample(1:6, size = 1, prob = P[s[j - 1], ])\n}\nS <- data.frame(\n  Iterazione = 1:10000,\n  Location = s\n)\n\nS %>%\n  mutate(\n    L1 = (Location == 1),\n    L2 = (Location == 2),\n    L3 = (Location == 3),\n    L4 = (Location == 4),\n    L5 = (Location == 5),\n    L6 = (Location == 6)\n  ) %>%\n  mutate(\n    Proporzione_1 = cumsum(L1) / Iterazione,\n    Proporzione_2 = cumsum(L2) / Iterazione,\n    Proporzione_3 = cumsum(L3) / Iterazione,\n    Proporzione_4 = cumsum(L4) / Iterazione,\n    Proporzione_5 = cumsum(L5) / Iterazione,\n    Proporzione_6 = cumsum(L6) / Iterazione\n  ) %>%\n  dplyr::select(\n    Iterazione, Proporzione_1, Proporzione_2, Proporzione_3,\n    Proporzione_4, Proporzione_5, Proporzione_6\n  ) -> S1\n\ngather(S1, Outcome, Probability, -Iterazione) -> S2\n\nggplot(S2, aes(Iterazione, Probability)) +\n  geom_line() +\n  facet_wrap(~Outcome, ncol = 3) +\n  ylim(0, .4) +\n  ylab(\"Frequenza relativa\") +\n  # theme(text=element_text(size=14))  +\n  scale_x_continuous(breaks = c(0, 3000, 6000, 9000))"},{"path":"regr-ml.html","id":"regr-ml","chapter":"Appendice I Adattare il modello lineare ai dati","heading":"Appendice I Adattare il modello lineare ai dati","text":"questo Capitolo verranno esposte alcune nozioni matematiche che stanno alla base dell’inferenza sul modello lineare.","code":""},{"path":"regr-ml.html","id":"minimi-quadrati","chapter":"Appendice I Adattare il modello lineare ai dati","heading":"I.1 Minimi quadrati","text":"Nel modello lineare classico, \\(y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\), coefficienti \\(\\beta_0\\) e \\(\\beta_1\\) sono stimati modo tale da minimizzare gli errori \\(\\varepsilon_i\\). Se il numero dei dati \\(n\\) è maggiore di 2, non è generalmente possibile trovare una retta che passi per tutte le osservazioni (\\(x, y\\)) (sarebbe \\(y_i = \\beta_0 + \\beta_1 x_i\\), senza errori, per tutti punti \\(= 1, \\dots, n\\)). L’obiettivo della stima dei minimi quadrati è quello di scegliere valori (\\(\\hat{\\beta}_0, \\hat{\\beta}_1\\)) che minimizzano la somma dei quadrati dei residui,\\[\\begin{equation}\ne_i = y_i − (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)\\,.\n\\end{equation}\\]Distinguiamo tra residui \\(e_i = y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)\\) e gli errori \\(\\varepsilon_i = y_i − (\\beta_0 + \\beta_1 x_i)\\). Il modello di regressione è scritto termini degli errori, ma possiamo solo lavorare con residui: non possiamo calcolare gli errori perché per farlo sarebbe necessario conoscere parametri ignoti \\(\\beta_0\\) e \\(\\beta_1\\).La somma dei residui quadratici (residual sum squares) è\\[\\begin{equation}\n\\text{RSS} = \\sum_{=1}^n (y_i = (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2\\,.\n\\end{equation}\\]coefficienti (\\(\\hat{\\beta}_0, \\hat{\\beta}_1\\)) che minimizzano RSS sono chiamati stime dei minimi quadrati, o minimi quadrati ordinari (ordinari least squares), o stime OLS.","code":""},{"path":"regr-ml.html","id":"stima-della-deviazione-standard-dei-residui-sigma","chapter":"Appendice I Adattare il modello lineare ai dati","heading":"I.1.1 Stima della deviazione standard dei residui \\(\\sigma\\)","text":"Nel modello lineare, gli errori \\(\\varepsilon_i\\) provengono da una distribuzione con media 0 e deviazione standard \\(\\sigma\\): la media è zero per definizione (qualsiasi media diversa da zero viene assorbita nell’intercetta, \\(\\beta_0\\)), e la deviazione standard degli errori può essere stimata dai dati. Un modo apparentemente naturale per stimare \\(\\sigma\\) potrebbe essere quello di calcolare la deviazione standard dei residui, \\(\\sqrt{\\frac{1}{n} \\sum_{=1}^n e_i^2} = \\sqrt{ \\frac{1}{n} \\sum_{=1}^n y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2}\\), ma questo approccio finisce per sottostimare \\(\\sigma\\).\nLa correzione standard di questa sottostima consiste nel sostituire \\(n\\) con \\(n - 2\\) al denominatore (la sottrazione di 2 deriva dal fatto che il valore atteso del modello lineare è stato calcolato utilizzando due coefficienti nel modello, l’intercetta e la pendenza, quali sono stati stimati dai dati campionari – si dice che, questo modo, abbiamo perso due gradi di libertà). Così facendo otteniamo\\[\\begin{equation}\n\\hat{\\sigma} = \\sqrt{\\frac{1}{n-2} \\sum_{=1}^n (y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2}\\, .\n\\end{equation}\\]Quando \\(n = 1\\) o \\(2\\) l’equazione precedente è priva di significato, il che ha senso: con solo due osservazioni è possibile adattare esattamente una retta al diagramma di dispersione e quindi non c’è modo di stimare l’errore dai dati.","code":""},{"path":"regr-ml.html","id":"calcolare-la-somma-dei-quadrati","chapter":"Appendice I Adattare il modello lineare ai dati","heading":"I.2 Calcolare la somma dei quadrati","text":"Seguendo Solomon Kurz, creiamo una funzione per calcolare la somma dei quadrati per diversi valori di \\(\\beta_0\\) e \\(\\beta_1\\) che, per semplicità, qui verranno chiamati \\(\\) e \\(b\\):Per fare un esempio concreto useremo un famoso dataset chiamato kidiq (Gelman, Hill, Vehtari 2020) che riporta dati di un’indagine del 2007 su un campione di donne americane adulte e sui loro bambini di età compresa tra 3 e 4 anni. dati sono costituiti da 434 osservazioni e 4 variabili:kid_score: QI del bambino; è il punteggio totale del Peabody Individual Achievement Test (PIAT) costituito dalla somma dei punteggi di tre sottoscale (Mathematics, Reading comprehension, Reading recognition);mom_hs: variabile dicotomica (0 1) che indica se la madre del bambino ha completato le scuole superiori (1) oppure (0);mom_iq: QI della madre;mom_age: età della madre.Calcoliamo alcune statistiche descrittive:Il QI medio dei bambini è di circa 87 mentre quello della madre è di 100. La gamma di età delle madri va da 17 29 anni con una media di circa 23 anni. Si noti infine che il 79% delle mamme ha un diploma di scuola superiore.Ci poniamo ora il problema di descrivere l’associazione tra il QI dei figli, kid_score, e il QI delle madri, mom_iq, mediante un modello lineare. Le stime dei minimi quadrati sono fornite dalla funzione lm():\nCalcoliamo la somma dei residui quadratici base al modello di regressione \\(\\hat{y}_i = 25.8 + 0.61 x_i\\):Per sviluppare una comprensione intuitiva del metodo dei minimi quadrati, esploriamo valori assunti da rss per diversi valori di \\(\\) e \\(b\\). Per semplicità, manteniamo costante b = 0.61 e variamo valori .Il minimo della funzione che qui abbiamo discretizzato costituisce la stima dei minimi quadrati del parametro \\(\\beta_0\\).Lo stesso può essere fatto per \\(b\\):Il minimo della funzione rappresentata qui sopra costituisce la stima dei minimi quadrati del parametro \\(\\beta_1\\).generale, possiamo dire che il metodo dei minimi quadrati consente di minimizzare la funzione quadratica \\(RSS = \\sum_{=1}^n \\left(y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)\\right)^2\\) rispetto alle due incognite \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\). Numericamente, ciò corrisponde variare sia che b simultaneamente un listato simile quello riportato sopra. Anche se il codice \\(\\R\\) necessario per ottenere questo risultato è più complesso di quello qui esaminato, l’idea di base non cambia.Osservazione. Nelle precedenti istruzioni \\(\\R\\) abbiamo utilizzato la funzione purrr::map_dbl(). Questo oggetto \\(\\R\\) consente di applicare una funzione (questo caso, rss()) ciascun elemento di un vettore input (nel caso presente, il vettore oppure il vettore b). La funzione purrr::map_dbl() ritorna un numero reale.","code":"\nrss <- function(x, y, a, b) {  \n  # x and y are vectors, \n  # a and b are scalars \n  resid <- y - (a + b * x)\n  return(sum(resid^2))\n  }\nlibrary(\"rio\")\ndf <- rio::import(here::here(\"data\", \"kidiq.dta\"))\nhead(df)\n#>   kid_score mom_hs    mom_iq mom_work mom_age\n#> 1        65      1 121.11753        4      27\n#> 2        98      1  89.36188        4      25\n#> 3        85      1 115.44316        4      27\n#> 4        83      1  99.44964        3      25\n#> 5       115      1  92.74571        4      27\n#> 6        98      0 107.90184        1      18\nsummary(df)\n#>    kid_score         mom_hs           mom_iq          mom_work    \n#>  Min.   : 20.0   Min.   :0.0000   Min.   : 71.04   Min.   :1.000  \n#>  1st Qu.: 74.0   1st Qu.:1.0000   1st Qu.: 88.66   1st Qu.:2.000  \n#>  Median : 90.0   Median :1.0000   Median : 97.92   Median :3.000  \n#>  Mean   : 86.8   Mean   :0.7857   Mean   :100.00   Mean   :2.896  \n#>  3rd Qu.:102.0   3rd Qu.:1.0000   3rd Qu.:110.27   3rd Qu.:4.000  \n#>  Max.   :144.0   Max.   :1.0000   Max.   :138.89   Max.   :4.000  \n#>     mom_age     \n#>  Min.   :17.00  \n#>  1st Qu.:21.00  \n#>  Median :23.00  \n#>  Mean   :22.79  \n#>  3rd Qu.:25.00  \n#>  Max.   :29.00\nfm <- lm(kid_score ~ mom_iq, data = df)\nfm %>%\n  tidy() %>% \n  filter(term == c(\"(Intercept)\", \"mom_iq\")) %>% \n  pull(estimate)\n#> [1] 25.7997778  0.6099746\nrss(df$mom_iq, df$kid_score, 25.8, 0.61)\n#> [1] 144137.3\ntibble(a = seq(20, 30, length.out = 30)) %>% \n  mutate(\n    rss = purrr::map_dbl(\n      a, \n      rss, \n      x = df$mom_iq, \n      y = df$kid_score,  \n      b = 0.61)\n    ) %>% \n  ggplot(aes(x = a, y = rss)) +\n  geom_point() +\n  labs(subtitle = \"Il valore b è tenuto costante (b = 0.61)\") \ntibble(b = seq(0.4, 0.8, length.out = 30)) %>% \n  mutate(\n    rss = purrr::map_dbl(\n      b, \n      rss, \n      x = df$mom_iq, \n      y = df$kid_score,  \n      a = 25.8)\n    ) %>% \n  ggplot(aes(x = b, y = rss)) +\n  geom_point() +\n  labs(subtitle = \"Il valore a è tenuto costante (a = 25.8)\") "},{"path":"regr-ml.html","id":"commenti-e-considerazioni-finali-29","chapter":"Appendice I Adattare il modello lineare ai dati","heading":"Commenti e considerazioni finali","text":"Se gli errori del modello lineare sono indipendenti e distribuiti normalmente, modo che \\(y_i \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x_i, \\sigma^2)\\) per ogni \\(\\), allora la stima ai minimi quadrati di (\\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\)) coincide con la stima di massima verosimiglianza di questi parametri. un modello lineare, la funzione di verosimiglianza è definita come la densità di probabilità delle osservazioni, dati parametri e predittori, ovvero,\\[\\begin{equation}\np(y \\mid \\beta_0, \\beta_1, \\sigma, x) = \\prod_{=1}^n \\mathcal{N}(y_i \\mid \\beta_0 + \\beta_1 x_i, \\sigma^2),\n\\tag{.1}\n\\end{equation}\\]dove \\(\\mathcal{N}(\\cdot | \\cdot, \\cdot)\\) è la funzione gaussiana.Un studio della (.1) mostra che la massimizzazione della verosimiglianza richiede la minimizzazione della somma dei quadrati dei residui. Se gli errori sono indipendenti e distribuiti normalmente, quindi, la stima dei minimi quadrati \\(\\hat{\\beta} = (\\hat{\\beta}_0, \\hat{\\beta}_1)\\) coincide con la stima di massima verosimiglianza per parametri del modello lineare.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"introduzione-al-linguaggio-r","chapter":"Appendice J Introduzione al linguaggio R","heading":"Appendice J Introduzione al linguaggio R","text":"questa sezione della dispensa saranno presentate le caratteristiche di base e la filosofia dell’ambiente \\(\\mathsf{R}\\), passando poi illustrare le strutture dati e le principali strutture di controllo. Verranno introdotte alcune funzioni utili per la gestione dei dati e verranno forniti rudimenti per realizzare semplici funzioni. Verranno introdotti tipi di file editabili RStudio (script, markdown, …). Nello specifico, dopo aver accennato alcune caratteristiche del sistema tidyverse, verranno illustrate le principali funzionalità dell’IDE RStudio e dei pacchetti dplyr e ggplot2. Sul web sono disponibili tantissime introduzioni ’uso di \\(\\mathsf{R}\\) come, ad esempio, Hands-Programming R, R Data Science, Data Science Psychologists, e Introduction Data Science.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"prerequisiti","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.1 Prerequisiti","text":"Al fine di utilizzare \\(\\mathsf{R}\\) è necessario eseguire le seguenti tre operazioni\nnell’ordine dato:Installare \\(\\mathsf{R}\\);Installare RStudio;Installare R-Packages (se necessario).Di seguito viene descritto come installare \\(\\mathsf{R}\\) e RStudio.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"installare-r-e-rstudio","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.1.1 Installare R e RStudio","text":"\\(\\mathsf{R}\\) è disponibile gratuitamente ed è scaricabile dal sito\nhttp://www.rproject.org/. Dalla pagina principale del sito\nr-project.org andiamo sulla sezione Download e scegliamo un server \npiacimento per scaricare il software d’installazione. Una volta\nscaricato l’installer, lo installiamo come un qualsiasi software,\ncliccando due volte sul file d’istallazione. Esistono versioni di \\(\\mathsf{R}\\) per\ntutti più diffusi sistemi operativi (Windows, Mac OS X e Linux).Il R Core Development Team lavora continuamente per migliorare le\nprestazioni di \\(\\mathsf{R}\\), per correggere errori e per consentire l’uso di con\nnuove tecnologie. Di conseguenza, periodicamente vengono rilasciate\nnuove versioni di \\(\\mathsf{R}\\). Informazioni questo proposito sono fornite sulla\npagina web https://www.r-project.org/. Per installare una nuova\nversione di \\(\\mathsf{R}\\) si segue la stessa procedura che è stata seguita per la\nprima installazione.Insieme al software si possono scaricare dal sito principale sia manuali d’uso che numerose dispense per approfondire diversi aspetti di \\(\\mathsf{R}\\). particolare, nel sito http://cran.r-project.org/-docs.html si possono trovare anche numerose dispense italiano (sezione “languages”).Dopo avere installato \\(\\mathsf{R}\\) è opportuno installare anche RStudio. RStudio si\npuò scaricare da https://www.rstudio.com/. Anche RStudio è disponibile\nper tutti più diffusi sistemi operativi.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"utilizzare-rstudio-per-semplificare-il-lavoro","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.1.2 Utilizzare RStudio per semplificare il lavoro","text":"Possiamo pensare ad \\(\\mathsf{R}\\) come al motore di un automobile e RStudio come\nal cruscotto di un automobile. Più precisamente, \\(\\mathsf{R}\\) è un linguaggio di\nprogrammazione che esegue calcoli mentre RStudio è un ambiente di\nsviluppo integrato (IDE) che fornisce un’interfaccia grafica aggiungendo\nuna serie di strumenti che facilitano la fase di sviluppo e di\nesecuzione del codice. Utilizzeremo dunque \\(\\mathsf{R}\\) mediante RStudio. altre\nparole,non apriteaprite inveceL’ambiente di lavoro di RStudio è costituito da quattro finestre: la finestra del codice (scrivere-eseguire script), la finestra della console (riga di comando -\noutput), la finestra degli oggetti (elenco oggetti-cronologia dei\ncomandi) e la finestra dei pacchetti-dei grafici-dell’aiuto linea.La console di RStudio.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"eseguire-il-codice","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.1.3 Eseguire il codice","text":"Mediante il menu tendina di RStudio, scegliendo il percorsooppurel’utente può aprire nella finestra del codice (alto destra) un \\(\\mathsf{R}\\) Notebook o un \\(\\mathsf{R}\\) script dove inserire le istruzioni da eseguire.un \\(\\mathsf{R}\\) script, un blocco di codice viene eseguito selezionando un\ninsieme di righe di istruzioni e digitando la sequenza di tasti\nCommand + Invio sul Mac, oppure Control + Invio su Windows. \nun R Notebook, un blocco di codice viene eseguito schiacciando il\nbottone con l’icona \\(\\color{red}\\blacktriangleright\\) (“Run current\nchunk”) posizionata destra rispetto al codice.","code":"File > New File > R NotebookFile > New File > R Script"},{"path":"introduzione-al-linguaggio-r.html","id":"installare-cmdstan","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.2 Installare cmdstan","text":"È possibile installare cmdstan almento tre modi. Per informazioni dettagliate, si vedano le istruzioni CmdStan Installation.Prima di installare cmdstan, tre raccomandazioni generali:usare la versione più recente del sistema operativo;usare la versione più recente di RStudio;usare la versione più recente di \\(\\mathsf{R}\\).Se tre vincoli precedenti sono soddisfatti, l’installazione di cmdstan dovrebbe procedere senza intoppi. Altrimenti si possono creare dei problemi di non facile soluzione.Il modo più semplice per installare cmdstan è quello di installare prima cmdstanr per poi utilizzare le funzionalità di quel pacchetto per l’installazione di cmdstan.Un secondo metodo (che è quello che io uso normalmente) è quello di installare dal sorgente, seguendo le istruzioni riportante su CmdStan Installation.Un terzo metodo (che richiede una minima comprensione delle funzionalità della shell e di Python) richiede, avendo prima installato Anaconda, di digitare sulla console del proprio computer (la shell) le seguenti istruzioni:Su macos, prima di installare cmdstan, è necessario installare la versione più recente di Xcode. Dopo avere installato Xcode, aprire la app. Verrà chiesto ’utente se si vogliono istallare delle componenti aggiuntive. Questo passaggio è cruciale, perché senza queste componenti aggiuntive cmdstan non funzionerà. Dopo avere installato le componenti aggiuntive, aprire Xcode e, caso, accettare termini della licenza. quel punto si può chiudere Xcode. Ogni volta che Xcode viene aggiornato (deve sempre essere aggiornato quando un aggiornamento è disponibile), queste operazioni vanno ripetute.","code":"conda create -n stan-env -c conda-forge cmdstan\nconda activate stan-env"},{"path":"introduzione-al-linguaggio-r.html","id":"chapter-sintassi","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3 Sintassi di base","text":"\\(\\mathsf{R}\\) è un linguaggio di programmazione orientato ’analisi dei dati, il\ncalcolo e la visualizzazione grafica. È disponibile su Internet una\nvasta gamma di materiali utile per avvicinarsi ’ambiente \\(\\mathsf{R}\\) e aiutare\nl’utente nell’apprendimento di questo software statistico. Cercheremo\nqui di fornire alcune indicazioni e una breve descrizione delle risorse\ndi base di \\(\\mathsf{R}\\).Aggiungo qui sotto alcune considerazioni che ho preso, pari pari, da un testo che tratta di un altro linguaggio di programmazione, ma che si applicano perfettamente anche al caso nostro. “Come ogni linguaggio, per parlare R è necessario seguire un insieme di regole. Come tutti linguaggi di programmazione, queste regole sono del tutto inflessibili e inderogabili. R, un enunciato o è sintatticamente corretto o è incomprensibile ’interprete, che lo segnalerà ’utente. Questo aspetto non è esattamente amichevole per chi non è abituato ai linguaggi di programmazione, e si trova così costretto ad una precisione di scrittura decisamente poco”analogica”. Tuttavia, ci sono due aspetti positivi nello scrivere codice, interrelati tra loro. Il primo è lo sforzo analitico necessario, che allena ad un’analisi precisa del problema che si vuole risolvere modo da poterlo formalizzare linguisticamente. Il secondo concerne una forma di autoconsapevolezza specifica: salvo “bachi” nel linguaggio (rarissimi sebbene possibili), il mantra del programmatore è “Se qualcosa non ti funziona, è colpa tua” (testo adattato da Andrea Valle).chi preferisce un approccio più “giocoso” posso suggerire il seguente link.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"utilizzare-la-console-mathsfr-come-calcolatrice","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.1 Utilizzare la console \\(\\mathsf{R}\\) come calcolatrice","text":"La console di RStudio contiene un cursore rappresentato dal simbolo “>”\n(linea di comando) dove si possono inserire comandi e le funzioni –\nrealtà è sempre meglio utilizzare un \\(\\mathsf{R}\\) Notebook anziché la console,\nma per ora esaminiamo il funzionamento di quest’ultima.La console di RStudio può essere utilizzata come semplice calcolatrice.\ncomandi elementari consistono di espressioni o di assegnazioni. Le\noperazioni aritmetiche vengono eseguite mediante simboli “standard:” +,\n*, -, /, sqrt(), log(), exp(), …comandi sono separati da un carattere di nuova linea (si immette un\ncarattere di nuova linea digitando il tasto Invio). Se un comando non\nè completo alla fine della linea, \\(\\mathsf{R}\\) darà un prompt differente che per\ndefault è il carattere + sulla linea seguente e continuerà leggere\nl’input finché il comando non è sintatticamente completo. Ad esempio,\\(\\mathsf{R}\\) è un ambiente interattivo, ossia comandi producono una risposta immediata. Se scriviamo 2 + 2 e premiamo il tasto di invio, comparirà nella riga successiva il risultato:Il risultato è preceduto da [1], il che significa che il risultato dell’operazione che abbiamo appena eseguito è il primo valore di questa linea. Alcune funzioni ritornano più di un singolo numero e, quel caso, l’informazione fornita da \\(\\mathsf{R}\\) è più utile. Per esempio, l’istruzione 100:130 ritorna \\(31\\) valori, ovvero numeri da \\(100\\) \\(130\\):questo caso, sul mio computer, [24] indica che il valore \\(123\\) è il ventiquattresimo numero che è stato stampato sulla console – su un altro computer le cose possono essere diverse quanto il risultato, credo, dipende dalla grandezza dello schermo.","code":"\n4 -\n+ \n+ 1\n#> [1] 3\n2 + 2\n#> [1] 4\n100:130\n#>  [1] 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n#> [20] 119 120 121 122 123 124 125 126 127 128 129 130"},{"path":"introduzione-al-linguaggio-r.html","id":"espressioni","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.2 Espressioni","text":"questo corso, cercheremo di evitare numeri nei nomi R, così come le lettere maiuscole e .. Useremo quindi nomi come: my_data, anova_results, square_root, ecc.Un’espressione \\(\\mathsf{R}\\) è un enunciato finito e autonomo del linguaggio: una frase conclusa, si potrebbe dire. Si noti che le espressioni \\(\\mathsf{R}\\) non sono delimitate dal ; come succede alcuni linguaggi di programmazione. L’ordine delle espressioni è l’ordine di esecuzione delle stesse.L’capo non è rilevante per \\(\\mathsf{R}\\). Questo permette di utilizzare l’capo per migliorare la leggibilità del codice.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"oggetti","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.3 Oggetti","text":"\\(\\mathsf{R}\\) è un linguaggio di programmazione oggetti, quindi si basa sulla creazione di oggetti e sulla possibilità di salvarli nella memoria del programma. \\(\\mathsf{R}\\) distingue tra maiuscole e minuscole come la maggior parte dei linguaggi basati su UNIX, quindi e sono nomi diversi e fanno riferimento oggetti diversi.comandi elementari di \\(\\mathsf{R}\\) consistono espressioni o assegnazioni.Se un’espressione viene fornita come comando, viene valutata, stampata sullo schermo e il valore viene perso, come succedeva alle operazioni aritmetiche che abbiamo presentato sopra discutendo l’uso della console \\(\\mathsf{R}\\) come calcolatrice.Un’assegnazione crea un oggetto oppure valuta un’espressione e passa il valore un oggetto, ma il risultato non viene stampato automaticamente sullo schermo. Per l’operazione di assegnazione si usa il simbolo <-. Ad esempio, per creare un oggetto che contiene il risultato dell’operazione 2 + 2 procediamo nel modo seguente:L’operazione di assegnazione (<-) copia il contenuto dell’operando destro (detto r-value) nell’operando sinistro detto (l-value). Il valore dell’espressione assegnazione è r-value. Nell’esempio precedente, res_sum (l-value) assume il valore di \\(4\\).","code":"\nres_sum <- 2 + 2\nres_sum\n#> [1] 4"},{"path":"introduzione-al-linguaggio-r.html","id":"variabili","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.4 Variabili","text":"L’oggetto res_sum è una variabile. Una spiegazione di ciò che questo significa è riportata qui sotto. “Una variabile è un segnaposto. Tutte le volte che si memorizza un dato lo si assegna ad una variabile. Infatti, se il dato è nella memoria, per potervi accedere, è necessario conoscere il suo indirizzo, la sua “etichetta” (come un grande magazzino cui si va cercare un oggetto base alla sua collocazione). Se il dato è memorizzato ma inaccessibile (come nel caso di un oggetto sperso un magazzino), allora non si può usare ed è soltanto uno spreco di spazio. La teoria delle variabili è un ambito molto complesso nella scienza della computazione. Ad esempio, una aspetto importante può concernere la tipizzazione delle variabili. Nei linguaggi “tipizzati” (ad esempio C), l’utente dichiara che userà quella etichetta (la variabile) per contenere solo ed esclusivamente un certo tipo di oggetto (ad esempio, un numero intero), e la variabile non potrà essere utilizzata per oggetti diversi (ad esempio, una stringa). questo caso, prima di usare una variabile se ne dichiara l’esistenza e se ne specifica il tipo. linguaggi non tipizzati non richiedono ’utente di specificare il tipo, che viene inferito vario modo (ad esempio, funzione dell’assegnazione del valore alla variabile). Alcuni linguaggi (ad esempio Python) non richiedono neppure la dichiarazione della variabile, che viene semplicemente usata. È l’interprete che inferisce che quella stringa è una variabile. La tipizzazione impone vincoli d’uso sulle variabili e maggiore scrittura del codice, ma assicura una chiara organizzazione dei dati. assenza di tipizzazione, si lavora maniera più rapida e snella, ma potenzialmente si può andare incontro situazioni complicate, come quando si cambia il tipo di una variabile “corsa” senza accorgersene” (Andrea Valle).\\(\\mathsf{R}\\) è un linguaggio non tipicizzato, come Python. \\(\\mathsf{R}\\) non è necessario dichiarare le variabili che si intendono utilizzare, né il loro tipo.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"r-console","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.5 R console","text":"La console di RStudio fornisce la possibilità di richiamare e rieseguire\ncomandi. tasti freccia verticale, \\(\\uparrow\\) e \\(\\downarrow\\), sulla\ntastiera possono essere utilizzati per scorrere avanti e indietro \ncomandi già immessi. Appena trovato il comando che interessa, lo si può\nmodificare, ad esempio, con tasti freccia orizzontali, immettendo\nnuovi caratteri o cancellandone altri.Se viene digitato un comando che \\(\\mathsf{R}\\) non riconosce, sulla console viene visualizzato un messaggio di errore; ad esempio,","code":"3 % 9\nErrore: unexpected input in \"3 % 9\""},{"path":"introduzione-al-linguaggio-r.html","id":"parentesi","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.6 Parentesi","text":"Le parentesi \\(\\mathsf{R}\\) (come generale ogni linguaggio di programmazione) assegnano un significato diverso alle porzioni di codice che delimitano.Le parentesi tonde funzionano come nell’algebra. Per esempionon è equivalente aLe due istruzioni precedenti producono risultati diversi perché, se\nla sequenza delle operazioni algebriche non viene specificata dalle\nparentesi, \\(\\mathsf{R}\\) assegna alle operazioni algebriche il seguente ordine\ndi priorità decrescente: esponenziazione, moltiplicazione /\ndivisione, addizione / sottrazione, confronti logici\n(<, >, <=, >=, ==, !=). È sempre una buona idea rendere esplicito\nl’ordine delle operazioni algebriche che si vuole eseguire mediante\nl’uso delle parentesi tonde.\nLe parentesi tonde vengono anche utilizzate per le funzioni, come\nvedremo nei prossimi paragrafi. Tra le parentesi tonde avremo dunque\nl’oggetto cui vogliamo applicare la funzione e gli argomenti\npassati alla funzione.Le parentesi graffe sono destinate alla programmazione. Un blocco\ntra le parentesi graffe viene letto come un oggetto unico che può\ncontenere una o più istruzioni.Le parentesi graffe sono destinate alla programmazione. Un blocco\ntra le parentesi graffe viene letto come un oggetto unico che può\ncontenere una o più istruzioni.Le parentesi quadre vengono utilizzate per selezionare degli\nelementi, per esempio ’interno di un vettore, o di una matrice, o\ndi un data.frame. L’argomento entro le parentesi quadre può essere\ngenerato da espressioni logiche.Le parentesi quadre vengono utilizzate per selezionare degli\nelementi, per esempio ’interno di un vettore, o di una matrice, o\ndi un data.frame. L’argomento entro le parentesi quadre può essere\ngenerato da espressioni logiche.","code":"\n2 + 3 * 4\n#> [1] 14\n(2 + 3) * 4\n#> [1] 20"},{"path":"introduzione-al-linguaggio-r.html","id":"i-nomi-degli-oggetti","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.7 I nomi degli oggetti","text":"Le entità create e manipolate da \\(\\mathsf{R}\\) si chiamano ‘oggetti’. Tali oggetti\npossono essere variabili (come nell’esempio che abbiamo visto sopra), array di numeri, caratteri, stringhe, funzioni, o più generale strutture costruite partire da tali\ncomponenti. Durante una sessione di R gli oggetti sono creati e\nmemorizzati attraverso opportuni nomi.nomi possono contenere un qualunque carattere alfanumerico e come\ncarattere speciale il trattino basso (_) o il punto. R fornisce \nseguenti vincoli per nomi degli oggetti: nomi degli oggetti non\npossono mai iniziare con un carattere numerico e non possono contenere \nseguenti simboli: $, @, !, ^, +, -, /, *. È buona\npratica usare nomi come ratio_of_sums. È fortemente sconsigliato\nutilizzare nei nomi degli oggetti caratteri accentati o, ancora peggio,\napostrofi. Per questa ragione è sensato creare nomi degli oggetti\nutilizzando la lingua inglese. È anche bene che nomi degli oggetti non\ncoincidano con nomi di funzioni. Ricordo nuovamente che \\(\\mathsf{R}\\) è case sensitive, cioè\ne sono due simboli diversi e identificano due oggetti\ndifferenti.questo corso cercheremo di evitare numeri nei nomi degli oggetti \\(\\mathsf{R}\\), così come le lettere maiuscole e il punto. Useremo quindi nomi come: my_data, regression_results, square_root, ecc.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"permanenza-dei-dati-e-rimozione-di-oggetti","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.8 Permanenza dei dati e rimozione di oggetti","text":"Gli oggetti vengono salvati nello “spazio di lavoro” (workspace). Il\ncomando ls() può essere utilizzato per visualizzare nomi degli\noggetti che sono quel momento memorizzati \\(\\mathsf{R}\\).Per eliminare oggetti dallo spazio di lavoro è disponibile la funzione\nrm(); ad esempiocancella tutti gli oggetti indicati entro parentesi. Per eliminare tutti\ngli oggetti presenti nello spazio di lavoro si può utilizzare la\nseguente istruzione:","code":"\nrm(x, y, z, ink, junk, temp, foo, bar)\nrm(list = ls())"},{"path":"introduzione-al-linguaggio-r.html","id":"chiudere-r","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.9 Chiudere R","text":"Quando si chiude RStudio il programma ci chiederà se si desidera salvare\nl’area di lavoro sul computer. Tale operazione è da evitare quanto\ngli oggetti così salvati andranno ad interferire con gli oggetti creati\nun lavoro futuro. Si consiglia dunque di rispondere negativamente \nquesta domanda.RStudio, selezionare Preferences dal menu tendina e, \nR General Workspace, deselezionare l’opzione\nRestore .RData workspace start- e scegliere l’opzione\nNever nella finestra di dialogo Save workspace \n.RData exit.RStudio, selezionare Preferences dal menu tendina e, \nR General Workspace, deselezionare l’opzione\nRestore .RData workspace start- e scegliere l’opzione\nNever nella finestra di dialogo Save workspace \n.RData exit.R, selezionare Preferences dal menu tendina e, Startup,\nselezionare l’opzione corrispondenza dell’item\nSave workspace exit R.R, selezionare Preferences dal menu tendina e, Startup,\nselezionare l’opzione corrispondenza dell’item\nSave workspace exit R.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"creare-ed-eseguire-uno-script-r-con-un-editore","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.10 Creare ed eseguire uno script R con un editore","text":"È molto più facile interagire con R manipolando uno script con un\neditore piuttosto che inserendo direttamente le istruzioni nella\nconsole. \\(\\mathsf{R}\\) fornisce il Text Editor dove è possibile inserire il codice\n(File \\(\\\\) New Script). Per salvare il file basta utilizzare l’apposito\nmenù tendina (estensione .R). Tale file potrà poi essere riaperto ed\nutilizzato un momento successivo.L’editore comunica con \\(\\mathsf{R}\\) nel modo seguente: dopo avere selezionato la\nporzione di codice che si vuole eseguire, si digita un’apposita sequenza\ndi tasti (Command + Enter su Mac OS X e ctrl + r Windows).\nctrl + r significa premere il tasto ctrl e, tenendolo premuto, premere il tasto \\(\\mathsf{R}\\) della tastiera.\nCosì facendo, \\(\\mathsf{R}\\) eseguirà le istruzioni selezionate e l’output verrà\nstampato sulla console. Il Text Editor fornito da \\(\\mathsf{R}\\) è piuttosto\nprimitivo: è fortemente consigliato utilizzare RStudio.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"commentare-il-codice","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.11 Commentare il codice","text":"Un “commento” è una parte di codice che l’interprete non tiene considerazione. Quando l’interprete arriva ad un segnalatore di commento salta fino al segnalatore di fine commento e di lì riprende il normale processo esecutivo.commenti sono parole linguaggio naturale (nel nostro caso l’italiano), che permettono agli utilizzatori di capire il flusso logico del codice e chi lo ha scritto di ricordare il perché di determinate istruzioni.\\(\\mathsf{R}\\), le parole dopo il simbolo # sono considerate commenti e sono ignorate; ad esempio:","code":"\n# Questo e' un commento"},{"path":"introduzione-al-linguaggio-r.html","id":"cambiare-la-cartella-di-lavoro","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.12 Cambiare la cartella di lavoro","text":"Quando si inizia una sessione di lavoro, \\(\\mathsf{R}\\) sceglie una cartella quale\n“working directory”. Sarà tale cartella che andrà cercare gli\nscript definiti dall’utilizzatore e file dei dati. È possibile\ndeterminare quale sia la corrente “working directory” digitando sulla\nconsole di RStudio l’istruzione:Per cambiare la cartella di lavoro (maniera tale che corrisponda alla\ncartella nella quale sono stati salvati dati e gli script da eseguire)\nsi sceglie la voce Set Working Directory sul menù tendina di RStudio\ne si selezione la voce Choose Directory… Nella finestra che compare,\nsi cambia la cartella con quella che si vuole.","code":"\ngetwd()"},{"path":"introduzione-al-linguaggio-r.html","id":"loggetto-base-di-r-il-vettore","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.13 L’oggetto base di R: il vettore","text":"\\(\\mathsf{R}\\) opera su strutture di dati; la più semplice di tali strutture è il\nvettore numerico, che consiste un insieme ordinato di numeri; ad\nesempio:Nell’istruzione precedente, c() è una funzione. R gli argomenti\nsono passati alle funzioni inserendoli ’interno delle parentesi\ntonde. Si noti che gli argomenti (questo caso, numeri\n\\(7.0, 10.2, -2.9, 21.4\\)) sono separati virgole. La funzione c() può\nprendere un numero arbitrario di argomenti e genera un vettore\nconcatenando suoi argomenti. L’operatore <- assegna un nome al\nvettore che è stato creato. Nel caso presente, digitando x possiamo\nvisualizzare il vettore che abbiamo creato:Se invece eseguiamo l’istruzionesenza assegnazione, il valore dell’espressione sarà visualizzato nella\nconsole, ma il vettore non potrà essere utilizzato nessun altro modo.","code":"\nx <- c(7.0, 10.2, -2.9, 21.4)\nx\n#> [1]  7.0 10.2 -2.9 21.4\nc(7.0, 10.2, -2.9, 21.4)\n#> [1]  7.0 10.2 -2.9 21.4"},{"path":"introduzione-al-linguaggio-r.html","id":"operazioni-vettorializzate","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.14 Operazioni vettorializzate","text":"Molte operazioni \\(\\mathsf{R}\\) sono vettorializzate, il che significa che esse\nsono eseguite parallelo determinati oggetti. Ciò consente di\nscrivere codice che sia efficiente, conciso e più facile da leggere\nrispetto al codice che contiene istruzioni non vettorializzate.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"vettori-aritmetici","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.15 Vettori aritmetici","text":"L’esempio più semplice che illustra come si svolgono le operazioni\nvettorializzate riguarda le operazioni algebriche applicate ai vettori.\nvettori, infatti, possono essere utilizzati espressioni numeriche\nnelle quali le operazioni algebriche vengono eseguite “elemento per\nelemento”.Per illustrare questo concetto, definiamo il vettore die che contiene\npossibili risultati del lancio di un dado:Supponiamo di volere sommare \\(10\\) ciascun elemento del vettore die.\nDato che le operazioni sui vettori sono eseguite elemento per elemento,\nper ottenere questo risultato è sufficiente eseguire l’istruzione:Si noti come la costante \\(10\\) sia stata sommata ciascun elemento del\nvettore. maniera corrispondente, l’istruzionesottrarrà un’unità da ciascuno degli elementi del vettore die.Se l’operazione aritmetica coinvolge due o più vettori, R allinea vettori ed esegue una sequenza di operazioni elemento per elemento. Per esempio, l’istruzionefa sì che due vettori vengano disposti l’uno di fianco ’altro per poi moltiplicare gli elementi corrispondenti: il primo elemento del primo vettore per il primo elemento del secondo vettore e così via. Il vettore risultante avrà la stessa dimensione dei due vettori che sono stati moltiplicati, come indicato qui sotto:\\[\n\\begin{array}{ccccc}\n1 & \\times & 1 & \\& 1 \\\\\n2 & \\times & 2 & \\& 4 \\\\\n3 & \\times & 3 & \\& 9 \\\\\n4 & \\times & 4 & \\& 16 \\\\\n5 & \\times & 5 & \\& 25 \\\\\n6 & \\times & 6 & \\& 36 \\\\\n\\hline\n\\verb+die+ & * & \\verb+die+ & = &\n\\end{array}\n\\]Oltre agli operatori aritmetici elementari +, -, *, /, e ^ per\nl’elevamento potenza, sono disponibili le più comuni funzioni\nmatematiche: log(), exp(), sin(), cos(), tan(), sqrt(),\nmax(), min() e così via. Altre funzioni di uso comune sono:\nrange() che restituisce un vettore c(min(x), max(x)); sort() che\nrestituisce un vettore ordinato; length(x) che restituisce il numero\ndi elementi di x; sum(x) che dà la somma degli elementi di x,\nmentre prod(x) dà il loro prodotto. Due funzioni statistiche di uso\ncomune sono mean(x), la media aritmetica, e var(x), la varianza.","code":"\ndie <- c(1, 2, 3, 4, 5, 6)\ndie\n#> [1] 1 2 3 4 5 6\ndie + 10\n#> [1] 11 12 13 14 15 16\ndie - 1\n#> [1] 0 1 2 3 4 5\ndie * die\n#> [1]  1  4  9 16 25 36"},{"path":"introduzione-al-linguaggio-r.html","id":"generazione-di-sequenze-regolari","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.16 Generazione di sequenze regolari","text":"\\(\\mathsf{R}\\) possiede un ampio numero di funzioni per generare sequenze di numeri.\nAd esempio, c(1:10) è il vettore c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10).\nL’espressione c(30:1) può essere utilizzata per generare una sequenza\n’indietro.La funzione seq() genera un vettore che contiene una sequenza regolare\ndi numeri, generata base determinate regole. Può avere 5 argomenti:\nprimi due rappresentano l’inizio () e la fine () della\nsequenza, il terzo specifica l’ampiezza del passo (), il quarto la\nlunghezza della sequenza (length.) e infine il quinto\n(along.), che se utilizzato deve essere l’unico parametro\npresente, è il nome di un vettore, ad esempio x, creando tal modo\nla sequenza 1, 2, …, length(x). Esempi di utilizzo della funzione\nseq() sono seguenti:Altra funzione utilizzata per generare sequenze è rep() che può essere\nutilizzata per replicare un oggetto vari modi. Ad esempio:metterà tre copie di die nell’oggetto die3.","code":"\nseq(from = 1, to = 10)\n#>  [1]  1  2  3  4  5  6  7  8  9 10\nseq(-5, 5, by = 2.5)\n#> [1] -5.0 -2.5  0.0  2.5  5.0\nseq(from = 1, to = 7, length.out = 4)\n#> [1] 1 3 5 7\nseq(along.with = die)\n#> [1] 1 2 3 4 5 6\ndie3 <- rep(die, times = 3)\ndie3\n#>  [1] 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6"},{"path":"introduzione-al-linguaggio-r.html","id":"generazione-di-numeri-casuali","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.17 Generazione di numeri casuali","text":"La funzione sample() è una delle tante funzioni che possono essere\nusate per generare numeri casuali. Per esempio, la seguente istruzione\nsimula dieci lanci di un dado sei facce:Il primo argomento di sample() è il vettore da cui la funzione\nestrarrà degli elementi caso; il secondo argomento specifica che\ndovranno essere effettuate 10 estrazioni casuali; il terzo argomento\nspecifica che le estrazioni sono con rimessa (cioè, lo stesso elemento\npuò essere estratto più di una volta).Scegliere un elemento caso dal vettore \\(\\{1, 2, 3, 4, 5, 6\\}\\) è\nequivalente lanciare un dado e osservare la faccia che si presenta.\nL’istruzione precedente corrisponde dunque alla simulazione di dieci\nlanci di un dado sei facce.","code":"\nroll <- sample(1:6, 10, replace = TRUE)\nroll\n#>  [1] 1 3 3 6 3 1 2 2 6 6"},{"path":"introduzione-al-linguaggio-r.html","id":"vettori-logici","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.18 Vettori logici","text":"Quando si manipolano vettori, talvolta si vogliono trovare gli\nelementi che soddisfano determinate condizioni logiche. Per esempio, \ndieci lanci di un dado, quante volte è uscito \\(5\\)? Per rispondere \nquesta domanda si possono usare gli operatori logici <, > e == per\nle operazioni di “minore di,” “maggiore di” e “uguale ”. Se scriviamocreiamo un vettore costituito da elementi TRUE/FALSE quali\nidentificano gli elementi del vettore che soddisfano la condizione\nlogica specificata.Possiamo trattare tale vettore come se fosse costituito da elementi di\nvalore \\(0\\) e \\(1\\). Sommando gli elementi di tale vettore, infatti,\npossiamo contare il numero di “5”:","code":"\nroll == 5\n#>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\nsum(roll == 5)\n#> [1] 0"},{"path":"introduzione-al-linguaggio-r.html","id":"dati-mancanti","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.19 Dati mancanti","text":"Quando si è presenza di un dato mancante, R assegna il valore\nspeciale NA, che sta per Available. generale, un’operazione\nsu un NA dà come risultato un NA. Nell’uso delle funzioni che\noperano sui dati sarà dunque necessario specificare che, qualunque\noperazione venga effettuata, gli NA devono essere esclusi.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"vettori-di-caratteri-e-fattori","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.20 Vettori di caratteri e fattori","text":"vettori di caratteri si creano formando una sequenza di caratteri\ndelimitati da doppie virgolette e possono essere concatenati un\nvettore attraverso la funzione c(). Successivamente, si può applicare\nla funzione factor(), che definisce automaticamente le modalità della\nvariabile categoriale. Ad esempio,Talvolta l’ordine dei livelli del fattore non importa, mentre altre\nvolte l’ordine è importante, per esempio, quando una variable\ncategoriale viene rappresentata un grafico. Per specificare l’ordine\ndei livelli del fattore si usa la seguente sintassi:","code":"\nsoc_status <- factor(\n  c(\"low\", \"high\", \"medium\", \"high\", \"low\", \"medium\", \"high\")\n)\nlevels(soc_status)\n#> [1] \"high\"   \"low\"    \"medium\"\nsoc_status <- \n  factor(soc_status, levels = c(\"low\", \"medium\", \"high\"))\nlevels(soc_status)\n#> [1] \"low\"    \"medium\" \"high\""},{"path":"introduzione-al-linguaggio-r.html","id":"funzioni-1","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.21 Funzioni","text":"\\(\\mathsf{R}\\) offre la possibilità di utilizzare un’enorme libreria di funzioni che\npermettono di svolgere operazioni complicate, quali ad esempio, il\ncampionamento casuale. Esaminiamo ora con più attenzione le proprietà\ndelle funzioni di \\(\\mathsf{R}\\) utilizzando ancora l’esempio del lancio di un dado.\nAbbiamo visto precedenza come il lancio di un dado possa essere\nsimulato da R con la funzione sample(). La funzione sample() prende\ntre argomenti: il nome di un vettore, un numero chiamato size e un\nargomento chiamato replace. La funzione sample() ritorna un numero\ndi elementi del vettore pari size. Ad esempioAssegnando TRUE ’argomento replace specifichiamo che vogliamo un\ncampionamento con rimessa.Se volgiamo eseguire una serie di lanci indipendenti di un dado,\neseguiamo ripetutamente la funzione sample() ponendo size uguale \n1:Come si fa sapere quanti e quali argomenti sono richiesti da una\nfunzione? Tale informazione viene fornita dalla funzione args(). Nel\nnostro casoci informa che il primo argomento è un vettore chiamato x, il secondo\nargomento è chiamato size ed ha il significato descritto sopra, il\nterzo argomento, replace, specifica se il campionamento è eseguito con\no senza reimmissione, e il quarto argomento, prob, assegna delle\nprobabilità agli elementi del vettore. Il significato degli argomenti\nviene spiegato nel file di help della funzione. Si noti che agli ultimi\ndue argomenti sono stati assegnati dei valori, detti di default. Ciò\nsignifica che, se l’utilizzatore non li cambia, verranno usati da . La\nspecificazione replace = FALSE significa che il campionamento viene\neseguito senza reimmissione. Se desideriamo un campionamento con\nreimmissione, basta specificare replace = TRUE (nel caso di una\nsingola estrazione è ovviamente irrilevante). Ad esempio, l’istruzione\nseguente simula risultati di 10 lanci indipendenti di un dado:Infine, prob = NULL specifica che non viene alterata la probabilità di\nestrazione degli elementi del vettore. generale, gli argomenti di una\nfunzione possono essere oggetti come vettori, matrici, altre funzioni,\nparametri o operatori logici.\\(\\mathsf{R}\\) ha un sistema di help interno formato HTML che si richiama con\nhelp.start(). Per avere informazioni su qualche funzione specifica,\nper esempio la funzione sample(), il comando da utilizzare è\nhelp(sample) oppure ?sample.","code":"\nsample(die, 2, replace = TRUE)\n#> [1] 3 4\nsample(die, 1, replace = TRUE)\n#> [1] 3\nsample(die, 1, replace = TRUE)\n#> [1] 2\nsample(die, 1, replace = TRUE)\n#> [1] 5\nargs(sample)\n#> function (x, size, replace = FALSE, prob = NULL) \n#> NULL\nsample(die, 10, replace = TRUE)\n#>  [1] 3 6 1 3 3 4 3 6 3 4"},{"path":"introduzione-al-linguaggio-r.html","id":"scrivere-proprie-funzioni","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.22 Scrivere proprie funzioni","text":"Abbiamo visto precedenza come sia possibile simulare risultati\nprodotti da dieci lanci di un dado o, maniera equivalente, dal\nsingolo lancio di dieci dadi. Possiamo replicare questo processo\ndigitando ripetutamente le stesse istruzioni nella console. Otterremo\nogni volta risultati diversi perché, ad ogni ripetizione, il generatore\ndi numeri pseudo-casuali di R dipende dal valore ottenuto dal clock\ninterno della macchina. La funzione set.seed() ci permette di\nreplicare esattamente risultati della generazione di numeri casuali.\nPer ottenere questo risultato, basta assegnare al seed un numero\narbitrario, es. set.seed(12345). Tuttavia, questa procedura è\npraticamente difficile da perseguire se il numero di ripetizioni è alto.\ntal caso è vantaggioso scrivere una funzione contenente il codice che\nspecifica il numero di ripetizioni. questo modo, per trovare il\nrisultato cercato basterà chiamare la funzione una sola volta.Le funzioni utilizzate da \\(\\mathsf{R}\\) sono costituite da tre elementi: il nome, il blocco del\ncodice e una serie di argomenti. Per creare una funzione è necessario\nimmagazzinare R questi tre elementi e function() consente di\nottenere tale risultato usando la sintassi seguente:Una chiamata di funzione è poi eseguita nel seguente modo:Per potere essere utilizzata, una funzione deve essere presente nella\nmemoria di lavoro di \\(\\mathsf{R}\\). Le funzioni salvate un file possono essere\nrichiamate utilizzando la funzione source(), ad esempio,\nsource(\"file_funzioni.R\").Consideriamo ora la funzione two_rolls() che ritorna la somma dei\npunti prodotti dal lancio di due dadi non truccati:La funzione two_rolls() inizia con il creare il vettore die che\ncontiene sei elementi: numeri da \\(1\\) \\(6\\). Viene poi utilizzata la\nfunzione sample() con gli gli argomenti, die, size = 2 e\nreplace = TRUE. Tale funzione restituisce il risultato del lancio di\ndue dadi. Il risultato fornito da sample(die, size = 2, replace = TRUE) viene assegnato ’oggetto res. L’oggetto res corrisponde dunque ad un vettore di due elementi.\nL’istruzione sum(res) somma gli elementi del vettore res e\nattribuisce il risultato di questa operazione sum_res. Infine, la\nfunzione return() ritorna il contenuto dell’oggetto sum_res.\nInvocando la funzione two_rolls() si ottiene dunque la somma del\nlancio di due dadi. generale, la funzione two_rolls() produrrà un\nrisultato diverso ogni volta che viene usata:La formattazione del codice mediante l’uso di spazi e rientri non è\nnecessaria ma è altamente raccomandata per minimizzare la probabilità di\ncompiere errori.","code":"\nnome_funzione <- function(arg1, arg2, ...) {\n  espressione1\n  espressione2\n  return(risultato)\n} \nnome_funzione(arg1, arg2, ...)\ntwo_rolls <- function() {\n  die <- 1:6\n  res <- sample(die, size = 2, replace = TRUE)\n  sum_res <- sum(res)\n  return(sum_res)\n}\ntwo_rolls()   \n#> [1] 9\ntwo_rolls()\n#> [1] 4\ntwo_rolls()\n#> [1] 7"},{"path":"introduzione-al-linguaggio-r.html","id":"pacchetti","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.23 Pacchetti","text":"Le funzioni di \\(\\mathsf{R}\\) sono organizzate pacchetti, più importanti dei\nquali sono già disponibili quando si accede al programma.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"istallazione-e-upgrade-dei-pacchetti","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.24 Istallazione e upgrade dei pacchetti","text":"Alcuni pacchetti non sono presenti nella release di base di \\(\\mathsf{R}\\). Per\ninstallare un pacchetto non presente è sufficiente scrivere nella\nconsole:Ad esempio,La prima volta che si usa questa funzione durante una sessione di lavoro\nsi dovrà anche selezionare da una lista il sito mirror da cui\nscaricare il pacchetto.Gli autori dei pacchetti periodicamente rilasciano nuove versioni dei\nloro pacchetti che contengono miglioramenti di varia natura. Per\neseguire l’upgrade dei pacchetti ggplot2 e dplyr, ad esempio, si usa\nla seguente istruzione:Per eseguire l’upgrade di tutti pacchetti l’istruzione è","code":"\ninstall.packages(\"nome_pacchetto\")\ninstall.packages(\"ggplot2\")\nupdate.packages(c(\"ggplot2\", \"dplyr\"))\nupdate.packages()"},{"path":"introduzione-al-linguaggio-r.html","id":"caricare-un-pacchetto-in-r","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.3.25 Caricare un pacchetto in R","text":"L’istallazione dei pacchetti non rende immediatamente disponibili le\nfunzioni essi contenute. L’istallazione di un pacchetto semplicemente\ncopia il codice sul disco rigido della macchina uso. Per potere usare\nle funzioni contenute un pacchetto installato è necessario caricare\nil pacchetto . Ciò si ottiene con il comando:se si vuole caricare il pacchetto ggplot2. questo punto diventa\npossibile usare le funzioni contenute ggplot2. Queste operazioni si\npossono anche eseguire usando dal menu tendina di RStudio.Per sapere quali sono pacchetti già presenti nella release di \\(\\mathsf{R}\\) con\ncui si sta lavorando, basta scrivere:","code":"\nlibrary(\"ggplot2\")\nlibrary()"},{"path":"introduzione-al-linguaggio-r.html","id":"chapter-strutture-dati","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4 Strutture di dati","text":"Solitamente gli psicologi raccolgono grandi quantità di dati. Tali dati\nvengono codificati R ’interno di oggetti aventi proprietà\ndiverse. Intuitivamente, R un oggetto è qualsiasi cosa cui è\npossibile assegnare un valore. dati possono essere di tipo numerico o\nalfanumerico. Di conseguenza, Rdistingue tra oggetti aventi modi\ndiversi. Inoltre, dati possono essere organizzati righe e colonne\nbase diversi tipi di strutture che R chiama classi.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"classi-e-modi-degli-oggetti","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.1 Classi e modi degli oggetti","text":"Gli oggetti R si distinguono seconda della loro classe (class) e\ndel loro modo (mode). La classe definisce il tipo di oggetto. R,\nvengono utilizzate cinque strutture di dati che corrispondono cinque\nclassi differenti: vector, matrix, array, list e data.frame.\nUn’altra classe di oggetti R è function (ad essa appartengono le\nfunzioni).La classe di appartenenza di un oggetto si stabilisce usando le funzioni\nclass(), oppure .list(), .function(), .logical(), e così\nvia. Queste funzioni restituisco TRUE e FALSE base\n’appartenenza o meno dell’argomento quella determinata classe.Gli oggetti R possono anche essere classificati base al loro ‘modo’.\nmodi ‘atomici’ degli oggetti sono: numeric, complex, character e\nlogical. Per esempio,Nel seguito verranno esaminate le cinque strutture di dati utilizzate da\nR.","code":"\nx <- c(4, 9)\nmode(x)\n#> [1] \"numeric\"\ncards <- c(\"9 of clubs\", \"10 of hearts\", \"jack of hearts\") \nmode(cards)\n#> [1] \"character\""},{"path":"introduzione-al-linguaggio-r.html","id":"vettori","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.2 Vettori","text":"vettori sono la classe di oggetto più importante R. Un vettore può\nessere creato usando la funzione c():Le dimensioni di un vettore presente nella memoria di lavoro possono essere trovare con la funzione length(); ad esempio,ci dice che y è un vettore costituito da cinque elementi. La somma, il\nminimo e il massimo degli elementi contenuti un vettore si trovano\ncon le seguenti istruzioni:Mentre ci sono sei ‘tipi’ di vettori ‘atomici’ R, noi ci\nfocalizzeremo sui tipi seguenti: ‘numeric’ (‘integer’: e.g., 5;\n‘double’: e.g., 5.5), ‘character’ (e.g., ‘pippo’) e ‘logical’\n(e.g., TRUE, FALSE). Usiamo la funzione typeof() per determinare\nil ‘tipo’ di un vettore atomico. Tutti gli elementi di un vettore\natomico devono essere dello stesso tipo. La funzione str() rende\nvisibile maniera compatta la struttura interna di un oggetto.","code":"\ny <- c(2, 1, 6, -3, 9)\ny\n#> [1]  2  1  6 -3  9\nlength(y)\n#> [1] 5\nsum(y)\n#> [1] 15\nmin(y)\n#> [1] -3\nmax(y)\n#> [1] 9"},{"path":"introduzione-al-linguaggio-r.html","id":"matrici","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.3 Matrici","text":"Una matrice è una collezione di vettori. Il comando per generare una\nmatrice è matrix():Il primo argomento è il vettore cui elementi andranno disporsi\n’interno della matrice. È poi necessario specificare le dimensioni\ndella matrice e il modo cui R dovrà riempire la matrice. Date le\ndimensioni del vettore, la specificazione del numero di righe (secondo\nargomento) è sufficiente per determinare le dimensioni della matrice.\nL’argomento byrow = FALSE è il default. tal caso, R riempie la\nmatrice per colonne. Se vogliamo che R riempia la matrice per righe,\nusiamo byrow = TRUE:Le dimensioni di una matrice presente nella memoria di lavoro possono\nessere trovare con la funzione dim(); ad esempio,ci dice che Y è una matrice con quattro righe e cinque colonne.","code":"\nX <- matrix(1:20, nrow = 4, byrow = FALSE)\nX\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1    5    9   13   17\n#> [2,]    2    6   10   14   18\n#> [3,]    3    7   11   15   19\n#> [4,]    4    8   12   16   20\nY <- matrix(1:20, nrow = 4, byrow = TRUE)\nY\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1    2    3    4    5\n#> [2,]    6    7    8    9   10\n#> [3,]   11   12   13   14   15\n#> [4,]   16   17   18   19   20\ndim(Y)\n#> [1] 4 5"},{"path":"introduzione-al-linguaggio-r.html","id":"array","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.4 Array","text":"Un array è una collezione di matrici (si veda la\nFigura 1.1). Per costruire un array con la\nfunzione array() è necessario specificare un vettore come primo\nargomento e un vettore di dimensioni, chiamato dim, quale secondo\nargomento:Un sottoinsieme di questi dati può essere selezionato, per esempio, nel\nmodo seguente:","code":"\nar <- array(\n  c(11:14, 21:24, 31:34), \n  dim = c(2, 2, 3)\n)\nar[, , 3]\n#>      [,1] [,2]\n#> [1,]   31   33\n#> [2,]   32   34"},{"path":"introduzione-al-linguaggio-r.html","id":"operazioni-aritmetiche-su-vettori-matrici-e-array","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.5 Operazioni aritmetiche su vettori, matrici e array","text":"","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"operazioni-aritmetiche-su-vettori","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.5.1 Operazioni aritmetiche su vettori","text":"vettori e le matrici (o gli array) possono essere utilizzati \nespressioni aritmetiche. Il risultato è un vettore o una matrice (o un\narray) formato dalle operazioni fatte elemento per elemento sui vettori\no sulle matrici. Ad esempio,restituisce un vettore di dimensioni uguali alle dimensioni di y, \ncui elementi sono dati dalla somma tra ciascuno degli elementi originari\ndi y e la costante “3”.Ovviamente, ad un vettore possono essere applicate tutte le altre\noperazioni algebriche, sempre elemento per elemento. Ad esempio,restituisce un vettore cui elementi sono uguali agli elementi di y\nmoltiplicati per 3.Se sono costituiti dallo stesso numero di elementi, due vettori possono\nessere sommati, sottratti, moltiplicati e divisi, laddove queste\noperazioni algebriche vengono eseguite elemento per elemento. Per\nesempio,","code":"\ny + 3\n#> [1]  5  4  9  0 12\n3 * y\n#> [1]  6  3 18 -9 27\nx <- c(1, 1, 2, 1, 3)\ny <- c(2, 1, 6, 3, 9)\nx + y\n#> [1]  3  2  8  4 12\nx - y\n#> [1] -1  0 -4 -2 -6\nx * y\n#> [1]  2  1 12  3 27\nx / y\n#> [1] 0.5000000 1.0000000 0.3333333 0.3333333 0.3333333"},{"path":"introduzione-al-linguaggio-r.html","id":"operazioni-aritmetiche-su-matrici","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.5.2 Operazioni aritmetiche su matrici","text":"Le operazioni algebriche elemento per elemento si possono estendere al\ncaso delle matrici. Per esempio, se X, Y sono entrambe matrici di\ndimensioni \\(4 \\times 5\\), allora la seguente operazionecrea una matrice D anch’essa di dimensioni \\(4 \\times 5\\) cui elementi\nsono ottenuti dalle operazioni fatte elemento per elemento sulle matrici\ne sugli scalari:","code":"\nM <- 2 * (X + Y) - 3 \nM\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1   11   21   31   41\n#> [2,]   13   23   33   43   53\n#> [3,]   25   35   45   55   65\n#> [4,]   37   47   57   67   77"},{"path":"introduzione-al-linguaggio-r.html","id":"operazioni-aritmetiche-su-array","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.5.3 Operazioni aritmetiche su array","text":"Le stesse considerazioni si estendono al caso degli array.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"liste","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.6 Liste","text":"Le liste assomigliano ai vettori perché raggruppano dati un insieme\nunidimensionale. Tuttavia, le liste non raggruppano elementi individuali\nma bensì oggetti di R, quali vettori e altre liste. Per esempio,Le doppie parentesi quadre identificano l’elemento della lista cui\nvogliamo fare riferimento. Per esempio,","code":"\nlist1 <- list(\"R\", list(TRUE, FALSE), 20:24)\nlist1\n#> [[1]]\n#> [1] \"R\"\n#> \n#> [[2]]\n#> [[2]][[1]]\n#> [1] TRUE\n#> \n#> [[2]][[2]]\n#> [1] FALSE\n#> \n#> \n#> [[3]]\n#> [1] 20 21 22 23 24\nlist1[[3]]\n#> [1] 20 21 22 23 24\nlist1[[3]][2]\n#> [1] 21"},{"path":"introduzione-al-linguaggio-r.html","id":"data-frame","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.7 Data frame","text":"data.frame sono strutture tipo matrice, cui le colonne possono\nessere vettori di tipi differenti. La funzione usata per generare un\ndata frame è data.frame(), che permette di unire più vettori di uguale\nlunghezza come colonne del data frame, ognuno dei quali si riferisce ad\nuna diversa variabile. Ad esempio,L’estrazione di dati da un data.frame può essere effettuata maniera\nsimile quanto avviene per vettori. Ad esempio, per estrarre la\nvariabile value dal data.frame df si può indicare l’indice della\nterza colonna:Dal momento che le colonne sono delle variabili, è possibile estrarle\nanche indicando nome della variabile, scrivendo\nnome_data_frame$nome_variabile:Per fare un esempio, creiamo un data.frame che contenga tutte le informazioni di un mazzo di carte da poker (Grolemund 2014). tale data.frame, ciascuna riga\ncorrisponde ad una carta – un mazzo da poker ci sono 52 carte,\nperciò il data.frame avrà 52 righe. Il vettore face indica con una\nstringa di caratteri il valore di ciascuna carta, il vettore suit\nindica il seme e il vettore value indica con un numero intero il\nvalore di ciascuna carta. Quindi, il data.frame avrà 3 colonne.Avendo salvato tutte queste informazioni nell’oggetto deck, possiamo\nstamparle sullo schermo semplicemente digitando il nome dell’oggetto che\nle contiene:Si noti che, schermo, R stampa un numero progressivo che corrisponde\nal numero della riga.","code":"\ndf <- data.frame(\n  face = c(\"ace\", \"two\", \"six\"),\n  suit = c(\"clubs\", \"clubs\", \"clubs\"), \n  value = c(1, 2, 3)\n)\ndf\n#>   face  suit value\n#> 1  ace clubs     1\n#> 2  two clubs     2\n#> 3  six clubs     3\ndf[, 3]\n#> [1] 1 2 3\ndf$value\n#> [1] 1 2 3\ndeck <- data.frame(\n  face = c(\"king\", \"queen\", \"jack\", \"ten\", \"nine\", \"eight\",\n  \"seven\", \"six\", \"five\", \"four\", \"three\", \"two\", \"ace\", \n  \"king\", \"queen\", \"jack\", \"ten\", \"nine\", \"eight\", \"seven\", \n  \"six\", \"five\", \"four\", \"three\", \"two\", \"ace\", \"king\", \n  \"queen\", \"jack\", \"ten\", \"nine\", \"eight\", \"seven\", \"six\", \n  \"five\", \"four\", \"three\", \"two\", \"ace\", \"king\", \"queen\", \n  \"jack\", \"ten\", \"nine\", \"eight\", \"seven\", \"six\", \"five\", \n  \"four\", \"three\", \"two\", \"ace\"), \n  suit = c(\"spades\", \"spades\", \"spades\", \"spades\", \n  \"spades\", \"spades\", \"spades\", \"spades\", \"spades\", \n  \"spades\", \"spades\", \"spades\", \"spades\", \"clubs\", \"clubs\", \n  \"clubs\", \"clubs\", \"clubs\", \"clubs\", \"clubs\", \"clubs\", \n  \"clubs\", \"clubs\", \"clubs\", \"clubs\", \"clubs\", \"diamonds\", \n  \"diamonds\", \"diamonds\", \"diamonds\", \"diamonds\", \n  \"diamonds\", \"diamonds\", \"diamonds\", \"diamonds\", \n  \"diamonds\", \"diamonds\", \"diamonds\", \"diamonds\", \"hearts\", \n  \"hearts\", \"hearts\", \"hearts\", \"hearts\", \"hearts\", \n  \"hearts\", \"hearts\", \"hearts\", \"hearts\", \"hearts\", \n  \"hearts\", \"hearts\"), \n  value = c(13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1)\n)\ndeck\n#>     face     suit value\n#> 1   king   spades    13\n#> 2  queen   spades    12\n#> 3   jack   spades    11\n#> 4    ten   spades    10\n#> 5   nine   spades     9\n#> 6  eight   spades     8\n#> 7  seven   spades     7\n#> 8    six   spades     6\n#> 9   five   spades     5\n#> 10  four   spades     4\n#> 11 three   spades     3\n#> 12   two   spades     2\n#> 13   ace   spades     1\n#> 14  king    clubs    13\n#> 15 queen    clubs    12\n#> 16  jack    clubs    11\n#> 17   ten    clubs    10\n#> 18  nine    clubs     9\n#> 19 eight    clubs     8\n#> 20 seven    clubs     7\n#> 21   six    clubs     6\n#> 22  five    clubs     5\n#> 23  four    clubs     4\n#> 24 three    clubs     3\n#> 25   two    clubs     2\n#> 26   ace    clubs     1\n#> 27  king diamonds    13\n#> 28 queen diamonds    12\n#> 29  jack diamonds    11\n#> 30   ten diamonds    10\n#> 31  nine diamonds     9\n#> 32 eight diamonds     8\n#> 33 seven diamonds     7\n#> 34   six diamonds     6\n#> 35  five diamonds     5\n#> 36  four diamonds     4\n#> 37 three diamonds     3\n#> 38   two diamonds     2\n#> 39   ace diamonds     1\n#> 40  king   hearts    13\n#> 41 queen   hearts    12\n#> 42  jack   hearts    11\n#> 43   ten   hearts    10\n#> 44  nine   hearts     9\n#> 45 eight   hearts     8\n#> 46 seven   hearts     7\n#> 47   six   hearts     6\n#> 48  five   hearts     5\n#> 49  four   hearts     4\n#> 50 three   hearts     3\n#> 51   two   hearts     2\n#> 52   ace   hearts     1"},{"path":"introduzione-al-linguaggio-r.html","id":"selezione-di-elementi","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.7.1 Selezione di elementi","text":"Una volta creato un data.frame, ad esempio quello che contiene un mazzo\nvirtuale di carte (si veda\nl’esempio \\[exmp:deck_of_cards\\]), è necessario sapere come manipolarlo.\nLa funzione head() mostra le prime sei righe del data.frame:Poniamoci ora il problema di mescolare il mazzo di carte e di estrarre\nalcune carte dal mazzo. Queste operazioni possono essere eseguite usando\nil sistema notazionale di R.Il sistema di notazione di R consente di estrarre singoli elementi\ndagli oggetti definiti da R. Per estrarre un valore da un data.frame,\nper esempio, dobbiamo scrivere il nome del data.frame seguito da una\ncoppia di parentesi quadre:’interno delle parentesi quadre ci sono due indici separati da una\nvirgola. R usa il primo indice per selezionare un sottoinsieme di righe\ndel data.frame e il secondo indice per selezionare un sottoinsieme di\ncolonne. L’indice è il numero d’ordine che etichetta progressivamente ognuno dei valori del vettore. Per esempio,restituisce l’elemento che si trova nella nella nona riga della seconda\ncolonna di deck.R ci sono sei modi diversi per specificare gli indici di un oggetto:\ninteri positivi, interi negativi, zero, spazi vuoti, valori logici e\nnomi. Esaminiamoli qui di seguito.","code":"\nhead(deck)\n#>    face   suit value\n#> 1  king spades    13\n#> 2 queen spades    12\n#> 3  jack spades    11\n#> 4   ten spades    10\n#> 5  nine spades     9\n#> 6 eight spades     8\ndeck[, ]\ndeck[9, 2]\n#> [1] \"spades\""},{"path":"introduzione-al-linguaggio-r.html","id":"interi-positivi","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.7.2 Interi positivi","text":"Gli indici \\(, j\\) possono essere degli interi positivi che identificano\nl’elemento nella \\(\\)-esima riga e nella \\(j\\)-esima colonna del\ndata.frame. Per l’esempio relativo al mazzo di carte, l’istruzioneritorna il valore nella prima riga e nella prima colonna. Per estrarre\npiù di un valore, usiamo un vettore di interi positivi. Per esempio, la\nprima riga di deck si trova conTale sistema notazionale non si applica solo ai data.frame ma può essere\nusato anche per gli altri oggetti di R.L’indice usato da R inizia da 1. altri linguaggi di programmazione,\nper esempio C, inizia da 0.","code":"\ndeck[1, 1]\n#> [1] \"king\"\ndeck[1, c(1:3)]\n#>   face   suit value\n#> 1 king spades    13"},{"path":"introduzione-al-linguaggio-r.html","id":"interi-negativi","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.7.3 Interi negativi","text":"Gli interi negativi fanno l’esatto contrario degli interi positivi: R\nritornerà tutti gli elementi tranne quelli specificati dagli interi\nnegativi. Per esempio, la prima riga del data.frame può essere\nspecificata nel modo seguenteovvero, escludendo tutte le righe seguenti.","code":"\ndeck[-(2:52), 1:3]\n#>   face   suit value\n#> 1 king spades    13"},{"path":"introduzione-al-linguaggio-r.html","id":"zero","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.7.4 Zero","text":"Quando lo zero viene usato come indice, R non ritorna nulla dalla\ndimensione cui lo zero si riferisce. L’istruzioneritorna un data.frame vuoto. Non molto utile.","code":"\ndeck[0, 0]\n#> data frame con 0 colonne e 0 righe"},{"path":"introduzione-al-linguaggio-r.html","id":"spazio","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.7.5 Spazio ’ ’","text":"Uno spazio viene usato quale indice per comunicare R di estrarre\ntutti valori quella dimensione. Questo è utile per estrarre intere\ncolonne o intere righe da un data.frame. Per esempio, l’istruzioneritorna la terza riga del data.frame deck.","code":"\ndeck[3, ]\n#>   face   suit value\n#> 3 jack spades    11"},{"path":"introduzione-al-linguaggio-r.html","id":"valori-booleani","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.7.6 Valori booleani","text":"Se viene fornito un vettore di stringhe TRUE, FALSE, R selezionerà\ngli elementi riga o colonna corrispondenti ai valori booleani TRUE\nusati quali indici. Per esempio, l’istruzioneritorna valori delle prime due colonne della terza riga di deck.","code":"\ndeck[3, c(TRUE, TRUE, FALSE)]\n#>   face   suit\n#> 3 jack spades"},{"path":"introduzione-al-linguaggio-r.html","id":"nomi","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.7.7 Nomi","text":"È possibile selezionare gli elementi del data.frame usando loro nomi.\nPer esempio,","code":"\ndeck[1, c(\"face\", \"suit\", \"value\")]\n#>   face   suit value\n#> 1 king spades    13\ndeck[, \"value\"]\n#>  [1] 13 12 11 10  9  8  7  6  5  4  3  2  1 13 12 11 10  9  8  7  6  5  4  3  2\n#> [26]  1 13 12 11 10  9  8  7  6  5  4  3  2  1 13 12 11 10  9  8  7  6  5  4  3\n#> [51]  2  1"},{"path":"introduzione-al-linguaggio-r.html","id":"giochi-di-carte","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.8 Giochi di carte","text":"Avendo presentato le nozioni base del sistema di notazione di R,\nutilizziamo tali conoscenze per manipolare il data.frame. L’istruzioneritorna tutte le righe e tutte e le colonne del data.frame deck. Le\nrighe sono identificate dal primo indice, che va da 1 52. Permutare \nmodo casuale l’indice delle righe equivale mescolare il mazzo di\ncarte. Per fare questo, utilizziamo la funzione sample() ponendo replace=FALSE e size\nuguale alla dimensione del vettore che contiene gli indici da 1 52:Utilizzando il vettore random di indici permutati otteniamo il\nrisultato cercato:Possiamo ora scrivere una funzione che include le precedenti istruzioni:Invocando la funzione shuffle() possiamo generare un data.frame che\nrappresenta un mazzo di carte mescolato:Se immaginiamo di distribuire le carte di questo mazzo due giocatori\ndi poker, per il primo giocatore avremo:e per il secondo:","code":"\ndeck[1:52, ]\nrandom <- sample(1:52, size = 52, replace = FALSE)\nrandom\n#>  [1] 41 35 51 22  3 10  2 15 11 16 46 21  7 19 43 17 27 50 39 44 14 18 40 47 31\n#> [26] 30 52 37 20 33  6  9  5 49 13  4  8 28 32 45 42 26 36  1 48 23 24 29 34 25\n#> [51] 38 12\ndeck_shuffled <- deck[random, ]\nhead(deck_shuffled)\n#>     face     suit value\n#> 41 queen   hearts    12\n#> 35  five diamonds     5\n#> 51   two   hearts     2\n#> 22  five    clubs     5\n#> 3   jack   spades    11\n#> 10  four   spades     4\nshuffle <- function(cards) {\n  random <- sample(1:52, size = 52, replace = FALSE) \n  return(cards[random, ])\n}\ndeck_shuffled <- shuffle(deck)\ndeck_shuffled[c(1, 3, 5, 7, 9), ]\n#>    face     suit value\n#> 26  ace    clubs     1\n#> 44 nine   hearts     9\n#> 29 jack diamonds    11\n#> 42 jack   hearts    11\n#> 22 five    clubs     5\ndeck_shuffled[c(2, 4, 6, 8, 10), ]\n#>     face     suit value\n#> 24 three    clubs     3\n#> 47   six   hearts     6\n#> 34   six diamonds     6\n#> 51   two   hearts     2\n#> 17   ten    clubs    10"},{"path":"introduzione-al-linguaggio-r.html","id":"variabili-locali","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.4.9 Variabili locali","text":"Si noti che, nell’esempio precedente, abbiamo passato l’argomento deck\nalla funzione shuffle(), perché questo è il nome del data.frame che\nvolevamo manipolare. Nella definizione della funzione shuffle(), però,\nl’argomento della funzione era chiamato cards. Il nome degli argomenti\nè diverso nei due casi. Allora perché l’istruzione shuffle(deck) non\ndà un messaggio d’errore?La risposta questa domanda è che nelle funzioni le variabili nascono\nquando la funzione entra esecuzione e muoiono al termine\ndell’esecuzione della funzione. Per questa ragione, sono dette ‘locali’.\nLa variabile cards, questo esempio, esiste soltanto ’interno\ndella funzione. Dunque non deve (necessariamente) avere lo stesso nome\ndi un altro oggetto che esiste al di fuori della funzione, nello spazio\ndi lavoro di R (anzi, è meglio se il nome degli oggetti usati\n’interno delle funzioni è diverso da quello degli oggetti che\nesistono fuori dalle funzioni). R sa che l’oggetto deck passato \nshuffle() corrisponde cards ’interno della funzione perché\nassegna il nome cards qualunque oggetto venga passato alla funzione\nshuffle() come primo (e, questo caso, unico) argomento.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"chapter-strut-contr","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.5 Strutture di controllo","text":"R il flusso della computazione segue l’ordine di lettura delle espressioni. controlli di flusso sono quei costrutti sintattici che possono modificare quest’ordine di computazione. Ad esempio, un ciclo ripete le istruzioni annidate al suo interno per un certo numero di volte, e quindi procede sequenzialmente da lì avanti, mentre un condizionale valuta una condizione rispetto alla quale il flusso di informazioni si biforca (se è vero / se è falso). Ci limitiamo qui ad introdurre il ciclo .","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"il-ciclo-for","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.5.1 Il ciclo for","text":"Il ciclo è una struttura di controllo iterativa che determina l’esecuzione di una porzione di codice ripetuta per un certo numero noto di volte. Il linguaggio R usa la seguente sintassi per il ciclo :(indice valori_indice) {\noperazioni\n}il che significa “esegui le operazioni operazioni per diversi valori di indice compresi nel vettore valori_indice”. Per esempio, il seguente ciclo non fa altro che stampare il valore della variabile contatore ciascuna esecuzione del ciclo:Un esempio (leggermente) più complicato è il seguente:Per esempio, quanti numeri pari sono contenuti un vettore? La\nrisposta questa domanda viene fornita dalla funzione\ncountEvenNumbers() che possiamo definire come indicato qui sotto:Nella funzione countEvenNumbers() abbiamo inizializzato la variabile\ncount zero. Prima dell’esecuzione del ciclo , dunque, count\nvale zero. Il ciclo viene eseguito tante volte quanti sono gli\nelementi che costituiscono il vettore x. L’indice dunque assume\nvalori compresi tra 1 e il valore che corrisponde al numero di elementi\ndi x. L’operazione modulo, indicato con %% dà come risultato il\nresto della divisione euclidea del primo numero per il secondo. Per\nesempio, 9 %% 2 dà come risultato \\(1\\) perché questo è il resto della\ndivisione \\(9/2\\). L’operazione modulo dà come risultato \\(0\\) per tutti \nnumeri pari. ciascuna esecuzione del ciclo l’operazione modulo\nviene eseguita, successivamente, su uno degli elementi di x. Se\nl’operazione modulo dà \\(0\\) come risultato, ovvero se il valore\nconsiderato è un numero pari, allora la variabile count viene\nincrementata di un’unità. L’istruzione return() ritorna il\nnumero di valori pari contenuti nel vettore di input alla funzione.\nSi noti che è necessario usare return(): la funzione ritornerà qualunque cosa sia stampato nell’ultima riga della funzione stessa.Facciamo un esempio:","code":"\nfor (i in 1:3) {\n  print(i)\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\nx_list <- seq(1, 9, by = 2)\nx_list\n#> [1] 1 3 5 7 9\nsum_x <- 0\nfor (x in x_list) {\n  sum_x <- sum_x + x\n  cat(\"L'indice corrente e'\", x, \"\\n\")\n  cat(\"La frequenza cumulata e'\", sum_x, \"\\n\") \n}\n#> L'indice corrente e' 1 \n#> La frequenza cumulata e' 1 \n#> L'indice corrente e' 3 \n#> La frequenza cumulata e' 4 \n#> L'indice corrente e' 5 \n#> La frequenza cumulata e' 9 \n#> L'indice corrente e' 7 \n#> La frequenza cumulata e' 16 \n#> L'indice corrente e' 9 \n#> La frequenza cumulata e' 25\ncountEvenNumbers <- function(x) {\n  count <- 0\n  for (i in 1:length(x)) {\n    if (x[i] %% 2 == 0)  \n      count = count + 1\n  }\n  count\n}\nx <- c(1, 2, 1, 4, 6, 3, 9, 12)\ncountEvenNumbers(x)\n#> [1] 4"},{"path":"introduzione-al-linguaggio-r.html","id":"chapter-input-output","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.6 Input/Output","text":"dati raccolti dallo psicologo sono contenuti file aventi formati\ndiversi: solo testo, CSV, Excel, eccetera. R prevede diverse funzioni\ndi importazione dei dati. Esamineremo qui la funzione read.table() per\nl’importazione di dati formato solo testo, ma funzioni analoghe\npossono essere usate per molti altri formati possibili.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"la-funzione-read.table","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.6.1 La funzione read.table()","text":"Ci sono tanti modi per importare un file dal nostro computer. R permette di utilizzare delle funzioni che sono già nella libreria di base, oppure possiamo utilizzare delle funzioni specifiche, seconda del tipo di file da importare, che sono contenute pacchetti aggiuntivi. Per leggere dati da file R è conveniente\npreliminarmente generare un file di dati formato ASCII, disponendoli\ncome si farebbe una matrice di dati, e mettere questo file nella\ncartella di lavoro corrente. Fatto questo, si può utilizzare la funzione\nread.table() presente nella libreria di base per leggere l’intero\ndataset. Se la prima riga del file contiene l’intestazione delle\nvariabili, allora read.table(\"my_file.txt\", header = TRUE)\ninterpreterà la prima riga del file come una riga dove sono contenuti \nnomi delle variabili, assegnando ciascun nome alle variabili del data\nframe:alternativa, si può impiegare la funzione read.csv(), che è adatta\nleggere dati salvati .csv. Utilizzando altre funzioni, si possono\nleggere R dati contenuti file aventi formati diversi da quelli\nconsiderati qui, quali Excel, SPSS, ecc.","code":"\nmydata <- read.table(\"my_file.txt\", header = TRUE)"},{"path":"introduzione-al-linguaggio-r.html","id":"file-di-dati-forniti-da-r","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.6.2 File di dati forniti da R","text":"R esistono comunque oltre 50 insiemi di dati contenuti nel package\nbase e altri sono disponibili altri packages. Per vedere l’elenco\ndegli insiemi di dati disponibili nel package base basta usare\nl’istruzione data(); per caricare un particolare insieme di dati, ad\nesempio cars, basta utilizzare l’istruzioneNella maggior parte dei casi questo corrisponde caricare un oggetto,\nsolitamente un data.frame dello stesso nome: per l’esempio considerato\nsi avrebbe un data frame di nome cars.","code":"\ndata(cars)"},{"path":"introduzione-al-linguaggio-r.html","id":"esportazione-di-un-file","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.6.3 Esportazione di un file","text":"Per esportare un data.frame formato .csv possiamo scrivere il\nseguente codicedove df_esempio è il data.frame da salvare e esempio.csv è il file\nche verrà salvato ’interno della nostra cartellla di lavoro.","code":"\nwrite.csv(df_esempio, file = \"esempio.csv\", row.names = FALSE)"},{"path":"introduzione-al-linguaggio-r.html","id":"pacchetto-rio","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.6.4 Pacchetto rio","text":"Un’alternativa più semplice è fornita dalle funzioni fornite dal pacchetto rio. Per importare dati da un file qualsiasi formato si usaPer esportare dati un file avente qualsiasi formato si usa invece","code":"\nmy_data_frame <- rio::import(\"my_file.csv\")\nrio::export(my_data_frame, \"my_file.csv\")"},{"path":"introduzione-al-linguaggio-r.html","id":"dove-sono-i-miei-file","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.6.5 Dove sono i miei file?","text":"Quello che abbiamo detto finora, proposito dell’importazione ed esportazione dei file, si riferisce file che si trovano nella cartella di lavoro (working directory). Ma non sempre ci troviamo questa situazione, il che è una buona cosa, perché se dobbiamo gestire un progetto anche leggermente complesso è sempre una buona idea salvare file che usiamo cartelle diverse. Per esempio, possiamo usare una cartella chiamata psicometria dove salviamo tutto il materiale di questo insegnamento. Nella cartella psicometria ci potrà essere una cartella chiamata scripts dove salveremo gli script con il codice R utilizzato per vari esercizi, e una cartella chiamata data dove possiamo salvare dati. Questa organizzazione minimale ci pone, però, difronte ad un problema: dati che vogliamo caricare R non si trovano nella cartella dove sono contenuti gli script. Quando importiamo un file di dati dobbiamo dunque specificare il percorso che identifica la posizione del file sul nostro computer.Questo problema può essere risolto due modi: speficicando l’indirizzo assoluto del file, o l’indirizzo relativo. Specificare l’indirizzo assoluto di un file comporta una serie di svantaggi. Il più grande è che non sarà possibile utilizzare quell’istruzione su una macchina diversa. Dunque, è molto più conveniente specificare l’indirizzo dei file modo relativo. Ma relativo rispetto cosa? Rispetto alla working directory che definirà l’origine del nostro percorso.È ovvio che la working directory cambia da progetto progetto. Infatti, per ciascun progetto dobbiamo specificare una diversa working directory. Per esempio, potremmo avere un progetto relativo ’insegnamento di Psicometria e un progetto relativo alla prova finale.Per organizzaere il lavoro questo modo, si procede come segue. Supponiamo di creare una cartella chiamata psicometria che contiene, al suo interno, le cartelle scripts e data:Supponiamo che queste cartelle contengano file che ho specificato sopra. Chiudiamo RStudio, se è aperto, e lo riapriamo di nuovo. Dal menu selezioniamo File -> New Project... questo modo si aprirà un menu che ci chiederà, tra le altre cose, se vogliamo creare un nuovo progetto (New project). Selezioniamo quell’opzione e navighiamo fino alla cartella psicometria e selezioniamo open. Questo creerà un file chiamato psicometria.Rproj nella cartella psicometria.Chiudiamo ora RStudio. Se vogliamo accedere al progetto “psicometria”, che abbiamo appena creato, dobbiamo semplicemente cliccare sul file psicometria.Rproj. Questo aprirà RStudio e farà modo che la working directory coincida con la cartalla psicometria. Ogni volta che vogliamo lavorare sui dati del progetto “psicometria” chiudiamo dunque RStudio (se è già aperto) e lo riapriamo cliccando sul file psicometria.Rproj.questo punto possiamo definire l’indirizzo dei file modo relativo – ovvero, relativo alla cartella psicometria. Per fare questo usiamo le funzionalità del pacchetto . Supponiamo di volere caricare un file di dati che si chiama dati_depressione.txt e si trova nella cartella psicometria/data. Per importare dati (dopo avere caricato pacchetti rio e ) useremo l’istruzione seguente:altre parole, così facendo specifichiamo il percorso relativo del file dati_depressione.txt (quanto l’origine corrisponde alla cartella psicometria). L’istruzione precedente significa che, partendo dalla cartella che coincide con la working directory (ovvero, psicometria) ci spostiamo nella cartella data e lì dentro troviamo il file chiamato dati_depressione.txt.","code":"psicometria/\n  ├── data\n  ├── scripts\nrio::import(here(\"data\", \"dati_depressione.txt\"))"},{"path":"introduzione-al-linguaggio-r.html","id":"manipolazione-dei-dati","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7 Manipolazione dei dati","text":"","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"motivazione","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.1 Motivazione","text":"Si chiamano “dati grezzi” quelli che provengono dal mondo circostanze, \ndati raccolti per mezzo degli strumenti usati negli esperimenti, per\nmezzo di interviste, di questionari, ecc. Questi dati (chiamati\ndataset) raramente vengono forniti con una struttura logica precisa.\nPer potere elaborarli mediante dei software dobbiamo prima trasformarli\nmaniera tale che abbiano una struttura logica organizzata. La\nstruttura che solitamente si utilizza è quella tabellare (matrice dei\ndati), ovvero si dispongono dati una tabella nella quale ciascuna\nriga corrisponde ad un’osservazione e ciascuna colonna corrisponde ad\nuna variabile rilevata. R una tale struttura è chiamata data frame.Utilizzando pacchetti del tidyverse (tidyverse è un insieme, o bundle, di pacchetti R), le operazioni di trasformazione dei dati risultano molto semplificate. Nel tidyverse data frame vengono leggermente modificati e si chiamano tibble. Per la manipolazione dei dati vengono usati seguenti pacchetti del tidyverse:dplyrtidyr (tibbles, dataframe e tabelle)stringr (stringhe)Il pacchetto dplyr (al momento uno dei pacchetti più famosi e utilizzati per la gestione dei dati) offre una serie di funzionalità che consentono di eseguire le operazioni più comuni di manipolazione dei dati maniera più semplice rispetto quanto succeda quando usiamo le funzioni base di R.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"trattamento-dei-dati-con-dplyr","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2 Trattamento dei dati con dplyr","text":"Il pacchetto dplyr include sei funzioni base: filter(), select(), mutate(), arrange(), group_by() e summarise(). Queste sei funzioni costituiscono verbi del linguaggio di manipolazione dei dati. questi sei verbi si aggiunge il pipe %>% che serve concatenare più operazioni. particolare, considerando una matrice osservazioni per variabili, select() e mutate() si occupano di organizzare le variabili, filter() e arrange() casi, e group_by() e summarise() gruppi.Per introdurre le funzionalità di dplyr, utilizzeremo dati msleep forniti dal pacchetto ggplot2. Tali dati descrivono le ore di sonno medie di 83 specie di mammiferi (Savage et al. 2007). Carichiamo il boundle tidyverse (che contiene ggplot2) e leggiamo nella memoria di lavoro l’oggetto msleep:","code":"\nlibrary(\"tidyverse\")\ndata(msleep)\ndim(msleep)\n#> [1] 83 11"},{"path":"introduzione-al-linguaggio-r.html","id":"operatore-pipe","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2.1 Operatore pipe","text":"Prima di presentare le funzionalità di dplyr, introduciamo l’operatore pipe %>% del pacchetto magrittr – ma ora presente anche base R nella versione |>. L’operatore pipe, %>% o |>, serve concatenare varie funzioni insieme, modo da inserire un’operazione dietro l’altra. Una spiegazione intuitiva dell’operatore pipe è stata fornita un tweet di @andrewheiss. Consideriamo la seguente istruzione pseudo-codice R:Il listato precedente descrive una serie di (pseudo) funzioni concatenate, le quali costituiscono gli argomenti di altre funzioni. Scritto così, il codice è molto difficile da capire. Possiamo però ottenere lo stesso risultato utilizzando l’operatore pipe che facilita enormememnte la leggibilità del codice:questa seconda versione del (pseudo) codice R si capisce molto meglio ciò che vogliamo fare. Il tibble viene passato alla funzione wake_up(). La funzione wake_up() ha come argomento l’ora del giorno: time = \"8:00\". Una volta “svegliati” (wake ) dobbiamo scendere dal letto. Quindi l’output di wake_up() viene passato alla funzione get_out_of_bed() la quale ha come argomento side = \"correct\" perché vogliamo scendere dal letto dalla parte giusta. E così via.Questo pseudo-codice chiarisce il significato dell’operatore pipe. L’operatore %>% è “syntactic sugar” per una serie di chiamate di funzioni concatenate, ovvero, detto altre parole, consente di definire la relazione tra una serie di funzioni nelle quali il risultato (output) di una funzione viene utilizzato come l’input di una funzione successiva.","code":"\nleave_house(\n  get_dressed(\n    get_out_of_bed(\n      wake_up(me, time = \"8:00\"), \n      side = \"correct\"), \n    pants = TRUE, \n    shirt = TRUE), \n  car = TRUE, \n  bike = FALSE\n)\nme %>% \n  wake_up(time = \"8:00\") %>% \n  get_out_of_bed(side = \"correct\") %>% \n  get_dressed(pants = TRUE, shirt = TRUE) %>% \n  leave_house(car = TRUE, bike = FALSE)"},{"path":"introduzione-al-linguaggio-r.html","id":"estrarre-una-singola-colonna-con-pull","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2.2 Estrarre una singola colonna con pull()","text":"Ritorniamo ora ’esempio precedente. Iniziamo trasformare il data frame msleep un tibble (che è identico ad un data frame ma viene stampato sulla console un modo diverso):\nEstraiamo da msleep la variabile sleep_total usando il verbo pull():","code":"\nmsleep <- tibble(msleep)\nmsleep %>% \n  pull(sleep_total)\n#>  [1] 12.1 17.0 14.4 14.9  4.0 14.4  8.7  7.0 10.1  3.0  5.3  9.4 10.0 12.5 10.3\n#> [16]  8.3  9.1 17.4  5.3 18.0  3.9 19.7  2.9  3.1 10.1 10.9 14.9 12.5  9.8  1.9\n#> [31]  2.7  6.2  6.3  8.0  9.5  3.3 19.4 10.1 14.2 14.3 12.8 12.5 19.9 14.6 11.0\n#> [46]  7.7 14.5  8.4  3.8  9.7 15.8 10.4 13.5  9.4 10.3 11.0 11.5 13.7  3.5  5.6\n#> [61] 11.1 18.1  5.4 13.0  8.7  9.6  8.4 11.3 10.6 16.6 13.8 15.9 12.8  9.1  8.6\n#> [76] 15.8  4.4 15.6  8.9  5.2  6.3 12.5  9.8"},{"path":"introduzione-al-linguaggio-r.html","id":"selezionare-più-colonne-con-select","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2.3 Selezionare più colonne con select()","text":"Se vogliamo selezionare da msleep un insieme di variabili, ad esempio name, vore e sleep_total, possiamo usare il verbo select():\nladdove la sequenza di istruzioni precedenti significa che abbiamo passato msleep alla funzione select() contenuta nel pacchetto dplyr e l’output di select() è stato salvato (usando l’operatore di assegnazione, <-) nell’oggetto dt. Alla funzione select() abbiamo passato gli argomenti name, vore e sleep_total.","code":"\ndt <- msleep %>%\n  dplyr::select(name, vore, sleep_total)\ndt\n#> # A tibble: 83 × 3\n#>   name                       vore  sleep_total\n#>   <chr>                      <chr>       <dbl>\n#> 1 Cheetah                    carni        12.1\n#> 2 Owl monkey                 omni         17  \n#> 3 Mountain beaver            herbi        14.4\n#> 4 Greater short-tailed shrew omni         14.9\n#> 5 Cow                        herbi         4  \n#> 6 Three-toed sloth           herbi        14.4\n#> 7 Northern fur seal          carni         8.7\n#> 8 Vesper mouse               <NA>          7  \n#> # … with 75 more rows"},{"path":"introduzione-al-linguaggio-r.html","id":"filtrare-le-osservazioni-righe-con-filter","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2.4 Filtrare le osservazioni (righe) con filter()","text":"Il verbo filter() consente di selezionare da un tibble un sottoinsieme di righe (osservazioni). Per esempio, possiamo selezionare tutte le osservazioni nella variabile vore contrassegnate come carni (ovvero, tutti carnivori):Per utilizzare il verbo filter() modo efficace è neccessario usare gli operatori relazionali (Tabella ??) e gli operatori logici (Tabella ??) di R. Per un approfondimento, si veda il Capitolo Comparisons di R Data Science.","code":"\ndt %>%\n  dplyr::filter(vore == \"carni\")\n#> # A tibble: 19 × 3\n#>   name                 vore  sleep_total\n#>   <chr>                <chr>       <dbl>\n#> 1 Cheetah              carni        12.1\n#> 2 Northern fur seal    carni         8.7\n#> 3 Dog                  carni        10.1\n#> 4 Long-nosed armadillo carni        17.4\n#> 5 Domestic cat         carni        12.5\n#> 6 Pilot whale          carni         2.7\n#> 7 Gray seal            carni         6.2\n#> 8 Thick-tailed opposum carni        19.4\n#> # … with 11 more rows"},{"path":"introduzione-al-linguaggio-r.html","id":"creare-una-nuova-variabile-con-mutate","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2.5 Creare una nuova variabile con mutate()","text":"Talvolta vogliamo creare una nuova variabile, per esempio, sommando o dividendo due variabili, oppure calcolandone la media. questo scopo si usa il verbo mutate(). Per esempio, se vogliamo esprimere valori di sleep_total minuti, moltiplichiamo per 60:","code":"\ndt %>% \n  mutate(\n    sleep_minutes = sleep_total * 60\n  ) %>%\n  dplyr::select(sleep_total, sleep_minutes)\n#> # A tibble: 83 × 2\n#>   sleep_total sleep_minutes\n#>         <dbl>         <dbl>\n#> 1        12.1           726\n#> 2        17            1020\n#> 3        14.4           864\n#> 4        14.9           894\n#> 5         4             240\n#> 6        14.4           864\n#> 7         8.7           522\n#> 8         7             420\n#> # … with 75 more rows"},{"path":"introduzione-al-linguaggio-r.html","id":"ordinare-i-dati-con-arrange","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2.6 Ordinare i dati con arrange()","text":"Il verbo arrange() ordina dati base ai valori di una o più variabili. Per esempio, possiamo ordinare la variabile sleep_total dal valore più alto al più basso questo modo:","code":"\ndt %>% \n  arrange(\n    desc(sleep_total)\n  )\n#> # A tibble: 83 × 3\n#>   name                   vore    sleep_total\n#>   <chr>                  <chr>         <dbl>\n#> 1 Little brown bat       insecti        19.9\n#> 2 Big brown bat          insecti        19.7\n#> 3 Thick-tailed opposum   carni          19.4\n#> 4 Giant armadillo        insecti        18.1\n#> 5 North American Opossum omni           18  \n#> 6 Long-nosed armadillo   carni          17.4\n#> 7 Owl monkey             omni           17  \n#> 8 Arctic ground squirrel herbi          16.6\n#> # … with 75 more rows"},{"path":"introduzione-al-linguaggio-r.html","id":"raggruppare-i-dati-con-group_by","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2.7 Raggruppare i dati con group_by()","text":"Il verbo group_by() raggruppa insieme valori base una o più variabili. Lo vedremo uso seguito insieme summarise().Nota: con dplyr(), le operazioni raggruppate vengono iniziate con la funzione group_by(). È una buona norma utilizzare ungroup() alla fine di una serie di operazioni raggruppate, altrimenti raggruppamenti verranno mantenuti nelle analisi successiva, il che non è sempre auspicabile.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"sommario-dei-dati-con-summarise","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2.8 Sommario dei dati con summarise()","text":"Il verbo summarise() collassa il dataset una singola riga dove viene riportato il risultato della statistica richiesta. Per esempio, la media del tempo totale del sonno è","code":"\ndt %>% \n  summarise(\n    m_sleep = mean(sleep_total, na.rm = TRUE)\n  ) \n#> # A tibble: 1 × 1\n#>   m_sleep\n#>     <dbl>\n#> 1    10.4"},{"path":"introduzione-al-linguaggio-r.html","id":"operazioni-raggruppate","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2.9 Operazioni raggruppate","text":"Sopra abbiamo visto come mammiferi considerati dormano, media, 10.4 ore al giorno. Troviamo ora il sonno medio funzione di vore:\nSi noti che, nel caso di 7 osservazioni, il valore di vore non era\nspecificato. Per tali osservazioni, dunque, la classe di appartenenza è\nNA.","code":"\ndt %>%\n  group_by(vore) %>%\n  summarise(\n    m_sleep = mean(sleep_total, na.rm = TRUE), \n    n = n()\n  )\n#> # A tibble: 5 × 3\n#>   vore    m_sleep     n\n#>   <chr>     <dbl> <int>\n#> 1 carni     10.4     19\n#> 2 herbi      9.51    32\n#> 3 insecti   14.9      5\n#> 4 omni      10.9     20\n#> 5 <NA>      10.2      7"},{"path":"introduzione-al-linguaggio-r.html","id":"applicare-una-funzione-su-più-colonne-across","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.2.10 Applicare una funzione su più colonne: across()","text":"È spesso utile eseguire la stessa operazione su più colonne, ma copiare e incollare è sia noioso che soggetto errori:\ntali circostanze è possibile usare la funzione across() che consente di riscrivere il codice precedente modo più succinto:\nPer dati presenti, ad esempio, possiamo avere:","code":"\ndf %>%\n  group_by(g1, g2) %>%\n  summarise(\n    a = mean(a),\n    b = mean(b),\n    c = mean(c),\n    d = mean(d)\n  )\ndf %>% \n  group_by(g1, g2) %>% \n  summarise(across(a:d, mean))\nmsleep %>%\n  group_by(vore) %>%\n  summarise(across(starts_with(\"sleep\"), ~ mean(.x, na.rm = TRUE)))\n#> # A tibble: 5 × 4\n#>   vore    sleep_total sleep_rem sleep_cycle\n#>   <chr>         <dbl>     <dbl>       <dbl>\n#> 1 carni         10.4       2.29       0.373\n#> 2 herbi          9.51      1.37       0.418\n#> 3 insecti       14.9       3.52       0.161\n#> 4 omni          10.9       1.96       0.592\n#> 5 <NA>          10.2       1.88       0.183"},{"path":"introduzione-al-linguaggio-r.html","id":"dati-categoriali-in-r","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.3 Dati categoriali in R","text":"Consideriamo una variabile che descrive il genere e include le categorie male, female e non-conforming. R, ci sono due modi per memorizzare queste informazioni. Uno è usare la classe character strings e l’altro è usare la classe factor. Non ci addentrimo qui nelle sottigliezze di questa distinzione, motivata gran parte per le necessità della programmazione con le funzioni di tidyverse. Per gli scopi di questo insegnamento sarà sufficiente codificare le variabili qualitative usando la classe factor. Una volta codificati dati qualitativi utilizzando la classe factor, si pongono spesso due problemi:modificare le etichette dei livelli (ovvero, le modalità) di un fattore,riordinare livelli di un fattore.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"modificare-le-etichette-dei-livelli-di-un-fattore","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.3.1 Modificare le etichette dei livelli di un fattore","text":"Esaminiamo l’esempio seguente.\nSupponiamo ora di volere che livelli del fattore f_1 abbiano le etichette new_1, new_2, ecc. Per ottenere questo risultato usiamo la funzione forcats::fct_recode():","code":"\nf_1 <- c(\"old_3\", \"old_4\", \"old_1\", \"old_1\", \"old_2\")\nf_1 <- factor(f_1)\ny <- 1:5\ndf <- tibble(f_1, y)\ndf\n#> # A tibble: 5 × 2\n#>   f_1       y\n#>   <fct> <int>\n#> 1 old_3     1\n#> 2 old_4     2\n#> 3 old_1     3\n#> 4 old_1     4\n#> 5 old_2     5\ndf <- df %>%\n  mutate(f_1 =\n    forcats::fct_recode(\n      f_1, \n      \"new_poco\" = \"old_1\", \n      \"new_medio\" = \"old_2\", \n      \"new_tanto\" = \"old_3\", \n      \"new_massimo\" = \"old_4\"\n      )\n   )\ndf\n#> # A tibble: 5 × 2\n#>   f_1             y\n#>   <fct>       <int>\n#> 1 new_tanto       1\n#> 2 new_massimo     2\n#> 3 new_poco        3\n#> 4 new_poco        4\n#> 5 new_medio       5"},{"path":"introduzione-al-linguaggio-r.html","id":"riordinare-i-livelli-di-un-fattore","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.3.2 Riordinare i livelli di un fattore","text":"Spesso livelli dei fattori hanno un ordinamento naturale. Quindi, gli utenti devono avere un modo per imporre l’ordine desiderato sulla codifica delle loro variabili qualitative. Se per qualche motivo vogliamo ordinare livelli f_1 ordine inverso, ad esempio, possiamo procedere nel modo seguente.\nPer approfondire le problematiche della manipolazione di variabili qualitative R, si veda McNamara Horton (2018).","code":"\ndf$f_1 <- factor(df$f_1,\n  levels = c(\n    \"new_massimo\", \"new_tanto\", \"new_medio\", \"new_poco\" \n  )\n)\nsummary(df$f_1)\n#> new_massimo   new_tanto   new_medio    new_poco \n#>           1           1           1           2"},{"path":"introduzione-al-linguaggio-r.html","id":"creare-grafici-con-ggplot2","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.4 Creare grafici con ggplot2()","text":"Il pacchetto ggplot2() è un potente strumento per rappresentare graficamente dati. Le iniziali del nome, gg, si riferiscono alla “Grammar Graphics”, che è un modo di pensare le figure come una serie di layer stratificati. Originariamente descritta da Wilkinson (2012), la grammatica dei grafici è stata aggiornata e applicata R da Hadley Wickham, il creatore del pacchetto.La funzione da cui si parte per inizializzare un grafico è ggplot(). La funzione ggplot() richiede due argomenti. Il primo è l’oggetto di tipo data.frame che contiene dati da visualizzare – alternativa al primo argomento, un dataframe può essere passato ggplot() mediante l’operatore pipe. Il secondo è una particolare lista che viene generata dalla funzione aes(), la quale determina l’aspetto (aesthetic) del grafico. La funzione aes() richiede necessariamente di specificare “x” e “y”, ovvero nomi delle colonne del data.frame che è stato utilizzato quale primo argomento di ggplot() (o che è stato passato da pipe), le quali rappresentano le variabili da porre rispettivamente sugli assi orizzontale e verticale.La definizione della tipologia di grafico e vari parametri sono poi definiti successivamente, aggiungendo ’oggetto creato da ggplot() tutte le componenti necessarie. Saranno quindi altre funzioni, come geom_bar(), geom_line() o geom_point() occuparsi di aggiungere al livello di base barre, linee, punti, e così via. Infine, tramite altre funzioni, ad esempio labs(), sarà possibile definire dettagli più fini.Gli elementi grafici (bare, punti, segmenti, …) usati da ggplot2 sono chiamati geoms. Mediante queste funzioni è possibile costruire diverse tipologie di grafici:geom_bar(): crea un layer con delle barre;geom_bar(): crea un layer con delle barre;geom_point(): crea un layer con dei punti (diagramma dispersione);geom_point(): crea un layer con dei punti (diagramma dispersione);geom_line(): crea un layer con una linea retta;geom_line(): crea un layer con una linea retta;geom_histogram(): crea un layer con un istogramma;geom_histogram(): crea un layer con un istogramma;geom_boxplot(): crea un layer con un box-plot;geom_boxplot(): crea un layer con un box-plot;geom_errorbar(): crea un layer con barre che rappresentano intervalli di confidenza;geom_errorbar(): crea un layer con barre che rappresentano intervalli di confidenza;geom_hline() e geom_vline() : crea un layer con una linea orizzontale o verticale definita dall’utente.geom_hline() e geom_vline() : crea un layer con una linea orizzontale o verticale definita dall’utente.Un comando generico ha la seguente forma:La prima volta che si usa il pacchetto ggplot2 è necessario installarlo. Per fare questo possiamo installare tidyverse che, oltre caricare ggplot2, carica anche altre utili funzioni per l’analisi dei dati. Ogni volta che si inizia una sessione R è necessario attivare pacchetti che si vogliono usare, ma non è necessario istallarli una nuova volta. Se è necessario specificare il pacchetto nel quale è contenuta la funzione che vogliamo utilizzare, usiamo la sintassi package::function(). Per esempio, l’istruzione ggplot2::ggplot() rende esplicito che stiamo usando la funzione ggplot() contenuta nel pacchetto ggplot2.","code":"\nmy_graph <- my_data %>% \n  ggplot(aes(x_var, y_var)) +\n  geom_...()"},{"path":"introduzione-al-linguaggio-r.html","id":"diagramma-a-dispersione-1","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.5 Diagramma a dispersione","text":"Consideriamo nuovamenti dati contenuti nel tibble msleep e poniamoci il problema di rappresentare graficamente la relazione tra il numero medio di ore di sonno giornaliero (sleep_total) e il peso dell’animale (bodywt). Usando le impostazioni di default di ggplot2, con le istruzioni seguenti, otteniamo il grafico fornito dalla figura seguente.Coloriamo ora maniera diversa punti che rappresentano animali carnivori, erbivori, ecc.È chiaro, senza fare alcuna analisi statistica, che la relazione tra le due variabili non è lineare. Trasformando maniera logaritmica valori dell’asse \\(x\\) la relazione si linearizza.Infine, aggiustiamo il “tema” del grafico (si noti l’utilizzo di una tavolozza di colori adatta ai daltonici mediante il pacchetto viridis), aggiungiamo le etichette sugli assi e il titolo.La visualizzazione può essere migliorata cambiando le etichette della legenda del grafico. Per fare questo è necessario intervenire sui dati prima di usare ggplot() – per esempio, come abbiamo fatto precedenza con la funzione forcats::fct_recode().","code":"\ndata(\"msleep\")\np <- msleep %>% \n  ggplot(\n    aes(x = bodywt, y = sleep_total)\n  ) +\n  geom_point()\nprint(p)\np <- msleep %>% \n  ggplot(\n    aes(x = bodywt, y = sleep_total, col = vore)\n  ) +\n  geom_point()\nprint(p)\np <- msleep %>% \n  ggplot(\n    aes(x = log(bodywt), y = sleep_total, col = vore)\n  ) +\n  geom_point()\nprint(p)\nlibrary(\"viridis\")\nmsleep %>%\n  ggplot(\n    aes(x = log(bodywt), y = sleep_total, col = vore)\n  ) +\n  geom_point(size = 2, alpha = .8) +\n  labs(\n    x = \"Peso corporeo (log)\",\n    y = \"Ore di sonno\",\n    title = \"Il sonno in 83 specie di mammiferi\",\n    subtitle = \"Un esempio di visualizzazione con ggplot()\",\n    caption = \"Fonte: Savage e West (2007)\"\n  ) +\n  scale_fill_viridis(discrete = TRUE, option = \"viridis\") +\n  theme_minimal() +\n  theme(legend.title = element_blank()) "},{"path":"introduzione-al-linguaggio-r.html","id":"istogramma-1","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.5.1 Istogramma","text":"Creiamo ora un istogramma che rappresenta la distribuzione del (logaritmo del) peso medio del cervello delle 83 specie di mammiferi considerate da Savage West (2007). L’argomento aes(y = ..density..) geom_histogram() produce le frequenze relative. L’opzione di default (senza questo argomento) porta ggplot() rappresentare le frequenze assolute.","code":"\nmsleep %>% \n  ggplot(\n    aes(log(brainwt))\n  ) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Peso del cervello (log)\",\n    y = \"Frequenza relativa\"\n  ) +\n  theme(legend.title = element_blank())"},{"path":"introduzione-al-linguaggio-r.html","id":"scrivere-il-codice-r-con-stile","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.7.6 Scrivere il codice R con stile","text":"Uno stile di programmazione è un insieme di regole per la gestione dell’indentazione dei blocchi di codice, per la creazione dei nomi dei file e delle variabili e per le convenzioni tipografiche che vengono usate. Scrivere il codice R con stile consente di creare listati più leggibili e semplici da modificare, minimizza la possibilità di errore, e consente correzioni e modifiche più rapide. Vi sono molteplici stili di programmazione che possono essere utilizzati dall’utente, anche se è bene attenersi quelle che sono le convenzioni maggiormente diffuse, allo scopo di favorire la comunicazione. ogni caso, l’importante è di essere coerenti, ovvero di adottare le stesse convenzioni tutte le parti del codice che si scrive. Ad esempio, se si sceglie di usare lo stile snake_case per il nome composto di una variabile (es., personality_trait), non è appropriato usare lo stile lower Camel case per un’altra variabile (es., socialStatus). Dato che questo argomento è stato trattato ampiamente varie sedi, mi limito qui rimandare ad uno stile di programmazione molto popolare, quello proposto da Hadley Wickham, il creatore di tidyverse. La soluzione più semplice è quella installare stiler, che è uno RStudio Addin, e formattare il codice maniera automatica utilizzando lo stile proposto da Hadley Wickham. Si possono ottenere informazioni su stiler seguendo questo link.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"flusso-di-lavoro-riproducibile","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8 Flusso di lavoro riproducibile","text":"","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"la-crisi-della-riproducibilità","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.1 La crisi della riproducibilità","text":"“Per il metodo scientifico è essenziale che gli esperimenti siano riproducibili. Vale dire che una persona diversa dallo sperimentatore originale deve essere grado di ottenere gli stessi risultati seguendo lo stesso protocollo sperimentale (Gilbert Chin).” Ma psicologia (e non solo) la riproducibilità è inferiore quanto previsto o desiderato. un famoso studio pubblicato su Science, un ampio gruppo di ricercatori (Open Science Collaboration others 2015) è riuscito replicare solo il 40 per cento circa dei risultati di 100 studi di psicologia cognitiva e sociale pubblicati precedenza. risultati di questo studio, e di molti altri pubblicati seguito, sono stati interpretati modi diversi. La preoccupazione sulla riproducibilità della ricerca è stata espressa mediante l’affermare secondo la quale “la maggior parte dei risultati della ricerca sono falsi” (Ioannidis 2005) oppure mediante l’affermazione secondo cui “dobbiamo apportare modifiche sostanziali al modo cui conduciamo la ricerca” (Cumming 2014). Alcuni ricercatori sono arrivati definire la presente situazione come una “crisi della riproducibilità dei risultati della ricerca”.Il termine “riproducibilità” (o “replicabilità”) è stato definito vari modi. Consideriamo la definizione fornita da Goodman, Fanelli, Ioannidis (2016):la riproducibilità dei metodi “si riferisce al fatto che il ricercatore fornisce dettagli sufficienti sulle procedure e sui dati dello studio modo che le stesse procedure possano … essere replicate esattamente” (pag. 2) con gli stessi dati;la riproducibilità dei metodi “si riferisce al fatto che il ricercatore fornisce dettagli sufficienti sulle procedure e sui dati dello studio modo che le stesse procedure possano … essere replicate esattamente” (pag. 2) con gli stessi dati;la riproducibilità dei risultati “si riferisce ’ottenimento degli stessi risultati dalla conduzione di uno studio indipendente le cui procedure replicano il più esattamente possibile quelle dell’esperimento originale” (pag. 2-3) con dati indipendenti;la riproducibilità dei risultati “si riferisce ’ottenimento degli stessi risultati dalla conduzione di uno studio indipendente le cui procedure replicano il più esattamente possibile quelle dell’esperimento originale” (pag. 2-3) con dati indipendenti;la riproducibilità inferenziale “si riferisce alla possibilità di trarre conclusioni qualitativamente simili da una replica indipendente di uno studio o da una nuova analisi dello studio originale” (pag. 4).la riproducibilità inferenziale “si riferisce alla possibilità di trarre conclusioni qualitativamente simili da una replica indipendente di uno studio o da una nuova analisi dello studio originale” (pag. 4).Per gli scopi presenti, ci focalizzeremo qui sulla riproducibilità dei metodi. Cioè, discuteremo di come R può aiutarci migliorare questo aspetto della riproducibilità. questo capitolo mostreremo come R possa essere utilizzato ’interno di un flusso di lavoro (workflow) riproducibile che integra (1) il codice di analisi dei dati, (2) dati medesimi e (3) il testo della relazione che comunica risultati dello studio. tal fine utilizzeremo due pacchetti R: rmarkdown e knitr. Questi pacchetti consentono di unire il codice R ad un linguaggio di marcatura (o di markup) chiamato Markdown. Il linguaggio di markup Markdown sta diventando sempre più popolare e viene usato, oltre che per creare reports di analisi di dati, anche per creare siti web, blog, libri, articoli accademici, curriculum vitae, slide, tesi di laurea. Per esempio, il presente sito web è stato scritto usando R-markdown.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"r-markdown","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.2 R-markdown","text":"Un linguaggio di markup permette di aggiungere mediante marcatori (tag) informazioni sulla struttura e sulla formattazione da applicare ad un documento. Un’introduzione al linguaggio Markdown può essere trovata, per esempio, qui oppure qui.questo capitolo ci focalizzeremo però sugli aspetti più importanti di R-markdown che permette di costruire documenti cui combinare testo formattato (quindi non solo commenti ma anche formule, titoli etc) e istruzioni codice (R e non solo) con corrispettivi output. Informazioni dettagliate su R-markdown sono disponibili qui e qui.Un file R-markdown è composto da tre tipi di oggetti:header formato YAML delimitato da ---,testo formato markdown,blocchi (“chunks”) di codice R, delimitati da tre apici.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"header","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.2.1 Header","text":"L’intestazione di un documento .Rmd (R-markdown) corrisponde al cosiddetto YAML header (un acronimo che significa Yet Another Markup Language). Lo YAML header controlla le caratteristiche generali del documento, incluso il tipo di documento che viene prodotto (un documento HTML che può essere visualizzato su tutti principali browser, un documento Microsoft Word o un PDF se abbiamo installato LaTeX sul nostro computer), la dimensione del carattere, lo stile, il titolo, l’autore, ecc. Nello YAML header (differenza del codice R) è necessario rispettare la spaziatura prestabilita delle istruzioni che vengono elencate. Gli elementi principali sono title:, author:, output:.L’argomento di output: è dove diciamo R-markdown quale tipo di file vogliamo che venga prodotto. Il tipo più flessibile, che non richiede alcuna configurazione, è html_document.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"testo","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.2.2 Testo","text":"Alla conclusione dello YAML header inizia il documento R-markdown. Da questo punto poi possiamo utilizzare testo normale, codice R e sintassi Markdown per controllare cosa viene mostrato e come.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"formattazione","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.2.3 Formattazione","text":"È possibile contrassegnare intestazioni, grassetto e corsivo come indicato di seguito.","code":"# Intestazione 1\n## Intestazione 2\n### Intestazione 3\n#### Intestazione 4\n##### Intestazione 5\n###### Intestazione 6\n\nQuesto è un testo normale.\nPossiamo scrivere in **grassetto** il testo usando due asterischi.\nPossiamo scrivere in *corsivo* usando un asterisco.\n\n>Questa è un’**area rientrata**.\n\nQuesta riga invece non è più rientrata."},{"path":"introduzione-al-linguaggio-r.html","id":"elenchi","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.2.4 Elenchi","text":"Per creare un elenco puntato si utilizza il segno più, il trattino o l’asterisco. Tutte le tre soluzioni portano allo stesso risultato.Un elenco numerato, invece, si crea con un numero seguito da un punto.","code":"- Punto 1 della lista\n- Punto 2 della lista\n- Punto 3 della lista1. Punto 1 della lista\n2. Punto 2 della lista\n3. Punto 3 della lista"},{"path":"introduzione-al-linguaggio-r.html","id":"hyperlink","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.2.5 Hyperlink","text":"Per inserire un hyperlink ci sono due metodi:specificare solo il percorso <http://rmarkdown.rstudio.com>, http://rmarkdown.rstudio.comcreare un link con [link](http://rmarkdown.rstudio.com)","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"immagini","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.2.6 Immagini","text":"Per inserire un’immagine la sintassi è molto simile: ![Esempio di immagine inserita un documento R-markdown.](images/hex-rmarkdown.png){width=20%}:Esempio di immagine inserita un documento R-markdown.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"codice-inline","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.2.7 Codice inline","text":"Per contrassegnare un’area di testo come codice, markdown utilizza il cosiddetto backtick, noto anche come gravis o accento grave, da non confondere con la virgoletta singola. La marcatura prevede un accento ’inizio e uno alla fine dell’area di testo corrispondente.","code":"Questo è `codice`."},{"path":"introduzione-al-linguaggio-r.html","id":"equazioni","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.2.8 Equazioni","text":"Equazioni possono essere inserite un documento R-markdown usando la sintassi . Qualsiasi cosa ’interno del segno di dollaro $ viene trattata come un’equazione “inline”. Qualunque cosa ’interno di due segni di dollaro $$ viene trattata come un’equazione sé stante.Per esempio, questa è la formula della distribuzione Normale espressa notazione LaTeX e riprodotta ’interno di un documento R-markdown:\\[\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\n  \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right)\n\\]","code":"f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\n  \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right)"},{"path":"introduzione-al-linguaggio-r.html","id":"codice-r","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.2.9 Codice R","text":"un documento R-markdown istruzioni di codice vengono inserite blocchi delimitati da tre apici. Ciò consente di valutare il codice ’interno del documento e di produrre un output che verrà stampato nel documento stesso. Possiamo dunque stampare tabelle e figure prodotti direttamente dal codice R. Ciò significa inoltre, che se qualcosa cambia nei dati o nelle analisi dei dati, le tabelle e le figure si aggiorneranno automaticamente.Un chunk R viene valutato proprio come il normale codice R, quindi si applica tutto ciò che abbiamo imparato nei capitoli precedenti. Se il chunk R produce un output, questo output verrà visualizzato nel documento.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"compilare-la-presentazione-r-markdown","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.8.3 Compilare la presentazione R-markdown","text":"Ma dove si trova questo magico documento che include il testo e l’output prodotto dal codice R? Ottima domanda. Siamo stati abituati ai programmi di videoscrittura (come Microsoft Word) che si conformano al cosiddetto stile “WYSIWYG” (See Get) – cioè, si vede come apparirà il documento stampato mentre lo si digita. Questo può avere alcuni vantaggi ma può anche essere molto limitante. R-Markdown, d’altra parte, funziona modo diverso. Ovvero, deve essere “compilato” (knitted) per passare dal file sorgente al documento formattato. RStudio, tale operazione è semplice: c’è un pulsante alto sinistra nel pannello di scripting di un documento .Rmd. È sufficiente selezionare tale pulsante e il nostro documento verrà creato.È importante notare che il codice del documento deve essere autonomo. Ciò significa che tutto ciò che vogliamo che venga eseguito deve essere incluso nel documento, indipendentemente da ciò che era già stato eseguito al di fuori di esso. Ad esempio, è perfettamente legittimo (e anche molto utile) testare il codice R al di fuori del documento Rmd. Tuttavia, quando compiliamo il documento Rmd, tutto ciò che è stato fatto al di fuori del documento Rmd viene dimenticato. Ciò consente di creare un documento autosufficiente che favorisce la riproducibilità dei metodi di analisi dei dati: utilizzando uno specifico documento Rmd con un campione di dati si giunge sempre allo stesso risultato e alla stessa interpretazione. Ciò non è invece vero se si utilizza un software con un interfaccia point--click.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"dati-mancanti-1","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.9 Dati mancanti","text":"","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"motivazione-1","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.9.1 Motivazione","text":"La pulizia dei dati (data cleaning) R è fondamentale per effettuare qualsiasi analisi. Uno degli aspetti più importanti della pulizia dei dati è la gestione dei dati mancanti. valori mancanti (missing values) vengono indicati dal codice NA, che significa available — non disponibile.","code":""},{"path":"introduzione-al-linguaggio-r.html","id":"trattamento-dei-dati-mancanti","chapter":"Appendice J Introduzione al linguaggio R","heading":"J.9.2 Trattamento dei dati mancanti","text":"Se una variabile contiene valori mancanti, R non è grado di applicare ad essa alcune Funzioni, come ad esempio la media. Per questa ragione, la gran parte delle funzioni di R prevedono modi specifici per trattare valori mancanti.Ci sono diversi tipi di dati “mancanti” R;NA - generico dato mancante;NaN - il codice NaN (Number) indica valori numerici impossibili, quali ad esempio un valore 0/0;Inf e -Inf - Infinity, si verifca, ad esempio, quando si divide un numero per 0.La funzione .na() ritorna un output che indica con TRUE le celle che contengono NA o NaN.Si noti chese .na(x) è TRUE, allora !.na(x) è FALSE;(!.na(x)) ritorna TRUE se tutti valori x sono NA;(.na(x)) risponde alla domanda: c’è qualche valore NA (almeno uno) x?;complete.cases(x) ritorna TRUE se ciascun elemento di x è NA; ritorna FALSE se almeno un elemento di x è NA;Le funzioni R .nan() e .infinite() si applicano ai tipi di dati NaN e Inf.Per esempio, consideriamo il seguente data.frame:Per creare un nuovo Dataframe senza valori mancanti:Oppure, se vogliamo eliminare le righe con NA solo una variabile:Se vogliamo esaminare le righe con dati mancanti qualunque colonna:Spesso valori mancanti vengono sostiuti con valori “ragionevoli”, come ad esempio la media dei valori quella colonna del Dataframe. Oppure, vengono considerati come “ragionevoli” valori che vengono predetti conoscendo le altre variabili del Dataframe. Questa procedura si chiama imputazione multipla. Questo è però un argomento avanzato che non verrà trattato questo insegnamento. La cosa più semplice da fare, presenza di dati mancanti, è semplicemente quella di escludere tutte le righe nelle quali ci sono degli NAs.","code":"\nd <- tibble(\n  w = c(1, 2, NA, 3, NA), \n  x = 1:5, \n  y = 1, \n  z = x ^ 2 + y,\n  q = c(3, NA, 5, 1, 4)\n)\nd\n#> # A tibble: 5 × 5\n#>       w     x     y     z     q\n#>   <dbl> <int> <dbl> <dbl> <dbl>\n#> 1     1     1     1     2     3\n#> 2     2     2     1     5    NA\n#> 3    NA     3     1    10     5\n#> 4     3     4     1    17     1\n#> 5    NA     5     1    26     4\nis.na(d$w)\n#> [1] FALSE FALSE  TRUE FALSE  TRUE\nis.na(d$x)\n#> [1] FALSE FALSE FALSE FALSE FALSE\nd_clean <- d[complete.cases(d), ]\nd_clean\n#> # A tibble: 2 × 5\n#>       w     x     y     z     q\n#>   <dbl> <int> <dbl> <dbl> <dbl>\n#> 1     1     1     1     2     3\n#> 2     3     4     1    17     1\nd1 <- d[!is.na(d$q), ]\nd1\n#> # A tibble: 4 × 5\n#>       w     x     y     z     q\n#>   <dbl> <int> <dbl> <dbl> <dbl>\n#> 1     1     1     1     2     3\n#> 2    NA     3     1    10     5\n#> 3     3     4     1    17     1\n#> 4    NA     5     1    26     4\nd_na <- d[!complete.cases(d), ]\nd_na\n#> # A tibble: 3 × 5\n#>       w     x     y     z     q\n#>   <dbl> <int> <dbl> <dbl> <dbl>\n#> 1     2     2     1     5    NA\n#> 2    NA     3     1    10     5\n#> 3    NA     5     1    26     4"}]
